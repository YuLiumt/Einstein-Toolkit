{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Content Einstein Toolkit: Introduction Install Cactus Thorn Source File Parameter Visualization General Relativity: Differential geometry Einstein Equation Solutions Gravitational Wave: Introduction Linearized Waves Extracting Gravitational Waveforms Numerical Relativity: Introduction 3+1 Decomposition ADM BSSN Conformal Transformation Coordinates Matter Sources Numerical Methods Search Pipeline: Introduction Matched Filtering Example: Poisson","title":"Home"},{"location":"#content","text":"Einstein Toolkit: Introduction Install Cactus Thorn Source File Parameter Visualization General Relativity: Differential geometry Einstein Equation Solutions Gravitational Wave: Introduction Linearized Waves Extracting Gravitational Waveforms Numerical Relativity: Introduction 3+1 Decomposition ADM BSSN Conformal Transformation Coordinates Matter Sources Numerical Methods Search Pipeline: Introduction Matched Filtering Example: Poisson","title":"Content"},{"location":"ET/Cactus/","text":"Program Flow Cactus executables always run from a parameter file, which specifies which thorns to use and sets the values of each thorn\u2019s parameters (the parameters that are not set will take on default values). There is no restriction on the name of the parameter file, although it is conventional to use the file extension .par . A parameter file is a text file whose lines are either comments or parameter statements. Comments are blank lines or lines that begin with \u2018#\u2019. A parameter statement consists of one or more parameter names, followed by an \u2018=\u2019, followed by the value(s) for this (these) parameter(s). The first parameter statement in any parameter file should set ActiveThorns, which is a special parameter that tells the program which thorns are to be activated. Only parameters from active thorns can be set (and only those routines scheduled by active thorns are run). By default all thorns are inactive. For example, 1 ActiveThorns = \"CartGrid3D\" Parameter specifications following ActiveThorns usually are carried out by listing the name of the thorn which defined the parameter, two colons, and the name of the parameter 1 wavetoyF77::amplitude Screen output As your Cactus executable runs, standard output and standard error are usually written to the screen. Standard output provides you with information about the run, and standard error reports warnings and errors from the flesh and thorns. As the program runs, the normal output provides the following information: Active thorns: This report shows whether the thorn activation was successful, and if successful gives the thorn\u2019s implementation. Failed parameters: If any of the parameters in the parameter file does not belong to any of the active thorns, or if the parameter value is not in the allowed range, an error is registered. For example, 1 2 3 4 5 Activating thorn idscalarwave...Success -> active implementation idscalarwave # if the parameter is not recognised Unknown parameter time::ddtfac # if the parameter value is not in the allowed range Unable to set keyword CartGrid3D::type - ByMouth not in any active range Checkpointing Checkpointing is defined as saving the current state of a run to a file. At a later time, this run can then be restarted from that state by recovering all the data from the checkpoint file. Cactus checkpointing and recovery methods are provided by thorns. In general, these thorns decide how often to generate a checkpoint. Parameter File Syntax A parameter file (or par file) is used to control the behaviour of a Cactus executable. A parameter statement is an expression of the form Left-Hand-Side = Right-Hand-Side . The Left-Hand-Side may be a fully qualified parameter name. The Right-Hand-Side is a value. Values can be any of the following Booleans : Booleans are either true (i.e. 1, true, on, \"true\", or \"on\") or false (i.e. 0, false, off, \"false\", or \"off\"). Integers : Integers can be positive or negative. Real numbers : Real numbers can be positive or negative and may be written with exponents (e.g. 1.0e-3, or -2.94d+10). Strings : Sequences of characters delimited by quotes. Variables : Parameter values can also contain variables of the form ${ VARIABLE } or $ENV{VARIABLE} . Expressions : Parameters statements of numeric or boolean type can use arithmetic expressions in place of explicit values. Array assignments : Arrays of parameters can be set by including an integer expression inside the square brackets following the name, e.g. thorn::parameters[0] . Optionally, an array of parameters may be set by means of a comma delimited list of values inside square brackets, e.g. thorn::parameters = [4.8, 3.2] . Please see the file par.peg in the directory Cactus/src/piraha/pegs for the full grammar describing the par file. The parameter file is read sequentially from top to bottom, this means that if you set the value of a parameter twice in the parameter file, the second value will be used. Note You can obtain lists of the parameters associated with each thorn using the command-line options. -O : Prints a full list of all parameters from all thorns which were compiled, along with descriptions and allowed values. -o : Prints the description and allowed values for a given parameter\u2014takes one argument. Cactus Application Interfaces Iterating Over Grid Points A grid function consists of a multi-dimensional array of grid points. These grid points fall into several types: interior: regular grid point, presumably evolved in time ghost: inter-process boundary, containing copies of values owned by another process physical boundary: outer boundary, presumably defined via a boundary condition symmetry boundary: defined via a symmetry, e.g. a reflection symmetry or periodicity Grid points in the edges and corners may combine several types. For example, a point in a corner may be a ghost point in the x direction, a physical boundary point in the y direction, and a symmetry point in the z direction. The size of the physical boundary depends on the application. The number of ghost points is defined by the driver; the number of symmetry points is in principle defined by the thorn implementing the respective symmetry condition, but will in general be the same as the number of ghost points to avoid inconsistencies. Note When iterating over grid points, one usually needs to know about the boundary sizes and boundary types present. The flesh provides a set of macros to iterate over particular types of grid points: CCTK_LOOP_ALL: Loop over all grid points CCTK_LOOP_INT: Loop over all interior grid points CCTK_LOOP_BND: Loop over all physical boundary points CCTK_LOOP_INTBND: Loop over all \u201cinterior\u201d physical boundary points, i.e. over all those physical boundary points that are not also ghost or symmetry points As described above, points on edges and corners can have several boundary types at once, e.g. can be both a physical and a symmetry point. LOOP_BND and LOOP_INTBND treat these different: LOOP_BND loops over all points that are physical boundaries (independent of whether they also are symmetry or ghost boundaries), while LOOP_INTBND loops over those points that are only physical boundaries (and excludes any points that belongs to a symmetry or ghost boundary). LOOP_BND does not require applying a symmetry condition or synchronisation afterwards (but does not allow taking tangential derivatives); LOOP_INTBND allows taking tangential derivatives (but requires applying symmetry boundaries and synchronising afterwards). Coordinates The flesh provides utility routines for registering and querying coordinate information. The flesh does not provide any coordinates itself, these must be supplied by a thorn. Thorns are not required to register coordinates to the flesh, but registering coordinates provides a means for infrastructure thorns to make use of coordinate information. I/O To allow flexible I/O, the flesh itself does not provide any output routines, however it provides a mechanism for thorns to register different routines as I/O methods. Interpolation Operators The flesh does not provide interpolation routines by itself. Instead, it offers a general function API to thorns, for the registration and invocation of interpolation operators. Reduction Operators A reduction operation can be defined as an operation on variables distributed across multiple processor resulting in a single number. Typical reduction operations are: sum, minimum/maximum value, and boolean operations. A typical application is, for example, finding the maximum reduction from processor local error estimates, therefore, making the previous processor local error known to all processors.","title":"Cactus"},{"location":"ET/Cactus/#parameter-file-syntax","text":"A parameter file (or par file) is used to control the behaviour of a Cactus executable. A parameter statement is an expression of the form Left-Hand-Side = Right-Hand-Side . The Left-Hand-Side may be a fully qualified parameter name. The Right-Hand-Side is a value. Values can be any of the following Booleans : Booleans are either true (i.e. 1, true, on, \"true\", or \"on\") or false (i.e. 0, false, off, \"false\", or \"off\"). Integers : Integers can be positive or negative. Real numbers : Real numbers can be positive or negative and may be written with exponents (e.g. 1.0e-3, or -2.94d+10). Strings : Sequences of characters delimited by quotes. Variables : Parameter values can also contain variables of the form ${ VARIABLE } or $ENV{VARIABLE} . Expressions : Parameters statements of numeric or boolean type can use arithmetic expressions in place of explicit values. Array assignments : Arrays of parameters can be set by including an integer expression inside the square brackets following the name, e.g. thorn::parameters[0] . Optionally, an array of parameters may be set by means of a comma delimited list of values inside square brackets, e.g. thorn::parameters = [4.8, 3.2] . Please see the file par.peg in the directory Cactus/src/piraha/pegs for the full grammar describing the par file. The parameter file is read sequentially from top to bottom, this means that if you set the value of a parameter twice in the parameter file, the second value will be used. Note You can obtain lists of the parameters associated with each thorn using the command-line options. -O : Prints a full list of all parameters from all thorns which were compiled, along with descriptions and allowed values. -o : Prints the description and allowed values for a given parameter\u2014takes one argument.","title":"Parameter File Syntax"},{"location":"ET/Cactus/#cactus-application-interfaces","text":"","title":"Cactus Application Interfaces"},{"location":"ET/Cactus/#iterating-over-grid-points","text":"A grid function consists of a multi-dimensional array of grid points. These grid points fall into several types: interior: regular grid point, presumably evolved in time ghost: inter-process boundary, containing copies of values owned by another process physical boundary: outer boundary, presumably defined via a boundary condition symmetry boundary: defined via a symmetry, e.g. a reflection symmetry or periodicity Grid points in the edges and corners may combine several types. For example, a point in a corner may be a ghost point in the x direction, a physical boundary point in the y direction, and a symmetry point in the z direction. The size of the physical boundary depends on the application. The number of ghost points is defined by the driver; the number of symmetry points is in principle defined by the thorn implementing the respective symmetry condition, but will in general be the same as the number of ghost points to avoid inconsistencies. Note When iterating over grid points, one usually needs to know about the boundary sizes and boundary types present. The flesh provides a set of macros to iterate over particular types of grid points: CCTK_LOOP_ALL: Loop over all grid points CCTK_LOOP_INT: Loop over all interior grid points CCTK_LOOP_BND: Loop over all physical boundary points CCTK_LOOP_INTBND: Loop over all \u201cinterior\u201d physical boundary points, i.e. over all those physical boundary points that are not also ghost or symmetry points As described above, points on edges and corners can have several boundary types at once, e.g. can be both a physical and a symmetry point. LOOP_BND and LOOP_INTBND treat these different: LOOP_BND loops over all points that are physical boundaries (independent of whether they also are symmetry or ghost boundaries), while LOOP_INTBND loops over those points that are only physical boundaries (and excludes any points that belongs to a symmetry or ghost boundary). LOOP_BND does not require applying a symmetry condition or synchronisation afterwards (but does not allow taking tangential derivatives); LOOP_INTBND allows taking tangential derivatives (but requires applying symmetry boundaries and synchronising afterwards).","title":"Iterating Over Grid Points"},{"location":"ET/Cactus/#coordinates","text":"The flesh provides utility routines for registering and querying coordinate information. The flesh does not provide any coordinates itself, these must be supplied by a thorn. Thorns are not required to register coordinates to the flesh, but registering coordinates provides a means for infrastructure thorns to make use of coordinate information.","title":"Coordinates"},{"location":"ET/Cactus/#io","text":"To allow flexible I/O, the flesh itself does not provide any output routines, however it provides a mechanism for thorns to register different routines as I/O methods.","title":"I/O"},{"location":"ET/Cactus/#interpolation-operators","text":"The flesh does not provide interpolation routines by itself. Instead, it offers a general function API to thorns, for the registration and invocation of interpolation operators.","title":"Interpolation Operators"},{"location":"ET/Cactus/#reduction-operators","text":"A reduction operation can be defined as an operation on variables distributed across multiple processor resulting in a single number. Typical reduction operations are: sum, minimum/maximum value, and boolean operations. A typical application is, for example, finding the maximum reduction from processor local error estimates, therefore, making the previous processor local error known to all processors.","title":"Reduction Operators"},{"location":"ET/Install/","text":"Required Software 1 2 3 4 5 6 7 8 9 10 # Debian (stretch, buster) su -c 'apt-get install build-essential pkg-config libopenmpi-dev openmpi-bin gfortran git subversion curl gnuplot gnuplot-x11' # Ubuntu (16.04.2, 17.04, 17.10) sudo apt-get install build-essential pkg-config mpich2? python libmpich2?-dev gfortran git subversion curl gnuplot gnuplot-x11 # Fedora (FC 25, 27) su -c ' yum -y install mpich2 python pkg-config mpich2-devel gsl gsl-devel libjpeg-devel hdf5 hdf5-mpich-devel gcc gcc-c++ gcc-gfortran patch numactl-devel numactl hwloc subversion git openssl-devel lapack-static gnuplot' # Mac OS (High Sierra), MacPorts sudo port -N install pkgconfig gcc8 openmpi fftw-3 gsl jpeg zlib hdf5 +fortran +gfortran openssl # Mac OS (High Sierra), Homebrew brew install gnuplot pkg-config gcc fftw gsl hdf5 --with-fortran hwloc jpeg openssl pkg-config szip open-mpi Prepare Tools A script called GetComponents is used to fetch the components of the Einstein Toolkit. You may download and make it executable it as follows: 1 2 3 cd ~/ curl -O -L https://raw.githubusercontent.com/gridaphobe/CRL/ET_2018_09/GetComponents chmod u+x GetComponents Below checks out Cactus, the Einstein Toolkit thorns, the Simulation Factory and example parameter files into a directory named Cactus. 1 ./GetComponents --parallel https://bitbucket.org/einsteintoolkit/manifest/raw/ET_2018_09/einsteintoolkit.th Warning Some versions of svn might show problems with the parallel checkout. If you see errors like (svn: E155037: Previous operation has not finished), try without the --parallel option. 1 ./GetComponents [options] [URL] Option Discribe \u2212\u2212help brief help message \u2212\u2212man full documentation \u2212\u2212verbose print all system commands as they are executed \u2212\u2212debug print all commands to be executed and exit \u2212\u2212anonymous use anonymous checkout for all components \u2212\u2212update process all updates \u2212\u2212root override root directory Configuring SimFactory for your machine Edit simfactory/etc/defs.local.ini . SimFactory also contains general support for specific operating systems commonly used on workstations or laptops, including Mac OS, Ubuntu, Cent OS and Scientific Linux. To configure SimFactory for one of these, you need to find the suitable files in simfactory/mdb/optionlists and simfactory/mdb/runscripts and specify their names on the sim setup command line. 1 2 3 4 5 6 7 8 9 10 11 # for Debian ./simfactory/bin/sim setup-silent --optionlist=debian.cfg --runscript debian.sh # for Ubuntu, Mint ./simfactory/bin/sim setup-silent --optionlist=ubuntu.cfg --runscript debian.sh # for Fedora (you may have to log out and back in if you have just intalled mpich to make the module command work) module load mpi ./simfactory/bin/sim setup-silent --optionlist=fedora.cfg --runscript debian.sh # OSX+MacPorts ./simfactory/bin/sim setup-silent --optionlist=osx-macports.cfg --runscript osx-macports.run # OSX+Homebrew ./simfactory/bin/sim setup-silent --optionlist=osx-homebrew.cfg --runscript generic-mpi.run After this step is complete you will find your machine's default setup under ./repos/simfactory2/mdb/machines/<hostname>.ini Note The main SimFactory binary is called \u201csim\u201d and is located in simfactory/bin . You can execute SimFactory explicitly as ./simfactory/bin/sim , but we recommend that you set up a shell alias in your shell startup file so that you can just use the command \u201csim\u201d. For bash users this file is .bashrc on Linux. Add the following to the shell startup file: 1 alias sim=./simfactory/bin/sim Building the Einstein Toolkit Assuming that SimFactory has been successfully set up on your machine, you should be able to build the Einstein Toolkit with 1 ./simfactory/bin/sim build --mdbkey make 'make -j2' --thornlist ../einsteintoolkit.th | cat Running 1 ./simfactory/bin/sim command [ options ] SimFactory needs to know a name for the simulation as well as what parameter file to use. You can either specify the name on the command line and give the parameter file with the --parfile option. For example 1 ./simfactory/bin/sim create-run <Simulation name> --parfile /Users/yuliu/Desktop/work/yuliu/CactusPar/<name.par> --procs=120 --walltime=8:0:0 1 ./simfactory/bin/sim create-run static_tov --parfile=par/static_tov_small_short.par --procs=2 --num-threads=1 --ppn-used=2 --walltime=8:0:0 | cat","title":"Install"},{"location":"ET/Install/#prepare-tools","text":"A script called GetComponents is used to fetch the components of the Einstein Toolkit. You may download and make it executable it as follows: 1 2 3 cd ~/ curl -O -L https://raw.githubusercontent.com/gridaphobe/CRL/ET_2018_09/GetComponents chmod u+x GetComponents Below checks out Cactus, the Einstein Toolkit thorns, the Simulation Factory and example parameter files into a directory named Cactus. 1 ./GetComponents --parallel https://bitbucket.org/einsteintoolkit/manifest/raw/ET_2018_09/einsteintoolkit.th Warning Some versions of svn might show problems with the parallel checkout. If you see errors like (svn: E155037: Previous operation has not finished), try without the --parallel option. 1 ./GetComponents [options] [URL] Option Discribe \u2212\u2212help brief help message \u2212\u2212man full documentation \u2212\u2212verbose print all system commands as they are executed \u2212\u2212debug print all commands to be executed and exit \u2212\u2212anonymous use anonymous checkout for all components \u2212\u2212update process all updates \u2212\u2212root override root directory","title":"Prepare Tools"},{"location":"ET/Install/#configuring-simfactory-for-your-machine","text":"Edit simfactory/etc/defs.local.ini . SimFactory also contains general support for specific operating systems commonly used on workstations or laptops, including Mac OS, Ubuntu, Cent OS and Scientific Linux. To configure SimFactory for one of these, you need to find the suitable files in simfactory/mdb/optionlists and simfactory/mdb/runscripts and specify their names on the sim setup command line. 1 2 3 4 5 6 7 8 9 10 11 # for Debian ./simfactory/bin/sim setup-silent --optionlist=debian.cfg --runscript debian.sh # for Ubuntu, Mint ./simfactory/bin/sim setup-silent --optionlist=ubuntu.cfg --runscript debian.sh # for Fedora (you may have to log out and back in if you have just intalled mpich to make the module command work) module load mpi ./simfactory/bin/sim setup-silent --optionlist=fedora.cfg --runscript debian.sh # OSX+MacPorts ./simfactory/bin/sim setup-silent --optionlist=osx-macports.cfg --runscript osx-macports.run # OSX+Homebrew ./simfactory/bin/sim setup-silent --optionlist=osx-homebrew.cfg --runscript generic-mpi.run After this step is complete you will find your machine's default setup under ./repos/simfactory2/mdb/machines/<hostname>.ini Note The main SimFactory binary is called \u201csim\u201d and is located in simfactory/bin . You can execute SimFactory explicitly as ./simfactory/bin/sim , but we recommend that you set up a shell alias in your shell startup file so that you can just use the command \u201csim\u201d. For bash users this file is .bashrc on Linux. Add the following to the shell startup file: 1 alias sim=./simfactory/bin/sim","title":"Configuring SimFactory for your machine"},{"location":"ET/Install/#building-the-einstein-toolkit","text":"Assuming that SimFactory has been successfully set up on your machine, you should be able to build the Einstein Toolkit with 1 ./simfactory/bin/sim build --mdbkey make 'make -j2' --thornlist ../einsteintoolkit.th | cat","title":"Building the Einstein Toolkit"},{"location":"ET/Install/#running","text":"1 ./simfactory/bin/sim command [ options ] SimFactory needs to know a name for the simulation as well as what parameter file to use. You can either specify the name on the command line and give the parameter file with the --parfile option. For example 1 ./simfactory/bin/sim create-run <Simulation name> --parfile /Users/yuliu/Desktop/work/yuliu/CactusPar/<name.par> --procs=120 --walltime=8:0:0 1 ./simfactory/bin/sim create-run static_tov --parfile=par/static_tov_small_short.par --procs=2 --num-threads=1 --ppn-used=2 --walltime=8:0:0 | cat","title":"Running"},{"location":"ET/Introduction/","text":"Cactus components (called thorns) interact with the framework (called the flesh) via a set of configuration (CCL) files provided by each thorn. The Cactus API supports C/C++ and F77/F90 programming languages for the thorns. This makes it easier for scientists to turn existing codes into thorns which can then make use of the complete Cactus infrastructure, and in turn be used by other thorns within Cactus. The Einstein Toolkit is a community-driven software platform of core computational tools to advance and support research in relativistic astrophysics and gravitational physics. Glossary Name Describe alias function function aliasing. AMR Automatic Mesh Refinement API Applications Programming Interface, the interface provided by some software component to programmers who use the component. An API usually consists of subroutine/function calls, but may also include structure definitions and definition of constant values. The Cactus Reference Manual documents most of the Cactus flesh APIs. arrangement A collection of thorns, stored in a subdirectory of the Cactus arrangements directory. autoconf A GNU program which builds a configuration script which can be used to make a Makefile. boundary zone A boundary zone is a set of points at the edge of a grid, interpreted as the boundary of the physical problem, and which contains boundary data. CCTK Cactus Computational Tool Kit (The Cactus flesh and computational thorns). CCL The Cactus Configuration Language, this is the language that the thorn configuration files are written in. configuration The combination of a set of thorns, and all the Cactus configure options which affect what binary will be produced when compiling Cactus. checkout Get a copy of source code from SVN. checkpoint Save the entire state of a Cactus run to a file, so that the run can be restarted at a later time. computational grid A discrete finite set of spatial points in \\mathfrak{R}^{n} \\mathfrak{R}^{n} (typically, 1 \\leq n \\leq 3 1 \\leq n \\leq 3 ). Historically, Cactus has required these points to be uniformly spaced (uniformly spaced grid), but now, Cactus supports non-uniform spacings (non-uniformly spaced grid), and mesh refinement. The grid consists of the physical domain and the boundary and symmetry points. CST The Cactus Specification Tool, which is the set of Perl scripts which parse the thorns\u2019 .ccl files, and generates the code that binds the thorn source files with the flesh. SVN Subversion is the favoured code distribution system for Cactus. domain decomposition The technique of breaking up a large computational problem into parts that are easier to solve. In Cactus, it refers especially to a decomposition wherein the parts are solved in parallel on separate computer processors. driver A special kind of thorn which creates and handles grid hierarchies and grid variables. Drivers are responsible for memory management for grid variables, and for all parallel operations, in response to requests from the scheduler. evolution An iteration interpreted as a step through time. Also, a particular Cactus schedule bin for executing routines when evolution occurs. flesh The Cactus routines which hold the thorns together, allowing them to communicate and scheduling things to happen with them. friend Interfaces that are friends, share their collective set of protected grid variables. function aliasing The process of referring to a function to be provided by an interface independently of which thorn actually contains the function, or what language the function is written in. The function is called an alias function. GA Shorthand for a grid array. GF Shorthand for a grid function. gmake GNU version of the make utility. ghost zone A set of points added for parallelisation purposes to a block of a grid lying on one processor, corresponding to points on the boundary of an adjoining block of the grid lying on another processor. Points from the boundary of the one block are copied (via an inter-processor communication mechanism) during synchronisation to the corresponding ghost zone of the other block, and vice versa. In single processor runs there are no ghost zones. grid Short for computational grid. grid array A grid variable whose global size need not be that of the computational grid; instead, the size is declared explicitly in an interface.ccl file. grid function A grid variable whose global size is the size of the computational grid. From another perspective, grid functions are functions defined on the domain of grid points. Typically, grid functions are used to discretely approximate functions defined on the domain R^n R^n , with finite differencing used to approximate partial derivatives. grid hierarchy A computational grid, and the grid variables associated with it. grid point A spatial point in the computational grid. grid scalar A grid variable with index zero, i.e. just a number on each processor. grid variable A variable which is passed through the flesh interface, either between thorns or between routines of the same thorn. This implies the variable is related to the computational grid, as opposed to being an internal variable of the thorn or one of its routines. grid scalar, grid function, and grid array are all examples of grid variables. GNATS The GNU program we use for reporting and tracking bugs, comments and suggestions. GNU GNU\u2019s Not Unix: a freely-distributable code project. GV Shorthand for grid variable. handle A signed integer value >= 0 passed by many Cactus routines and used to represent a dynamic data or code object. implementation Defines the interface that a thorn presents to the rest of a Cactus program. inherit A thorn that inherits from another implementation can access all the other implementation\u2019s public variables. interpolation Given a set of grid variables and interpolation points (points in the grid coordinate space, which are typically distinct from the grid points), interpolation is the act of producing values for the grid variables at each interpolation point over the entire grid hierarchy. local array An array that is declared in thorn code, but not declared in the thorn\u2019s interface.ccl , as opposed to a grid array. local interpolation Given a set of grid variables and interpolation points (points in the grid coordinate space ,which are typically distinct from the grid points), interpolation is the act of producing values for the grid variables at each interpolation point on a particular grid. NUL character The C programming language uses a \u201cNUL character\u201d to terminate character strings. A NUL character has the integer value zero, but it\u2019s useful to write it as \u2019\\0\u2019, to emphasize to human readers that this has type char rather than int. null pointer, NULL pointer C defines a \u201cnull pointer\u201d, often (slightly incorrectly) called a \u201cNULL pointer\u201d, which is guaranteed not to point to any object. You get a null pointer by converting the integer constant 0 to a pointer type, e.g. int* ptr = 0; . parallelisation The process of utilising multiple computer processors to work on different parts of a computational problem at the same time, in order to obtain a solution of the problem more quickly. Cactus achieves parallelisation by means of domain decomposition. parameter A variable that controls the run time behaviour of the Cactus executable. Parameters have default values which can be set in a parameter file. parameter file Also called par file.) A text file used as the input of a Cactus program, specifying initial values of thorn parameters. PUGH The default driver thorn for Cactus which uses MPI. PVM Parallel Virtual Machine, provides interprocessor communication. reduction Given a set of grid variables on a computational grid, reduction is the process of producing values for the variables on a proper subset of points from the grid. scheduler The part of the Cactus flesh that determines the order and circumstances in which to execute Cactus routines. Thorn functions and schedule groups are registered with the flesh via the thorn\u2019s schedule.ccl file to be executed in a certain schedule bin, before or after another function or group executes, and so forth. schedule bin One of a set of special timebins pre-defined by Cactus. schedule group A timebin defined by a thorn, in its schedule.ccl file. Each schedule group must be defined to occur in a Cactus schedule bin or another schedule group. shares An implementation may share restricted parameters with another implementation, which means the other implementation can get the parameter values, and if the parameters are steerable, it can change them. steerable parameter A parameter which can be changed at any time after the program has been initialised. symmetry operation A grid operation that is a manifestation of a geometrical symmetry, especially rotation or reflection. symmetry zone A set of points laying at the edge of the computational grid and containing data obtained by some symmetry operation from another part of the same grid. synchronisation The process of copying information from the outer part of a computational interior on one processor to the corresponding ghost zone (see) on another processor. Also refers to a special Cactus timebin corresponding to the occurrence of this process. thorn A collection of subroutines defining a Cactus interface. ThornList A file used by the Cactus CST to determine which thorns to compile into a Cactus executable. Can also be used to determine which thorns to check out from SVN. time bin A time interval in the duration of a Cactus run wherein the flesh runs specified routines. See scheduler, schedule bin.","title":"Introduction"},{"location":"ET/Introduction/#glossary","text":"Name Describe alias function function aliasing. AMR Automatic Mesh Refinement API Applications Programming Interface, the interface provided by some software component to programmers who use the component. An API usually consists of subroutine/function calls, but may also include structure definitions and definition of constant values. The Cactus Reference Manual documents most of the Cactus flesh APIs. arrangement A collection of thorns, stored in a subdirectory of the Cactus arrangements directory. autoconf A GNU program which builds a configuration script which can be used to make a Makefile. boundary zone A boundary zone is a set of points at the edge of a grid, interpreted as the boundary of the physical problem, and which contains boundary data. CCTK Cactus Computational Tool Kit (The Cactus flesh and computational thorns). CCL The Cactus Configuration Language, this is the language that the thorn configuration files are written in. configuration The combination of a set of thorns, and all the Cactus configure options which affect what binary will be produced when compiling Cactus. checkout Get a copy of source code from SVN. checkpoint Save the entire state of a Cactus run to a file, so that the run can be restarted at a later time. computational grid A discrete finite set of spatial points in \\mathfrak{R}^{n} \\mathfrak{R}^{n} (typically, 1 \\leq n \\leq 3 1 \\leq n \\leq 3 ). Historically, Cactus has required these points to be uniformly spaced (uniformly spaced grid), but now, Cactus supports non-uniform spacings (non-uniformly spaced grid), and mesh refinement. The grid consists of the physical domain and the boundary and symmetry points. CST The Cactus Specification Tool, which is the set of Perl scripts which parse the thorns\u2019 .ccl files, and generates the code that binds the thorn source files with the flesh. SVN Subversion is the favoured code distribution system for Cactus. domain decomposition The technique of breaking up a large computational problem into parts that are easier to solve. In Cactus, it refers especially to a decomposition wherein the parts are solved in parallel on separate computer processors. driver A special kind of thorn which creates and handles grid hierarchies and grid variables. Drivers are responsible for memory management for grid variables, and for all parallel operations, in response to requests from the scheduler. evolution An iteration interpreted as a step through time. Also, a particular Cactus schedule bin for executing routines when evolution occurs. flesh The Cactus routines which hold the thorns together, allowing them to communicate and scheduling things to happen with them. friend Interfaces that are friends, share their collective set of protected grid variables. function aliasing The process of referring to a function to be provided by an interface independently of which thorn actually contains the function, or what language the function is written in. The function is called an alias function. GA Shorthand for a grid array. GF Shorthand for a grid function. gmake GNU version of the make utility. ghost zone A set of points added for parallelisation purposes to a block of a grid lying on one processor, corresponding to points on the boundary of an adjoining block of the grid lying on another processor. Points from the boundary of the one block are copied (via an inter-processor communication mechanism) during synchronisation to the corresponding ghost zone of the other block, and vice versa. In single processor runs there are no ghost zones. grid Short for computational grid. grid array A grid variable whose global size need not be that of the computational grid; instead, the size is declared explicitly in an interface.ccl file. grid function A grid variable whose global size is the size of the computational grid. From another perspective, grid functions are functions defined on the domain of grid points. Typically, grid functions are used to discretely approximate functions defined on the domain R^n R^n , with finite differencing used to approximate partial derivatives. grid hierarchy A computational grid, and the grid variables associated with it. grid point A spatial point in the computational grid. grid scalar A grid variable with index zero, i.e. just a number on each processor. grid variable A variable which is passed through the flesh interface, either between thorns or between routines of the same thorn. This implies the variable is related to the computational grid, as opposed to being an internal variable of the thorn or one of its routines. grid scalar, grid function, and grid array are all examples of grid variables. GNATS The GNU program we use for reporting and tracking bugs, comments and suggestions. GNU GNU\u2019s Not Unix: a freely-distributable code project. GV Shorthand for grid variable. handle A signed integer value >= 0 passed by many Cactus routines and used to represent a dynamic data or code object. implementation Defines the interface that a thorn presents to the rest of a Cactus program. inherit A thorn that inherits from another implementation can access all the other implementation\u2019s public variables. interpolation Given a set of grid variables and interpolation points (points in the grid coordinate space, which are typically distinct from the grid points), interpolation is the act of producing values for the grid variables at each interpolation point over the entire grid hierarchy. local array An array that is declared in thorn code, but not declared in the thorn\u2019s interface.ccl , as opposed to a grid array. local interpolation Given a set of grid variables and interpolation points (points in the grid coordinate space ,which are typically distinct from the grid points), interpolation is the act of producing values for the grid variables at each interpolation point on a particular grid. NUL character The C programming language uses a \u201cNUL character\u201d to terminate character strings. A NUL character has the integer value zero, but it\u2019s useful to write it as \u2019\\0\u2019, to emphasize to human readers that this has type char rather than int. null pointer, NULL pointer C defines a \u201cnull pointer\u201d, often (slightly incorrectly) called a \u201cNULL pointer\u201d, which is guaranteed not to point to any object. You get a null pointer by converting the integer constant 0 to a pointer type, e.g. int* ptr = 0; . parallelisation The process of utilising multiple computer processors to work on different parts of a computational problem at the same time, in order to obtain a solution of the problem more quickly. Cactus achieves parallelisation by means of domain decomposition. parameter A variable that controls the run time behaviour of the Cactus executable. Parameters have default values which can be set in a parameter file. parameter file Also called par file.) A text file used as the input of a Cactus program, specifying initial values of thorn parameters. PUGH The default driver thorn for Cactus which uses MPI. PVM Parallel Virtual Machine, provides interprocessor communication. reduction Given a set of grid variables on a computational grid, reduction is the process of producing values for the variables on a proper subset of points from the grid. scheduler The part of the Cactus flesh that determines the order and circumstances in which to execute Cactus routines. Thorn functions and schedule groups are registered with the flesh via the thorn\u2019s schedule.ccl file to be executed in a certain schedule bin, before or after another function or group executes, and so forth. schedule bin One of a set of special timebins pre-defined by Cactus. schedule group A timebin defined by a thorn, in its schedule.ccl file. Each schedule group must be defined to occur in a Cactus schedule bin or another schedule group. shares An implementation may share restricted parameters with another implementation, which means the other implementation can get the parameter values, and if the parameters are steerable, it can change them. steerable parameter A parameter which can be changed at any time after the program has been initialised. symmetry operation A grid operation that is a manifestation of a geometrical symmetry, especially rotation or reflection. symmetry zone A set of points laying at the edge of the computational grid and containing data obtained by some symmetry operation from another part of the same grid. synchronisation The process of copying information from the outer part of a computational interior on one processor to the corresponding ghost zone (see) on another processor. Also refers to a special Cactus timebin corresponding to the occurrence of this process. thorn A collection of subroutines defining a Cactus interface. ThornList A file used by the Cactus CST to determine which thorns to compile into a Cactus executable. Can also be used to determine which thorns to check out from SVN. time bin A time interval in the duration of a Cactus run wherein the flesh runs specified routines. See scheduler, schedule bin.","title":"Glossary"},{"location":"ET/Lorene/","text":"LORENE is a set of C++ classes to solve various problems arising in numerical relativity, and more generally in computational astrophysics. It provides tools to solve partial differential equations by means of multi-domain spectral methods. The online service CompOSE provides data tables for different state of the art equations of state (EoS) ready for further usage in astrophysical applications, nuclear physics and beyond. The cold neutron star EoS tables can be used directly within LORENE to obtain models of (rotating/magnetised) neutron stars.","title":"Lorene"},{"location":"ET/Source File/","text":"The make system uses file extensions to designate coding language, as well as other properties of the code in the file. In order to use Cactus #include directives in a file, it must be preprocessed. Adding Source Files By default, the CCTK looks in the src directory of the thorn for source files. There are two ways in which to specify the sources. The easiest is to use the make.code.defn based method in which the CCTK does all the work, but you may instead put a Makefile in the src directory and do everything yourself. The Cactus make system looks for a file called make.code.defn in that directory (if there is no file called Makefile in the src directory). At its simplest, this file contains two lines 1 2 SRCS = <list of all source files in this directory> SUBDIRS = <list of all subdirectories, including subdirectories of subdirectories> Each subdirectory listed should then have a make.code.defn file containing just a SRCS = line, a SUBDIRS = line will be ignored. Coding Style Indentation: Two spaces, no tabs. Brace positioning: 1 2 3 4 do { <statement> } while(); GRDOC: All files should start with a grdoc header, and all functions should have grdoc headers. The function grdoc should contain a description of the function, saying what it does. the functions called by this function. all function arguments with descriptions of what they are and what they are used for. the return codes should be described. The standard grdoc function header is of the form 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /*@@ @routine Template @date Fri Oct 6 10:51:49 2000 @author Yu Liu @desc An example of grdoc @enddesc @calls templatefunc2 @calledby @history @endhistory @var templatestring @vdesc string describing foobar @vtype const char * @vio in @vcomment @endvar @returntype int * @returndesc 0 - success @endreturndesc @@*/ Header Files: 1 2 3 4 5 6 7 8 9 #ifndef <Name of Header File in Capitals> #define <Name of Header File in Capitals> < body of header file > #endif #ifdef __cplusplus extern \"C\" { #endif Source Files: Source files should have as their first lines after all the include files: 1 2 static const char *rcsid = \"$Header$\"; CCTK_FILEVERSION(MaintGuide_Template_c); <source file> should be replaced by Flesh: <directory>_<core filename>_<extension> (e.g. main_Groups_c) Thorn: <arrangement>_<thorn>_<core filename>_<extension> (e.g. CactusBase_CartGrid3D_CartGrid3D_c) Naming Conventions: All functions which may be used by thorns should have names beginning with CCTK_ and then capitalised words with no underscores. All functions used internally by the flesh should have names beginning with CCTKi_ and then capitalised words with no underscores. Header files to be included by thorns should have names beginning with cctk_ , and followed by capitalised words with no underscores. All Cactus sourcefile names (except general utility files) should use capitilised words without underscores. Fortran Any source file using Cactus infrastructure should include the header file cctk.h using the line 1 #include \"cctk.h\" Variables Any routine using Cactus argument lists should include at the top of the file the header 1 #include \"cctk_Arguments.h\" A Cactus macro CCTK ARGUMENTS is defined for each thorn to contain: - General information about the grid hierarchy. - All the grid variables defined in the thorn\u2019s interface.ccl - All the grid variables required from other thorns as requested by the inherits and friend lines in the interface.ccl These variables must be declared at the start of the routine using the macro DECLARE_CCTK_ARGUMENTS . Parameters Any routine using Cactus parameters should include at the top of the file the header 1 #include \"cctk_Parameters.h\" The parameters should be declared at the start of the routine using them with the macro DECLARE_CCTK_PARAMETERS . To compare a string valued parameter and Fortran string, use the macro CCTK_EQUALS() or the function CCTK_Equals() . To print the value of a string valued parameter to screen, use the subroutine CCTK_PrintString() . A further function CCTK_FortranString provides a mechanism for converting a string parameter to a Fortran string. Cactus Fortran Functions Cactus Fortran functions can all be declared by adding the statement 1 #include \"cctk_Functions.h\" near the top of the file, and adding the declaration 1 DECLARE_CCTK_FUNCTIONS to a module or a subroutine after the implicit none statement, but before any executable code. Fortran Modules Fortran modules should be placed into source files that have the same name as the module, followed by the corresponding file name suffix. A module metric should thus be placed, e.g. into a file metric.F90 . This convention allows the Cactus build system to automatically deduce the compile time dependencies. If you do not follow this convention, then you have to include the modules into the thorn\u2019s make.code.deps file. Example 1 2 3 4 5 6 7 8 9 10 #include \"cctk.h\" #include \"cctk_Arguments.h\" #include \"cctk_Parameters.h\" subroutine MyNewRoutine ( CCTK_ARGUMENTS , flag ) implicit none DECLARE_CCTK_ARGUMENTS DECLARE_CCTK_PARAMETERS c Main code goes here return end C Any source file using Cactus infrastructure should include the header file cctk.h using the line 1 #include \"cctk.h\" Variables Any routine using Cactus argument lists should include at the top of the file the header 1 #include \"cctk_Arguments.h\" A Cactus macro CCTK ARGUMENTS is defined for each thorn to contain: - General information about the grid hierarchy. - All the grid variables defined in the thorn\u2019s interface.ccl - All the grid variables required from other thorns as requested by the inherits and friend lines in the interface.ccl These variables must be declared at the start of the routine using the macro DECLARE_CCTK_ARGUMENTS . Parameters Any routine using Cactus parameters should include at the top of the file the header 1 #include \"cctk_Parameters.h\" The parameters should be declared at the start of the routine using them with the macro DECLARE_CCTK_PARAMETERS . Example 1 2 3 4 5 6 7 8 9 #include \"cctk.h\" #include \"cctk_Arguments.h\" #include \"cctk_Parameters.h\" void MyCRoutine ( CCTK_ARGUMENTS ) { DECLARE_CCTK_ARGUMENTS DECLARE_CCTK_PARAMETERS /* Here goes your code */ } Cactus Variables The Cactus variables which are passed through the macro CCTK ARGUMENTS are Name Describe cctkGH A C pointer identifying the grid hierarchy. cctk_dim An integer with the number of dimensions used for this grid hierarchy. cctk_lsh An array of cctk_dim integers with the local grid size on this processor. cctk_ash An array of cctk_dim integers with the allocated size of the array. This may be larger than the local size; the additional points may not be used. cctk_gsh An array of cctk_dim integers with the global grid size. cctk_iteration The current iteration number. cctk_delta_time A CCTK_REAL with the timestep. cctk_time A CCTK_REAL with the current time. cctk_delta_space An array of cctk_dim CCTK_REALs with the grid spacing in each direction. cctk_nghostzones An array of cctk_dim integers with the number of ghostzones used in each direction. cctk_origin_space An array of cctk_dim CCTK_REALs with the spatial coordinates of the global origin of the grid. The following variables describe the location of the local grid (e.g. the grid treated on a given processor) within the global grid. Name Describe cctk_lbnd An array of cctk_dim integers containing the lowest index (in each direction) of the local grid, as seen on the global grid. Note that these indices start from zero, so you need to add one when using them in Fortran thorns. cctk_ubnd An array of cctk_dim integers containing the largest index (in each direction) of the local grid, as seen on the global grid. Note that these indices start from zero, so you need to add one when using them in Fortran thorns. cctk_bbox An array of 2*cctk_dim integers, which indicate whether the boundaries are internal boundaries (e.g. between processors), or physical boundaries. A value of 1 indicates a physical (outer) boundary at the edge of the computational grid, and 0 indicates an internal boundary. The following variable is needed for grid refinement methods Name Describe cctk_levfac An array of cctk_dim integer factors by which the local grid is refined in the corresponding direction with respect to the base grid. cctk_levoff and cctk_levoffdenom Two arrays of cctk_dim integers describing the distance by which the local grid is offset with respect to the base grid, measured in local grid spacings. The distance in direction dir is given by 1.0 * cctk_levoff[dir] / cctk_levoffdenom[dir]. cctk_timefac The integer factor by which the time step size is reduced with respect to the base grid. The following variables are used for identifying convergence levels. Name Describe cctk_convlevel The convergence level of this grid hierarchy. The base level is 0, and every level above that is coarsened by a factor of cctk_convfac. cctk_convfac The factor between convergence levels. The relation between the resolutions of different convergence levels is \\Delta x_{L}=\\Delta x_{0} \\cdot F^{L} \\Delta x_{L}=\\Delta x_{0} \\cdot F^{L} , where L is the convergence level and F is the convergence factor. The convergence factor defaults to 2. The variables cctk_delta_space, cctk_delta_time, and cctk_origin space denote the grid spacings, time step size, and spatial origin on the base grid. Cactus Data Types To provide portability across platforms, the Cactus grid variables and parameters are defined and declared using Cactus data types (CCTK_INT, CCTK_REAL, CCTK_COMPLEX).","title":"Source File"},{"location":"ET/Source File/#adding-source-files","text":"By default, the CCTK looks in the src directory of the thorn for source files. There are two ways in which to specify the sources. The easiest is to use the make.code.defn based method in which the CCTK does all the work, but you may instead put a Makefile in the src directory and do everything yourself. The Cactus make system looks for a file called make.code.defn in that directory (if there is no file called Makefile in the src directory). At its simplest, this file contains two lines 1 2 SRCS = <list of all source files in this directory> SUBDIRS = <list of all subdirectories, including subdirectories of subdirectories> Each subdirectory listed should then have a make.code.defn file containing just a SRCS = line, a SUBDIRS = line will be ignored.","title":"Adding Source Files"},{"location":"ET/Source File/#coding-style","text":"Indentation: Two spaces, no tabs. Brace positioning: 1 2 3 4 do { <statement> } while(); GRDOC: All files should start with a grdoc header, and all functions should have grdoc headers. The function grdoc should contain a description of the function, saying what it does. the functions called by this function. all function arguments with descriptions of what they are and what they are used for. the return codes should be described. The standard grdoc function header is of the form 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /*@@ @routine Template @date Fri Oct 6 10:51:49 2000 @author Yu Liu @desc An example of grdoc @enddesc @calls templatefunc2 @calledby @history @endhistory @var templatestring @vdesc string describing foobar @vtype const char * @vio in @vcomment @endvar @returntype int * @returndesc 0 - success @endreturndesc @@*/ Header Files: 1 2 3 4 5 6 7 8 9 #ifndef <Name of Header File in Capitals> #define <Name of Header File in Capitals> < body of header file > #endif #ifdef __cplusplus extern \"C\" { #endif Source Files: Source files should have as their first lines after all the include files: 1 2 static const char *rcsid = \"$Header$\"; CCTK_FILEVERSION(MaintGuide_Template_c); <source file> should be replaced by Flesh: <directory>_<core filename>_<extension> (e.g. main_Groups_c) Thorn: <arrangement>_<thorn>_<core filename>_<extension> (e.g. CactusBase_CartGrid3D_CartGrid3D_c) Naming Conventions: All functions which may be used by thorns should have names beginning with CCTK_ and then capitalised words with no underscores. All functions used internally by the flesh should have names beginning with CCTKi_ and then capitalised words with no underscores. Header files to be included by thorns should have names beginning with cctk_ , and followed by capitalised words with no underscores. All Cactus sourcefile names (except general utility files) should use capitilised words without underscores.","title":"Coding Style"},{"location":"ET/Source File/#fortran","text":"Any source file using Cactus infrastructure should include the header file cctk.h using the line 1 #include \"cctk.h\"","title":"Fortran"},{"location":"ET/Source File/#variables","text":"Any routine using Cactus argument lists should include at the top of the file the header 1 #include \"cctk_Arguments.h\" A Cactus macro CCTK ARGUMENTS is defined for each thorn to contain: - General information about the grid hierarchy. - All the grid variables defined in the thorn\u2019s interface.ccl - All the grid variables required from other thorns as requested by the inherits and friend lines in the interface.ccl These variables must be declared at the start of the routine using the macro DECLARE_CCTK_ARGUMENTS .","title":"Variables"},{"location":"ET/Source File/#parameters","text":"Any routine using Cactus parameters should include at the top of the file the header 1 #include \"cctk_Parameters.h\" The parameters should be declared at the start of the routine using them with the macro DECLARE_CCTK_PARAMETERS . To compare a string valued parameter and Fortran string, use the macro CCTK_EQUALS() or the function CCTK_Equals() . To print the value of a string valued parameter to screen, use the subroutine CCTK_PrintString() . A further function CCTK_FortranString provides a mechanism for converting a string parameter to a Fortran string.","title":"Parameters"},{"location":"ET/Source File/#cactus-fortran-functions","text":"Cactus Fortran functions can all be declared by adding the statement 1 #include \"cctk_Functions.h\" near the top of the file, and adding the declaration 1 DECLARE_CCTK_FUNCTIONS to a module or a subroutine after the implicit none statement, but before any executable code.","title":"Cactus Fortran Functions"},{"location":"ET/Source File/#fortran-modules","text":"Fortran modules should be placed into source files that have the same name as the module, followed by the corresponding file name suffix. A module metric should thus be placed, e.g. into a file metric.F90 . This convention allows the Cactus build system to automatically deduce the compile time dependencies. If you do not follow this convention, then you have to include the modules into the thorn\u2019s make.code.deps file.","title":"Fortran Modules"},{"location":"ET/Source File/#example","text":"1 2 3 4 5 6 7 8 9 10 #include \"cctk.h\" #include \"cctk_Arguments.h\" #include \"cctk_Parameters.h\" subroutine MyNewRoutine ( CCTK_ARGUMENTS , flag ) implicit none DECLARE_CCTK_ARGUMENTS DECLARE_CCTK_PARAMETERS c Main code goes here return end","title":"Example"},{"location":"ET/Source File/#c","text":"Any source file using Cactus infrastructure should include the header file cctk.h using the line 1 #include \"cctk.h\"","title":"C"},{"location":"ET/Source File/#variables_1","text":"Any routine using Cactus argument lists should include at the top of the file the header 1 #include \"cctk_Arguments.h\" A Cactus macro CCTK ARGUMENTS is defined for each thorn to contain: - General information about the grid hierarchy. - All the grid variables defined in the thorn\u2019s interface.ccl - All the grid variables required from other thorns as requested by the inherits and friend lines in the interface.ccl These variables must be declared at the start of the routine using the macro DECLARE_CCTK_ARGUMENTS .","title":"Variables"},{"location":"ET/Source File/#parameters_1","text":"Any routine using Cactus parameters should include at the top of the file the header 1 #include \"cctk_Parameters.h\" The parameters should be declared at the start of the routine using them with the macro DECLARE_CCTK_PARAMETERS .","title":"Parameters"},{"location":"ET/Source File/#example_1","text":"1 2 3 4 5 6 7 8 9 #include \"cctk.h\" #include \"cctk_Arguments.h\" #include \"cctk_Parameters.h\" void MyCRoutine ( CCTK_ARGUMENTS ) { DECLARE_CCTK_ARGUMENTS DECLARE_CCTK_PARAMETERS /* Here goes your code */ }","title":"Example"},{"location":"ET/Source File/#cactus-variables","text":"The Cactus variables which are passed through the macro CCTK ARGUMENTS are Name Describe cctkGH A C pointer identifying the grid hierarchy. cctk_dim An integer with the number of dimensions used for this grid hierarchy. cctk_lsh An array of cctk_dim integers with the local grid size on this processor. cctk_ash An array of cctk_dim integers with the allocated size of the array. This may be larger than the local size; the additional points may not be used. cctk_gsh An array of cctk_dim integers with the global grid size. cctk_iteration The current iteration number. cctk_delta_time A CCTK_REAL with the timestep. cctk_time A CCTK_REAL with the current time. cctk_delta_space An array of cctk_dim CCTK_REALs with the grid spacing in each direction. cctk_nghostzones An array of cctk_dim integers with the number of ghostzones used in each direction. cctk_origin_space An array of cctk_dim CCTK_REALs with the spatial coordinates of the global origin of the grid. The following variables describe the location of the local grid (e.g. the grid treated on a given processor) within the global grid. Name Describe cctk_lbnd An array of cctk_dim integers containing the lowest index (in each direction) of the local grid, as seen on the global grid. Note that these indices start from zero, so you need to add one when using them in Fortran thorns. cctk_ubnd An array of cctk_dim integers containing the largest index (in each direction) of the local grid, as seen on the global grid. Note that these indices start from zero, so you need to add one when using them in Fortran thorns. cctk_bbox An array of 2*cctk_dim integers, which indicate whether the boundaries are internal boundaries (e.g. between processors), or physical boundaries. A value of 1 indicates a physical (outer) boundary at the edge of the computational grid, and 0 indicates an internal boundary. The following variable is needed for grid refinement methods Name Describe cctk_levfac An array of cctk_dim integer factors by which the local grid is refined in the corresponding direction with respect to the base grid. cctk_levoff and cctk_levoffdenom Two arrays of cctk_dim integers describing the distance by which the local grid is offset with respect to the base grid, measured in local grid spacings. The distance in direction dir is given by 1.0 * cctk_levoff[dir] / cctk_levoffdenom[dir]. cctk_timefac The integer factor by which the time step size is reduced with respect to the base grid. The following variables are used for identifying convergence levels. Name Describe cctk_convlevel The convergence level of this grid hierarchy. The base level is 0, and every level above that is coarsened by a factor of cctk_convfac. cctk_convfac The factor between convergence levels. The relation between the resolutions of different convergence levels is \\Delta x_{L}=\\Delta x_{0} \\cdot F^{L} \\Delta x_{L}=\\Delta x_{0} \\cdot F^{L} , where L is the convergence level and F is the convergence factor. The convergence factor defaults to 2. The variables cctk_delta_space, cctk_delta_time, and cctk_origin space denote the grid spacings, time step size, and spatial origin on the base grid.","title":"Cactus Variables"},{"location":"ET/Source File/#cactus-data-types","text":"To provide portability across platforms, the Cactus grid variables and parameters are defined and declared using Cactus data types (CCTK_INT, CCTK_REAL, CCTK_COMPLEX).","title":"Cactus Data Types"},{"location":"ET/Thorn/","text":"A thorn is the basic working module within Cactus. All user supplied code goes into thorns, which are, by and large, independent of each other. Relationships among thorns are all based upon relationships among the implementations they provide. Thorns are grouped into arrangements. This is a logical grouping of thorns which is purely for organisational purposes. The arrangements live in the arrangements directory of the main Cactus directory. A thorn consists of a subdirectory of an arrangement containing four administrative files: Name Describe interface.ccl This defines the implementation the thorn provides, and the variables the thorn needs, along with their visibility to other implementations. param.ccl This defines the parameters that are used to control the thorn, along with their visibility to other implementations. schedule.ccl This defines which functions are called from the thorn and when they are called. It also handles memory and communication assignment for grid variables. configuration.ccl This file is optional for a thorn. If it exists, it contains extra configuration options of this thorn. Thorns can also contain a subdirectory called src , which should hold source files and compilation instructions for the thorn a subdirectory src/include for include files a README containing a brief description of the thorn a doc directory for documentation a par directory for example parameter files a test subdirectory may also be added, to hold the thorn\u2019s test suite. Note Each thorn provides 3 configuration files (interface.ccl, param.ccl, schedule.ccl), detailing its interface with the Flesh and with other thorns. Cactus contains a rule-based scheduling system, which determines which routines, from which thorns are run in which order. Cactus Configuration Language (CCL) files are text files used to define configuration information for a thorn. Their formal syntax is described using Piraha, a parsing expression grammar engine that supports multiple languages (see https://github.com/stevenrbrandt/piraha-peg for a description of formal syntax). Note CCL files are (mostly) case independent, and may contain comments introduced by the hash \u2018#\u2019 character, which indicates that the rest of the line is a comment. If the last non-blank character of a line in a CCL file is a backslash \u2018\\\u2019, the following line is treated as a continuation of the current line. The interface.ccl File The interface.ccl file is used to declare A header block giving details of the thorn\u2019s relationship with other thorns. A block detailing which include files are used from other thorns, and which include files are provided by this thorn. Blocks detailing aliased functions provided or used by this thorn. A series of blocks listing the thorn\u2019s global variables. Header Block: The implementation is declared by a single line at the top of the file implements: <name> declares that the thorn provides an implementation called <name> . The implementation name must be unique among all thorns. There are three different access levels available for variables Name Describe Public Can be \u2018inherited\u2019 by other implementations. Protected Can be shared with other implementations which declare themselves to be friends of this one. Private Can only be seen by this thorn. By default, all groups are private, to change this, an access specification of the form public: or protected: . Corresponding to the first two access levels there are two relationship statements that can be used to get variables from other implementations. Name Describe Inherits Inheriting from another implementation makes all that implementation\u2019s public variables available to your thorn. Inheritance is transitive (if A inherits from B, and B inherits from C, then A also implicitly inherits from C), but not commutative. Friend Being a friend of another implementation makes all that implementation\u2019s protected variables available to your thorn. Friendship is associative, commutative and transitive (i.e. if A is a friend of B, and B is a friend of C, then A is implicitly a friend of C). Include Files: The include file section has the form: 1 2 USES INCLUDE [SOURCE|HEADER]: <file_name> INCLUDE[S] [SOURCE|HEADER]: <file_to_include> in <file_name> The former is used when a thorn wishes to use an include file from another thorn. The latter indicates that this thorn adds the code in to the include file . If the include file is described as SOURCE, the included code is only executed if the providing thorn is active. Both default to HEADER. Function Aliasing: If any aliased function is to be used or provided by the thorn, then the prototype must be declared with the form: 1 <return_type> FUNCTION <alias>(<arg1_type> <intent1> [ARRAY] <arg1>, ...) <return_type> The <return_type> must be either void, CCTK_INT, CCTK_REAL, CCTK_COMPLEX, CCTK_POINTER, or CCTK_POINTER_TO_CONST. The keyword SUBROUTINE is equivalent to void FUNCTION. <alias> The name of the aliased function <alias> must contain at least one uppercase and one lowercase letter and follow the C standard for function names. <arg_type> The type of each argument, <arg type> , must be either CCTK_INT, CCTK_REAL, CCTK_COMPLEX, CCTK_POINTER, CCTK_POINTER_TO_CONST, or STRING. All string arguments must be the last arguments in the list. <intent*> The intent of each argument, <intent*> , must be either IN, OUT, or INOUT. An argument may only be modified if it is declared to have intent OUT or INOUT. [ARRAY] If the argument is an array then the prefix ARRAY must also be given. function pointer If the argument <arg*> is a function pointer, then the argument itself (which will preceded by the return type) should be 1 CCTK_FPOINTER <function_arg1>(<arg1_type> <intent1> <arg1>, ...) aliased function If an aliased function is to be required, then the block is required. 1 REQUIRES FUNCTION <alias> If an aliased function is to be (optionally) used, then the block is required. 1 USES FUNCTION <alias> Variable Blocks: The thorn\u2019s variables are collected into groups. The thorn\u2019s variables are defined by: 1 2 3 4 5 6 [<access>:] <data_type> <group_name>[<number>] [TYPE = <group_type>] [DIM=<dim>] [TIMELEVELS=<num>] [SIZE=<size in each direction>] [DISTRIB=<distribution_type>] [GHOSTSIZE=<ghostsize>] [TAGS=<string>] [\"<group_description>\"] { <variable_name>[,] <variable_name> } [\"<group_description>\"] Note The options TYPE, DIM, etc., following must all appear on one line. Name Describe access defines which thorns can use the following groups of variables. access can be either public, protected or private. data_type defines the data type of the variables in the group. Supported data types are CHAR, BYTE, INT, REAL, and COMPLEX. group_name must be an alphanumeric name (which may also contain underscores) which is unique across group and variable names within the scope of the thorn. A group name is compulsory. [number] if present, indicates that this is a vector group. TYPE designates the kind of variables held by the group. The choices are GF, ARRAY or SCALAR. This field is optional, with the default variable type being SCALAR. DIM defines the spatial dimension of the ARRAY or GF. The default value is DIM=3. TIMELEVELS defines the number of timelevels a group has if the group is of type ARRAY or GF, and can take any positive value. The default is one timelevel. SIZE defines the number grid-points an ARRAY has in each direction. This should be a comma-separated list of valid arithmetical expressions consisting of integers or integer-valued parameters. DISTRIB defines the processor decomposition of an ARRAY. DISTRIB=DEFAULT distributes SIZE grid-points across all processors. DISTRIB=CONSTANT implies that SIZE grid-points should be allocated on each processor. The default value is DISTRIB=DEFAULT. GHOSTSIZE defines number of ghost zones in each dimension of an ARRAY. It defaults to zero. TAGS defines an optional string which is used to create a set of key-value pairs associated with the group. An optional description of the group can be given on the last line. If the variable block is omitted, this description can be given at the end of the declaration line. Cactus variables are used instead of local variables for a number of reasons: Cactus variables can be made visible to other thorns, allowing thorns to communicate and share data. Cactus variables can be distributed and communicated among processors, allowing parallel computation. A database of Cactus variables, and their attributes, is held by the flesh, and this information is used by thorns, for example, for obtaining a list of variables for checkpointing. Many Cactus APIs and tools can only be used with Cactus variables. Cactus provides features for error checking based on Cactus variables and their attributes. Cactus variables are collected into groups. All variables in a group are of the same data type, and have the same attributes. Most Cactus operations act on a group as a whole. A group must be declared in its thorn\u2019s interface.ccl file. Groups can be either scalars, grid functions (GFs), or grid arrays. Name Describe SCALAR This is just a single number, e.g. the total energy of some field. These variables aren\u2019t communicated between processors\u2014what would be the result of such communication? GF This is the most common group type. A GF is an array with a specific size, set at run time in the parameter file, which is distributed across processors. All GFs have the same size, and the same number of ghostzones. Groups of GFs can also specify a dimension, and number of timelevels. ARRAY This is a more general form of the GF. Each group of arrays can have a distinct size and number of ghostzones, in addition to dimension and number of timelevels. The drawback of using an array over a GF is that a lot of data about the array can only be determined by function calls, rather than the quicker methods available for GFs. The param.ccl File The param.ccl file is used to specify the parameters used to control an individual thorn, and to specify the values these parameters are allowed to take. If a parameter is not assigned in a parameter file, it is given its default value. Parameter Data Scoping Items: : The keyword access designates that all parameter object specification items, up to the next parameter data scoping item, are in the same protection or scoping class. access can take the values: Name Describe Global These parameters are seen by all thorns. Restricted These parameters may be used by other implementations if they so desire. Private These are only seen by this thorn. shares in this case, an implementation name must follow the colon. It declares that all the parameters in the following scoping block are restricted variables from the specified implementation. Parameter Object Specification Items 1 2 3 4 5 [EXTENDS|USES] <parameter type> <parameter name> [<len>] \"<parameter description>\" [AS <alias>] [STEERABLE=<NEVER|ALWAYS|RECOVER>] [ACCUMULATOR=<expression>] [ACCUMULATOR-BASE=<parameter name>] { <parameter values> } <default value> where the options AS, STEERABLE, etc., following , must all appear in one line. Note that the beginning brace ({) must sit on a line by itself; the ending brace (}) must be at the beginning of a line followed by on that same line. A thorn can declare that it EXTENDS a parameter of another thorn. This allows it to declare additional acceptable values. By default, it is acceptable for two thorns to declare the same value as acceptable. If the thorn wants to simply use a parameter from another thorn, without declaring additional values, use USES instead. The parameter name must be unique within the scope of the thorn. The default value must match one of the ranges given in the parameter type [len] is an integer, if present, indicates that this is an array parameter of len values of the specified type. alias allows a parameter to appear under a different name in this thorn, other than its original name in another thorn. The name, as seen in the parameter file, is unchanged. STEERABLE specifies when a parameter value may be changed. By default, parameters may not be changed after the parameter file has been read, or on restarting from checkpoint. This option relaxes this restriction, specifying that the parameter may be changed at recovery time from a parameter file or at any time using the flesh routine CCTK_ParameterSet . The value RECOVERY is used in checkpoint/recovery situations, and indicates that the parameter may be altered until the value is read in from a recovery par file, but not after. ACCUMULATOR specifies that this is an accumulator parameter. Such parameters cannot be set directly, but are set by other parameters who specify this one as an ACCUMULATOR-BASE . The expression is a two-parameter arithmetical expression of x and y. Setting the parameter consists of evaluating this expression successively, with x being the current value of the parameter (at the first iteration this is the default value), and y the value of the setting parameter. This procedure is repeated, starting from the default value of the parameter, each time one of the setting parameters changes. ACCUMULATOR-BASE specifies the name of an ACCUMULATOR parameter which this parameter sets. The depend on the , which may be one of the following: INT 1 <range description> [::\"<comment describing this range>\"] Here, a <range description> specifies a set of integers, and has one of the following forms: * : means any integer <integer> : means only <integer> <lower bound>:<upper bound> : means all integers in the range from to <lower bound>:<upper bound>:<positive step> : means all integers in the range from to in steps of where has one of the forms <empty field> : means no lower limit * : means no lower limit <integer> : means a closed interval starting at [<integer> : also means a closed interval starting at (<integer> : means an open interval starting at Name Describe REAL The range specification is the same as with integers, except that here, no step implies a continuum of values. Note that numeric constants should be expressed as in C (e.g. 1e-10). Note also that one cannot use the Cactus types such as CCTK_REAL4 to specify the precision of the parameter; parameters always have the default precision. KEYWORD Each entry in the list of acceptable values for a keyword has the form <keyword value> :: \"<description>\" Keyword values should be enclosed in double quotes. The double quotes are mandatory if the keyword contains spaces. STRING Allowed values for strings should be specified using regular expressions. To allow any string, the regular expression \"\" should be used. (An empty regular expression matches anything.) Regular expressions and string values should be enclosed in double quotes. The double quotes are mandatory if the regular expression or the string value is empty or contains spaces. BOOLEAN No <parameter values> should be specified for a boolean parameter. The schedule.ccl File Cactus contains a rule-based scheduling system, which determines which routines, from which thorns are run in which order. A schedule configuration file consists of: Assignment statements to switch on storage for grid variables for the entire duration of program execution. Schedule blocks to schedule a subroutine from a thorn to be called at specific times during program execution in a given manner. Conditional statements for both assignment statements and schedule blocks to allow them to be processed depending on parameter values. Assignment Statements: These lines have the form: 1 STORAGE: <group>[timelevels] The storage line includes the number of timelevels to activate storage for, this number can be from 1 up to the maximum number or timelevels for the group, as specified in the defining interface.ccl file. If the maximum number of timelevels is 1 (the default), this number may be omitted. Alternatively timelevels can be the name of a parameter accessible to the thorn. The parameter name is the same as used in C routines of the thorn, fully qualified parameter names of the form thorn::parameter are not allowed. In this case 0 (zero) timelevels can be requested, which is equivalent to the STORAGE statement being absent. Schedule Blocks: 1 2 3 4 5 6 7 8 9 10 11 schedule [ GROUP ] < function name | group name > AT | IN [ AS < alias > ] [ WHILE < variable > ] [ IF < variable > ] [ BEFORE | AFTER < function name >| ( < function name > ...)] { LANG : < FORTRAN | C > OPTIONS : [ list of options ] TAGS : [ list of keyword = value definitions ] STORAGE : [ group list with timelevels ] READS : [ group list ] WRITES : [ group list ] TRIGGERS : [ group list ] SYNC : [ group list ] } \"Description of function\" Name Describe GROUP Schedule a schedule group with the same options as a schedule function. The schedule group will be created if it doesn\u2019t exist. <function name|group name> The name of a function or a schedule group to be scheduled. Function and schedule group names are case sensitive. AT|IN Each schedule item is scheduled either AT a particular scheduling bin, or IN a schedule group. AS Provides an alias for a function or schedule group which should be used for scheduling before, after or in. This can be used to provide thorn independence for other thorns scheduling functions, or schedule groups relative to this one. WHILE Executes a function or schedule group until the given variable (which must be a fully qualified integer grid scalar) has the value zero. IF Executes a function or schedule group only if the given variable (which must be a fully qualified integer grid scalar) has a non-zero value. BEFORE/AFTER Takes a function name, a function alias, a schedule group name, or a parenthesesenclosed white space-separated list of these. (Any names that are not provided by an active thorn are ignored.) Note that a single schedule block may have multiple BEFORE/AFTER clauses. Using the schedule.ccl files, thorn functions can be scheduled to run in the different timebins which are executed by the Cactus flesh. Name Describe CCTK_RECOVER_PARAMETERS Used by thorns with relevant I/O methods as the point to read parameters when recovering from checkpoint files. Grid variables are not available in this timebin. Scheduling in this timebin is special. CCTK_STARTUP Run before any grids are constructed, this is the timebin, for example, where grid independent information (e.g. output methods, reduction operators) is registered. Note that since no grids are setup at this point, grid variables cannot be used in routines scheduled here. CCTK_WRAGH This timebin is executed when all parameters are known, but before the driver thorn constructs the grid. It should only be used to set up information that is needed by the driver. CCTK_PARAMCHECK This timebin is for thorns to check the validity of parameter combinations. This bin is also executed before the grid hierarchy is made, so that routines scheduled here only have access to the global grid size and the parameters. CCTK_PREREGRIDINITIAL This timebin is used in mesh refinement settings. It is ignored for unigrid runs. This bin is executed whenever the grid hierarchy is about to change during evolution; compare CCTK_PREREGRID. Routines that decide the new grid structure should be scheduled in this bin. CCTK_POSTREGRIDINITIAL This timebin is used in mesh refinement settings. It is ignored for unigrid runs. This bin is executed whenever the grid hierarchy or patch setup has changed during evolution; see CCTK_POSTREGRID. It is, e.g. necessary to re-apply the boundary conditions or recalculate the grid points\u2019 coordinates after every changing the grid hierarchy. CCTK_BASEGRID This timebin is executed very early after a driver thorn constructs grid; this bin should only be used to set up coordinate systems on the newly created grids. CCTK_INITIAL This is the place to set up any required initial data. This timebin is not run when recovering from a checkpoint file. CCTK_POSTINITIAL This is the place to modify initial data, or to calculate data that depend on the initial data. This timebin is also not run when recovering from a checkpoint file. CCTK_POSTRESTRICTINITIAL This timebin is used only in mesh refinement settings. It is ignored for unigrid runs. This bin is executed after each restriction operation while initial data are set up; compare CCTK_POSTRESTRICT. It is, e.g. necessary to re-apply the boundary conditions after every restriction operation. CCTK_POSTPOSTINITIAL This is the place to modify initial data, or to calculate data that depend on the initial data. This timebin is executed after the recursive initialisation of finer grids if there is a mesh refinement hierarchy, and it is also not run when recovering from a checkpoint file. CCTK_RECOVER_VARIABLES Used by thorns with relevant I/O methods as the point to read in all the grid variables when recovering from checkpoint files. CCTK_POST_RECOVER_VARIABLES This timebin exists for scheduling any functions which need to modify grid variables after recovery. CCTK_CPINITIAL Used by thorns with relevant I/O methods as the point to checkpoint initial data if required. CCTK_CHECKPOINT Used by thorns with relevant I/O methods as the point to checkpoint data during the iterative loop when required. CCTK_PREREGRID This timebin is used in mesh refinement settings. It is ignored for unigrid runs. This bin is executed whenever the grid hierarchy is about to change during evolution; compare CCTK_PREREGRIDINITIAL. Routines that decide the new grid structure should be scheduled in this bin. CCTK_POSTREGRID This timebin is used in mesh refinement settings. It is ignored for unigrid runs. This bin is executed whenever the grid hierarchy or patch setup has changed during evolution; see CCTK_POSTREGRIDINITIAL. It is, e.g. necessary to re-apply the boundary conditions or recalculate the grid points\u2019 coordinates after every changing the grid hierarchy. CCTK_PRESTEP The timebin for scheduling any routines which need to be executed before any routines in the main evolution step. This timebin exists for thorn writers convenience, the BEFORE, AFTER, etc., functionality of the schedule.ccl file should allow all functions to be scheduled in the main CCTK_EVOL timebin. CCTK_EVOL The timebin for the main evolution step. CCTK_POSTRESTRICT This timebin is used only in mesh refinement settings. It is ignored for unigrid runs. This bin is executed after each restriction operation during evolution; compare CCTK_POSTRESTRICTINITIAL. It is, e.g. necessary to re-apply the boundary conditions after every restriction operation. CCTK_POSTSTEP The timebin for scheduling any routines which need to be executed after all the routines in the main evolution step. This timebin exists for thorn writers convenience, the BEFORE, AFTER, etc., functionality of the schedule.ccl file should allow all functions to be scheduled in the main CCTK_EVOL timebin. CCTK_ANALYSIS The ANALYSIS timebin is special, in that it is closely coupled with output, and routines which are scheduled here are typically only executed if output of analysis variables is required. Routines which perform analysis should be independent of the main evolution loop (that is, it should not matter for the results of a simulation whether routines in this timebin are executed or not). CCTK_TERMINATE Called after the main iteration loop when Cactus terminates. Note that sometime, in this timebin, a driver thorn should be destroying the grid hierarchy and removing grid variables. CCTK_SHUTDOWN Cactus final shutdown routines, after the grid hierarchy has been destroyed. Grid variables are no longer available. It is possible to state that the routine must run BEFORE or AFTER another routine or set of routines. It is also possible to schedule the routine under an alias name by using AS <alias name> . Name Describe LANG The code language for the function (either C or FORTRAN). No language should be specified for a schedule group. OPTIONS Schedule options are used for mesh refinement and multi-block simulations, and they determine \u201cwhere\u201d a routine executes. Possible options are: meta, meta_early, meta_late, global, global_early, global_late, level, singlemap, local, loop_meta, loop_global, loop_level, loop_singlemap, loop_local. TAGS Schedule tags. These tags must have the form keyword=value , and must be in a syntax accepted by Util_TableCreateFromString . STORAGE List of variable groups which should have storage switched on for the duration of the function or schedule group. Each group must specify how many timelevels to activate storage for, from 1 up to the maximum number for the group as specified in the defining interface.ccl file. If the maximum is 1 (the default) this number may be omitted. Alternatively timelevels can be the name of a parameter accessible to the thorn. The parameter name is the same as used in C routines of the thorn, fully qualified parameter names of the form thorn::parameter are not allowed. In this case 0 (zero) timelevels can be requested, which is equivalent to the STORAGE statement being absent. READS READS is used to declare which grid variables are read by the routine. This information is used e.g. to determine which variables need to be copied between host and device for OpenCL or CUDA kernel. This information can also be used to ensure that all variables that are read have previously been written by another routine. WRITES WRITES is used to declare which grid variables are written by the routine. This information is used e.g. to determine which variables need to be copied between host and device for OpenCL or CUDA kernel. This information can also be used to ensure that all variables that are read have previously been written by another routine. TRIGGER List of grid variables or groups to be used as triggers for causing an ANALYSIS function or group to be executed. Any schedule block for an analysis function or analysis group may contain a TRIGGER line. SYNCHRONISE List of groups to be synchronised, as soon as the function or schedule group is exited. Option names are case-insensitive. There can be several options given at the same time. Name Describe META This routine will only be called once, even if several simulations are performed at the same time. This can be used, for example, to initialise external libraries, or to set up data structures that live in global variables. META-EARLY This option is identical to to META option with the exception that the routine will be called together with the routines on the first subgrid. META-LATE This option is identical to to META option with the exception that the routine will be called together with the routines on the last subgrid. GLOBAL This routine will only be called once on a grid hierarchy, not for all subgrids making up the hierarchy. This can be used, for example, for analysis routines which use global reduction or interpolation routines, rather than the local subgrid passed to them, and hence should only be called once. GLOBAL-EARLY This option is identical to to GLOBAL option with the exception that the routine will be called together with the routines on the first subgrid. GLOBAL-LATE This option is identical to to GLOBAL option with the exception that the routine will be called together with the routines on the last subgrid. LEVEL This routine will only be called once on any \u201clevel\u201d of the grid hierarchy. That is, it will only be called once for any set of sub-grids which have the same cctk_levfac numbers. SINGLEMAP This routine will only be called once on any of the \u201cpatches\u201d that form a \u201clevel\u201d of the grid hierarchy. LOCAL This routine will be called on every \u201ccomponent\u201d. LOOP-META Loop once. LOOP-GLOBAL Loop over all simulations. LOOP-LEVEL Loop over all \u201clevels\u201d. LOOP-SINGLEMAP Loop over all \u201cpatches\u201d. LOOP-LOCAL Loop over all \u201ccomponents\u201d. Conditional Statements: Any schedule block or assignment statements can be optionally surrounded by conditional if-elseif-else constructs using the parameter data base. These can be nested, and have the general form: 1 2 3 4 5 if (<conditional-expression>) { [<assignments>] [<schedule blocks>] } <conditional-expression> can be any valid C construct evaluating to a truth value. Such conditionals are evaluated only at program startup, and are used to pick between different static schedule options. For dynamic scheduling, the SCHEDULE WHILE construction should be used. The configuration.ccl File A configuration.ccl file defines capabilities which a thorn either provides or requires, or may use if available. Unlike implementations, only one thorn providing a particular capability may be compiled into a configuration at one time. Thus, this mechanism may be used to, for example: provide access to external libraries; provide access to functions which other thorns must call, but are too complex for function aliasing; or to split a thorn into several thorns, all of which require some common (not aliased) functions. A configuration options file can contain any number of the following sections: 1 2 3 4 5 6 PROVIDES <Capability> { SCRIPT <Configuration script> [VERSION <Version String>] LANG <Language> [OPTIONS [<option>[,<option>]...]] }","title":"Thorn"},{"location":"ET/Thorn/#the-interfaceccl-file","text":"The interface.ccl file is used to declare A header block giving details of the thorn\u2019s relationship with other thorns. A block detailing which include files are used from other thorns, and which include files are provided by this thorn. Blocks detailing aliased functions provided or used by this thorn. A series of blocks listing the thorn\u2019s global variables. Header Block: The implementation is declared by a single line at the top of the file implements: <name> declares that the thorn provides an implementation called <name> . The implementation name must be unique among all thorns. There are three different access levels available for variables Name Describe Public Can be \u2018inherited\u2019 by other implementations. Protected Can be shared with other implementations which declare themselves to be friends of this one. Private Can only be seen by this thorn. By default, all groups are private, to change this, an access specification of the form public: or protected: . Corresponding to the first two access levels there are two relationship statements that can be used to get variables from other implementations. Name Describe Inherits Inheriting from another implementation makes all that implementation\u2019s public variables available to your thorn. Inheritance is transitive (if A inherits from B, and B inherits from C, then A also implicitly inherits from C), but not commutative. Friend Being a friend of another implementation makes all that implementation\u2019s protected variables available to your thorn. Friendship is associative, commutative and transitive (i.e. if A is a friend of B, and B is a friend of C, then A is implicitly a friend of C). Include Files: The include file section has the form: 1 2 USES INCLUDE [SOURCE|HEADER]: <file_name> INCLUDE[S] [SOURCE|HEADER]: <file_to_include> in <file_name> The former is used when a thorn wishes to use an include file from another thorn. The latter indicates that this thorn adds the code in to the include file . If the include file is described as SOURCE, the included code is only executed if the providing thorn is active. Both default to HEADER. Function Aliasing: If any aliased function is to be used or provided by the thorn, then the prototype must be declared with the form: 1 <return_type> FUNCTION <alias>(<arg1_type> <intent1> [ARRAY] <arg1>, ...) <return_type> The <return_type> must be either void, CCTK_INT, CCTK_REAL, CCTK_COMPLEX, CCTK_POINTER, or CCTK_POINTER_TO_CONST. The keyword SUBROUTINE is equivalent to void FUNCTION. <alias> The name of the aliased function <alias> must contain at least one uppercase and one lowercase letter and follow the C standard for function names. <arg_type> The type of each argument, <arg type> , must be either CCTK_INT, CCTK_REAL, CCTK_COMPLEX, CCTK_POINTER, CCTK_POINTER_TO_CONST, or STRING. All string arguments must be the last arguments in the list. <intent*> The intent of each argument, <intent*> , must be either IN, OUT, or INOUT. An argument may only be modified if it is declared to have intent OUT or INOUT. [ARRAY] If the argument is an array then the prefix ARRAY must also be given. function pointer If the argument <arg*> is a function pointer, then the argument itself (which will preceded by the return type) should be 1 CCTK_FPOINTER <function_arg1>(<arg1_type> <intent1> <arg1>, ...) aliased function If an aliased function is to be required, then the block is required. 1 REQUIRES FUNCTION <alias> If an aliased function is to be (optionally) used, then the block is required. 1 USES FUNCTION <alias> Variable Blocks: The thorn\u2019s variables are collected into groups. The thorn\u2019s variables are defined by: 1 2 3 4 5 6 [<access>:] <data_type> <group_name>[<number>] [TYPE = <group_type>] [DIM=<dim>] [TIMELEVELS=<num>] [SIZE=<size in each direction>] [DISTRIB=<distribution_type>] [GHOSTSIZE=<ghostsize>] [TAGS=<string>] [\"<group_description>\"] { <variable_name>[,] <variable_name> } [\"<group_description>\"] Note The options TYPE, DIM, etc., following must all appear on one line. Name Describe access defines which thorns can use the following groups of variables. access can be either public, protected or private. data_type defines the data type of the variables in the group. Supported data types are CHAR, BYTE, INT, REAL, and COMPLEX. group_name must be an alphanumeric name (which may also contain underscores) which is unique across group and variable names within the scope of the thorn. A group name is compulsory. [number] if present, indicates that this is a vector group. TYPE designates the kind of variables held by the group. The choices are GF, ARRAY or SCALAR. This field is optional, with the default variable type being SCALAR. DIM defines the spatial dimension of the ARRAY or GF. The default value is DIM=3. TIMELEVELS defines the number of timelevels a group has if the group is of type ARRAY or GF, and can take any positive value. The default is one timelevel. SIZE defines the number grid-points an ARRAY has in each direction. This should be a comma-separated list of valid arithmetical expressions consisting of integers or integer-valued parameters. DISTRIB defines the processor decomposition of an ARRAY. DISTRIB=DEFAULT distributes SIZE grid-points across all processors. DISTRIB=CONSTANT implies that SIZE grid-points should be allocated on each processor. The default value is DISTRIB=DEFAULT. GHOSTSIZE defines number of ghost zones in each dimension of an ARRAY. It defaults to zero. TAGS defines an optional string which is used to create a set of key-value pairs associated with the group. An optional description of the group can be given on the last line. If the variable block is omitted, this description can be given at the end of the declaration line. Cactus variables are used instead of local variables for a number of reasons: Cactus variables can be made visible to other thorns, allowing thorns to communicate and share data. Cactus variables can be distributed and communicated among processors, allowing parallel computation. A database of Cactus variables, and their attributes, is held by the flesh, and this information is used by thorns, for example, for obtaining a list of variables for checkpointing. Many Cactus APIs and tools can only be used with Cactus variables. Cactus provides features for error checking based on Cactus variables and their attributes. Cactus variables are collected into groups. All variables in a group are of the same data type, and have the same attributes. Most Cactus operations act on a group as a whole. A group must be declared in its thorn\u2019s interface.ccl file. Groups can be either scalars, grid functions (GFs), or grid arrays. Name Describe SCALAR This is just a single number, e.g. the total energy of some field. These variables aren\u2019t communicated between processors\u2014what would be the result of such communication? GF This is the most common group type. A GF is an array with a specific size, set at run time in the parameter file, which is distributed across processors. All GFs have the same size, and the same number of ghostzones. Groups of GFs can also specify a dimension, and number of timelevels. ARRAY This is a more general form of the GF. Each group of arrays can have a distinct size and number of ghostzones, in addition to dimension and number of timelevels. The drawback of using an array over a GF is that a lot of data about the array can only be determined by function calls, rather than the quicker methods available for GFs.","title":"The interface.ccl File"},{"location":"ET/Thorn/#the-paramccl-file","text":"The param.ccl file is used to specify the parameters used to control an individual thorn, and to specify the values these parameters are allowed to take. If a parameter is not assigned in a parameter file, it is given its default value. Parameter Data Scoping Items: : The keyword access designates that all parameter object specification items, up to the next parameter data scoping item, are in the same protection or scoping class. access can take the values: Name Describe Global These parameters are seen by all thorns. Restricted These parameters may be used by other implementations if they so desire. Private These are only seen by this thorn. shares in this case, an implementation name must follow the colon. It declares that all the parameters in the following scoping block are restricted variables from the specified implementation. Parameter Object Specification Items 1 2 3 4 5 [EXTENDS|USES] <parameter type> <parameter name> [<len>] \"<parameter description>\" [AS <alias>] [STEERABLE=<NEVER|ALWAYS|RECOVER>] [ACCUMULATOR=<expression>] [ACCUMULATOR-BASE=<parameter name>] { <parameter values> } <default value> where the options AS, STEERABLE, etc., following , must all appear in one line. Note that the beginning brace ({) must sit on a line by itself; the ending brace (}) must be at the beginning of a line followed by on that same line. A thorn can declare that it EXTENDS a parameter of another thorn. This allows it to declare additional acceptable values. By default, it is acceptable for two thorns to declare the same value as acceptable. If the thorn wants to simply use a parameter from another thorn, without declaring additional values, use USES instead. The parameter name must be unique within the scope of the thorn. The default value must match one of the ranges given in the parameter type [len] is an integer, if present, indicates that this is an array parameter of len values of the specified type. alias allows a parameter to appear under a different name in this thorn, other than its original name in another thorn. The name, as seen in the parameter file, is unchanged. STEERABLE specifies when a parameter value may be changed. By default, parameters may not be changed after the parameter file has been read, or on restarting from checkpoint. This option relaxes this restriction, specifying that the parameter may be changed at recovery time from a parameter file or at any time using the flesh routine CCTK_ParameterSet . The value RECOVERY is used in checkpoint/recovery situations, and indicates that the parameter may be altered until the value is read in from a recovery par file, but not after. ACCUMULATOR specifies that this is an accumulator parameter. Such parameters cannot be set directly, but are set by other parameters who specify this one as an ACCUMULATOR-BASE . The expression is a two-parameter arithmetical expression of x and y. Setting the parameter consists of evaluating this expression successively, with x being the current value of the parameter (at the first iteration this is the default value), and y the value of the setting parameter. This procedure is repeated, starting from the default value of the parameter, each time one of the setting parameters changes. ACCUMULATOR-BASE specifies the name of an ACCUMULATOR parameter which this parameter sets. The depend on the , which may be one of the following: INT 1 <range description> [::\"<comment describing this range>\"] Here, a <range description> specifies a set of integers, and has one of the following forms: * : means any integer <integer> : means only <integer> <lower bound>:<upper bound> : means all integers in the range from to <lower bound>:<upper bound>:<positive step> : means all integers in the range from to in steps of where has one of the forms <empty field> : means no lower limit * : means no lower limit <integer> : means a closed interval starting at [<integer> : also means a closed interval starting at (<integer> : means an open interval starting at Name Describe REAL The range specification is the same as with integers, except that here, no step implies a continuum of values. Note that numeric constants should be expressed as in C (e.g. 1e-10). Note also that one cannot use the Cactus types such as CCTK_REAL4 to specify the precision of the parameter; parameters always have the default precision. KEYWORD Each entry in the list of acceptable values for a keyword has the form <keyword value> :: \"<description>\" Keyword values should be enclosed in double quotes. The double quotes are mandatory if the keyword contains spaces. STRING Allowed values for strings should be specified using regular expressions. To allow any string, the regular expression \"\" should be used. (An empty regular expression matches anything.) Regular expressions and string values should be enclosed in double quotes. The double quotes are mandatory if the regular expression or the string value is empty or contains spaces. BOOLEAN No <parameter values> should be specified for a boolean parameter.","title":"The param.ccl File"},{"location":"ET/Thorn/#the-scheduleccl-file","text":"Cactus contains a rule-based scheduling system, which determines which routines, from which thorns are run in which order. A schedule configuration file consists of: Assignment statements to switch on storage for grid variables for the entire duration of program execution. Schedule blocks to schedule a subroutine from a thorn to be called at specific times during program execution in a given manner. Conditional statements for both assignment statements and schedule blocks to allow them to be processed depending on parameter values. Assignment Statements: These lines have the form: 1 STORAGE: <group>[timelevels] The storage line includes the number of timelevels to activate storage for, this number can be from 1 up to the maximum number or timelevels for the group, as specified in the defining interface.ccl file. If the maximum number of timelevels is 1 (the default), this number may be omitted. Alternatively timelevels can be the name of a parameter accessible to the thorn. The parameter name is the same as used in C routines of the thorn, fully qualified parameter names of the form thorn::parameter are not allowed. In this case 0 (zero) timelevels can be requested, which is equivalent to the STORAGE statement being absent. Schedule Blocks: 1 2 3 4 5 6 7 8 9 10 11 schedule [ GROUP ] < function name | group name > AT | IN [ AS < alias > ] [ WHILE < variable > ] [ IF < variable > ] [ BEFORE | AFTER < function name >| ( < function name > ...)] { LANG : < FORTRAN | C > OPTIONS : [ list of options ] TAGS : [ list of keyword = value definitions ] STORAGE : [ group list with timelevels ] READS : [ group list ] WRITES : [ group list ] TRIGGERS : [ group list ] SYNC : [ group list ] } \"Description of function\" Name Describe GROUP Schedule a schedule group with the same options as a schedule function. The schedule group will be created if it doesn\u2019t exist. <function name|group name> The name of a function or a schedule group to be scheduled. Function and schedule group names are case sensitive. AT|IN Each schedule item is scheduled either AT a particular scheduling bin, or IN a schedule group. AS Provides an alias for a function or schedule group which should be used for scheduling before, after or in. This can be used to provide thorn independence for other thorns scheduling functions, or schedule groups relative to this one. WHILE Executes a function or schedule group until the given variable (which must be a fully qualified integer grid scalar) has the value zero. IF Executes a function or schedule group only if the given variable (which must be a fully qualified integer grid scalar) has a non-zero value. BEFORE/AFTER Takes a function name, a function alias, a schedule group name, or a parenthesesenclosed white space-separated list of these. (Any names that are not provided by an active thorn are ignored.) Note that a single schedule block may have multiple BEFORE/AFTER clauses. Using the schedule.ccl files, thorn functions can be scheduled to run in the different timebins which are executed by the Cactus flesh. Name Describe CCTK_RECOVER_PARAMETERS Used by thorns with relevant I/O methods as the point to read parameters when recovering from checkpoint files. Grid variables are not available in this timebin. Scheduling in this timebin is special. CCTK_STARTUP Run before any grids are constructed, this is the timebin, for example, where grid independent information (e.g. output methods, reduction operators) is registered. Note that since no grids are setup at this point, grid variables cannot be used in routines scheduled here. CCTK_WRAGH This timebin is executed when all parameters are known, but before the driver thorn constructs the grid. It should only be used to set up information that is needed by the driver. CCTK_PARAMCHECK This timebin is for thorns to check the validity of parameter combinations. This bin is also executed before the grid hierarchy is made, so that routines scheduled here only have access to the global grid size and the parameters. CCTK_PREREGRIDINITIAL This timebin is used in mesh refinement settings. It is ignored for unigrid runs. This bin is executed whenever the grid hierarchy is about to change during evolution; compare CCTK_PREREGRID. Routines that decide the new grid structure should be scheduled in this bin. CCTK_POSTREGRIDINITIAL This timebin is used in mesh refinement settings. It is ignored for unigrid runs. This bin is executed whenever the grid hierarchy or patch setup has changed during evolution; see CCTK_POSTREGRID. It is, e.g. necessary to re-apply the boundary conditions or recalculate the grid points\u2019 coordinates after every changing the grid hierarchy. CCTK_BASEGRID This timebin is executed very early after a driver thorn constructs grid; this bin should only be used to set up coordinate systems on the newly created grids. CCTK_INITIAL This is the place to set up any required initial data. This timebin is not run when recovering from a checkpoint file. CCTK_POSTINITIAL This is the place to modify initial data, or to calculate data that depend on the initial data. This timebin is also not run when recovering from a checkpoint file. CCTK_POSTRESTRICTINITIAL This timebin is used only in mesh refinement settings. It is ignored for unigrid runs. This bin is executed after each restriction operation while initial data are set up; compare CCTK_POSTRESTRICT. It is, e.g. necessary to re-apply the boundary conditions after every restriction operation. CCTK_POSTPOSTINITIAL This is the place to modify initial data, or to calculate data that depend on the initial data. This timebin is executed after the recursive initialisation of finer grids if there is a mesh refinement hierarchy, and it is also not run when recovering from a checkpoint file. CCTK_RECOVER_VARIABLES Used by thorns with relevant I/O methods as the point to read in all the grid variables when recovering from checkpoint files. CCTK_POST_RECOVER_VARIABLES This timebin exists for scheduling any functions which need to modify grid variables after recovery. CCTK_CPINITIAL Used by thorns with relevant I/O methods as the point to checkpoint initial data if required. CCTK_CHECKPOINT Used by thorns with relevant I/O methods as the point to checkpoint data during the iterative loop when required. CCTK_PREREGRID This timebin is used in mesh refinement settings. It is ignored for unigrid runs. This bin is executed whenever the grid hierarchy is about to change during evolution; compare CCTK_PREREGRIDINITIAL. Routines that decide the new grid structure should be scheduled in this bin. CCTK_POSTREGRID This timebin is used in mesh refinement settings. It is ignored for unigrid runs. This bin is executed whenever the grid hierarchy or patch setup has changed during evolution; see CCTK_POSTREGRIDINITIAL. It is, e.g. necessary to re-apply the boundary conditions or recalculate the grid points\u2019 coordinates after every changing the grid hierarchy. CCTK_PRESTEP The timebin for scheduling any routines which need to be executed before any routines in the main evolution step. This timebin exists for thorn writers convenience, the BEFORE, AFTER, etc., functionality of the schedule.ccl file should allow all functions to be scheduled in the main CCTK_EVOL timebin. CCTK_EVOL The timebin for the main evolution step. CCTK_POSTRESTRICT This timebin is used only in mesh refinement settings. It is ignored for unigrid runs. This bin is executed after each restriction operation during evolution; compare CCTK_POSTRESTRICTINITIAL. It is, e.g. necessary to re-apply the boundary conditions after every restriction operation. CCTK_POSTSTEP The timebin for scheduling any routines which need to be executed after all the routines in the main evolution step. This timebin exists for thorn writers convenience, the BEFORE, AFTER, etc., functionality of the schedule.ccl file should allow all functions to be scheduled in the main CCTK_EVOL timebin. CCTK_ANALYSIS The ANALYSIS timebin is special, in that it is closely coupled with output, and routines which are scheduled here are typically only executed if output of analysis variables is required. Routines which perform analysis should be independent of the main evolution loop (that is, it should not matter for the results of a simulation whether routines in this timebin are executed or not). CCTK_TERMINATE Called after the main iteration loop when Cactus terminates. Note that sometime, in this timebin, a driver thorn should be destroying the grid hierarchy and removing grid variables. CCTK_SHUTDOWN Cactus final shutdown routines, after the grid hierarchy has been destroyed. Grid variables are no longer available. It is possible to state that the routine must run BEFORE or AFTER another routine or set of routines. It is also possible to schedule the routine under an alias name by using AS <alias name> . Name Describe LANG The code language for the function (either C or FORTRAN). No language should be specified for a schedule group. OPTIONS Schedule options are used for mesh refinement and multi-block simulations, and they determine \u201cwhere\u201d a routine executes. Possible options are: meta, meta_early, meta_late, global, global_early, global_late, level, singlemap, local, loop_meta, loop_global, loop_level, loop_singlemap, loop_local. TAGS Schedule tags. These tags must have the form keyword=value , and must be in a syntax accepted by Util_TableCreateFromString . STORAGE List of variable groups which should have storage switched on for the duration of the function or schedule group. Each group must specify how many timelevels to activate storage for, from 1 up to the maximum number for the group as specified in the defining interface.ccl file. If the maximum is 1 (the default) this number may be omitted. Alternatively timelevels can be the name of a parameter accessible to the thorn. The parameter name is the same as used in C routines of the thorn, fully qualified parameter names of the form thorn::parameter are not allowed. In this case 0 (zero) timelevels can be requested, which is equivalent to the STORAGE statement being absent. READS READS is used to declare which grid variables are read by the routine. This information is used e.g. to determine which variables need to be copied between host and device for OpenCL or CUDA kernel. This information can also be used to ensure that all variables that are read have previously been written by another routine. WRITES WRITES is used to declare which grid variables are written by the routine. This information is used e.g. to determine which variables need to be copied between host and device for OpenCL or CUDA kernel. This information can also be used to ensure that all variables that are read have previously been written by another routine. TRIGGER List of grid variables or groups to be used as triggers for causing an ANALYSIS function or group to be executed. Any schedule block for an analysis function or analysis group may contain a TRIGGER line. SYNCHRONISE List of groups to be synchronised, as soon as the function or schedule group is exited. Option names are case-insensitive. There can be several options given at the same time. Name Describe META This routine will only be called once, even if several simulations are performed at the same time. This can be used, for example, to initialise external libraries, or to set up data structures that live in global variables. META-EARLY This option is identical to to META option with the exception that the routine will be called together with the routines on the first subgrid. META-LATE This option is identical to to META option with the exception that the routine will be called together with the routines on the last subgrid. GLOBAL This routine will only be called once on a grid hierarchy, not for all subgrids making up the hierarchy. This can be used, for example, for analysis routines which use global reduction or interpolation routines, rather than the local subgrid passed to them, and hence should only be called once. GLOBAL-EARLY This option is identical to to GLOBAL option with the exception that the routine will be called together with the routines on the first subgrid. GLOBAL-LATE This option is identical to to GLOBAL option with the exception that the routine will be called together with the routines on the last subgrid. LEVEL This routine will only be called once on any \u201clevel\u201d of the grid hierarchy. That is, it will only be called once for any set of sub-grids which have the same cctk_levfac numbers. SINGLEMAP This routine will only be called once on any of the \u201cpatches\u201d that form a \u201clevel\u201d of the grid hierarchy. LOCAL This routine will be called on every \u201ccomponent\u201d. LOOP-META Loop once. LOOP-GLOBAL Loop over all simulations. LOOP-LEVEL Loop over all \u201clevels\u201d. LOOP-SINGLEMAP Loop over all \u201cpatches\u201d. LOOP-LOCAL Loop over all \u201ccomponents\u201d. Conditional Statements: Any schedule block or assignment statements can be optionally surrounded by conditional if-elseif-else constructs using the parameter data base. These can be nested, and have the general form: 1 2 3 4 5 if (<conditional-expression>) { [<assignments>] [<schedule blocks>] } <conditional-expression> can be any valid C construct evaluating to a truth value. Such conditionals are evaluated only at program startup, and are used to pick between different static schedule options. For dynamic scheduling, the SCHEDULE WHILE construction should be used.","title":"The schedule.ccl File"},{"location":"ET/Thorn/#the-configurationccl-file","text":"A configuration.ccl file defines capabilities which a thorn either provides or requires, or may use if available. Unlike implementations, only one thorn providing a particular capability may be compiled into a configuration at one time. Thus, this mechanism may be used to, for example: provide access to external libraries; provide access to functions which other thorns must call, but are too complex for function aliasing; or to split a thorn into several thorns, all of which require some common (not aliased) functions. A configuration options file can contain any number of the following sections: 1 2 3 4 5 6 PROVIDES <Capability> { SCRIPT <Configuration script> [VERSION <Version String>] LANG <Language> [OPTIONS [<option>[,<option>]...]] }","title":"The configuration.ccl File"},{"location":"ET/Visualization/","text":"gnuplot You should see a number of files with the extension .asc . These are 0-D (reductions of 3-D grid functions to scalar values) and 1-D ASCII output files that can be plotted with gnuplot. http://cactuscode.org/documentation/visualization/gnuPlot/ Plot Start gnuplot with the command: 1 gnuplot and at the gnuplot prompt type: 1 plot '<filename>.asc' using 2:3 with linespoints Python The following commands will generate a simple line plot of the data. 1 2 3 4 5 6 7 import matplotlib import numpy as np import matplotlib.pyplot as plt import os home = os . environ [ \"HOME\" ] lin_data = np . genfromtxt ( home + \"/simulations/<filepath>.asc\" ) plt . plot ( lin_data [:, 1 ], lin_data [:, 2 ]) VisIt Getting started Once the software is running, the button Open can be used to open files from the simulation. Make sure to select Open file as type: CarpetHDF5, otherwise VisIt may try to load the data using another format. If you are using the Simulation Factory to launch and manage the run, the data will be output under the directory <basedir>/<simulation name>/output-<nnnn>/<parfile name> , where <nnnn> is the number of the restart. There are essentially two types of files that can be visualised with VisIt: Files from the thorn CarpetIOHDF5 , with .h5 extension, which will be read by the CarpetHDF5 plugin in VisIt and represent the 1D, 2D, or 3D configuration of a specific field, on a number of constant-time spaces. Files from the thorn QuasiLocalMeasures , with .vtk extension, which are read natively by VisIt and represent the shape and properties of relevant 2D topological spheres, such as the apparent horizons, also at different times. Plot We first need to load the data, using the Open button and selecting the correct path for the database . We can then generate the plot by clicking Add > Pseudocolor > <filename> . If the Auto Apply feature in VisIt is not selected, we need to click on Draw to make the plot appear. VisIt comes with sixteen standard plots: Boundary, Contour, Curve, FilledBoundary, Histogram, Label, Mesh, Pseudocolor, Scatter, Streamline, Subset, Surface, Tensor, Truecolor, Vector, and Volume. Boundary and FilledBoundary Plots The Boundary plot and FilledBoundary plot are discussed together because of their similarity. Both plots concentrate on the boundaries between materials but each plot shows the boundary in a different way. Contour Plot This plot displays the location of values for scalar variables like density or pressure using lines for 2D plots and surfaces for 3D plots. Curve Plot The Curve plot displays a simple group of X-Y pair data such as that output by 1D simulations or data produced by Lineouts of 2D or 3D datasets. Curve plots are useful for visualizations where it is useful to plot 1D quantities that evolve over time. Histogram Plot The Histogram plot divides the data range of a scalar variable into a number of bins and groups the variable\u2019s values, weighted by cell area or revolved volume, into different bins. The values in each bin are then used to create a bar graph or curve that represents the distribution of values throughout the variable\u2019s data range. The Histogram plot can be used to determine where data values cluster in the range of a scalar variable. Label Plot The Label plot can display mesh information, scalar fields, vector fields, tensor fields, array variables, subset names, and material names. The Label plot is often used as a debugging device for simulation codes since it allows the user to see labels containing the exact values at the computational mesh\u2019s nodes or cell centers. Since the Label plot\u2019s job is to display labels representing the computational mesh or the fields defined on that mesh, it does not convey much information about the actual mesh geometry. Since having a Label plot by itself does not usually give enough information to understand the plotted dataset, the Label plot is almost always used with other plots. Mesh Plot The Mesh plot displays the computational mesh over which a database\u2019s variables are defined. The mesh plot is often added to the visualization window when other plots are visualized to allow individual cells to be clearly seen. Pseudocolor plot The Pseudocolor plot maps a scalar variable\u2019s data values to colors and uses the colors to \u201cpaint\u201d values onto the variable\u2019s computational mesh. The result is a clear picture of the database geometry painted with variable values that have been mapped to colors. You might try this plot first when examining a scientific database for the first time since it reveals so much information about the plotted variable. Scatter Plot The Scatter plot allows you to combine multiple scalar fields into a point mesh so you can investigate the relationships between multiple input variables. Streamline Plot The Streamline plot shows the behavior of particles in a vector field. The Streamline plot calculates the value of the vector field at seed locations, which are produced by point sources, and integrates through the vector field to create a streamline. Streamlines can be displayed as a line, a tube, or as a ribbon if you also want to show the vorticity of the vector field. Surface Plot The Surface plot takes 2D scalar databases as input and adds a height component to the variable\u2019s mesh, resulting in a height map that is then pseudocolored by the plotted variable. You might want to use this plot to examine 2D datasets because features of the plotted variable are highlighted by the height of the plot in addition to being highlighted by the plot\u2019s colors. Tensor plot The Tensor plot displays tensor variables using ellipsoid glyphs to convey information about a tensor variable\u2019s eigenvalues. Each glyph\u2019s scaling and rotation is controlled by the eigenvalues/eigenvectors of the tensor as follows: for each tensor, the eigenvalues (and associated eigenvectors) are sorted to determine the major, medium, and minor eigenvalues/eigenvectors.","title":"Visualization"},{"location":"ET/Visualization/#gnuplot","text":"You should see a number of files with the extension .asc . These are 0-D (reductions of 3-D grid functions to scalar values) and 1-D ASCII output files that can be plotted with gnuplot. http://cactuscode.org/documentation/visualization/gnuPlot/","title":"gnuplot"},{"location":"ET/Visualization/#plot","text":"Start gnuplot with the command: 1 gnuplot and at the gnuplot prompt type: 1 plot '<filename>.asc' using 2:3 with linespoints","title":"Plot"},{"location":"ET/Visualization/#python","text":"The following commands will generate a simple line plot of the data. 1 2 3 4 5 6 7 import matplotlib import numpy as np import matplotlib.pyplot as plt import os home = os . environ [ \"HOME\" ] lin_data = np . genfromtxt ( home + \"/simulations/<filepath>.asc\" ) plt . plot ( lin_data [:, 1 ], lin_data [:, 2 ])","title":"Python"},{"location":"ET/Visualization/#visit","text":"","title":"VisIt"},{"location":"ET/Visualization/#getting-started","text":"Once the software is running, the button Open can be used to open files from the simulation. Make sure to select Open file as type: CarpetHDF5, otherwise VisIt may try to load the data using another format. If you are using the Simulation Factory to launch and manage the run, the data will be output under the directory <basedir>/<simulation name>/output-<nnnn>/<parfile name> , where <nnnn> is the number of the restart. There are essentially two types of files that can be visualised with VisIt: Files from the thorn CarpetIOHDF5 , with .h5 extension, which will be read by the CarpetHDF5 plugin in VisIt and represent the 1D, 2D, or 3D configuration of a specific field, on a number of constant-time spaces. Files from the thorn QuasiLocalMeasures , with .vtk extension, which are read natively by VisIt and represent the shape and properties of relevant 2D topological spheres, such as the apparent horizons, also at different times.","title":"Getting started"},{"location":"ET/Visualization/#plot_1","text":"We first need to load the data, using the Open button and selecting the correct path for the database . We can then generate the plot by clicking Add > Pseudocolor > <filename> . If the Auto Apply feature in VisIt is not selected, we need to click on Draw to make the plot appear. VisIt comes with sixteen standard plots: Boundary, Contour, Curve, FilledBoundary, Histogram, Label, Mesh, Pseudocolor, Scatter, Streamline, Subset, Surface, Tensor, Truecolor, Vector, and Volume.","title":"Plot"},{"location":"ET/Visualization/#boundary-and-filledboundary-plots","text":"The Boundary plot and FilledBoundary plot are discussed together because of their similarity. Both plots concentrate on the boundaries between materials but each plot shows the boundary in a different way.","title":"Boundary and FilledBoundary Plots"},{"location":"ET/Visualization/#contour-plot","text":"This plot displays the location of values for scalar variables like density or pressure using lines for 2D plots and surfaces for 3D plots.","title":"Contour Plot"},{"location":"ET/Visualization/#curve-plot","text":"The Curve plot displays a simple group of X-Y pair data such as that output by 1D simulations or data produced by Lineouts of 2D or 3D datasets. Curve plots are useful for visualizations where it is useful to plot 1D quantities that evolve over time.","title":"Curve Plot"},{"location":"ET/Visualization/#histogram-plot","text":"The Histogram plot divides the data range of a scalar variable into a number of bins and groups the variable\u2019s values, weighted by cell area or revolved volume, into different bins. The values in each bin are then used to create a bar graph or curve that represents the distribution of values throughout the variable\u2019s data range. The Histogram plot can be used to determine where data values cluster in the range of a scalar variable.","title":"Histogram Plot"},{"location":"ET/Visualization/#label-plot","text":"The Label plot can display mesh information, scalar fields, vector fields, tensor fields, array variables, subset names, and material names. The Label plot is often used as a debugging device for simulation codes since it allows the user to see labels containing the exact values at the computational mesh\u2019s nodes or cell centers. Since the Label plot\u2019s job is to display labels representing the computational mesh or the fields defined on that mesh, it does not convey much information about the actual mesh geometry. Since having a Label plot by itself does not usually give enough information to understand the plotted dataset, the Label plot is almost always used with other plots.","title":"Label Plot"},{"location":"ET/Visualization/#mesh-plot","text":"The Mesh plot displays the computational mesh over which a database\u2019s variables are defined. The mesh plot is often added to the visualization window when other plots are visualized to allow individual cells to be clearly seen.","title":"Mesh Plot"},{"location":"ET/Visualization/#pseudocolor-plot","text":"The Pseudocolor plot maps a scalar variable\u2019s data values to colors and uses the colors to \u201cpaint\u201d values onto the variable\u2019s computational mesh. The result is a clear picture of the database geometry painted with variable values that have been mapped to colors. You might try this plot first when examining a scientific database for the first time since it reveals so much information about the plotted variable.","title":"Pseudocolor plot"},{"location":"ET/Visualization/#scatter-plot","text":"The Scatter plot allows you to combine multiple scalar fields into a point mesh so you can investigate the relationships between multiple input variables.","title":"Scatter Plot"},{"location":"ET/Visualization/#streamline-plot","text":"The Streamline plot shows the behavior of particles in a vector field. The Streamline plot calculates the value of the vector field at seed locations, which are produced by point sources, and integrates through the vector field to create a streamline. Streamlines can be displayed as a line, a tube, or as a ribbon if you also want to show the vorticity of the vector field.","title":"Streamline Plot"},{"location":"ET/Visualization/#surface-plot","text":"The Surface plot takes 2D scalar databases as input and adds a height component to the variable\u2019s mesh, resulting in a height map that is then pseudocolored by the plotted variable. You might want to use this plot to examine 2D datasets because features of the plotted variable are highlighted by the height of the plot in addition to being highlighted by the plot\u2019s colors.","title":"Surface Plot"},{"location":"ET/Visualization/#tensor-plot","text":"The Tensor plot displays tensor variables using ellipsoid glyphs to convey information about a tensor variable\u2019s eigenvalues. Each glyph\u2019s scaling and rotation is controlled by the eigenvalues/eigenvectors of the tensor as follows: for each tensor, the eigenvalues (and associated eigenvectors) are sorted to determine the major, medium, and minor eigenvalues/eigenvectors.","title":"Tensor plot"},{"location":"ET/parameter/","text":"Flesh The Cactus flesh knows about everything in schedule.ccl files, and handles sorting scheduled routines into an order which is consistent with the BEFORE and AFTER clauses in all the schedule groups. The flesh also handles repeatedly calling scheduled routines which are scheduled with a WHILE clause. In addition, the flesh determines when storage is turned on/off for grid scalars, functions, and arrays and when grid arrays and functions are synchronised, based on the STORAGE: and SYNC: statements in schedule blocks. 1 2 # Flesh parameters Cactus::<Flesh parameters> = <Value> The default value is shown in square brackets, while curly braces show allowed parameter values. Value Describe Cactus::cctk_run_title Description of this simulation [\"\"] Cactus::cctk_full_warnings Give detailed information for each warning statement [yes] Cactus::highlight_warning_messages Highlight CCTK warning messages [yes] Cactus::cctk_timer_output Give timing information [off] {off, full} Cactus::allow_mixeddim_gfs Allow use of GFs from different dimensions [no] Cactus::cctk_brief_output Give only brief output [no] Cactus::cctk_show_banners Show any registered banners for the different thorns [yes] Cactus::cctk_show_schedule Print the scheduling tree to standard output [yes] Cactus::cctk_strong_param_check Die on parameter errors in CCTK_PARAMCHECK [yes] Cactus::recovery_mode How to behave when recovering from a checkpoint [strict] {strict, relaxed} Cactus::info_format Specifies the content and format of CCTK_INFO()/CCTK_VINFO messages. [basic] {\"basic\", \"numeric time stamp\", \"human-readable time stamp\", \"full time stamp\"} Cactus::terminate Condition on which to terminate evolution loop [iteration] {never, iteration, time, runtime, any, all} Cactus::cctk_final_time Final time for evolution, overridden by cctk_itlast unless it is positive [-1.0] Cactus::cctk_initial_time Initial time for evolution [0.0] Cactus::cctk_itlast Final iteration number [10] Cactus::max_runtime Terminate evolution loop after a certain elapsed runtime (in minutes); set to zero to disable this termination condition [0] Cactus::terminate_next Terminate on next iteration ? [no] Coordinate Systems CoordBase The CoordBase thorn provides a method of registering coordinate systems and their properties. The data describing coordinate systems are held on Cactus key-value tables. Thorns which provide coordinates will inherit from CoordBase. The coordinate values themselves can be specified in a number of ways, depending on the nature of the coordinate system. This way symmetries of the coordinates on the computational grid can be exploited to minimize memory consumption. Since computations performed with Cactus are done on a discrete lattice, only a discrete set of coordinate values are used for any coordinate system. The symmetries of how the coordinate values vary on the grid points make coordinates fall into three types: uniform, nonuniform, and warped. For a uniform coordinate system, it is sufficient to specify the origin and spacing for a uniform coordinate. A nonuniform coordinate can be specified with a 1D grid variable. A warped coordinate system will always need a nD grid variable. FMR and AMR will need an nD grid variable to specify the coordinate values. CoordBase provides a way for specifying the extent of the simulation domain that is independent of the actual coordinate and symmetry thorns. This is necessary because the size of the physical domain is not necessarily the same as the size of the computational grid, which is usually enlarged by symmetry zones and/or boundary zones. CoordBase also provides a way for specifying the discretisation of the boundary that is independent of the actual boundary thorns. This defines the locations of the boundary points and thus the extent of the computational grid. When it is necessary to increase the number of boundary points, then boundary_size_x_lower is the only parameter that needs to be changed. The boolean parameter boundary_internal_x_lower specifies whether the boundary points extend inwards at the lower x face. The boundary points should either be staggered about the physical boundary, or the last boundary point should be located exactly on the physical boundary. This is specified by the boolean parameter boundary_staggered_x_lower . The integer parameter boundary_shiftout_x_lower can be used to shift the boundary points outwards (or inwards with negative values) by multiples of the grid spacing. Parameter Key Defaults Describe Option domainsize \"minmax\" Domain size specification \"minmax\":: \"lower and upper boundary locations\"; \"extent\":: \"coordinate extent\"; \"spacing\" :: \"grid spacing and number of grid cells\" spacing \"gridspacing\" Grid spacing specification \"gridspacing\" :: \"grid spacing\"; \"numcells\":: \"number of grid cells\" zero_origin_x \"no\" Is the lower boundary located at x=0? xmin 0.0 Location of lower x boundary (:) :: \"\" xmax 1.0 Location of upper x boundary (:) :: \"\" xextent 1.0 Domain extent in x direction (0:) :: \"\" dx 1.0 Grid spacing in x direction (0:) :: \"\" ncells_x 1 Number of grid cells in x direction 0: :: \"\" zero_origin_y \"no\" Is the lower boundary located at y=0? ymin 0.0 Location of lower y boundary (:) :: \"\" ymax 1.0 Location of upper y boundary (:) :: \"\" yextent 1.0 Domain extent in y direction (0:) :: \"\" dy 1.0 Grid spacing in y direction (0:) :: \"\" ncells_y 1 Number of grid cells in y direction 0: :: \"\" zero_origin_z \"no\" Is the lower boundary located at z=0? zmin 0.0 Location of lower z boundary (:) :: \"\" zmax 1.0 Location of upper z boundary (:) :: \"\" zextent 1.0 Domain extent in z direction (0:) :: \"\" dz 1.0 Grid spacing in z direction (0:) :: \"\" ncells_z 1 Number of grid cells in z direction 0: :: \"\" boundary_size_x_lower 1 Boundary zones at the lower x face 0: :: \"\" boundary_internal_x_lower \"no\" Do the boundary points extend inwards at the lower x face? boundary_staggered_x_lower \"no\" Is the boundary is staggered about the grid points at the lower x face? boundary_shiftout_x_lower 0 Offset between the boundary location and the first boundary point at the lower x face : :: \"when not staggered: use 0 for an open, 1 for a closed manifold\" boundary_size_x_upper 1 Boundary zones at the upper x face 0: :: \"\" boundary_internal_x_upper \"no\" Do the boundary points extend inwards at the upper x face? boundary_staggered_x_upper \"no\" Is the boundary is staggered about the grid points at the upper x face? boundary_shiftout_x_upper 0 Offset between the boundary location and the first boundary point at the upper x face : :: \"when not staggered: use 0 for an open, 1 for a closed manifold\" boundary_size_y_lower 1 Boundary zones at the lower y face 0: :: \"\" boundary_internal_y_lower \"no\" Do the boundary points extend inwards at the lower y face? boundary_staggered_y_lower \"no\" Is the boundary is staggered about the grid points at the lower y face? boundary_shiftout_y_lower 0 Offset between the boundary location and the first boundary point at the lower y face : :: \"when not staggered: use 0 for an open, 1 for a closed manifold\" boundary_size_y_upper 1 Boundary zones at the upper y face 0: :: \"\" boundary_internal_y_upper \"no\" Do the boundary points extend inwards at the upper y face? boundary_staggered_y_upper \"no\" Is the boundary is staggered about the grid points at the upper y face? boundary_shiftout_y_upper 0 Offset between the boundary location and the first boundary point at the upper y face : :: \"when not staggered: use 0 for an open, 1 for a closed manifold\" boundary_size_z_lower 1 Boundary zones at the lower z face 0: :: \"\" boundary_internal_z_lower \"no\" Do the boundary points extend inwards at the lower z face? boundary_staggered_z_lower \"no\" Is the boundary is staggered about the grid points at the lower z face? boundary_shiftout_z_lower 0 Offset between the boundary location and the first boundary point at the lower z face : :: \"when not staggered: use 0 for an open, 1 for a closed manifold\" boundary_size_z_upper 1 Boundary zones at the upper z face 0: :: \"\" boundary_internal_z_upper \"no\" Do the boundary points extend inwards at the upper z face? boundary_staggered_z_upper \"no\" Is the boundary is staggered about the grid points at the upper z face? boundary_shiftout_z_upper 0 Offset between the boundary location and the first boundary point at the upper z face : :: \"when not staggered: use 0 for an open, 1 for a closed manifold\" CartGrid3D This thorn sets up a Cartesian grid, for a given domain. It also provides a method for registering symmetries of Grid Functions across the grid axes, and a call for applying symmetry boundary conditions. Specifying the Grid Size, Range, and Spacing CartGrid3D provides several different methods for setting up the integer grid size, floating-point grid spacing, and floating-point grid range. You specify which method to use, with the grid::type parameter. Value Describe byrange You specify the x, y, and z grid ranges, either with separate grid::xmin , grid::xmax , grid::ymin , grid::ymax , grid::zmin , and grid::zmax parameters, or with the grid::xyzmin and grid::xyzmax parameters. box This is a special case of grid::type = \"byrange\" with the grid ranges hard-wired to grid::xyzmin = -0.5 and grid::xyzmax = +0.5 . byspacing You specify the x, y, and z grid spacings, either with separate grid::dx , grid::dy , and grid::dz parameters, or with the grid::dxyz parameter. grid::avoid_originx This is a Boolean parameter; if set to true then the grid will be \u201chalf-centered\u201d across x = 0 x = 0 , ie there will be grid points at \\ldots, x=-\\frac{3}{2} \\Delta x, x=-\\frac{1}{2} \\Delta x, x=+\\frac{1}{2} \\Delta x, x=+\\frac{3}{2} \\Delta x, \\ldots \\ldots, x=-\\frac{3}{2} \\Delta x, x=-\\frac{1}{2} \\Delta x, x=+\\frac{1}{2} \\Delta x, x=+\\frac{3}{2} \\Delta x, \\ldots , but not at x = 0 x = 0 . Specifying the Grid Symmetry CartGrid3D allows you to specify the grid symmetry with the grid::domain parameter. Value Describe full There are no symmetries. bitant The grid includes only the z \\geq 0 z \\geq 0 half-space; there is a reflection symmetry across the z = 0 z = 0 plane. quadrant The grid includes only the \\{x \\geq 0, y \\geq 0\\} \\{x \\geq 0, y \\geq 0\\} quadrant. ; there is a reflection symmetry across both the x = 0 x = 0 plane and the y = 0 y = 0 plane. octant The grid includes only the \\{x \\geq 0, y \\geq 0, z \\geq 0\\} \\{x \\geq 0, y \\geq 0, z \\geq 0\\} octant; there is a reflection symmetry across each of the x = 0 x = 0 plane, the y = 0 y = 0 plane and the z = 0 z = 0 plane. Parameter Key Defaults Describe Option no_origin \"yes\" DEPRECATED: Don't place grid points on the coordinate origin/axes : :: \"\" no_originx \"yes\" DEPRECATED: Don't place grid points on the x-coordinate origin/axes : :: \"\" no_originy \"yes\" DEPRECATED: Don't place grid points on the y-coordinate origin/axes : :: \"\" no_originz \"yes\" DEPRECATED: Don't place grid points on the z-coordinate origin/axes : :: \"\" avoid_originx \"yes\" Don't place grid points on the x-coordinate origin/axes : :: \"\" avoid_originy \"yes\" Don't place grid points on the y-coordinate origin/axes : :: \"\" avoid_originz \"yes\" Don't place grid points on the z-coordinate origin/axes : :: \"\" avoid_origin \"yes\" Don't place grid points on the coordinate origin/axes : :: \"\" register_default_coordinate_systems \"yes\" register cartnd as the default coordinate systems dx 0.3 Coarse grid spacing in x-direction 0: :: \"Positive\" dy 0.3 Coarse grid spacing in y-direction 0: :: \"Positive\" dz 0.3 Coarse grid spacing in z-direction 0: :: \"Positive\" dxyz 0.0 Coarse grid spacing in x,y,z-directions 0: :: \"Positive\" xmin -1.0 Coordinate minimum in x-direction : :: \"Anything\" ymin -1.0 Coordinate minimum in y-direction : :: \"Anything\" zmin -1.0 Coordinate minimum in z-direction : :: \"Anything\" xyzmin -424242 Coordinate minimum in x,y,z-directions : :: \"Anything\" xmax 1.0 Coordinate maximum in x-direction : :: \"Anything\" ymax 1.0 Coordinate maximum in y-direction : :: \"Anything\" zmax 1.0 Coordinate maximum in z-direction : :: \"Anything\" xyzmax -424242 Coordinate maximum in xyz-directions : :: \"Anything\" type \"box\" Grid type \"box\":: \"Box grid from -0.5 to 0.5\"; \"byrange\":: \"Specify min and max values\"; \"byspacing\":: \"Specify grid spacings\"; \"coordbase\":: \"Get specification from CoordBase\"; \"multipatch\" :: \"Get specification from MultiPatch\" domain \"full\" Domain type \"octant\" :: \"Use an octant about the origin\"; \"quadrant\" :: \"Use a quadrant in x-y plane\"; \"quadrant_reflect_rotate\" :: \"Use a quadrant with rotation symmetry about an axis\"; \"bitant\" :: \"Use a bitant about the x-y plane\"; \"bitant_rotate\" :: \"Use a bitant with rotation symmetry about an axis\"; \"full\" :: \"Use the full domain\" bitant_plane \"xy\" Plane defining bitant domain \"xy\" :: \"xy-plane\"; \"xz\" :: \"xz-plane\"; \"yz\" :: \"yz-plane\" quadrant_direction \"z\" Direction defining quadrant domain \"x\":: \"x-direction\"; \"y\":: \"y-direction\"; \"z\":: \"z-direction\" rotation_axis \"z\" Axis about which the rotation symmetry is to be applied \"x\":: \"x-axis\"; \"y\":: \"y-axis\"; \"z\":: \"z-axis\" symmetry_xmin \"no\" Symmetry boundary condition on lower x boundary : :: \"Logical\" symmetry_ymin \"no\" Symmetry boundary condition on lower y boundary : :: \"Logical\" symmetry_zmin \"no\" Symmetry boundary condition on lower z boundary : :: \"Logical\" symmetry_xmax \"no\" Symmetry boundary condition on upper x boundary : :: \"Logical\" symmetry_ymax \"no\" Symmetry boundary condition on upper y boundary : :: \"Logical\" symmetry_zmax \"no\" Symmetry boundary condition on upper z boundary : :: \"Logical\" set_coordinate_ranges_on \"all On which grids to set the coordinate ranges \"all grids\" :: \"set ranges in local mode, on the coarsest level\"; \"all maps\":: \"set ranges in singlemap mode, on the coarsest level\"; \"first level\" :: \"set ranges in level mode, on the first level\" SymBase Provide generic handling of symmetries for grids and grid arrays. Parameter Key Defaults Describe Option verbose \"yes\" Output symmetry boundary face descriptions after registration Coordinates Llama is a multipatch infrastructure for Cactus. This thorn provides definition of patch systems and coordinates. Parameter Key Defaults Describe Option coordinate_system \"Cartesian\" Available patch systems \"Cartesian\" :: \"Cartesian coordinates (unit Jacobian)\"; \"TwoPatchCartesian\" :: \"Two Cartesian patches with one common face\"; \"TwoPatchDistorted\" :: \"One Cartesian and one distorted patch, overlapping\"; \"Thornburg04\" :: \"Jonathan's AHFinderDirect coordinates\"; \"Thornburg13\" :: \"Jonathan's AHFinderDirect coordinates as a 13 patch system (Do not use with radial stretch)\"; \"Thornburg04nc\" :: \"Jonathan's system without a central Cartesian patch\"; \"CylinderInBox\" :: \"A hollow (spherical) cylinder in a (Cartesian) box\"; \"Sphere+Column\" :: \"Excision type overlapping sphere + column grid\"; \"Cylinder+Column\" :: \"Cylindrical grid + central column\" symmetry \"full\" Select a symmetry \"full\":: \"full domain\"; \"+z bitant\" :: \"bitant mode (positive z)\"; \"+xyz octant\" :: \"octant mode (positive xyz)\" verbose \"yes\" Output information periodically store_jacobian \"yes\" Numerically evaluate and store the transformation da i/dx k (a: local, x: global) store_inverse_jacobian \"no\" Numerically evaluate and store the transformation dx i/da k (a: local, x: global) store_jacobian_derivative \"yes\" Store the derivative of the Jacobian d 2[global]/d[local] 2 store_volume_form \"no\" Store determinant of Jacobian patch_boundary_size 1 Number of inter-patch boundary points which are filled via interpolation (should be >= nghostzones) 0: :: \"\" stagger_patch_boundaries \"no\" Stagger the grid at the inter-patch boundaries? additional_overlap_size 0 Additional overlap between patches; this overlap is evolved, not interpolated 0: :: \"\" register_symmetry \"yes\" Register patch boundaries as symmetries outer_boundary_size 1 Number of outer boundary points 0: :: \"\" internal_outer_boundaries \"no\" Do the outer boundary points extend inwards? stagger_outer_boundaries \"no\" Stagger the grid at the outer boundaries shiftout_outer_boundaries 0 Offset between the boundary location and the first outer boundary point : :: \"\" additional_symmetry_size 0 Additional shiftout for symmetry boundaries 0:1 :: \"Must be 0 for staggered boundaries (cell-centered AMR); otherwise 1\" nMonteCarloParticles 500000 Number of Monte-Carlo particles for determining fraction of cells that are on the nominal grid. This is used for the computation of the volume form. 0::: \"the larger the better\" MonteCarloSeed 1 A seed for random number generator to get Monte Carlo particle distribution. 0::: \"Something positive\" ncells_x 10 Number of cells in the x direction 0: :: \"\" ncells_y 10 Number of cells in the x direction 0: :: \"\" ncells_z 10 Number of cells in the x direction 0: :: \"\" patch_xmin 0.0 xmin for the patch : :: \"\" patch_ymin -0.5 ymin for the patch : :: \"\" patch_zmin -0.5 zmin for the patch : :: \"\" patch_xmax 1.0 xmin for the patch : :: \"\" patch_ymax 0.5 ymin for the patch : :: \"\" patch_zmax 0.5 zmin for the patch : :: \"\" patch_one_ncells_x 10 Number of cells in the x direction for patch one 0: :: \"\" patch_one_ncells_y 10 Number of cells in the y direction for patch one 0: :: \"\" patch_one_ncells_z 10 Number of cells in the z direction for patch one 0: :: \"\" patch_one_xmin 0.0 xmin for patch one : :: \"\" patch_one_ymin -0.5 ymin for patch one : :: \"\" patch_one_zmin -0.5 zmin for patch one : :: \"\" patch_one_xmax 1.0 xmin for patch one : :: \"\" patch_one_ymax 0.5 ymin for patch one : :: \"\" patch_one_zmax 0.5 zmin for patch one : :: \"\" patch_two_ncells_x 10 Number of cells in the x direction for patch two 0: :: \"\" patch_two_ncells_y 10 Number of cells in the y direction for patch two 0: :: \"\" patch_two_ncells_z 10 Number of cells in the z direction for patch two 0: :: \"\" patch_two_xmin -1.0 xmin for patch two : :: \"\" patch_two_ymin -0.5 ymin for patch two : :: \"\" patch_two_zmin -0.5 zmin for patch two : :: \"\" patch_two_xmax 0.0 xmin for patch two : :: \"\" patch_two_ymax 0.5 ymin for patch two : :: \"\" patch_two_zmax 0.5 zmin for patch two : :: \"\" h_cartesian 0.0 Inner cube resolution 0: :: \"positive\" h_radial 0.0 Radial resolution 0: :: \"positive\" sphere_inner_radius 0.0 Inner radius for the spherical grids 0: :: \"positive\" sphere_outer_radius 0.0 Location of the physical outer boundary. 0: :: \"positive\" n_angular 0 Number of grid cells in the angular directions on the outer grids 0::2 :: \"even numbers required when bitant symmetry is used with non-staggered boundaries\"; 1::2 :: \"odd numbers required when bitant symmetry is used with non-staggered boundaries\" h_radial_inner 0.0 Radial resolution for patches 1-6 of Thornburg13 0: :: \"positive\" h_radial_outer 0.0 Radial resolution for patches 7-13 of Thornburg13 0: :: \"positive\" sphere_medium_radius 0.0 Medium radius for the 13 patch system spherical grids 0: :: \"positive\" n_angular_inner 0 Number of gridpoints in angular directions on the patches 1-6 0: :: \"positive\" n_angular_outer 0 Number of gridpoints in angular directions on the patches 7-13 0: :: \"positive\" cubical_inner_boundary \"no\" give the inner boundary a cubical shape radial_stretch \"no\" Stretch the radial coordinate stretch_rmin_1 1e10 Inner radius of first stretching region 0: :: \"positive\" stretch_rmax_1 2e10 Outer radius of first stretching region 0: :: \"positive\" h_radial_1 -1 Intended radial resolution of the first stretched domain :: \"negative turns off stretching\" box_radius 3.0 Half-size of Cartesian box 0: :: \"\" cylinder_radius 1.0 Inner radius of cylinder 0: :: \"\" transition_radius 2.0 Transition radius between box and cylinder (0: :: \"\" theta_min 10 Minimal polar angle to cover by the spherical grid patch, in degrees (0:90) :: \"positive please\" n_angular_phi 40 Number of angular points in the phi direction 0: :: \"positive\" n_angular_theta 10 Number of angular points in the theta direction 0: :: \"positive\" n_xy 10 Number of points in xy-direction on the column patches 0: :: \"positive\" cylinder_inner_radius 1.0 Inner radius of the cylinder 0: :: \"\" cylinder_outer_radius 2.0 Outer radius of the cylinder 0: :: \"\" cylinder_zmin -2.0 Minimum z for cylinder and column : :: \"\" cylinder_zmax 2.0 Maximum z for cylinder and column : :: \"\" h_z 0.1 Spacing in z direction 0: :: \"\" Time Integration Time Calculates the timestep used for an evolution. Description The method is chosen using the keyword parameter time::timestep method. given The timestep is fixed to the value of the parameter time::timestep . courant_static Calculates the timestep once at the start of the simulation, based on a simple courant type condition using the spatial gridsizes and the parameter time::dtfac . \\Delta t=\\operatorname{dt} \\mathrm{fac} * \\min \\left(\\Delta x^{i}\\right) \\Delta t=\\operatorname{dt} \\mathrm{fac} * \\min \\left(\\Delta x^{i}\\right) Note that it is up to the user to custom dtfac to take into account the dimension of the space being used, and the wave speed. - courant_speed The timestep being set before each iteration using the spatial dimension of the grid, the spatial grid sizes, the parameter courant_fac and the grid variable courant_wave_speed . The algorithm used is \\Delta t=\\operatorname{courant}\\_ \\mathrm{fac} * \\min \\left(\\Delta x^{i}\\right) / \\mathrm{courant}\\_\\mathrm{wave}\\_ \\text { speed } / \\sqrt{\\mathrm{dim}} \\Delta t=\\operatorname{courant}\\_ \\mathrm{fac} * \\min \\left(\\Delta x^{i}\\right) / \\mathrm{courant}\\_\\mathrm{wave}\\_ \\text { speed } / \\sqrt{\\mathrm{dim}} For this algorithm to be successful, the variable courant_wave_speed must have been set by some thorn to the maximum propagation speed on the grid before this thorn sets the timestep, - courant_time the timestep is chosen using \\Delta t=\\operatorname{courant}\\_ \\mathrm{fac} * \\mathrm{courant}\\_\\mathrm{min}\\_ \\text { time } / \\sqrt{\\mathrm{dim}} \\Delta t=\\operatorname{courant}\\_ \\mathrm{fac} * \\mathrm{courant}\\_\\mathrm{min}\\_ \\text { time } / \\sqrt{\\mathrm{dim}} where the grid variable courant_min_time must be set by some thorn to the minimum time for a wave to cross a gridzone before this thorn sets the timestep, Parameter Key Defaults Describe Option timestep_method \"courant_static\" Method for calculating timestep \"given\":: \"Use given timestep\"; \"courant_static\" :: \"Courant condition at BASEGRID (using dtfac)\"; \"courant_speed\":: \"Courant condition at POSTSTEP (using wavespeed and courant_fac)\"; \"courant_time\" :: \"Courant condition at POSTSTEP (using min time and courant_fac)\" timestep_outonly \"no\" Don't set a dynamic timestep, just output what it would be timestep 0.0 Absolute value for timestep : :: \"Could be anything\" dtfac 0.5 The standard timestep condition dt = dtfac*max(delta_space) 0: :: \"For positive timestep\"; :0 :: \"For negative timestep\" courant_fac 0.9 The courant timestep condition dt = courant_fac*max(delta_space)/speed/sqrt(dim) 0: :: \"For positive timestep\"; :0 :: \"For negative timestep\" timestep_outevery 1 How often to output courant timestep 1: :: \"Zero means no output\" verbose \"no\" Give selective information about timestep setting Examples 1 2 3 4 5 6 7 8 9 # Fixed Value Timestep time::timestep_method = \"given\" time::timestep = 0.1 # Calculate Static Timestep Based on Grid Spacings. The following parameters set the timestep to be 0.25 grid::dx grid::dy grid::dz time::timestep_method = \"courant_static\" time::dtfac = 0.5 MoL This thorn provides generic time integrators. Description The Method of Lines (MoL) converts a (system of) partial differential equation(s) into an ordinary differential equation containing some spatial differential operator. \\partial_{t} \\mathbf{q}+\\mathbf{A}^{i}(\\mathbf{q}) \\partial_{i} \\mathbf{B}(\\mathbf{q})=\\mathbf{s}(\\mathbf{q}) \\partial_{t} \\mathbf{q}+\\mathbf{A}^{i}(\\mathbf{q}) \\partial_{i} \\mathbf{B}(\\mathbf{q})=\\mathbf{s}(\\mathbf{q}) Given this separation of the time and space discretizations, well known stable ODE integrators such as Runge-Kutta can be used to do the time integration. The keyword MoL::ODE_Method chooses between the different methods. To switch between the different types of generic methods there is also the keyword MoL::Generic_Type . The parameter MoL::MoL_Intermediate_Steps controls the number of intermediate steps for the ODE solver. For the generic Runge-Kutta solvers it controls the order of accuracy of the method. For the ICN methods this parameter controls the number of iterations taken, which does not check for stability. The parameter MoL::MoL_Num_Scratch_Levels controls the amount of scratch space used. Time evolution methods provided by MoL The standard \"ICN\" $$ \\begin{aligned} \\mathbf{q}^{(0)} &=\\mathbf{q}^{n} \\ \\mathbf{q}^{(i)} &=\\mathbf{q}^{(0)}+\\frac{\\Delta t}{2} \\mathbf{L}\\left(\\mathbf{q}^{(i-1)}\\right), \\quad i=1, \\ldots, N-1 \\ \\mathbf{q}^{(N)} &=\\mathbf{q}^{(N-1)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(N-1)}\\right) \\ \\mathbf{q}^{n+1} &=\\mathbf{q}^{(N)} \\end{aligned} $$ he \u201caveraging\u201d ICN method \"ICN-avg\" instead calculates intermediate steps before averaging $$ \\begin{aligned} \\mathbf{q}^{(0)} &=\\mathbf{q}^{n} \\ \\tilde{\\mathbf{q}}^{(i)} &=\\frac{1}{2}\\left(\\mathbf{q} {(i)}+\\mathbf{q} {n}\\right), \\quad i=0, \\ldots, N-1 \\ \\mathbf{q}^{(i)} &=\\mathbf{q}^{(0)}+\\Delta t \\mathbf{L}\\left(\\tilde{\\mathbf{q}}^{(N-1)}\\right) \\ \\mathbf{q}^{n+1} &=\\mathbf{q}^{(N)} \\end{aligned} $$ The Runge-Kutta methods are those typically used in hydrodynamics Explicitly the first order method is the Euler method: $$ \\begin{aligned} \\mathbf{q}^{(0)} &=\\mathbf{q}^{n} \\ \\mathbf{q}^{(1)} &=\\mathbf{q}^{(0)}+\\Delta t \\mathbf{L}\\left(\\tilde{\\mathbf{q}}^{(0)}\\right) \\ \\mathbf{q}^{n+1} &=\\mathbf{q}^{(1)} \\end{aligned} $$ The second order method is: $$ \\begin{aligned} \\mathbf{q}^{(0)} &=\\mathbf{q}^{n} \\ \\mathbf{q}^{(1)} &=\\mathbf{q}^{(0)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(0)}\\right) \\ \\mathbf{q}^{(2)} &=\\frac{1}{2}\\left(\\mathbf{q} {(0)}+\\mathbf{q} {(1)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(1)}\\right)\\right) \\ \\mathbf{q}^{n+1} &=\\mathbf{q}^{(2)} \\end{aligned} $$ The third order method is: $$ \\begin{aligned} \\mathbf{q}^{(0)} &=\\mathbf{q}^{n} \\ \\mathbf{q}^{(1)} &=\\mathbf{q}^{(0)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(0)}\\right) \\ \\mathbf{q}^{(2)} &=\\frac{1}{4}\\left(3 \\mathbf{q} {(0)}+\\mathbf{q} {(1)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(1)}\\right)\\right) \\ \\mathbf{q}^{(3)} &=\\frac{1}{3}\\left(\\mathbf{q}^{(0)}+2 \\mathbf{q}^{(2)}+2 \\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(2)}\\right)\\right) \\ \\mathbf{q}^{n+1} &=\\mathbf{q}^{(3)} \\end{aligned} $$ The fourth order method, which is not strictly TVD, is: $$ \\begin{aligned} \\mathbf{q}^{(0)} &=\\mathbf{q}^{n} \\ \\mathbf{q}^{(1)} &=\\mathbf{q}^{(0)}+\\frac{1}{2} \\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(0)}\\right) \\ \\mathbf{q}^{(2)} &=\\mathbf{q}^{(0)}+\\frac{1}{2} \\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(1)}\\right) \\ \\mathbf{q}^{(3)} &=\\mathbf{q}^{(0)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(2)}\\right) \\ \\mathbf{q}^{n+1} &=\\frac{1}{6}\\left(-2 \\mathbf{q}^{(0)}+2 \\mathbf{q}^{(1)}+4 \\mathbf{q}^{(2)}+2 \\mathbf{q}^{(3)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(3)}\\right)\\right) \\ \\mathbf{q}^{n+1} &=\\mathbf{q}^{(4)} \\end{aligned} $$ Parameter Key Defaults Describe Option MoL_Num_Evolved_Vars 0 The maximum number of variables to be evolved by MoL (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Num_Evolved_Vars_Slow 0 The maximum number of 'slow' variables to be evolved by MoL (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Num_Constrained_Vars 0 The maximum number of constrained variables with timelevels that MoL needs to know about (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Num_SaveAndRestore_Vars 0 The maximum number of variables to be evolved outside of MoL but that MoL needs to know about (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Max_Evolved_Array_Size 0 The maximum total size of any grid arrays to be evolved 0: :: \"Anything non negative. Accumulated by other thorns\" MoL_Num_ArrayEvolved_Vars 0 The maximum number of array variables to be evolved by MoL (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Num_ArrayConstrained_Vars 0 The maximum number of array constrained variables with timelevels that MoL needs to know about (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Num_ArraySaveAndRestore_Vars 0 The maximum number of array variables to be evolved outside of MoL but that MoL needs to know about (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Num_Scratch_Levels 0 Number of scratch levels required by the ODE method 0: :: \"Anything non negative\" ODE_Method \"ICN\" The ODE method use by MoL to do time integration \"Generic\" :: \"Generic Shu-Osher Runge-Kutta type\"; \"ICN\" :: \"Iterative Crank Nicholson\"; \"ICN-avg\" :: \"Iterative Crank Nicholson with averaging\"; \"Euler\" :: \"Euler\"; \"RK2\" :: \"Efficient RK2\"; \"RK2-central\" :: \"Central RK2\"; \"RK3\" :: \"Efficient RK3\"; \"RK4\" :: \"Efficient RK4\"; \"RK45\":: \"RK45 (Fehlberg) with error estimation\"; \"RK45CK\":: \"RK45CK (Cash-Karp) with error estimation\"; \"RK65\":: \"RK65 with error estimation\"; \"RK87\":: \"RK87 with error estimation\"; \"AB\":: \"Adams-Bashforth\"; \"RK2-MR-2:1\":: \"2 nd order 2:1 multirate RK scheme based on RK2 due to Schlegel et al 2009. This requires init_RHS_zero='no'.\"; \"RK4-MR-2:1\":: \"3 rd order 2:1 multirate RK scheme based on RK43 due to Schlegel et al 2009. This requires init_RHS_zero='no'.\"; \"RK4-RK2\" :: \"RK4 as fast method and RK2 as slow method\" Generic_Type \"RK\" If using the generic method, which sort \"RK\" :: \"One of the standard TVD Runge-Kutta methods\"; \"ICN\" :: \"Iterative Crank Nicholson as a generic method\"; \"Table\" :: \"Given from the generic method descriptor parameter\"; \"Classic RK3\" :: \"Efficient RK3 - classical version\" ICN_avg_theta 0.5 theta of averaged ICN method, usually 0.5 0:1 :: \"0 <= theta <= 1\" ICN_avg_swapped \"no\" Use swapped averages in ICN method? AB_Type \"1\" If using the the AB method, which sort \"1\" :: \"same as forward Euler\"; \"2\" :: \"second order\"; \"3\" :: \"third order\"; \"4\" :: \"fourth order\"; \"5\" :: \"fifth order\" AB_initially_reduce_order \"yes\" Reduce order of accuracy initially so that no past timelevels of initial data are required MoL_Intermediate_Steps 3 Number of intermediate steps taken by the ODE method 1: :: \"Anything greater than 1\" MoL_Memory_Always_On \"yes\" Do we keep the scratch arrays allocated all the time? MoL_Tiny 1.e-15 Effective local machine zero; required by generic solvers 0: :: \"Defaults to 1.e-15\" initial_data_is_crap \"no\" If the initial data routine fails to set up the previous time levels, copy the current backwards run_MoL_PostStep_in_Post_Recover_Variables \"yes\" Schedule the PostStep parts after recovery so that symmetries are automatically done correctly. set_ID_boundaries \"yes\" Should boundaries be overwritten (via synchronization, prolongation, boundary conditions) by MoL? Generic_Method_Descriptor \"GenericIntermediateSteps A string used to create a table containing the description of the generic method \".\":: \"Should contain the Alpha and Beta arrays, and the number of intermediate steps\" MoL_NaN_Check \"no\" Should the RHS GFs be checked for NaNs? disable_prolongation \"yes\" If Mesh refinement is enabled should we use buffer zones in intermediate steps? skip_initial_copy \"no\" Skip initial copy from previous to current time level init_RHS_zero \"yes\" Initialise the RHS to zero adaptive_stepsize \"no\" Choose the time step size adaptively maximum_absolute_error 1.0e-6 Maximum allowed absolute error for adaptive stepsize control 0.0:) :: \"\" maximum_relative_error 1.0e-6 Maximum allowed relative error for adaptive stepsize control 0.0:) :: \"\" RHS_error_weight 1.0 Weight of the RHS in the relative error calculation 0.0: :: \"should be between zero and one\" safety_factor 0.9 Safety factor for stepsize control (0.0:) :: \"should be less than one\" maximum_decrease 10.0 Maximum stepsize decrease factor (1.0:) :: \"should be larger than one\" maximum_increase 5.0 Maximum stepsize increase factor (1.0:) :: \"should be larger than one\" verbose \"normal\" How verbose should MoL be? \"none\" :: \"No output at all (not implemented)\"; \"normal\" :: \"Standard verbosity\"; \"register\" :: \"List the variables registered as well\"; \"extreme\":: \"Everything you never wanted to know\" Boundary Condtition Boundary Provides a generic interface to boundary conditions, and provides a set of standard boundary conditions for one, two, and three dimensional grid variables. In addition, it allows all considerations of symmetry to be separated from those of physical boundary conditions. Boundary conditions can be local, meaning that the boundary point can be updated based on data in its immediate vicinity, or non-local, meaning that the new value on the boundary depends on data from a remote region of the computational domain Currently thorn Boundary allows a separate boundary condition to be applied to each face of the domain, however this is only implemented at the moment using the older deprecated interface. Thorn Boundary also provides seven standard boundary conditions, which can be applied to one, two, or three dimensional grid variables. The boundary conditions available are Scalar: the value of the given field or fields at the boundary is set to a given scalar value, for example zero. Flat: the value of the given field or fields at the boundary is copied from the value one grid point in, in any direction. Radiation: Grid functions are given for the current time level as well as grid functions from a past timelevel which are needed for constructing the boundary condition. Copy: Copy the boundary values from a different grid function, for example the previous timelevel. The two grid functions (or groups of grid functions) must have the same geometry. Robin: The Robin boundary condition is f(r)=f_{0}+\\frac{k}{r^{n}} f(r)=f_{0}+\\frac{k}{r^{n}} Static: The static boundary condition ensures that the boundary values do not evolve in time, by copying their values from previous timelevels. None: The \u201cNone\u201d boundary condition does just that, nothing. Grid variables should have symmetry boundary conditions applied to them, but do not have their physical boundary conditions applied using a properly registered function. Parameter Key Defaults Describe Option radpower -1 Power of decay rate in extrapolation used in radiative boundaries : :: \"A negative value switches off this feature\" register_scalar \"yes\" Register routine to handle the 'Scalar' boundary condition register_flat \"yes\" Register routine to handle the 'Flat' boundary condition register_radiation \"yes\" Register routine to handle the 'Radiation' boundary condition register_copy \"yes\" Register routine to handle the 'Copy' boundary condition register_robin \"yes\" Register routine to handle the 'Robin' boundary condition register_static \"yes\" Register routine to handle the 'Static' boundary condition register_none \"yes\" Register routine to handle the 'None' boundary condition ReflectionSymmetry Provide reflection symmetries, i.e., bitant, quadrant, and octant mode. Parameter Key Defaults Describe Option verbose \"no\" Produce screen output while applying boundary conditions reflection_x \"no\" Reflection symmetry at the lower x boundary reflection_y \"no\" Reflection symmetry at the lower y boundary reflection_z \"no\" Reflection symmetry at the lower z boundary reflection_upper_x \"no\" Reflection symmetry at the upper x boundary reflection_upper_y \"no\" Reflection symmetry at the upper y boundary reflection_upper_z \"no\" Reflection symmetry at the upper z boundary avoid_origin_x \"yes\" Stagger about the origin on the lower x boundary? avoid_origin_y \"yes\" Stagger about the origin on the lower y boundary? avoid_origin_z \"yes\" Stagger about the origin on the lower z boundary? avoid_origin_upper_x \"yes\" Stagger about the origin on the upper x boundary? avoid_origin_upper_y \"yes\" Stagger about the origin on the upper y boundary? avoid_origin_upper_z \"yes\" Stagger about the origin on the upper z boundary? Mesh refinement PUGH This thorn provides a unigrid parallel driver with MPI. Description Grid Size 1 2 3 4 5 6 7 8 9 10 # To set the global size of a N-D grid to be 40 grid points in each direction use PUGH::global_nsize = 40 # To set the global size of a 2D grid to be 40\u00d720 use PUGH::global_nx = 40 PUGH::global_ny = 20 # To set the local size of a 2D grid to be 40 \u00d7 20 on each processor, use PUGH::local_nx = 40 PUGH::local_ny = 20 Periodic Boundary Conditions 1 2 3 4 5 6 # By default, no periodic boundary conditions are applied. To apply periodic boundary conditions in all directions, set PUGH::periodic = \"yes\" # To apply periodic boundary conditions in just the x- and y- directions in a 3 dimensional domain, use PUGH::periodic = \"yes\" PUGH::periodic_z = \"no\" Processor Decomposition By default PUGH will distribute the computational grid evenly across all processors To manually specify the load distribution, set PUGH::partition = \"manual\" and then, depending on the grid dimension, set the remaining parameters to distribute the load in each direction. The computational grid can be manually distributed using PUGH\u2019s string parameters partition_[1d_x|2d_x|2d_y|3d_x|3d_y|3d_z] Parameter Key Defaults Describe Option periodic \"no\" Periodic boundary conditions periodic_x \"yes\" Periodic boundary conditions in x-direction periodic_y \"yes\" Periodic boundary conditions in y-direction periodic_z \"yes\" Periodic boundary conditions in z-direction global_nx 10 The size of the grid in the x direction 0: :: \"Grid of this size distributed across all processors\" global_ny 10 The size of the grid in the y direction 0: :: \"Grid of this size distributed across all processors\" global_nz 10 The size of the grid in the z direction 0: :: \"Grid of this size distributed across all processors\" global_nsize -1 The size of the grid in each spatial direction -1: :: \"Grid of this size in each dir distributed across all processors\" ghost_size_x 1 The width of the ghost zone in the x direction 0: :: \"Must be a positive integer\" ghost_size_y 1 The width of the ghost zone in the y direction 0: :: \"Must be a positive integer\" ghost_size_z 1 The width of the ghost zone in the z direction 0: :: \"Must be a positive integer\" ghost_size -1 The width of the ghost zone in each direction -1: :: \"Any positive number to override the ghost_size_[xyz] parameters\" info \"none\" Provide additional information about what PUGH is doing \"none\" :: \"No extra information\"; \"load\" :: \"Load on each processor\" local_nx -1 The size of the grid in the x direction -1: :: \"Grid of this size on each processor\" local_ny -1 The size of the grid in the y direction -1: :: \"Grid of this size on each processor\" local_nz -1 The size of the grid in the z direction -1: :: \"Grid of this size on each processor\" local_nsize -1 The size of the grid in each spatial direction -1: :: \"Grid of this size in each dir on each processor\" local_size_includes_ghosts \"yes\" Does the local grid size include the ghost zones? enable_all_storage \"no\" Enable storage for all GFs? physical2logical \"direct\" Physical process to logical process mapping method to use \"direct\":: \"Maps MPI IDs directly to IJKs\"; \"example\" :: \"Maps MPI IDs directly to IJKs using a lookup table\" processor_topology \"automatic\" How to determine the processor topology \"manual\":: \"Specified by proc_top_nx etc\"; \"automatic\" :: \"Automatically generated\"; \"automatic_old\" :: \"Automatically generated (old method)\" processor_topology_1d_x 0 Number of processors in X direction 0::: \"See proc_topology\" processor_topology_2d_x 0 Number of processors in X direction 0::: \"See proc_topology\" processor_topology_2d_y 0 Number of processors in Y direction 0::: \"See proc_topology\" processor_topology_3d_x 0 Number of processors in X direction 0::: \"See proc_topology\" processor_topology_3d_y 0 Number of processors in Y direction 0::: \"See proc_topology\" processor_topology_3d_z 0 Number of processors in Z direction 0::: \"See proc_topology\" initialize_memory \"none\" How to initialize memory for grid variables at allocation time \"none\" :: \"Do not initialize storage for allocated grid variables (default)\"; \"zero\" :: \"Zero out all elements of all allocated grid variables\"; \"NaN\":: \"Set all elements of allocated floating point grid variables to Not-a-Number values\" partition \"automatic\" Is the partition manual \"automatic\":: \"even\"; \"manual\" :: \"specified by partition_XYZ ..\" partition_1d_x \"\" Tells how to partition on direction X . :: \"A regex which matches anything\" partition_2d_x \"\" Tells how to partition on direction X . :: \"A regex which matches anything\" partition_2d_y \"\" Tells how to partition on direction y . :: \"A regex which matches anything\" partition_3d_x \"\" Tells how to partition on direction X . :: \"A regex which matches anything\" partition_3d_y \"\" Tells how to partition on direction y . :: \"A regex which matches anything\" partition_3d_z \"\" Tells how to partition on direction z . :: \"A regex which matches anything\" storage_verbose \"no\" Report on memory assignment \"yes\":: \"Standard storage information\"; \"report\" :: \"Provide a report of storage every storage_report_every iterations and at termination\"; \"no\" :: \"Provide no information\" storage_report_every 0 How often to provide a report on storage information 0:0 :: \"Never report\"; 1: :: \"Report at intervals\" cacheline_mult 4001 Multiplier for cacheline number 0:::\"Any positive number\" overloadevolve \"yes\" Overload Evolve driver function overloadsyncgroup \"no\" Overload SyncGroup driver function overloadsyncgroupsbydiri \"yes\" Overload SyncGroupsByDirI driver function overloadenablegroupstorage \"yes\" Overload EnableGroupStorage driver function overloaddisablegroupstorage \"yes\" Overload DisableGroupStorage driver function overloadenablegroupcomm \"yes\" Overload EnableGroupComm driver function overloaddisablegroupcomm \"yes\" Overload DisableGroupComm driver function overloadbarrier \"yes\" Overload Barrier driver function overloadparallelinit \"yes\" Overload ParallelInit driver function overloadexit \"yes\" Overload Exit driver function overloadabort \"yes\" Overload Abort driver function overloadmyproc \"yes\" Overload MyProc driver function overloadnprocs \"yes\" Overload nProcs driver function overloadarraygroupsizeb \"yes\" Overload ArrayGroupSizeB driver function overloadquerygroupstorageb \"yes\" Overload QueryGroupStorageB driver function overloadgroupdynamicdata \"yes\" Overload GroupDynamicData driver function Carpet https://arxiv.org/pdf/gr-qc/0310042.pdf The Carpet driver, which lives in the Carpet arrangement, is divided into several parts. The thorn Carpet is the main driver piece; it provides all the routines and structures that Cactus expects from it. The thorn CarpetLib is the workhorse that does all the bookkeeping and data shuffling. Those two alone form a valid Cactus driver; the other thorns provide additional functionality. The thorns CarpetInterp, CarpetReduce, and CarpetSlab provide the corresponding interpolation, reduction, and slabbing interfaces. The thorns CarpetIOASCII and CarpetIOFlexIO provide I/O methods. Finally, thorn CarpetRegrid provides a user interface to select where and what to refine. (The actual refinement is handled in CarpetLib.) Carpet is a mesh refinement driver. It knows about a hierarchy of refinement levels, where each level is decomposed into a set of cuboid grid patches. For historic reasons it also has a notion of multigrid levels, but those are currently unused. In order to allow multiple processors to run efficiently in parallel, the grid is broken down into several rectangular components, and each processor is assigned one of these components. The components will usually overlap by a few grid points, so as to allow the processors to calculate spatial derivatives (which require neighbouring grid points) without having to communicate for every grid point. From time to time it is then necessary to synchronise the overlapping region, which is the only time at which communication happens. Setting up a grid hierarch is in Carpet handled by three different entities: Carpet itself decides the extent of the domain, the type of outer boundary conditions, and distributes the domain onto processors. a regridding thorn is responsible for deciding the shape of the grid hierarchy. CarpetLib handles the details and actually manages the data. A regridding thorn, such as CarpetRegrid or CarpetRegrid2, sets up the grid hierarchy. The grid hierarchy consists of several refinement levels, and each refinement level consists of several refined regions. We assume that boundary location and boundary discretisation are set up via CoordBase. This is necessary since other methods do not allow specifying sufficient details to handle e.g. refined regions intersecting mesh refinement boundaries. The main distinction between an outer boundary point and an interior point from Carpet\u2019s point of view is that an outer boundary point is not evolved in time. Instead, the value of boundary points must be completely determined by the value of interior points. Parameter Key Defaults Describe Option domain_from_coordbase \"no\" Use the domain description from CoordBase domain_from_multipatch \"no\" Use the domain description from MultiPatch global_nx 10 Grid size in x direction 0: :: \"must be nonnegative\" global_ny 10 Grid size in y direction 0: :: \"must be nonnegative\" global_nz 10 Grid size in z direction 0: :: \"must be nonnegative\" global_nsize -1 Grid size in each spatial direction 0: :: \"must be nonnegative\"; -1:: \"use the per-dimension parameters\" ghost_size_x 1 Ghost zones in x direction 0: :: \"must be nonnegative\" ghost_size_y 1 Ghost zones in y direction 0: :: \"must be nonnegative\" ghost_size_z 1 Ghost zones in z direction 0: :: \"must be nonnegative\" ghost_size -1 Ghost zones in each spatial direction 0: :: \"must be nonnegative\"; -1:: \"use the per-dimension parameters\" ghost_sizes \"\" Number of ghost zones for each refinement level periodic \"no\" do not use this parameter periodic_x \"yes\" do not use this parameter periodic_y \"yes\" do not use this parameter periodic_z \"yes\" do not use this parameter refinement_centering \"vertex\" Centering \"vertex\" :: \"use a vertex centred grid structure\"; \"cell\" :: \"use a cell centred grid structure\" eno_interpolation_type \"samples\" What is represented by values in cells DEPRECATED \"samples\":: \"grid values a sample values of the solution\" max_refinement_levels 1 Maximum number of refinement levels (including the base level) 1: :: \"must be positive\" max_timelevels -1 Maximum number of time levels (including the current time level) -1 :: \"Set automatically to prolonation_order_time+1\"; 1: :: \"Set this explicitly\" refinement_factor 2 Refinement factor 1: :: \"must be positive\" space_refinement_factors \"\" Spatial refinement factors over the coarsest level \" ^$ \" :: \"Use the value of refinement_factor\" time_refinement_factors \"\" Temporal refinement factors over the coarsest level \" ^$ \" :: \"Use the value of refinement_factor\" refine_timestep \"no\" Correct Time::dtfac for spacings on finer grids convergence_level 0 Convergence level : :: \"negative for finer, positive for coarser resolutions\" num_convergence_levels 1 Number of convergence levels (including the base level) 1: :: \"must be positive\" convergence_factor 2 Multigrid factor 1: :: \"must be positive\" num_maps 1 Number of maps 1: :: \"\" model \"world\" Model name for multi-model simulations -- the model name is used to distribute the processors onto the models \".+\" :: \"\" prolongation_order_space 1 Order of prolongation operator in space 0: :: \"vertex centred orders must be odd\" prolongation_orders_space \"\" Order of prolongation operator in space for each refinement level \" ^$ \" :: \"Use the value of prolongation_order_space\" prolongation_order_time 1 Order of prolongation operator in time 0: :: \"\" use_buffer_zones \"no\" Use buffer zones additional_buffer_zones 0 Additional buffer zones : :: \"\" use_overlap_zones \"no\" Use overlap zones additional_overlap_zones 0 Additional overlap zones : :: \"\" use_tapered_grids \"no\" Use tapered grids, avoiding time interpolation during evolution num_integrator_substeps -1 Number of substeps of the time integrator -1: :: \"Call MoLNumIntegratorSubsteps\"; 0: :: \"\" sync_during_time_integration \"yes\" Synchronise during time integration, even when prolongation is switched off base_extents braces Extents of base grid components, in grid point units of the finest level \" ^$ \" :: \"leave empty for one grid component covering the whole region (default)\" base_outerbounds \"\" Outer boundaries of base grid components \"^$\" :: \"leave empty for using the default, which depends on cctk_gsh\" enable_all_storage \"no\" Enable storage for all grid functions enable_no_storage \"no\" Exit before beginning to enable storage for grid functions poison_new_timelevels \"yes\" Try to catch uninitialised grid elements by setting new timelevels to values that will catch your attention check_for_poison \"no\" Explicitely check for the poison value after every time step poison_value 0 UNUSED; use CarpetLib::poison_value instead :: \"\" max_poison_locations 10 Maximum number of poison locations that are printed to the screen -1:: \"print all locations\"; 0: :: \"print only that many locations\" checksum_timelevels \"no\" Try to catch unintentionally changed timelevels by taking checksums and comparing against these suppress_restriction \"no\" Suppress the restriction operations. This makes the coarser refinement levels independent of the finer ones. verbose \"no\" Display more info on the screen veryverbose \"no\" Display a lot of info on the screen storage_verbose \"no\" Display verbose storage information if veryverbose barriers \"no\" Insert barriers at strategic places for debugging purposes (slows down execution) schedule_barriers \"no\" Insert barriers between scheduled items, so that timer statistics become more reliable (slows down execution) sync_barriers \"no\" Insert barriers before and after syncs, so that the sync timer is more reliable (slows down execution) output_internal_data \"no\" Periodically print internal data to the screen for debugging purposes timing_average_window_minutes 10.0 Time interval (in wall time minutes) for calculating the current physics time per hour (0.0: :: \"\" print_timestats_every 0 Print interesting timing statistics periodically -1:: \"don't report\"; 0 :: \"don't report\"; 1: :: \"report every so many iterations\" print_grid_info yes Print information about the grids on regridding output_timers_every 0 Print detailed statistics periodically -1:: \"don't report\"; 0 :: \"don't report\"; 1: :: \"report every so many iterations\" timer_file \"carpet-timing-statistics\" File name in which detailed timing statistics are collected \" ^$ \" :: \"empty filename: no file output\"; \" ^.+$ \" :: \"file name\" output_initialise_timer_tree \"no\" Output timing information in tree form to standard output for Initialise output_timer_tree_every 0 Output timing information in tree form to standard output for Evolve every so many iterations 0 :: \"don't report\"; 1: :: \"report every so many iterations\" output_xml_timer_tree \"no\" Output timing information in tree form as XML recompose_verbose \"no\" Output debug information during recomposing processor_topology \"automatic\" How to determine the processor topology \"manual\":: \"Specified by processor_topology_\"; \"along-z\" :: \"Split the region along the z direction only\"; \"along-dir\" :: \"Split the region along one direction only\"; \"automatic\" :: \"Choose the topology automatically\"; \"recursive\" :: \"Choose the topology automatically, using a different algorithm that may lead to better load balancing\"; \"balanced\":: \"Choose the topology automatically, ensuring a maximum load balance\" processor_topology_3d_x 1 Number of processors in x-direction 1: :: \"must be positive\" processor_topology_3d_y 1 Number of processors in y-direction 1: :: \"must be positive\" processor_topology_3d_z 1 Number of processors in z-direction 1: :: \"must be positive\" split_direction 2 Direction in which the domain should be split (for processor_topology=along-dir) 0: :: \"0 for x, 1 for y, 2 for z, etc.\" no_split_direction -1 Direction in which the domain must not be split (for processor_topology=automatic) -1:: \"split in all directions\"; 0: :: \"0 for x, 1 for y, 2 for z, etc.\" constant_load_per_processor \"no\" Keep the load per processor constant -- this is meant for benchmarks aspect_ratio_x 1.0 Desired aspect ratio for each processor's domain (0: :: \"\" aspect_ratio_y 1.0 Desired aspect ratio for each processor's domain (0: :: \"\" aspect_ratio_z 1.0 Desired aspect ratio for each processor's domain (0: :: \"\" min_points_per_proc 0 Minimum number of grid points per processor 0: :: \"that many\" split_components \"yes\" Split components onto processes; without this, one needs many components and few processes granularity 1 When splitting components, create sizes that are multiples of this granularity 1: :: \"TODO: query CoordBase or related thorns for this information\" granularity_boundary 0 When splitting components, assume this many boundary points that don't count towards the granularity 0: :: \"TODO: use CoordBase's number of boundary points for this\" ghost_zone_cost 0.025 Relative cost of ghost zones for 'recursive' load balancing 0: :: \"\" maximum_imbalance 0.1 Maximum load imbalance (0.0: :: \"\" same_number_of_components_on_each_process \"yes\" Ensure that each process has the same number of components, adding empty dummy components if necessary num_threads -1 Number of threads per process -1:: \"use system default, probably influenced by OMP_NUM_THREADS\"; 1: :: \"use this many threads\" set_cpu_affinity \"no\" Set the process CPU affinity, overwriting the respective system setting grid_structure_filename \"\" File name to output grid structure to (empty = no output) \".\" :: \"must be a legal file name\" grid_coordinates_filename \"\" File name to output grid coordinates to (empty = no output) \".\" :: \"must be a legal file name\" init_each_timelevel \"no\" Call initial data routines once for each timelevel init_fill_timelevels \"no\" Fill past time levels from current time level after calling initial data routines prolongate_initial_data \"no\" Prolongate the refined regions during initial data generation regrid_during_initialisation \"no\" Regrid while initialising regrid_during_recovery \"no\" Regrid while recovering regrid_in_level_mode \"yes\" Regrid in level mode (instead of singlemap mode), enabling more efficient processor distributions when there are multiple maps time_interpolation_during_regridding \"yes\" Interpolate finer levels in time during regridding output_after_regridding \"no\" Call OutputGH after regridding init_3_timelevels \"no\" Set up 3 timelevels of initial data adaptive_stepsize \"no\" Allow adaptive timestep sizes use_unusedpoints_mask \"no\" Turn on storage and usage of 'unusedpoints_mask' CarpetLib This thorn contains the backend library that provides mesh refinement. Parameter Key Defaults Describe Option verbose \"no\" Print info to the screen barriers \"no\" Insert barriers at strategic places for debugging purposes (slows down execution) commstate_verbose \"no\" Print debug info from the commstate class omit_prolongation_points_when_restricting \"no\" Do not restrict to points which are used to prolongate the boundary proper_nesting_distance 4 Minimum distance (in grid points) between two level interfaces 0: :: \"any non-negative value is fine; the default value is just a guess\" use_dgfe \"no\" Use DGFE operators instead of Lagrange operators interpolate_from_buffer_zones \"no\" Use buffer points for interpolation use_loopcontrol_in_operators \"no\" Use LoopControl to parallelize AMR operators use_openmp \"yes\" Use OpenMP to parallelize AMR operators use_higher_order_restriction \"no\" Use third order cell centered restriction operators instead of first order restriction_order_space 3 Order of restriction operator to use with use_higher_order_restriction 1 :: \"linear interpolation, this is Carpet's original implementation\"; 3 :: \"third order accurate restriction for grid functions where prolongation is not (W)ENO\"; 5 :: \"fifth order accurate restriction for grid functions where prolongation is not (W)ENO\" support_staggered_operators \"no\" Provide one extra ghost point during restriction for staggered operators - EXPERIMENTAL output_bboxes \"no\" Output bounding box information to the screen check_bboxes \"yes\" Check bounding box information for self-consistency poison_new_memory \"no\" Try to catch uninitialised data by setting newly allocated memory to values that will catch your attention electric_fence \"no\" Surround each allocated memory block by canaries to check for out-of-bounds accesses fence_width 1 number of guard cells to use 1: :: \"any number of cells\" poison_value 255 Integer value (0..255) used to poison new timelevels (with memset) 0:255 :: \"Must fit into a byte.Use 0 for zero, 255 for nan, and e.g. 113 for a large value.\" deadbeef 666 A strange integer value that indicates that something has gone wrong; the integer equivalent of a nan : :: \"should be large and positive\" max_core_size_MB -2 Maximum size of a core file, set via setrlimit -2:: \"unchanged\"; -1:: \"unlimited\"; 0: :: \"limited\" max_memory_size_MB -2 Maximum amount of memory per MPI process, set via setrlimit -2:: \"unchanged\"; -1:: \"unlimited\"; 0: :: \"limited\" test_backtrace \"no\" Kill yourself to test the backtrace mechanism print_timestats_every -1 Print timing statistics periodically -1:: \"don't report\"; 0 :: \"report after initialisation\"; 1: :: \"report every so many iterations\" timestat_file \"carpetlib-timing-statistics\" File name in which timestat output is collected (because stdout from the root node may not be enough) \" ^$ \" :: \"empty filename: no file output\"; \" ^.+$ \" :: \"file name\" use_ipm_timing_regions no Call IPM (via MPI_Pcontrol) to define regions print_memstats_every -1 Report periodically how much memory is used per process -1:: \"don't report\"; 0 :: \"report after setting up initial data\"; 1: :: \"report every so many iterations\" max_allowed_memory_MB 0 Maximum allowed amount of memory per process that can be allocated for grid variables (in Megabytes) -1:: \"no maximum\"; 0 :: \"no maximum\"; 1: :: \"abort if more memory is used\" memstat_file \"carpetlib-memory-statistics\" File name in which memstat output is collected (because stdout from the root node may not be enough) \" ^$ \" :: \"empty filename: no file output\"; \" ^.+$ \" :: \"file name\" combine_recompose \"yes\" Recompose all grid functions of one refinement levels at once avoid_arraysize_bytes 0 Avoid array sizes that are multiples of this 0 :: \"don't avoid anything\"; # 2: :: \"\" message_size_multiplier 1 Enlarge size of transmitted messages by this factor 1: :: \"\" message_count_multiplier 1 Transmit messages this many times 1: :: \"\" interleave_communications \"no\" Try to interleave communications with each other; each processor begins to communicate with its 'right neighbour' in rank, instead of with the root processor barrier_between_stages \"no\" Add a barrier between the communication stages (slows down, but may make timing numbers easier to interpret) check_communication_schedule \"no\" Check the communication schedule at run time (expensive) combine_sends \"no\" Send data together and in order of processor ranks use_mpi_send \"no\" Use MPI_Send instead of MPI_Isend use_mpi_ssend \"no\" Use MPI_Ssend instead of MPI_Isend pad_to_cachelines \"yes\" Pad arrays to the cache line size (only when VECTORISE_ALIGNED_ARRAYS is set) CarpetRegrid2 Set up refined regions by specifying a set of centres and radii about them. The refined regions are then the conjunction of these regions. The grid hierarchy consists of several refinement levels, and each refinement level consists of several refined regions. Parameter Key Defaults Describe Option verbose \"no\" Display regridding information on the terminal veryverbose \"no\" Display much regridding information on the terminal min_distance 4 Minimum distance (in grid points) between coarse and fine grid boundaries 0: :: \"\" ensure_proper_nesting \"yes\" Ensure proper nesting automatically freeze_unaligned_levels \"no\" Do not change refinement levels that do not exist at this time freeze_unaligned_parent_levels \"no\" Do not change refinement levels where the parent does not exist at this time min_fraction 0.9 Minimum fraction of required refined points that need to be present in a refined region 0: :: \"\" snap_to_coarse \"no\" Ensure that the fine grid extent coincides with coarse grid points granularity 1 Granularity of size of refined regions 1: :: \"\" boundary_shiftout 0 Number of grid points added to the refinement boundary radius : :: \"\" regrid_every 0 Regrid every n time steps -1 :: \"regrid never\"; 0 :: \"regrid during initial data calculation only\"; 1: :: \"regrid every n time steps\" symmetry_rotating90 no Ensure a 90 degree rotating symmetry about the z axis symmetry_rotating180 no Ensure a 180 degree rotating symmetry about the z axis symmetry_parity no parity symmetry_periodic_x no Ensure a periodicity symmetry in the x direction symmetry_periodic_y no Ensure a periodicity symmetry in the y direction symmetry_periodic_z no Ensure a periodicity symmetry in the z direction expect_symmetric_grids \"no\" Expect a grid structure that is symmetric about the origin, and abort if it is not adaptive_refinement \"no\" Use level_mask for adaptive refinement adaptive_block_size 8 Block size for adaptive refinement 1: :: \"\" adaptive_block_size_x -1 Block size in x direction for adaptive refinement -1 :: \"use adaptive_block_size\"; 1: :: \"\" adaptive_block_size_y -1 Block size in y direction for adaptive refinement -1 :: \"use adaptive_block_size\"; 1: :: \"\" adaptive_block_size_z -1 Block size in z direction for adaptive refinement -1 :: \"use adaptive_block_size\"; 1: :: \"\" num_centres 0 Number of refinement centres 0:10 :: \"\" add_levels_automatically \"no\" Automatically add a new refinement level at each regrid num_levels_1 1 Number of refinement levels for this centre 1:30 :: \"\" active_1 \"yes\" Is this region active? position_x_1 0.0 Position of this centre : :: \"\" position_y_1 0.0 Position of this centre : :: \"\" position_z_1 0.0 Position of this centre : :: \"\" movement_threshold_1 0.0 Minimum movement to trigger a regridding 0: :: \"\" radius_rel_change_threshold_1 0.0 Minimum RELATIVE change in radius to trigger a regridding 0.0: :: \"\" num_levels_2 1 Number of refinement levels for this centre 1:30 :: \"\" active_2 \"yes\" Is this region active? position_x_2 0.0 Position of this centre : :: \"\" position_y_2 0.0 Position of this centre : :: \"\" position_z_2 0.0 Position of this centre : :: \"\" movement_threshold_2 0.0 Minimum movement to trigger a regridding 0: :: \"\" radius_rel_change_threshold_2 0.0 Minimum change in radius to trigger a regridding 0.0: :: \"\" CarpetInterp This thorn provides a parallel interpolator for Carpet. Parameter Key Defaults Describe Option barriers \"no\" Insert barriers at strategic places for debugging purposes (slows down execution) poison -4.20042e+30 Poison value : :: \"\" ipoison -420042 Integer poison value : :: \"\" tree_search \"yes\" Use a tree search to find the source processor check_tree_search \"no\" Cross-check the result of the tree search CarpetReduce This thorn provides parallel reduction operators for Carpet. This thorn now uses a weight function. This makes it possible to perform physically meaningful spatial reduction operations. The weight is 1 for all \"normal\" grid points. The weight is set to 0 on symmetry and possible the outer boundary, and it might be set to \u00bd on the edge of the boundary. Setting this depends on the coordinate thorn, and currently works only when the coordinates are defined via CoordBase. The weight is also reduced or set to 0 on coarser grids that are overlaid by finer grid. The weight should also be reduced or set to 0 near and in excised regions. This should happen in conjunction with an excision boundary thorn. Parameter Key Defaults Describe Option verbose \"no\" Produce screen output while running debug_iweight \"no\" Allow debugging iweight grid function by keeping it allocated min_max_time_interpolation \"yes\" Interpolate in time for min/max reductions Partial Differential Equation (PDE) CT_MultiLevel This thorn implements a multigrid solver for systems of elliptic partial differential equations. This thorn requires Carpet, which it uses to manage the access to the grid structure and to pass information between the different levels (via the restriction and prolongation operators). The thorn also inherits from boundary and grid for boundary APIs and coordinate labels. Multigrid schemes are designed to solve elliptic equations on a hierarchy of grids. Each equation in the system to solve is parametrized as follows: \\begin{array}{c}{c_{x x} \\partial_{x x} \\psi+c_{x y} \\partial_{x y} \\psi+c_{x z} \\partial_{x z} \\psi+c_{y y} \\partial_{y y} \\psi+c_{y z} \\partial_{y z} \\psi+c_{z z} \\partial_{z z} \\psi} \\\\ {c_{x} \\partial_{x} \\psi+c_{y} \\partial_{y} \\psi+c_{z} \\partial_{z} \\psi+c_{0} \\psi^{n_{0}}+c_{1} \\psi^{n_{1}}+c_{2} \\psi^{n_{2}}+c_{3} \\psi^{n_{3}}+c_{4} \\psi^{n_{4}}=0}\\end{array} \\begin{array}{c}{c_{x x} \\partial_{x x} \\psi+c_{x y} \\partial_{x y} \\psi+c_{x z} \\partial_{x z} \\psi+c_{y y} \\partial_{y y} \\psi+c_{y z} \\partial_{y z} \\psi+c_{z z} \\partial_{z z} \\psi} \\\\ {c_{x} \\partial_{x} \\psi+c_{y} \\partial_{y} \\psi+c_{z} \\partial_{z} \\psi+c_{0} \\psi^{n_{0}}+c_{1} \\psi^{n_{1}}+c_{2} \\psi^{n_{2}}+c_{3} \\psi^{n_{3}}+c_{4} \\psi^{n_{4}}=0}\\end{array} All the coefficients c_\u2217 c_\u2217 and the powers n_\u2217 n_\u2217 can be specified by setting the parameters *_gfname[*] to the desired grid function name. These parameters are arrays to allow for the solution of systems of equations. The only other parameter which must be set to ensure correct operation is CT_MultiLevel::topMGlevel , which tells the solver which is the \ufb01nest refinement level that covers the entire domain in which the equation is to be solved. CT_MultiLevel needs at least one external thorn to set the PDE coefficients CT_Analytic . Parameter Key Defaults Describe Option mode \"generic\" Which equation should we solve? \"generic\" :: \"Generic elliptic operator, to be defined via the coefficients\"; \"constraints\" :: \"The GR constraints\" model \"None\" Model used to populate the auxiliary functions \"Bowen-York\" :: \"Bowen-York extrinsic curvature for multiple punctures\"; \"Expanding BH lattice\" :: \"An expanding black-hole lattice\"; \"Lump\" :: \"Generic compact source in Tmunu\"; \"Inhomogeneous Helmholtz\":: \"Inhomogeneous Helmholtz equation\"; \"None\" :: \"No auxiliaries needed\" cycle_type \"V How should be cycle over the refinement levels? \"V cycle\" :: \"A V cycle\"; \"FMG cycle\" :: \"A FMG cycle\" verbose \"no\" Output debugging information? \"no\" :: \"no\"; \"yes\" :: \"yes\" veryverbose \"no\" Output more debugging information? \"no\" :: \"no\"; \"yes\" :: \"yes\" output_norms \"no\" Output the norms of psi and residual, and those of their errors? \"no\" :: \"no\"; \"yes\" :: \"yes\" compare_to_exact \"no\" Output a file with the difference between the solution at each iteration and the exact solution, if known \"no\" :: \"no\"; \"yes\" :: \"yes\" output_walk \"no\" Output a file with the parameter-space walk followed by the algorithm? \"no\" :: \"no\"; \"yes\" :: \"yes\" fill_ADM \"no\" Should the equation solution be used to fill the ADM variables? \"no\" :: \"no\"; \"yes\" :: \"yes\" boundary_conditions \"none\" Which boundary conditions to apply to psi \"Robin\":: \"Robin\"; \"TwoPunctures\" :: \"Dirichlet BCs from TwoPunctures\"; \"none\" :: \"This thorn will apply no boundary conditions\" exact_offset 0.0 Offset between exact solution and grid function pointed by exact_solution_gfname ::: \"Any real number\" fd_order 2 Order of FD 2:4:2 :: \"Order of differencing\" number_of_equations 1 How many equations are to be solved concurrently? 1:10:: \"A positive integer smaller than or equal to 10\" number_of_auxiliaries 0 How many auxiliary functions do we need? 0::: \"A non-negative integer\" nrelsteps_up 2 How many times should we relax each level inside the upward leg of a cycle? 0::: \"Any non-negative integer\" nrelsteps_down 2 How many times should we relax each level inside the downward leg of a cycle? 0::: \"Any non-negative integer\" nrelsteps_bottom 2 How many times should we relax each level at the bottom of a cycle? 0::: \"Any non-negative integer\" nrelsteps_top 2 How many times should we relax each level at the top of a cycle? 0::: \"Any non-negative integer\" integral_refinement 1 How much to refine the grid via interpolation before calculating integrals 1: :: \"Any integer greater than zero\" tol 1e-06 Maximum residual tolerated 0: ::\"Any non-negative real\" eps 1e-06 Regularization factor at the punctures 0: ::\"Any non-negative real\" omega 1 Overrelaxation factor 0:2 ::\"Real larger than zero and smaller than 2\" reset_psi \"no\" Reset psi after each relaxation step? How? \"no\":: \"Do not reset\"; \"to value\":: \"Reset to the value specified by reset_value\"; \"through integrability\" :: \"Reset so that the integrability condition is satisfied\" reset_every 1 How often should we reset psi? 1: :: \"Any positive integer\" reset_x 0 x-coordinate of point of reference for variable resetting : ::\"Any real number (contained in the domain!)\" reset_y 0 y-coordinate of point of reference for variable resetting : ::\"Any real number (contained in the domain!)\" reset_z 0 z-coordinate of point of reference for variable resetting : ::\"Any real number (contained in the domain!)\" enforce_int 0 Enforce the integral compatibility condition? 0:1:1 :: \"True or false\" topMGlevel 0 Finest level that covers the entire domain 0::: \"Any non-negative integer (< Carpet::reflevels!)\" fill_Aij \"Analytic Where does the final Aij come from? \"Solver\" :: \"Aij is solved for as well\"; \"Analytic Xi\":: \"Aij comes from differentiating an analytic Xi\"; \"Analytic Aij\" :: \"Aij comes from an exact solution\" CT_Analytic Parameter Key Defaults Describe Option verbose 0 verbose : :: \"\" other_timelevels 1 Number of active timelevels for non-evolved grid functions 0:3 :: \"\" kx 0 Wavelength parameter along x : :: \"\" ky 0 Wavelength parameter along y : :: \"\" kz 0 Wavelength parameter along z : :: \"\" ampG 0 Coefficient of the gaussian term in the exact solution : :: \"\" ampS 0 Coefficient of the sine term in the exact solution : :: \"\" ampC 0 Constant coefficient in the exact solution : :: \"\" ampI 0 Multiplication factor between initial guess and exact solution : :: \"\" ampC1 0 Initial value for testc1 : :: \"\" ampSg 0 Coefficient of the 1/r term in the exact solution : :: \"\" ampV 0 Coefficient of the vector part in the exact solution : :: \"\" ampVG 0 Coefficient of the vector part in the exact solution (gaussian term) : :: \"\" sigma 1 Width of transition function in extrinsic curvature : :: \"\" l 0 Location of transition function in extrinsic curvature : :: \"\" phasex 0 Phase in the initial data for psi along x : :: \"\" phasey 0 Phase in the initial data for psi along y : :: \"\" phasez 0 Phase in the initial data for psi along z : :: \"\" Kc 0 Coefficient of extrinsic curvature : :: \"\" Ke 0 Coefficient of extrinsic curvature in exact solution : :: \"\" massa 0 mass of first black hole : :: \"\" massb 0 mass of second black hole : :: \"\" xa 0 x-coordinate of first black hole for BY initial data : :: \"\" ya 0 y-coordinate of first black hole for BY initial data : :: \"\" za 0 z-coordinate of first black hole for BY initial data : :: \"\" xb 0 x-coordinate of second black hole for BY initial data : :: \"\" yb 0 y-coordinate of second black hole for BY initial data : :: \"\" zb 0 z-coordinate of second black hole for BY initial data : :: \"\" Pax 0 x-component of linear momentum of first black hole for BY initial data : :: \"\" Pay 0 y-component of linear momentum of first black hole for BY initial data : :: \"\" Paz 0 z-component of linear momentum of first black hole for BY initial data : :: \"\" Pbx 0 x-component of linear momentum of second black hole for BY initial data : :: \"\" Pby 0 y-component of linear momentum of second black hole for BY initial data : :: \"\" Pbz 0 z-component of linear momentum of second black hole for BY initial data : :: \"\" eps 1.e-6 Smoothing factor : :: \"\" edgeL 10 Coordinate length of cell edge : :: \"\" rBall 1 Coordinate radius of ball of density for Poisson's equation : :: \"\" vecA 1 Coordinate center of gaussian representing the X^i vector in the CTT decomposition of the constraints : :: \"\" imaxF 1 Max number of Fourier modes to include in x direction : :: \"\" jmaxF 1 Max number of Fourier modes to include in y direction : :: \"\" kmaxF 1 Max number of Fourier modes to include in z direction : :: \"\" tile_size -1 Loop tile size : :: \"\" free_data \"exact\" How to set the free data for the extrinsic curvature? \"exact\" :: \"\"; \"Expanding BH lattice\" :: \"\"; \"Bowen-York\" :: \"\"; \"Poisson\" :: \"\"; \"Lump\" :: \"\" CT_Analytic_MaxNumEvolvedVars 0 Number of evolved variables used by this thorn 0:0 :: \"Number of evolved variables used by this thorn\" CT_Analytic_MaxNumArrayEvolvedVars 0 Number of Array evolved variables used by this thorn 0:0 :: \"Number of Array evolved variables used by this thorn\" timelevels 3 Number of active timelevels 0:3 :: \"\" rhs_timelevels 1 Number of active RHS timelevels 0:3 :: \"\" CT_Analytic_Poisson_Calc_calc_every 1 CT_Analytic_Poisson_Calc_calc_every : :: \"\" CT_Analytic_Exact_Calc_calc_every 1 CT_Analytic_Exact_Calc_calc_every : :: \"\" CT_Analytic_ExpandingLattice_Calc_calc_every 1 CT_Analytic_ExpandingLattice_Calc_calc_every : :: \"\" CT_Analytic_BY_Calc_calc_every 1 CT_Analytic_BY_Calc_calc_every : :: \"\" CT_Analytic_Lump_Calc_calc_every 1 CT_Analytic_Lump_Calc_calc_every : :: \"\" CT_Analytic_ExactBoundary_calc_every 1 CT_Analytic_ExactBoundary_calc_every : :: \"\" CT_Analytic_LumpBoundary_calc_every 1 CT_Analytic_LumpBoundary_calc_every : :: \"\" CT_Analytic_Poisson_Calc_calc_offset 0 CT_Analytic_Poisson_Calc_calc_offset : :: \"\" CT_Analytic_Exact_Calc_calc_offset 0 CT_Analytic_Exact_Calc_calc_offset : :: \"\" CT_Analytic_ExpandingLattice_Calc_calc_offset 0 CT_Analytic_ExpandingLattice_Calc_calc_offset : :: \"\" CT_Analytic_BY_Calc_calc_offset 0 CT_Analytic_BY_Calc_calc_offset : :: \"\" CT_Analytic_Lump_Calc_calc_offset 0 CT_Analytic_Lump_Calc_calc_offset : :: \"\" CT_Analytic_ExactBoundary_calc_offset 0 CT_Analytic_ExactBoundary_calc_offset : :: \"\" CT_Analytic_LumpBoundary_calc_offset 0 CT_Analytic_LumpBoundary_calc_offset : :: \"\" IOASCII Thorn IOASCII provides I/O methods for 1D, 2D, and 3D output of grid arrays and grid functions into files in ASCII format. Einstein The basic variables are those of the ADM formulation of Einstein\u2019s equations, namely the spatial 3-metric \\gamma_{i j} \\gamma_{i j} , the lapse \\alpha \\alpha , the shift \\beta \\beta , and the extrinsic curvature K_{i j} K_{i j} . The 4-metric is given by d s^{2}=-\\left(\\alpha^{2}-\\beta^{i} \\beta_{i}\\right) d t^{2}+\\beta_{i} d t d x^{i}+\\gamma_{i j} d x^{i} d x^{j} d s^{2}=-\\left(\\alpha^{2}-\\beta^{i} \\beta_{i}\\right) d t^{2}+\\beta_{i} d t d x^{i}+\\gamma_{i j} d x^{i} d x^{j} If \\gamma_{i j} \\gamma_{i j} is the 3-metric of a spacelike Cauchy surface with normal n, then K_{i j}=\\frac{1}{2} \\mathcal{L}_{n} \\gamma_{i j} K_{i j}=\\frac{1}{2} \\mathcal{L}_{n} \\gamma_{i j} The ADM equations then evolve the spatial three metric \\gamma_{i j} \\gamma_{i j} and the extrinsic curvature K_{i j} K_{i j} using \\begin{aligned} \\frac{d}{d t} \\gamma_{i j}=&-2 \\alpha K_{i j} \\\\ \\frac{d}{d t} K_{i j}=&-D_{i} D_{j} \\alpha+\\alpha\\left(R_{i j}+K K_{i j}\\right.\\\\ &-2 K_{i k} K_{j}^{k} - ^{(4)} R_{i j} ) \\end{aligned} \\begin{aligned} \\frac{d}{d t} \\gamma_{i j}=&-2 \\alpha K_{i j} \\\\ \\frac{d}{d t} K_{i j}=&-D_{i} D_{j} \\alpha+\\alpha\\left(R_{i j}+K K_{i j}\\right.\\\\ &-2 K_{i k} K_{j}^{k} - ^{(4)} R_{i j} ) \\end{aligned} with \\frac{d}{d t}=\\partial_{t}-\\mathcal{L}_{\\beta} \\frac{d}{d t}=\\partial_{t}-\\mathcal{L}_{\\beta} These variables are defined in the thorn ADMBase, and are the ones that are used to communicate the geometry to other thorns. It is not necessary to use all of these thorns to make use of CactusEinstein, however. The only thorn which is necessary is ADMBase, since it defines the variables and parameters on which the rest of the CactusEinstein thorns depend. ADMConstraints: computes the 3 + 1 Hamiltonian (energy) and momentum constraints ADMCoupling: allows thorns to \u2018register\u2019 their matter field contributions to the stress energy tensor ADMMacros: macros for computing various quantities which are commonly used in 3 + 1 numerical relativity, such as Christoffel symbols, covariant derivatives, the Ricci tensor, etc etc; some of these support both 2 nd and 4 th order finite differencing AHFinder: searches for apparent horizons CoordGauge: manages gauge quantities EvolSimple: a demo evolution thorn Extract: \u2018extracts\u2019 gravitational-wave waveforms IDAnalyticBH: analytic black hole initial data IDAxiBrillBH: axisymmetric Brill wave with black hole initial data IDBrillData: Brill wave initial data IDLinearWaves: linearized wave initial data IDSimple: a demo initial data thorn, provides Minkowski space with conformal factor Maximal: maximal slicing gauge condition PsiKadelia: computes various Neumann-Penrose quantities SpaceMask: provides a \u2018mask\u2019 for the spatial grid StaticConformal: provides for a static conformal factor TimeGeodesic: computes timelike geodesics Exact: analytical solutions where the full 4-metric is known throughout the entire spacetime, eg. Schwarzschild, Kerr, various cosmological solutions. ADMBase This thorn provides the basic variables used to communicate between thorns doing General Relativity in the 3+1 formalism. Description It provides the basic variables (3-metric, extrinsic curvature, lapse and shift vector) for the 3 + 1 formalism, in addition to a set of parameters to regulate the methods used for their evolution. These variables are used to communicate between thorns providing initial data, evolution methods and analysis routines for the 3 + 1 formalism. The variables provided by ADMBase are: - The 3-metric tensor, g_{i j} g_{i j} gxx, gxy, gxz, gyy, gyz, gzz - The extrinsic curvature tensor, K_{i j} K_{i j} kxx, kxy, kxz, kyy, kyz, kzz - The lapse function, \\alpha \\alpha alp - The (optional) shift vector \\beta^{i} \\beta^{i} betax, betay, betaz Initial data for the 3 + 1 variables is specified by the initial_data (3-metric and extrinsic curvature), initial_lapse (lapse), and initial_shift (shift) parameters. By default, ADMBase initialises the 3- metric and extrinsic curvature to Minkowski and the lapse to one. Analogous to specifying initial data, evolution methods are chosen by the evolution method (3-metric and extrinsic curvature), lapse_evolution_method (lapse), and shift_evolution_method (shift) parameters. By default, ADMBase does not evolve the 3-metric or extrinsic curvature, and holds the lapse and shift static. Parameter Key Defaults Describe Option initial_data \"Cartesian Initial metric and extrinsic curvature datasets \"Cartesian Minkowski\" :: \"Minkowski values in cartesian coordinates\" initial_lapse \"one\" Initial lapse value \"one\" :: \"Uniform lapse\" initial_shift \"zero\" Initial shift value \"none\" :: \"Shift is inactive\"; \"zero\" :: \"Shift is zero\" initial_dtlapse \"none\" Initial dtlapse value \"none\" :: \"Dtlapse is inactive\"; \"zero\" :: \"Dtlapse is zero\" initial_dtshift \"none\" Initial dtshift value \"none\" :: \"Dtshift is inactive\"; \"zero\" :: \"Dtshift is zero\" evolution_method \"static\" The metric an extrinsic curvature evolution method \"none\" :: \"The metric and extrinsic curvature are not evolved\"; \"static\" :: \"The metric and extrinsic curvature are not evolved\"; \"ID-apply-regrid\" :: \"The metric and extrinsic curvature are not evolved and initial data is used to fill in new grid points after regridding\"; \"ID-apply-always\" :: \"The metric and extrinsic curvature are not evolved and initial data is used to fill in new grid points before each step and after grid changes\" lapse_evolution_method \"static\" The lapse evolution method \"static\" :: \"lapse is not evolved\"; \"ID-apply-regrid\" :: \"lapse is not evolved and initial data is used to fill in new grid points after regridding\"; \"ID-apply-always\" :: \"lapse is not evolved and initial data is used to fill in new grid points before each step and after grid changes\" shift_evolution_method \"static\" The shift evolution method \"static\" :: \"dtlapse is not evolved\"; \"ID-apply-regrid\" :: \"dtlapse is not evolved and initial data is used to fill in new grid points after regridding\"; \"ID-apply-always\" :: \"dtlapse is not evolved and initial data is used to fill in new grid points before each step and after grid changes\" dtshift_evolution_method \"flat\" The dtshift evolution method \"\" :: \"must be a registered boundary condition\" metric_type \"physical\" The semantics of the metric variables (physical, static conformal, etc) \"physical\" :: \"metric and extrinsic curvature are the physical ones\" lapse_prolongation_type \"Lagrange\" The kind of boundary prolongation for the lapse \"Lagrange\" :: \"standard prolongation (requires several time levels)\"; \"none\" :: \"no prolongation (use this if you do not have enough time levels active)\" shift_prolongation_type \"Lagrange\" The kind of boundary prolongation for the shift \"Lagrange\" :: \"standard prolongation (requires several time levels)\"; \"none\" :: \"no prolongation (use this if you do not have enough time levels active)\" metric_prolongation_type \"Lagrange\" The kind of boundary prolongation for the metric and extrinsic curvature \"Lagrange\" :: \"standard prolongation (requires several time levels)\"; \"none\" :: \"no prolongation (use this if you do not have enough time levels active)\" lapse_timelevels 1 Number of time levels for the lapse 0:3 :: \"\" shift_timelevels 1 Number of time levels for the shift 0:3 :: \"\" metric_timelevels 1 Number of time levels for the metric and extrinsic curvature 0:3 :: \"\" ADMAnalysis This thorn does basic analysis of the metric and extrinsic curvature tensors. It calculates if output is requested for them. the trace of the extrinsic curvature (t r K) (t r K) the determinant of the metric (\\operatorname{detg}) (\\operatorname{detg}) the components of the metric in spherical coordinates \\left(g_{r r}, g_{r \\theta}, g_{r \\phi}, g_{\\theta \\theta}, g_{\\phi \\theta}, g_{\\phi \\phi}\\right) \\left(g_{r r}, g_{r \\theta}, g_{r \\phi}, g_{\\theta \\theta}, g_{\\phi \\theta}, g_{\\phi \\phi}\\right) the components of the extrinsic curvature in spherical coordinates \\left(K_{r r}, K_{r \\theta}, K_{r \\phi}, K_{\\theta \\theta}, K_{\\theta \\phi}, K_{\\phi \\phi}\\right) \\left(K_{r r}, K_{r \\theta}, K_{r \\phi}, K_{\\theta \\theta}, K_{\\theta \\phi}, K_{\\phi \\phi}\\right) components of the Ricci tensor \\left(\\mathcal{R}_{i j}\\right) \\left(\\mathcal{R}_{i j}\\right) for i, j \\in\\{1,2,3\\} i, j \\in\\{1,2,3\\} the Ricci scalar (\\mathcal{R}) (\\mathcal{R}) The trace of the extrinsic curvature at each point on the grid is placed in the grid function trK . The algorithm for calculating the trace uses the physical metric, that is it includes any conformal factor. \\operatorname{trK} \\equiv \\operatorname{tr} K=\\frac{1}{\\psi^{4}} g^{i j} K_{i j} \\operatorname{trK} \\equiv \\operatorname{tr} K=\\frac{1}{\\psi^{4}} g^{i j} K_{i j} The determinant of the 3-metric at each point on the grid is placed in the grid function detg . This is always the determinant of the conformal metric, that is it does not include any conformal factor. \\operatorname{detg} \\equiv \\operatorname{detg}=-g_{13}^{2} * g_{22}+2 * g_{12} * g_{13} * g_{23}-g_{11} * g_{23}^{2}-g_{12}^{2} * g_{33}+g_{11} * g_{22} * g_{33} \\operatorname{detg} \\equiv \\operatorname{detg}=-g_{13}^{2} * g_{22}+2 * g_{12} * g_{13} * g_{23}-g_{11} * g_{23}^{2}-g_{12}^{2} * g_{33}+g_{11} * g_{22} * g_{33} If the parameter 'normalize_dtheta_dphi' is true, the thorn projects the spherical components onto ( r*dtheta , r*sin(theta)*dphi ) instead of the default vector ( dtheta , dphi ). Parameter Key Defaults Describe Option normalize_dtheta_dphi \"no\" Project angular components onto r*dtheta and r*sin(theta)*dphi ricci_persist \"no\" Keep storage of the Ricci tensor and scalar around? ricci_timelevels 1 Number of time levels for the Ricci tensor and scalar 1:3 :: \"\" ricci_prolongation_type \"none\" The kind of boundary prolongation for the Ricci tensor and scalar \"Lagrange\" :: \"standard prolongation (requires several time levels)\"; \"copy\" :: \"use data from the current time level (requires only one time level)\"; \"none\" :: \"no prolongation (use this if you do not have enough time levels active)\" ADMMacros This thorn provides various macros which can be used to calculate quantities, such as the Christoffel Symbol or Riemann Tensor components, using the basic variables of thorn ADMBase. The macros work pointwise to calculate quantities at the grid point (i, j, k); it\u2019s up to you to loop over all the grid points where you want computations done. Description By default, the macros use centered 2 nd order finite differencing, with 3-point finite difference molecules. That is, when finite differencing the the grid-point indices i \u00b1 1, j \u00b1 1, and k \u00b1 1 must also be valid, and driver::ghost_size must be set to at least 1. Some of the macros also support centered 4 th order finite differencing; This is selected with the parameter spatial_order . This may be set to either 2 or 4; it defaults to 2. If it\u2019s set to 4, then 5-point finite difference molecules are used, so the grid-point indices i \u00b1 2, j \u00b1 2, and k \u00b1 2 must also be valid, and driver::ghost size must be set to at least 2. Parameter Key Defaults Describe Option spatial_order 2 Order of spatial differencing 2 :: \"2 nd order finite differencing\"; 4 :: \"4 th order finite differencing\" Initial data The initial data are computed using the Compact Object CALculator (COCAL) InitBase Thorn InitBase specifies how initial data are to be set up. It does not set up any initial data by itself, nor does it contain any routines which are to be called. It is merely a convenient repository remembering how initial data are to be set up, so that other thorns can check their actions against this thorn. There are several possibilities: The initial data thorn sets up data on one time level, while other time levels are scratch space. The time evolution method must start up from a single time level. (This is the default.) The initial data thorn sets up data on exactly one time level, and is called once for each active time level. (This means that the initial data thorn can only access the current time level.) The initial data thorn sets up data on exactly two time levels, and is called once for each active time level. (This means that the initial data thorn can only access the current and the first past time level.) The initial data thorn sets up data on all active time levels. (This makes it necessary that the initial data thorn checks the number of active time levels.) Parameter Key Defaults Describe Option initial_data_setup_method \"init_some_levels\" Procedure for setting up initial data \"init_some_levels\":: \"Set up at least one time level; other time levels are scratch space\"; \"init_single_level\" :: \"Set up exactly one time level; other time levels are not accessed\"; \"init_two_levels\" :: \"Set up exactly two time levels; other time levels are not accessed\"; \"init_all_levels\" :: \"Set up all active time levels\" TOVSolver The Tolman-Oppenheimer-Volkoff solution is a static perfect fluid \u201cstar\u201d. Here it is intended for use without evolving the matter terms. This provides a compact strong \ufb01eld solution which is static but does not contain singularities. The equations for a TOV star are usually derived in Schwarzschild coordinates. In these coordinates, the metric can be brought into the form d s^{2}=-e^{2 \\phi} d t^{2}+\\left(1-\\frac{2 m}{r}\\right)^{-1} d r^{2}+r^{2} d \\Omega^{2} d s^{2}=-e^{2 \\phi} d t^{2}+\\left(1-\\frac{2 m}{r}\\right)^{-1} d r^{2}+r^{2} d \\Omega^{2} Here we are assuming that the stress energy tensor is given by T^{\\mu \\nu}=(\\mu+P) u^{\\mu} u^{\\nu}+P g^{\\mu \\nu} T^{\\mu \\nu}=(\\mu+P) u^{\\mu} u^{\\nu}+P g^{\\mu \\nu} Description Parameter Key Defaults Describe Option TOV_Num_TOVs 1 The number of TOVs 1: :: \"Greater than 0\" TOV_Solve_for_TOVs 3 Solve for TOVs even if no TOV initial data was requested? 0:3 :: \"depreciated in favour of TOVSolver::TOV_Enforce_Interpolation\" TOV_Enforce_Interpolation \"no\" Enforce the interpolation of the data onto the Hydro GFs even without tov as specified initial data TOV_Num_Radial 100000 The number of radial points for the ODE integration 1: :: \"Greater than 0\" TOV_Gamma 2.0 The polytropic constant in P = K rho^Gamma 1.0: :: \"The physical range at high Lorentz factors is [1,2], but otherwise higher values of gamma can also be used\" TOV_K 100.0 The polytropic constant in P = K rho^Gamma (0.0: :: \"Greater than 0\" TOV_ProperPosition \"no\" For use only with two NSs, atm only handles equal mass TOV_Fast_Interpolation \"yes\" Use faster interpolation algorithm? Default is yes. TOV_Clear_Initial_Data \"yes\" Clear initial data (spacetime)? Default is yes. TOV_Use_Old_Initial_Data \"no\" Take old initial data into account (spacetime)? Default is no. TOV_Use_Old_Matter_Initial_Data \"no\" Use also old matter initial data? Default is no. TOV_Conformal_Flat_Three_Metric \"no\" Use conformal factor to get the 3-metric flat. default is no TOV_Combine_Method \"average\" Which combine method should be used. \"maximum\" :: \"Take the maximum of rho and gxx as clue for the rest as clue.\"; \"average\" :: \"Take the average of all available parts.\" TOV_Populate_Timelevels 1 Populate that amount of timelevels 1:3 :: \"1 (default) to 3\" TOV_Momentum_Psi_Power 0 Power of Psi to be multiplied with J^i for Mom : :: \"anything, 0 as default\" TOV_fake_evolution 0 Fake evolution by setting ID at every step : :: \"anything, 0 as off (default), everything else as on\" TOV_save_to_datafile \"\" Only save data to file and exit \".\" :: \"Any filename, not used if empty\" Evolution ADMCoupling This thorn allows seamless coupling of evolution and analysis thorns to any thorns which contribute matter terms to the stress energy tensor T_{a b} T_{a b} . Description The point is to allow clean coupling of matter thorns and spacetime evolution thorns. This avoids explicit dependencies between the spacetime and matter evolution thorns. Spacetime evolution thorns and various analysis thorns may need to know the value of the stress-energy tensor. ML_BSSN Parameter Key Defaults Describe Option evolution_method evolution_method \"ML_BSSN\" :: \"\" lapse_evolution_method lapse_evolution_method \"ML_BSSN\" :: \"\" shift_evolution_method shift_evolution_method \"ML_BSSN\" :: \"\" dtlapse_evolution_method dtlapse_evolution_method \"ML_BSSN\" :: \"\" dtshift_evolution_method dtshift_evolution_method \"ML_BSSN\" :: \"\" verbose 0 verbose : :: \"\" other_timelevels 1 Number of active timelevels for non-evolved grid functions 0:4 :: \"\" harmonicF 1 d/dt alpha = - f alpha^n K (harmonic: f=1, 1+log: f=2) : :: \"\" alphaDriver 0 d/dt alpha = ... - alphaDriver (alpha - 1) (use 1/M (?)) : :: \"\" shiftGammaCoeff 0 d/dt beta^i = C Xt^i (use C=0.75/M) : :: \"\" betaDriver 0 d/dt beta^i = ... - betaDriver alpha^shiftAlphaPower beta^i (use 1/M (?)) : :: \"\" shiftAlphaPower 0 d/dt beta^i = ... - betaDriver alpha^shiftAlphaPower beta^i (use 0 (?)) : :: \"\" spatialBetaDriverRadius 1000000000000 Radius at which the betaDriver starts to be reduced (0: :: \"positive\" spatialShiftGammaCoeffRadius 1000000000000 Radius at which shiftGammaCoeff starts to be reduced (0: :: \"positive\" minimumLapse 0 Enforced minimum of the lapse function 0: :: \"non-negative\" epsDiss 0 Dissipation strength 0: :: \"non-negative\" LapseACoeff -1. (OUTDATED) Evolve time derivative of lapse A? (now evolveA) 0. :: \"off\"; 1. :: \"on\"; -1. :: \"default\" ShiftBCoeff -1. (OUTDATED) Evolve time derivative of shift B^i? (now evolveB) 0. :: \"off\"; 1. :: \"on\"; -1. :: \"default\" LapseAdvectionCoeff -1. (OUTDATED) Advect lapse? (now advectLapse) 0. :: \"off\"; 1. :: \"on\"; -1. :: \"default\" ShiftAdvectionCoeff -1. (OUTDATED) Advect shift? (now advectShift) 0. :: \"off\"; 1. :: \"on\"; -1. :: \"default\" fdOrder 4 Finite differencing order 2 :: \"\"; 4 :: \"\"; 6 :: \"\"; 8 :: \"\" conformalMethod 0 Treatment of conformal factor 0 :: \"phi method\"; 1 :: \"W method\" evolveA 0 Evolve time derivative of lapse A? (former LapseACoeff) 0 :: \"off\"; 1 :: \"on\" evolveB 1 Evolve time derivative of shift B^i? (former ShiftBCoeff) 0 :: \"off\"; 1 :: \"on\" harmonicN 2 d/dt alpha = - f alpha^n K (harmonic: n=2, 1+log: n=1) : :: \"\" shiftFormulation 0 shift formulation 0 :: \"Gamma driver\"; 1 :: \"harmonic\" useSpatialBetaDriver 0 Enable spatially varying betaDriver 0 :: \"off\"; 1 :: \"on\" useSpatialShiftGammaCoeff 0 Enable spatially varying shiftGammaCoeff 0 :: \"off\"; 1 :: \"on\" advectLapse 1 Advect lapse? (former LapseAdvectionCoeff) 0 :: \"off\"; 1 :: \"on\" advectShift 1 Advect shift? (former ShiftAdvectionCoeff) 0 :: \"off\"; 1 :: \"on\" fixAdvectionTerms 0 Modify driver and advection terms to work better? 0 :: \"off\"; 1 :: \"on\" tile_size -1 Loop tile size : :: \"\" initial_boundary_condition \"scalar\" Boundary condition for initial condition for some of the BSSN variables \"scalar\" :: \"not recommended; use ML_BSSN_Helper's value 'extrapolate-gammas' instead\" rhs_boundary_condition \"scalar\" Boundary condition for BSSN RHS and some of the ADMBase variables \"scalar\" :: \"not recommended; use ML_BSSN_Helper's option 'NewRad' instead\" rhs_evaluation \"splitBy\" Whether and how the RHS routine should be split to improve performance \"combined\" :: \"use a single routine (probably slow)\"; \"splitBy\" :: \"split into 3 routines via Kranc\" my_initial_data \"default\" (OUTDATED) \"ADMBase\" :: \"from ADMBase\"; \"default\" :: \"do nothing\" my_initial_boundary_condition \"default\" (OUTDATED) \"none\" :: \"none\"; \"default\" :: \"do nothing\" my_rhs_boundary_condition \"default\" (OUTDATED) \"none\" :: \"none\"; \"static\" :: \"static\"; \"default\" :: \"do nothing\" my_boundary_condition \"default\" (OUTDATED) \"none\" :: \"none\"; \"Minkowski\" :: \"Minkowski\"; \"default\" :: \"do nothing\" dt_lapse_shift_method \"default\" (OUTDATED) Treatment of ADMBase dtlapse and dtshift \"correct\" :: \"(unused)\"; \"noLapseShiftAdvection\" :: \"(unused)\"; \"default\" :: \"do nothing\" apply_dissipation \"default\" (OUTDATED) Whether to apply dissipation to the RHSs \"always\" :: \"yes\"; \"never\" :: \"no\"; \"default\" :: \"do nothing\" ML_BSSN_MaxNumEvolvedVars 25 Number of evolved variables used by this thorn 25:25 :: \"Number of evolved variables used by this thorn\" ML_BSSN_MaxNumArrayEvolvedVars 0 Number of Array evolved variables used by this thorn 0:0 :: \"Number of Array evolved variables used by this thorn\" timelevels 3 Number of active timelevels 0:4 :: \"\" rhs_timelevels 1 Number of active RHS timelevels 0:4 :: \"\" ML_BSSN_InitialADMBase1Everywhere_calc_every 1 ML_BSSN_InitialADMBase1Everywhere_calc_every : :: \"\" ML_BSSN_InitialADMBase2Interior_calc_every 1 ML_BSSN_InitialADMBase2Interior_calc_every : :: \"\" ML_BSSN_InitialADMBase2BoundaryScalar_calc_every 1 ML_BSSN_InitialADMBase2BoundaryScalar_calc_every : :: \"\" ML_BSSN_EnforceEverywhere_calc_every 1 ML_BSSN_EnforceEverywhere_calc_every : :: \"\" ML_BSSN_ADMBaseEverywhere_calc_every 1 ML_BSSN_ADMBaseEverywhere_calc_every : :: \"\" ML_BSSN_ADMBaseInterior_calc_every 1 ML_BSSN_ADMBaseInterior_calc_every : :: \"\" ML_BSSN_ADMBaseBoundaryScalar_calc_every 1 ML_BSSN_ADMBaseBoundaryScalar_calc_every : :: \"\" ML_BSSN_EvolutionInterior_calc_every 1 ML_BSSN_EvolutionInterior_calc_every : :: \"\" ML_BSSN_EvolutionInteriorSplitBy1_calc_every 1 ML_BSSN_EvolutionInteriorSplitBy1_calc_every : :: \"\" ML_BSSN_EvolutionInteriorSplitBy2_calc_every 1 ML_BSSN_EvolutionInteriorSplitBy2_calc_every : :: \"\" ML_BSSN_EvolutionInteriorSplitBy3_calc_every 1 ML_BSSN_EvolutionInteriorSplitBy3_calc_every : :: \"\" ML_BSSN_EvolutionBoundaryScalar_calc_every 1 ML_BSSN_EvolutionBoundaryScalar_calc_every : :: \"\" ML_BSSN_EvolutionAnalysisInit_calc_every 1 ML_BSSN_EvolutionAnalysisInit_calc_every : :: \"\" ML_BSSN_EvolutionAnalysisInterior_calc_every 1 ML_BSSN_EvolutionAnalysisInterior_calc_every : :: \"\" ML_BSSN_ConstraintsEverywhere_calc_every 1 ML_BSSN_ConstraintsEverywhere_calc_every : :: \"\" ML_BSSN_ConstraintsInterior_calc_every 1 ML_BSSN_ConstraintsInterior_calc_every : :: \"\" ML_BSSN_InitialADMBase1Everywhere_calc_offset 0 ML_BSSN_InitialADMBase1Everywhere_calc_offset : :: \"\" ML_BSSN_InitialADMBase2Interior_calc_offset 0 ML_BSSN_InitialADMBase2Interior_calc_offset : :: \"\" ML_BSSN_InitialADMBase2BoundaryScalar_calc_offset 0 ML_BSSN_InitialADMBase2BoundaryScalar_calc_offset : :: \"\" ML_BSSN_EnforceEverywhere_calc_offset 0 ML_BSSN_EnforceEverywhere_calc_offset : :: \"\" ML_BSSN_ADMBaseEverywhere_calc_offset 0 ML_BSSN_ADMBaseEverywhere_calc_offset : :: \"\" ML_BSSN_ADMBaseInterior_calc_offset 0 ML_BSSN_ADMBaseInterior_calc_offset : :: \"\" ML_BSSN_ADMBaseBoundaryScalar_calc_offset 0 ML_BSSN_ADMBaseBoundaryScalar_calc_offset : :: \"\" ML_BSSN_EvolutionInterior_calc_offset 0 ML_BSSN_EvolutionInterior_calc_offset : :: \"\" ML_BSSN_EvolutionInteriorSplitBy1_calc_offset 0 ML_BSSN_EvolutionInteriorSplitBy1_calc_offset : :: \"\" ML_BSSN_EvolutionInteriorSplitBy2_calc_offset 0 ML_BSSN_EvolutionInteriorSplitBy2_calc_offset : :: \"\" ML_BSSN_EvolutionInteriorSplitBy3_calc_offset 0 ML_BSSN_EvolutionInteriorSplitBy3_calc_offset : :: \"\" ML_BSSN_EvolutionBoundaryScalar_calc_offset 0 ML_BSSN_EvolutionBoundaryScalar_calc_offset : :: \"\" ML_BSSN_EvolutionAnalysisInit_calc_offset 0 ML_BSSN_EvolutionAnalysisInit_calc_offset : :: \"\" ML_BSSN_EvolutionAnalysisInterior_calc_offset 0 ML_BSSN_EvolutionAnalysisInterior_calc_offset : :: \"\" ML_BSSN_ConstraintsEverywhere_calc_offset 0 ML_BSSN_ConstraintsEverywhere_calc_offset : :: \"\" ML_BSSN_ConstraintsInterior_calc_offset 0 ML_BSSN_ConstraintsInterior_calc_offset : :: \"\" phi_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" gt11_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" gt12_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" gt13_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" gt22_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" gt23_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" gt33_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" Xt1_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" Xt2_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" Xt3_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" trK_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" At11_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" At12_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" At13_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" At22_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" At23_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" At33_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" alpha_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" A_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" beta1_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" beta2_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" beta3_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" B1_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" B2_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" B3_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_log_confac_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_metric_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_Gamma_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_trace_curv_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_curv_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_lapse_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_dtlapse_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_shift_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_dtshift_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" phi_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" gt11_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" gt12_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" gt13_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" gt22_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" gt23_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" gt33_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" Xt1_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" Xt2_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" Xt3_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" trK_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" At11_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" At12_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" At13_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" At22_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" At23_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" At33_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" alpha_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" A_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" beta1_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" beta2_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" beta3_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" B1_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" B2_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" B3_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_log_confac_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_metric_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_Gamma_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_trace_curv_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_curv_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_lapse_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_dtlapse_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_shift_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_dtshift_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" phi_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" gt11_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" gt12_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" gt13_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" gt22_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" gt23_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" gt33_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" Xt1_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" Xt2_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" Xt3_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" trK_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" At11_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" At12_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" At13_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" At22_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" At23_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" At33_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" alpha_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" A_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" beta1_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" beta2_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" beta3_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" B1_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" B2_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" B3_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_log_confac_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_metric_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_Gamma_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_trace_curv_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_curv_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_lapse_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_dtlapse_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_shift_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_dtshift_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" phi_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" gt11_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" gt12_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" gt13_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" gt22_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" gt23_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" gt33_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" Xt1_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" Xt2_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" Xt3_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" trK_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" At11_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" At12_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" At13_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" At22_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" At23_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" At33_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" alpha_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" A_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" beta1_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" beta2_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" beta3_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" B1_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" B2_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" B3_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_log_confac_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_metric_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_Gamma_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_trace_curv_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_curv_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_lapse_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_dtlapse_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_shift_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_dtshift_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" Hydro Thorn locate in /Users/yuliu/Cactus/arrangements/EinsteinBase/TmunuBase TmunuBase Provide grid functions for the stress-energy tensor T_{\\mu \\nu} T_{\\mu \\nu} . Thorn TmunuBase is for the stress-energy tensor what thorn ADMBase is for the metric tensor. Description The variables provided by TmunuBase are: The \u201cscalar\u201d part of T_{\\mu \\nu} T_{\\mu \\nu} , its time-time component: eTtt The \u201cvector\u201d part of T_{\\mu \\nu} T_{\\mu \\nu} , its time-space components: eTtx, eTty, eTtz The \u201ctensor\u201d part of T_{\\mu \\nu} T_{\\mu \\nu} , its space-space components: eTxx, eTxy, eTxz, eTyy, eTyz, eTzz These components have the pre\ufb01x e to avoid naming conflicts with existing variables. Many thorns dealing with matter already use variable names such as Ttt. Several parameters choose how TmunuBase behaves at run time: The parameter stress_energy_storage activates storage for T_{\\mu \\nu} T_{\\mu \\nu} . The parameter stress_energy_at_RHS moves calculating the T_{\\mu \\nu} T_{\\mu \\nu} from the evol bin into the MoL_PostStep group. This increases the order of accuracy of the spacetime\u2013matter coupling, but is only possible when thorn MoL is used. The parameter timelevels chooses the number of time levels for T_{\\mu \\nu} T_{\\mu \\nu} . The default is a single time level, which is sufficient for unigrid simulation. Mesh refinement simulation may require several time levels if mesh refinement boundaries require correct values. The parameter prolongation_type defines the prolongation operator for mesh refinement boundaries. Since the values of T_{\\mu \\nu} T_{\\mu \\nu} change at each time step. T_{\\mu \\nu} T_{\\mu \\nu} needs to be recalculated frequently. This happens either in the schedule bin evol or in the schedule group MoL_PostStep. Parameter Key Defaults Describe Option stress_energy_storage no Should the stress-energy tensor have storage? stress_energy_at_RHS no Should the stress-energy tensor be calculated for the RHS evaluation? support_old_CalcTmunu_mechanism no Should the old CalcTmunu.inc mechanism be supported? This is deprecated. timelevels 1 Number of time levels 0:3 :: \"\" prolongation_type \"Lagrange\" The kind of boundary prolongation for the stress-energy tensor \" ^Lagrange$ \" :: \"standard prolongation (requires several time levels)\"; \" ^none$ \" :: \"no prolongation (use this if you do not have enough time levels active)\"; \"\" :: \"any other supported prolongation type\" HydroBase The idea behind this thorn is to create a slim, common set of variables, parameters and scheduling groups which can then be used by different hydrodynamics codes. Currently the de\ufb01ned primitive variables are rho: rest mass density \\rho \\rho press: pressure P eps: specific internal energy \\epsilon \\epsilon vel[3]: contravariant fluid three velocity v^{i} v^{i} with respect to the Eulerian observer Y_e: electron fraction Y_{e} Y_{e} temperature: temperature T entropy: specific entropy per particle s Bvec[3]: contravariant magnetic \ufb01eld vector Currently the scheduling blocks are: Initializing the primitive variables Converting primitive variables to conservative variables Calculating the right hand side (RHS) in the method of lines (MoL) Setting and updating an excision mask Applying boundary conditions HydroBase does not require a specific set of units itself. These units are derived from the conventions M_{\\mathrm{sun}}=1 ; c=G=1 M_{\\mathrm{sun}}=1 ; c=G=1 which are commonly used in astrophysics and in relativity. The former sets the mass scale to the solar one and the latter adopts the same units for time, length and mass. Parameter Key Defaults Describe Option initial_hydro \"zero\" The hydro initial data \"zero\" :: \"hydro variables are set to vacuum (without atmosphere)\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" evolution_method \"none\" The hydro evolution method \"none\" :: \"hydro variables are not evolved\" timelevels 1 Number of time levels in evolution scheme 1:3 :: \"\" prolongation_type \"ENO\" The prolongation operator used by Carpet for HydroBase variables \"ENO\":: \"Third order ENO operators; only third order is implemented\"; \"WENO\" :: \"Fifth order WENO operators; only fifth order is implemented\"; \".\" :: \"Anything else\" initial_Y_e \"none\" Initial value for Y_e \"none\" :: \"inactive\"; \"one\":: \"initially set to one\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" initial_Abar \"none\" Initial value for Abar \"none\" :: \"inactive\"; \"zero\" :: \"initially set to zero\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" Y_e_evolution_method \"none\" Evolution method for Y_e \"none\" :: \"Evolution for Y_e is disabled\" Abar_evolution_method \"none\" Evolution method for Abar \"none\" :: \"Evolution for Abar is disabled\" temperature_evolution_method \"none\" Evolution method for temperature \"none\" :: \"Evolution for temperature is disabled\" entropy_evolution_method \"none\" Evolution method for entropy \"none\" :: \"Evolution for entropy is disabled\" initial_Bvec \"none\" Initial value for Bvec \"none\" :: \"inactive\"; \"zero\" :: \"initially set to zero\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" initial_Avec \"none\" Initial value for Avec \"none\" :: \"inactive\"; \"zero\" :: \"initially set to zero\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" initial_Aphi \"none\" Initial value for Aphi \"none\" :: \"inactive\"; \"zero\" :: \"initially set to zero\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" Bvec_evolution_method \"none\" Evolution method for Bvec \"none\" :: \"Evolution for Bvec is disabled\" hydro_excision 0 Turn on of off (default) storage for hydro excision 0: :: \"Anything else than 0 turns hydro_excision on, added to by other thorns\" initial_temperature \"none\" Initial value for temperature \"none\":: \"inactive\"; \"zero\":: \"initially set to zero\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" initial_entropy \"none\" Initial value for entropy \"none\":: \"inactive\"; \"zero\":: \"initially set to zero\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" GRHydro GRHydro is a fully general-relativistic three-dimensional hydrodynamics code. It evolves the hydrodynamics using High Resolution Shock Capturing methods and can work with realistic equations of state. GRHydro uses the hydro variables de\ufb01ned in HydroBase and provides own \u201cconserved\u201d hydro variables and methods to evolve them. It does not provide any information about initial data or equations of state. For these, other thorns are required. Initial data for shocks can be set using GRHydro_Init_Data and will include the essential thorns GRHydro EOS_Omni ADMBase ADMCoupling MoL. The actual evolution in time is controlled by the Method of Lines thorn MoL. The equations of general relativistic hydrodynamics can be written in the flux conservative form \\partial_{t} q+\\partial_{x^{i}} f^{(i)}(q)=s(q) \\partial_{t} q+\\partial_{x^{i}} f^{(i)}(q)=s(q) where q is a set of conserved variables, f^{(i)}(q) f^{(i)}(q) the fluxes and s(q) s(q) the source terms. The 8 conserved variables are labeled D the generalized particle number density, S_{i} S_{i} the generalized momenta in each direction, \\tau \\tau internal energy term and \\mathscr{B}^{k} \\mathscr{B}^{k} the densitized magnetic field. Description recon_method: The type of reconstruction method to use. tvd is the standard. ppm is more accurate but it requires more resources. eno gives in theory arbitrary order of accuracy but it is practically unworthy to go beyond fifth order. tvd_limiter: When using tvd reconstruction the choice of limiter can have a large effect. vanleerffC2 is probably the best to use, but the extremes of minmod and Superbee are also interesting. ppm_detect: When using ppm reconstruction with shocks, the shock detection algorithm can notably sharpen the pro\ufb01le. Riemann solvers: Marquina is the standard solver used. HLLE is significantly faster, but sometimes provides cruder approximation. Equations of state: These are controlled by the GRHydro_eos_type and GRHydro_eos_table parameters. Changing these parameters will depend on which equation of state thorns you have compiled in. Initial data parameters: GRHydro_rho_central is inherited by many initial data thorns to set the central density of compact fluid objects such as single stars. Parameter Key Defaults Describe Option initial_shift \"never\" \"Comoving\" :: \"Set the shift so the matter is approximately comoving\"; \"GRHydro\" :: \"Use GRHydro to evolve the hydro variables\"; \"GRHydro_Avec\" :: \"Use GRHydro to evolve the MHD variables, evolving the Vector Potential\"; \"Bvec_from_Avec\" :: \"Calculate B^i for an initially specified A_i\"; \"always\" :: \"use the mask\"; \"auto\" :: \"check if CarpetEvolutionMask is active, then use the mask\"; \"never\":: \"do not use the mask\" GRHydro_enable_internal_excision \"true\" Set this to 'false' to disable the thorn-internal excision. GRHydro_hydro_excision 1 Turns excision automatically on in HydroBase 1:1 :: \"Only '1' allowed\" sources_spatial_order 2 Order of spatial differencing of the source terms 2 :: \"2 nd order finite differencing\"; 4 :: \"4 th order finite differencing\" GRHydro_MaxNumEvolvedVars 5 The maximum number of evolved variables used by GRHydro 0 :: \"when using multirate\"; 5:12 :: \"dens scon[3] tau (B/A)vec[3] psidc ye entropy Aphi\" GRHydro_MaxNumEvolvedVarsSlow 0 The maximum number of evolved variables used by GRHydro 0 :: \"do not use multirate\"; 5:12 :: \"dens scon[3] tau (B/A)vec[3] psidc ye entropy Aphi\" GRHydro_MaxNumConstrainedVars 37 The maximum number of constrained variables used by GRHydro 7:48 :: \"A small range, depending on testing or not\" GRHydro_MaxNumSandRVars 16 The maximum number of save and restore variables used by GRHydro 0:16 :: \"A small range, depending on testing or not\" recon_method \"tvd\" Which reconstruction method to use \"tvd\" :: \"Slope limited TVD\"; \"ppm\":: \"PPM reconstruction\"; \"eno\":: \"ENO reconstruction\"; \"weno\" :: \"WENO reconstruction\"; \"weno-z\" :: \"WENO-Z reconstruction\"; \"mp5\":: \"MP5 reconstruction\" method_type \"RSA Which type of method to use \"RSA FV\":: \"Reconstruct-Solve-Average finite volume method\"; \"Flux Split FD\" :: \"Finite difference using Lax-Friedrichs flux splitting\" check_for_trivial_rp \"yes\" Do check for trivial Riemann Problem recon_vars \"primitive\" Which type of variables to reconstruct \"primitive\" :: \"Reconstruct the primitive variables\"; \"conservative\" :: \"Reconstruct the conserved variables\" tvd_limiter \"minmod\" Which slope limiter to use \"minmod\" :: \"Minmod\"; \"vanleerMC2\" :: \"Van Leer MC - Luca\"; \"Superbee\" :: \"Superbee\" myfloor 1.e-10 A minimum number for the TVD reconstruction routine 0.0: :: \"Must be positive\" use_optimized_ppm \"no\" use C++ templated version of PPM. Experimental ppm_detect \"no\" Should the PPM solver use shock detection? ppm_flatten \"stencil_3\" Which flattening procedure should the PPM solver use? \"stencil_3\" :: \"our flattening procedure, which requires only stencil 3 and which may work\"; \"stencil_4\" :: \"original C&W flattening procedure, which requires stencil 4\" ppm_epsilon 0.33 Epsilon for PPM zone flattening 0.0: :: \"Must be positive. Default is from Colella & Woodward\" ppm_omega1 0.75 Omega1 for PPM zone flattening : :: \"Anything goes. Default is from Colella & Woodward\" ppm_omega2 10.0 Omega2 for PPM zone flattening : :: \"Anything goes. Default is from Colella & Woodward\" ppm_omega_tracer 0.50 Omega for tracer PPM zone flattening : :: \"Anything goes. Default is from Plewa & Mueller\" ppm_epsilon_shock 0.01 Epsilon for PPM shock detection : :: \"Anything goes. Default is from Colella & Woodward\" ppm_eta1 20.0 Eta1 for PPM shock detection : :: \"Anything goes. Default is from Colella & Woodward\" ppm_eta2 0.05 Eta2 for PPM shock detection : :: \"Anything goes. Default is from Colella & Woodward\" ppm_k0 0.2 K0 for PPM shock detection : :: \"Anything goes. Default suggested by Colella & Woodward is: (polytropic constant)/10.0\" ppm_small 1.e-7 A floor used by PPM shock detection 0.0:1.0 :: \"In [0,1]\" ppm_mppm 0 Use modified (enhanced) ppm scheme 0:1 :: \"0 (off, default) or 1 (on)\" ppm_mppm_debug_eigenvalues 0 write eigenvalues into debug grid variables 0:1 :: \"0 (off, default) or 1 (on)\" mp5_alpha 4.0 alpha parameter for MP5 reconstruction 0: :: \"positive\" mp5_eps 0.0 epsilon parameter for MP5 reconstruction 0: :: \"0.0 or very small and positive. 1e-10 is suggested by Suresh&Huynh. TOV star requires 0.0\" mp5_adaptive_eps no Same as WENO adaptive epsilon: adaptively reduce mp5_eps according to norm of stencil. Original algorithm does not use this. use_enhanced_ppm no Use the enhanced ppm reconstruction method proposed by Colella & Sekora 2008 and McCorquodale & Colella 2011 GRHydro_oppm_reflevel -1 Ref level where oPPM is used instead of ePPM (used with use_enhaced_ppm=yes). -1:10 :: \"0-10 (the reflevel number) or -1 (off)\" enhanced_ppm_C2 1.25 Parameter for enhancecd ppm limiter. Default from McCorquodale & Colella 2011 : :: \"must be greater than 1. According to Colella&Sekora 2008, enhanced ppm is insensitive to C in [1.25,5]\" enhanced_ppm_C3 0.1 Parameter for enhancecd ppm limiter. Default from McCorquodale & Colella 2011 0: :: \"must be greater than 0.\" reconstruct_Wv no Reconstruct the primitive velocity W_Lorentz*vel, rather than just vel. eno_order 2 The order of accuracy of the ENO reconstruction 1: :: \"Anything above 1, but above 5 is pointless\" WENO_order 5 The order of accuracy of the WENO reconstruction 5:: \"Fifth-order\" weno_eps 1e-26 WENO epsilon parameter. For WENO-z, 1e-40 is recommended 0::: \"small and positive\" weno_adaptive_epsilon yes use modified smoothness indicators that take into account scale of solution (adaptive epsilon) riemann_solver \"HLLE\" Which Riemann solver to use \"Roe\" :: \"Standard Roe solver\"; \"Marquina\" :: \"Marquina flux\"; \"HLLE\" :: \"HLLE\"; \"HLLC\" :: \"HLLC\"; \"LLF\" :: \"Local Lax-Friedrichs (MHD only at the moment)\" HLLE_type \"Standard\" Which HLLE type to use \"Standard\" :: \"Standard HLLE solver\"; \"Tadmor\" :: \"Tadmor's simplification of HLLE\" left_eigenvectors \"analytical\" How to compute the left eigenvectors \"analytical\" :: \"Analytical left eigenvectors\"; \"numerical\" :: \"Numerical left eigenvectors\" numerical_viscosity \"fast\" How to compute the numerical viscosity \"fast\" :: \"Fast numerical viscosity\"; \"normal\" :: \"Normal numerical viscosity\" apply_H_viscosity no H viscosity is useful to fix the carbuncle instability seen at strong shocks bound \"none\" Which boundary condition to use - FIXME \"flat\" :: \"Zero order extrapolation\"; \"none\" :: \"None\"; \"static\" :: \"Static, no longer supported\"; \"scalar\" :: \"Constant\" GRHydro_stencil 2 Width of the stencil 0: :: \"Must be positive\" GRHydro_eos_type \"General\" Type of Equation of State \"Polytype\" :: \"P = P(rho) or P = P(eps)\"; \"General\" :: \"P = P(rho, eps)\" GRHydro_eos_table \"Ideal_Fluid\" Name for the Equation of State . :: \"Can be anything\" GRHydro_eos_rf_prec 1.0e-8 Precision to which root finding should be carried out (0.0: :: \"anything larger than 0 goes\" GRHydro_eos_hot_eps_fix \"no\" Activate quasi-failsafe mode for hot EOSs GRHydro_eos_hot_prim2con_warn \"yes\" Warn about temperature workaround in prim2con GRHydro_c2p_reset_eps_tau_hot_eos \"no\" As a last resort, reset tau reconstruct_temper \"no\" if set to true, temperature will be reconstructed GRHydro_hot_atmo_temp 0.1e0 Temperature of the hot atmosphere in MeV (0.0: :: \"Larger than 0 MeV\" GRHydro_max_temp 90.0e0 maximum temperature we allow (0.0: :: \"Larger than 0 MeV\" GRHydro_hot_atmo_Y_e 0.5e0 Y_e of the hot atmosphere 0.0: :: \"Larger than 0\" GRHydro_Y_e_min 0.0 minimum allowed Y_e 0.0: :: \"Larger than or equal to zero\" GRHydro_Y_e_max 1.0 maximum allowed Y_e 0.0: :: \"Larger than or equal to zero; 1 is default\" GRHydro_c2p_warnlevel 0 Warnlevel for Con2Prim warnings 0:1 :: \"Either 0 or 1\" GRHydro_c2p_failed_action \"abort\" what to do when we detect a c2p failure \"abort\" :: \"abort with error\"; \"terminate\" :: \"request termination\" sqrtdet_thr -1.0 Threshold to apply cons rescalings deep inside the horizon 1.0::: \"Larger values guarantees this sort of rescaling only deep inside the horizon\"; -1.0:: \"Do not apply limit\" max_magnetic_to_gas_pressure_ratio -1.0 consider pressure to be magnetically dominated if magnetic pressure to gas pressure ratio is higher than this (0::: \"any positive value, eg. 100.\"; -1.0:: \"disable\" c2p_reset_pressure \"no\" If the pressure guess is unphysical should we recompute it? c2p_reset_pressure_to_value 1.e-20 The value to which the pressure is reset to when a failure occurrs in C2P 0: :: \"greater than zero\" c2p_resort_to_bisection no If the pressure guess is unphysical, should we try with bisection (slower, but more robust) GRHydro_eps_min 1.e-10 Minimum value of specific internal energy - this is now only used in GRHydro_InitData's GRHydro_Only_Atmo routine 0: :: \"Positive\" GRHydro_perc_ptol 1.e-8 Tolerance for primitive variable solve (percent) 0: :: \"Do we really want both tolerances?\" GRHydro_del_ptol 1.e-18 Tolerance for primitive variable solve (absolute) 0: :: \"Do we really want both tolerances?\" GRHydro_countmax 100 Maximum number of iterations for Con2Prim solve 1: :: \"Must be positive\" GRHydro_countmin 1 Minimum number of iterations for Con2Prim solve 0: :: \"Must be non negative\" GRHydro_polish 0 Number of extra iterations after root found 0: :: \"Must be non negative\" GRHydro_rho_central 1.e-5 Central Density for Star : :: \"\" tau_rel_min 1.e-10 A minimum relative tau (taumin = maxtau(t=0) * tau_rel_min) below which tau is reschaled 0: :: \"\" rho_abs_min -1.0 A minimum rho below which evolution is turned off (atmosphere). If negative, the relative minimum will be used instead. -1.0: :: \"\" rho_rel_min 1.e-9 A minimum relative rho (rhomin = centden * rho_rel_min) below which evolution is turned off (atmosphere). Only used if rho_abs_min < 0.0 0: :: \"\" initial_rho_abs_min -1.0 An absolute value for rho in the atmosphere. To be used by initial data routines only. Unused if negative. -1.0: :: \"\" initial_rho_rel_min -1.0 A relative (to the central density) value for rho in the atmosphere. To be used by initial data routines only. Unused if negative. -1.0: :: \"\" initial_atmosphere_factor -1.0 A relative (to the initial atmosphere) value for rho in the atmosphere. This is used at initial time only. Unused if negative. -1.0: :: \"\" rho_abs_min_after_recovery -1.0 A new absolute value for rho in the atmosphere. To be used after recovering. Unused if negative. -1.0: :: \"\" GRHydro_atmo_tolerance A point is set to atmosphere in the Con2Prim's if its rho < GRHydro_rho_min *(1+GRHydro_atmo_tolerance) . This avoids occasional spurious oscillations in carpet buffer zones lying in the atmosphere (because prolongation happens on conserved variables) 0.0: :: \"Zero or larger. A useful value could be 0.0001\" atmo_falloff_radius 50.0 The radius for which the atmosphere starts to falloff as (atmo_falloff_radius/r)**atmo_falloff_power 0: :: \"Anything positive\" atmo_falloff_power 0.0 The power at which the atmosphere level falls off as (atmo_falloof_radius/r)**atmo_falloff_power 0: :: \"Anything positive\" atmo_tolerance_radius 50.0 The radius for which the atmosphere tolerance starts to increase as (r/atmo_tolerance_radius)**atmo_tolerance_power 0: :: \"Anything positive\" atmo_tolerance_power 0.0 The power at which the atmosphere tolerance increases as (r/atmo_tolerance_radius)**atmo_tolerance_power 0: :: \"Anything positive\" wk_atmosphere \"no\" Use some of Wolfgang Kastauns atmosphere tricks Check_Rho_Minimum \"no\" Should a check on rho < GRHydro_rho_min be performed and written as WARNING level 2? EoS_Change \"no\" Recalculate fluid quantities if changing the EoS EoS_Change_type \"Gamma\" Change polytropic K or Gamma? \"K\" :: \"Change the K\"; \"Gamma\" :: \"Change the Gamma\"; \"GammaKS\":: \"Change K and Gamma, Shibata et al. 2004 3-D GR Core Collapse style\" initial_Gamma 1.3333 If changing Gamma, what was the value used in the initial data routine? (0.0: :: \"Positive\" initial_k 100.0 If changing K, what was the value used in the initial data routine? (0.0: :: \"Positive\" use_weighted_fluxes \"no\" Weight the flux terms by the cell surface areas comoving_factor 0.0 Factor multiplying the velocity for the comoving shift 0.0:2.0 :: \"[0,2] is allowed, but [0,1] is probably reasonable\" comoving_attenuate \"tanh\" Which attenuation method for the comoving shift \"sqrt\" :: \"Multiply by sqrt(rho/rho_max)\"; \"tanh\" :: \"Multiply by \u00bd(1+tanh(factor(rho/rho_max - offset)))\" comoving_v_method \"projected\" Which method for getting the radial velocity \"projected\" :: \"vr = x_i . v^i / r\"; \"components\" :: \"vr = sqrt(v_i v^i)\" comoving_tanh_factor 10.0 The factor in the above tanh attenuation (0.0: :: \"Any positive number\" comoving_tanh_offset 0.05 The offset in the above tanh attenuation 0.0:1.0 :: \"Only makes sense in [0,1]\" set_trivial_rp_grid_function 0 set gf for triv. rp (only for debugging) 0:1 :: \"0 for no (default), 1 for yes\" evolve_tracer \"no\" Should we advect tracers? number_of_tracers 0 Number of tracer variables to be advected 0: :: \"positive or zero\" use_min_tracer \"no\" Should there be a floor on the tracer? min_tracer 0.0 The floor placed on the tracer : :: \"Anything\" number_of_particles 0 Number of particles to track 0: :: \"0 switches off particle tracking\" number_of_arrays 0 Number of arrays to evolve 0:3 :: \"Either zero or three, depending on the particles\" particle_interpolator \"Lagrange What interpolator should be used for the particles \".+\":: \"A valid interpolator name\" particle_interpolation_order 2 What order should be used for the particle interpolation 1: :: \"A valid positive interpolation order\" gradient_method \"First Which method is used to set GRHydro::DiffRho? \"First diff\":: \"Standard first differences\"; \"Curvature\" :: \"Curvature based method of Paramesh / FLASH\"; \"Rho weighted\":: \"Based on the size of rho\" GRHydro_NaN_verbose 2 The warning level for NaNs occuring within GRHydro 0: :: \"The warning level\" GRHydro_lorentz_overshoot_cutoff 1.e100 Set the Lorentz factor to this value in case it overshoots (1/0) 0: :: \"Some big value\" clean_divergence \"no\" Use hyperbolic divergence cleaning kap_dc 10.0 The kap parameter for divergence cleaning 0: :: \"Any non-negative value, but 1.0 to 10.0 seems preferred\" psidcspeed \"light Which speed to set for psidc \"char speed\":: \"Based on the characteristic speeds\"; \"light speed\" :: \"Set the characteristic speeds to speed of light\"; \"set speed\" :: \"Manually set the characteristic speeds: [setcharmin,setcharmax]\" setcharmax 1.0 Maximum characteristic speed for psidc if psidcspeed is set 0:1 :: \"Any value smaller than speed of light\" setcharmin -1.0 Minimum characteristic speed for psidc if psidcspeed is set -1:0 :: \"Any value smaller than speed of light - sign should be negative\" decouple_normal_Bfield yes when using divergence cleaning properly decouple Bx,psidc subsystem track_divB \"no\" Track the magnetic field constraint violations transport_constraints \"no\" Use constraint transport for magnetic field Avec_gauge \"lorenz\" Which gauge condition to use when evolving the vector potential \"algebraic\":: \"Algebraic gauge\"; \"lorenz\" :: \"Lorenz gauge\" Tmunu_damping_radius_min -1 damping radius at which we start to damp with a tanh function -1:: \"damping switched off\"; 0: :: \"damping radius at which we start to damp\" Tmunu_damping_radius_max -1 damping radius at which Tmunu becomes 0 -1:: \"damping switched off\"; 0: :: \"greater than minimum radius above\" con2prim_oct_hack \"no\" Disregard c2p failures in oct/rotsym90 boundary cells with xyz < 0 GRHydro_c2p_warn_from_reflevel 0 Start warning on given refinement level and on higher levels 0: :: \"Greater or equal to 0\" sync_conserved_only no Only sync evolved conserved quantities during evolution. use_MoL_slow_multirate_sector no Whether to make use of MoL's slow multirate sector verbose no Some debug output constrain_to_1D no Set fluid velocities to zero for non-radial motion use_cxx_code yes Use experimental C++ code? GRHydro_InitData This thorn generates some initial data for the GRHydro code. Parameter Key Defaults Describe Option initial_hydro \"xshock\" \"shocktube\" :: \"Shocktube type\"; \"shocktube_hot\" :: \"Shocktube with hot nuclear EOS\"; \"only_atmo\":: \"Set only a low atmosphere\"; \"read_conformal\":: \"After reading in initial alp, rho and gxx from h5 files, sets the other quantities\"; \"simple_wave\" :: \"Set initial data from Anile Miller Motta, Phys.Fluids. 26, 1450 (1983)\"; \"monopole\":: \"Monopole at the center\"; \"cylexp\":: \"Cylindrical Explosion\"; \"rotor\" :: \"Magnetic Rotor test from DelZanna,Bucciantini, and Londrillo A&A 400, 397-413 (2003)\"; \"advectedloop\":: \"Magnetic advected loop test\"; \"alfvenwave\":: \"Circularly polarized Alfven wave\"; \"hydro_bondi_solution\" :: \"Spherical single black hole Bondi solution\"; \"hydro_bondi_solution_iso\" :: \"Spherical single black hole Bondi solution - TEST ISO CASE!!!!!!\"; \"magnetized_bondi_solution\" :: \"Magnetized Spherical single black hole Bondi solution\"; \"magnetized_bondi_solution_iso\" :: \"Magnetized Spherical single black hole Bondi solution - TEST ISO CASE!!!!!!\"; }; ; EXTENDS KEYWORD initial_Bvec; {; \"shocktube\":: \"Shocktube type\"; \"cylexp\" :: \"Poloidal Magnetic Field\"; \"poloidalmagfield\" :: \"Poloidal Magnetic Field\"; \"magnetized Bondi\" :: \"radial magnetic field appropriate for Bondi test\"; }; ; EXTENDS KEYWORD initial_Avec; {; \"poloidalmagfield\" :: \"Poloidal Magnetic Field\"; }; ; EXTENDS KEYWORD initial_entropy; {; \"magnetized Bondi\" :: \"Initial entropy for a radial magnetic field appropriate for Bondi test\"; }; ; ; shares:ADMBase; ; EXTENDS KEYWORD initial_data \"\"; {; #\"shocktube\":: \"Shock tube initial data for GRHydro\"; \"con2primtest\":: \"Testing the con -> prim conversion\"; \"con2prim2con_test\" :: \"Testing the con -> prim -> con conversion\"; \"prim2con2prim_test\":: \"Testing the prim -> con -> prim conversion\"; \"prim2con2prim_polytype_test\":: \"Testing the prim -> con -> prim conversion - polytype version\"; \"reconstruction_test\" :: \"Testing reconstruction\"; }; ; private:; ; KEYWORD shocktube_type \"Diagonal or parallel shock?\"; {; \"diagshock\":: \"Diagonal across all axes\"; \"diagshock2d\" :: \"Diagonal across x-y axes\"; \"xshock\":: \"Parallel to x axis\"; \"yshock\":: \"Parallel to y axis\"; \"zshock\":: \"Parallel to z axis\"; \"sphere\":: \"spherically symmetric shock\" shock_case \"Sod\" Simple, Sod's problem or other? \"Simple\":: \"GRAstro_Hydro test case\"; \"Sod\" :: \"Sod's problem\"; \"Blast\" :: \"Strong blast wave\"; \"Balsaralike1\" :: \"Hydro version of Balsara Test #1\"; \"Balsara0\":: \"Balsara Test #1, but unmagnetized\"; \"Balsara1\":: \"Balsara Test #1\"; \"Balsara2\":: \"Balsara Test #2\"; \"Balsara3\":: \"Balsara Test #3\"; \"Balsara4\":: \"Balsara Test #4\"; \"Balsara5\":: \"Balsara Test #5\"; \"Alfven\":: \"Generical Alfven Test\"; \"Komissarov1\" :: \"Komissarov Test #1\"; \"Komissarov2\" :: \"Komissarov Test #2\"; \"Komissarov3\" :: \"Komissarov Test #3\"; \"Komissarov4\" :: \"Komissarov Test #4\"; \"Komissarov5\" :: \"Komissarov Test #5\"; \"Komissarov6\" :: \"Komissarov Test #6\"; \"Komissarov7\" :: \"Komissarov Test #7\"; \"Komissarov8\" :: \"Komissarov Test #8\"; \"Komissarov9\" :: \"Komissarov Test #9\" shock_xpos 0.0 Position of shock plane: x ::: \"Anything\" shock_ypos 0.0 Position of shock plane: y ::: \"Anything\" shock_zpos 0.0 Position of shock plane: z ::: \"Anything\" shock_radius 1.0 Radius of sperical shock 0.0: :: \"Anything positive\" change_shock_direction 0.3 Change the shock direction 0:1 :: \"It is the sound speed where the fluid velocity is zero\" simple_wave_v_max 0.7 The v_max constant in Anile Miller Motta, Phys.Fluids. 26, 1450 (1983) 0:1 :: \"It is the maximum velocity in the initial configuration (see p. 1457, bottom of first column)\" the 0.0 atmosphere : :: \"Anything\" attenuate_atmosphere \"no\" Attenuate the velocity in the atmosphere Bx_init 0.0 Initial B-field in the x-dir : :: \"Anything\" By_init 0.0 Initial B-field in the y-dir : :: \"Anything\" Bz_init 0.0 Initial B-field in the z-dir : :: \"Anything\" rho_init 1.0d-6 Initial rest mass density (0::: \"Anything positive.\" velx_init 1.0d-1 Initial x velocity ::: \"Anything.\" vely_init 1.0d-1 Initial y velocity ::: \"Anything.\" velz_init 1.0d-1 Initial z velocity ::: \"Anything.\" eps_init 1.0d-6 Initial specific internal energy (0::: \"Anything positive.\" press_init 6.666666666666667d-7 Initial pressure (0::: \"Anything positive.\" use_c2p_with_entropy_eqn no Use the con2prim routine that uses the entropy equation instead of the energy equation dens_init 1.29047362 Initial conserved mass density (0::: \"Anything positive.\" sx_init 0.166666658 Initial x component of conserved momentum density ::: \"Anything.\" sy_init 0.166666658 Initial y component of conserved momentum density ::: \"Anything.\" sz_init 0.166666658 Initial z component of conserved momentum density ::: \"Anything.\" tau_init 0.484123939 Initial conserved total energy density (0::: \"Anything positive.\" gxx_init 1.0 Initial xx metric componenent ::: \"Anything, but be carefull to set a positive definite 3-metric!\" gxy_init 0.0 Initial xy metric componenent ::: \"Anything, but be carefull to set a positive definite 3-metric!\" gxz_init 0.0 Initial xz metric componenent ::: \"Anything, but be carefull to set a positive definite 3-metric!\" gyy_init 1.0 Initial yy metric componenent ::: \"Anything, but be carefull to set a positive definite 3-metric!\" gyz_init 0.0 Initial yz metric componenent ::: \"Anything, but be carefull to set a positive definite 3-metric!\" gzz_init 1.0 Initial zz metric componenent ::: \"Anything, but be carefull to set a positive definite 3-metric!\" monopole_type \"Point\" Which kind of monopole? \"Point\" :: \"Single point with Bx /= 0\"; \"Gauss\" :: \"Gaussian w/radius R_Gauss\"; \"1dalt\" :: \"1-d alternating\"; \"2dalt\" :: \"2-d alternating\"; \"3dalt\" :: \"3-d alternating\" R_Gauss 1.0 Radius for a Gaussian monopole 0: :: \"Any positive number\" Monopole_point_Bx 1.0 Pointlike Monopole Bx value : :: \"Any number\" cyl_r_inner 0.8 Inner Radius (0: :: \"Any positive number\" cyl_r_outer 1.0 Outer Radius (0: :: \"Any positive number\" cyl_rho_inner 1.d-2 density in inner core (0: :: \"any positive number\" cyl_press_inner 1.d0 pressure in inner core (0: :: \"any positive number\" cyl_rho_outer 1.d-4 density in outer region (0: :: \"any positive number\" cyl_press_outer 3.d-5 pressure in outer region (0: :: \"any positive number\" advectedloop_type \"2D\" 2-dimensional or 3-dimensional? \"2D\":: \"2-dimensional (B^z=0)\"; \"3D\":: \"3-dimensional (B^3=0, where B^3 advectedloop_case \"V^z=0\" V^z=0 or not? \"V^z=0\":: \"Useful to evaluate divB deviations\"; \"V^z/=0\" :: \"Useful to evaluate con2prim robustness in keeping V^z const.\" advectedloop_delA \"Exact\" How to calculate B^i field from the potential A^b \"Exact\" :: \"Analytic, exact closed formula applied\"; \"Numeric\" :: \"Finite difference approximation of the derivatives applied\" alfvenwave_type \"1D\" 1-dimensional or 2-dimensional? \"1D\":: \"1-dimensional\"; \"2D\":: \"2-dimensional (in x-y plane)\" alfvenwave_pressure 1.0 P_gas for the Alfven wave (0: :: \"positive\" mdot_sonicpt_bondi 12.566370614359172954 Accretion rate at sonic point in hydro units (0: :: \"positive\" solution 1.e-15 { (-1.:1.) :: (0::: \"dimensionless inner radius for Bondi solution\" bondi_bmag 0.01 B_0 parameter for magnetized Bondi 0: :: \"Anything positive\" bondi_radial_offset 0.0 redefine r_grid=r_KS-r0 to avoid singularity on grid 0: :: \"Any positive number\" set_bondi_beta_sonicpt no Set plasma beta parameter instead of bondi_bmag bondi_Bvec_method \"direct\" how to compute the magnetic field vector \"direct\":: \"directly from Cartesian metric\"; \"transform\" :: \"transform Schwarzschild solution to Kerr Schild\" bondi_evolve_only_annulus \"no\" reset to initial data outside of bondi_freeze_inner_radius and bondi_freeze_outer_radius bondi_freeze_inner_radius -1. reset to initial at radii below this : :: \"any value\" bondi_freeze_outer_radius 1e300 reset to initial at radii above this : :: \"any value\" bondi_overwrite_boundary \"no\" reset data to initial data in outer boundary in boundary condition poloidal_P_p 1 Index of pressure factor (0: :: \"Any non-negative integer\" rotor_xc 0.5 center of rotation : :: \"Any location\" rotor_yc 0.5 center of rotation : :: \"Any location\" rotor_bvcxl 1.0 intial component of Bvec[0] : :: \"any real number\" rotor_bvcyl 0.0 intial component of Bvec[1] : :: \"any real number\" rotor_bvczl 0.0 intial component of Bvec[2] : :: \"any real number\" rotor_r_rot 0.1 radius of rotor (0: :: \"any positive number\" rotor_v_max 0.995 Maximum velocity (-1:1) :: \"any subluminal speed (negative is clockwise)\" rotor_rhoin 10.d0 initial density inside rotor (0: :: \"any positive number\" rotor_pressin 1.d0 initial pressure inside rotor (0: :: \"any positive number\" rotor_rhoout 1.d0 initial density outside rotor (0: :: \"any positive number\" rotor_pressout 1.d0 initial pressure outside rotor (0: :: \"any positive number\" rotor_use_smoothing yes Smooth the edge? rotor_rsmooth_rel 0.05 Define the radius in relative terms if so (0: :: \"any positive number\" Black Hole AHFinder This thorn looks for apparent horizons (AH) in 3D. An AH is defined as a surface where the expansion of outgoing null geodesics is zero. It calulates various quantities like horizon area and its corresponding mass. Description ahfinder::ahf_active To activate the thorn set ahf_active = \u201dyes\u201d . This parameter is set by default to \u201dno\u201d. ahfinder::ahf_flow By default the minimization algorithm is used. To switch to the flow algorithm one has to set ahf_flow = \u201dyes\u201d . ahfinder::ahf_findevery Specifies how often the finder is called. The default is to find horizons at every iteration. ahfinder::ahf_findafter The number of iterations after which the thorn is called the first time can be specified by this parameter. ahfinder::ahf_findaftertime Instead of specifying the number of iterations, one can specify after how much coordinate time the thorn is called the first time. ahfinder::ahf_lmax The maximal number of terms in the expansion in \u03b8. The default value is 8. The maximal value is 19. ahfinder::ahf_phi If axisymmetry is expected the surface does not need to be expanded in phi. This is the default. To look for non-axisymmetric surface use ahf_phi = \u201dyes\u201d . ahfinder::ahf_[xyz]c Sets the x-, y-, and z-coordinates of the center of the expansion. The default is the origin (ahf_xc = 0, ahf_yc = 0, ahf_zc = 0). The center of the expansion should be set inside the expected apparent horizon, otherwise the algorithm will fail. ahfinder::ahf_wander The center of the expansion can also be allowed to move. To do this use ahf_wander = \u201dyes\u201d . However, this only works with the minimization algorithm. ahfinder::ahf_r0 Sets the radius of the initial sphere. The default is 0.0, forcing the largest sphere possible in the grid. ahfinder::ahf_find3 Set ahf_find3 = \u201dyes\u201d to search for three horizons. The default is to look for only one horizon. ahfinder::ahf_[xyz]_[012] Sets the x-, y-, and z-coordinates of the center of the expansion for horizon 0, 1 and 2. The default in each case is the origin. ahfinder::ahf_r0_[0-2] Sets the radius of the initial spheres for horizon 0, 1 and 2. The default in all cases is 0.0, forcing the largest sphere possible in the grid. ahfinder::ahf_guessold To use on old horizon as initial guess set ahf_guessold = \u201dyes\u201d . However, if during the evolution the apparent horizon jumps discontinuously it might be lost by using this option. ahfinder::ahf_nn0, ahfinder::ahf_nn2 If no old horizon is used the inital guess can be specified further for the minimization algorithm. This algorithm is sensitive to the initial guess, so this is important. ahfinder::ahf_sloppyguess It is also possible to use only a sphere as initial guess. This is much faster and is done by using ahf_sloppyguess = \u201dyes\u201d . ahfinder::ahf_inner If one wants to look for an inner horizon instead of an outer one, use ahfinder::ahf_inner = \u201dyes\u201d . This only works with the minimization algorithm. ahfinder::ahf_ntheta The number of subdivisions in \u03b8. ahfinder::ahf_nphi The number of subdivisions in \\phi \\phi . Parameter Key Defaults Describe Option ahf_active \"no\" Activate AHFinder? ahf_persists \"no\" Do the finder grid functions stay around? ahf_ReportAlways \"no\" Report for all surfaces found (yes) or just for apparent horizons (no) ahf_find3 \"no\" Searching for 3 surfaces? ahf_trapped_surface \"no\" Minimize (expansion + delta) to find trapped surface? ahf_findevery 1 How often to look for horizons 1: :: \"Set to 1 for searching each iteration\" ahf_findafter 0 After how many iterations look for horizons 0: :: \"Any positive integer\" ahf_findaftertime 0.0 After how much time look for horizons 0.0: :: \"Any positive real number. If non-zero overides ahf_findafter\" trapped_surface_delta 0.0 find (expansion = delta) surface : :: \"Just a real number\" ahf_phi \"no\" Expand also in phi? (seach for non-axisymmetric surface) ahf_offset \"no\" Center offset from origin? ahf_wander \"no\" Allow the center to wander? ahf_lmax 8 Maximum number of terms in theta expansion 0:19 :: \"Range from 0 to 19\" ahf_xc 0.0 x-coordinate of center of expansion : :: \"Anything\" ahf_yc 0.0 y-coordinate of center of expansion : :: \"Anything\" ahf_zc 0.0 z-coordinate of center of expansion : :: \"Anything\" ahf_xc_0 0.0 x-coordinate of center of expansion for first surface with find3 : :: \"Anything\" ahf_yc_0 0.0 y-coordinate of center of expansion for first surface with find3 : :: \"Anything\" ahf_zc_0 0.0 z-coordinate of center of expansion for first surface with find3 : :: \"Anything\" ahf_xc_1 0.0 x-coordinate of center of expansion for second surface with find3 : :: \"Anything\" ahf_yc_1 0.0 y-coordinate of center of expansion for second surface with find3 : :: \"Anything\" ahf_zc_1 0.0 z-coordinate of center of expansion for second surface with find3 : :: \"Anything\" ahf_xc_2 0.0 x-coordinate of center of expansion for third surface with find3 : :: \"Anything\" ahf_yc_2 0.0 y-coordinate of center of expansion for third surface with find3 : :: \"Anything\" ahf_zc_2 0.0 z-coordinate of center of expansion for third surface with find3 : :: \"Anything\" ahf_ntheta 100 Number of subdivisions in theta 1: :: \"Any sensible integer\" ahf_nphi 100 Number of subdivisions in phi 1: :: \"Any sensible integer\" ahf_refx \"no\" Reflection symmetry x->-x? ahf_refy \"no\" Reflection symmetry y->-y? ahf_refz \"no\" Reflection symmetry z->-z? ahf_cartoon \"no\" Cartoon mode? ahf_octant \"no\" Octant symmetry? \"no\" :: \"No octant symmetry\"; \"yes\":: \"Octant symmetry: reflection symmetry on all three coordinate planes\"; \"high\" :: \"Octant symmetry + symmetry of rotation of pi/2 around z axis\" ahf_minarea \"no\" Minimize area instead of expansion? ahf_maxiter 10 Maximum number of iterations of POWELL : :: \"Any sensible integer value\" ahf_tol 0.1 Tolerance for minimization routines 0: :: \"A sensible positive number\" ahf_sloppyguess \"no\" Use sphere as initial guess? ahf_guess_absmin \"no\" Use absolute min to start minimization? ahf_guessold \"no\" Use old horizon as initial guess? ahf_inner \"no\" Look for inner horizon? ahf_manual_guess \"no\" Use specified coefficients for guess? ahf_nn0 10 Number of subdivisions of c0(0) for initial guess : :: \"Some positive integer\" ahf_nn2 10 Number of subdivisions of c0(2) for initial guess : :: \"Some positive integer\" ahf_r0 0.0 Radius of initial sphere (0 forces largest sphere) : :: \"Anything\" ahf_r0_0 0.0 Radius of first initial sphere for find3 (0 forces largest sphere) : :: \"Anything\" ahf_r0_1 0.0 Radius of second initial sphere for find3 (0 forces largest sphere) : :: \"Anything\" ahf_r0_2 0.0 Radius of third initial sphere for find3 (0 forces largest sphere) : :: \"Anything\" ahf_flow \"no\" Use flow instead of minimization? ahf_flowiter 200 Maximum number of iterations for flow 0: :: \"Anything\" ahf_flowa 0.01 alpha parameter for flow : ::\"Anything\" ahf_flowb 0.5 beta parameter for flow : :: \"Anything\" ahf_flowh 0.0 Weight of H flow : :: \"Anything\" ahf_flowc 1.0 Weight of C flow : :: \"Anything\" ahf_flown 0.0 Weight of N flow : :: \"Anything\" ahf_flowtol 0.0001 Tolerance for flow : :: \"Anything\" ahf_maxchange 0.1 Maximum relative difference between 1 big and 2 small steps : :: \"Anything\" ahf_minchange 0.01 Minimum relative difference between 1 big and 2 small steps : :: \"Anything\" ahf_logfile \"no\" Write log file? ahf_verbose \"yes\" Print messages to screen? ahf_veryverbose \"no\" Print messages at each iteration step to screen? ahf_guessverbose \"no\" Print info on initial guess? ahf_1Doutput \"no\" 1D output of grid functions? ahf_2Doutput \"no\" 2D output of grid functions? ahf_3Doutput \"no\" 3D output of grid functions? ahf_HDF5output \"no\" HDF5 output of AHFinder data? ahf_areamap \"no\" Find area map? ahf_gaussout \"yes\" Output gaussian curvature of horizon? ahf_mask \"off\" Use mask? \"off\":: \"Mask is off\"; \"strong\" :: \"Mask set only for definite horizons\"; \"weak\" :: \"Mask set for both definite and probable horizons\" ahf_masktype \"cube\" Type of mask \"lego\" :: \"Mask is a lego sphere\"; \"cube\" :: \"Mask is a cube\"; \"poly\" :: \"Mask is a polyhedra\" ahf_mask_time -1.0 Time after which to start setting the mask : :: \"Anything goes. Negative number means setting the mask as soon as possible\" ahf_mask_0 \"yes\" Mask for first horizon with find3? ahf_mask_1 \"yes\" Mask for second horizon with find3? ahf_mask_2 \"yes\" Mask for third horizon with find3? ahf_maskbuffer 5 Number of grid points in mask buffer zone 0 :: \"Positive please\" ahf_maskshrink 0.8 Shrink factor for mask 0.0:1.0 :: \"Must be positive and not larger than 1\" ahf_shiftcoeff 0.0 Coefficient for shift : :: \"Anything goes\" interpolation_order 2 Order for interpolation 1:4 :: \"Choose between first and fourth order interpolation\" interpolation_operator \"uniform Name of interpolation operator to use \".+\" :: \"A valid name for a registered interpolation operator\" Example Minimal parameter settings 1 2 3 4 5 # The simplest parameter settings for using the flow algorithm for a full 3D horizon with a large sphere as initial guess interpolation_order = 2 # Second order interpolation ahf_active = \"yes\" ahf_flow = \"yes\" ahf_phi = \"yes\" AHFinderDirect The BH apparent horizon is located and monitored through the AHFinderDirect thorn. We estimate the BH mass M_{\\mathrm{BH}} M_{\\mathrm{BH}} and the BH dimensionless spin parameter a / M_{\\mathrm{BH}} a / M_{\\mathrm{BH}} using the isolated horizon formalism. Thorn AHFinderDirect finds an apparent horizon by numerically solving equation \\Theta \\equiv \\nabla_{i} n^{i}+K_{i j} n^{i} n^{j}-K=0 \\Theta \\equiv \\nabla_{i} n^{i}+K_{i j} n^{i} n^{j}-K=0 It requires as input the usual Cactus 3-metric g_{i j} g_{i j} and extrinsic curvature K_{i j} K_{i j} , (and optionally the conformal factor \\psi \\psi if the StaticConformal metric semantics are used), and produces as output the Cactus(x, y, z) coordinates of a large number of points on the apparent horizon, together with some auxiliary information like the apparent horizon area and centroid position, and the irreducable mass associated with the area. There are some restrictions on the spacetime, or more precisely on each slice where you want to find apparent horizons, which are necessary in order for AHFinderDirect to work: AHFinderDirect requires that the Cactus geometry ( g_{i j} g_{i j} , K_{i j} K_{i j} and \\psi \\psi ) be nonsingular in a neighborhood of the apparent horizon. In particular, this means that it quite certainly will not work for spacetimes/slicings which have a singular geometry on the horizon, such as Schwarzschild/Schwarzschild and Kerr/Boyer-Lindquist. Less obviously, this also means that if there is a singularity in the geometry somewhere near the apparent horizon, then you need to have a high enough Cactus 3-D grid resolution that the geometry interpolation doesn\u2019t \u201csee\u201d the singularity. At the moment AHFinderDirect and the Cactus interpolators don\u2019t know how to avoid an excised region, so if the apparent horizon gets too close to an excised region, you\u2019ll get garbage results as the interpolator tries to interpolate data from the excised region. Description This thorn has lots of parameters, but most of them have reasonable default values which you probably won\u2019t need to change. Here I describe the parameters which you are likely to want to at least look at, and possibly set explicitly. find_every This is an integer parameter specifying how often AHFinderDirect should try to find apparent horizons. N_horizons How many apparent horizons do you want to find in each slice? Note that N_horizons sets the number of apparent horizons you want to find in the Cactus 3-D numerical grid, not in the whole spacetime. verbose_level This controls how verbose this thorn is in printing informational (non-error) messages describing what it\u2019s doing. In order from tersest to most verbose, the allowable values are \"no output\": Don\u2019t print anything. \"physics highlights\": Print only a single line each time AHFinderDirect runs, giving which horizons were found. \"physics details\": Print two lines for each horizon found, giving the horizon area, centroid position, and irreducible mass. \"algorithm highlights\": Also print a single line for each Newton iteration giving the 2-norm and \u221e-norm of the \\Theta(h) \\Theta(h) \"algorithm details\": Print lots of detailed messages tracing what the code is doing. \"algorithm debug\": Print even more detailed messages tracing what the code is doing, mainly useful for debugging purposes. For each apparent horizon you want to \ufb01nd, you need to specify the Cactus (x, y, z) coordinates of a local coordinate system origin. You specify the local coordinate system origin for each horizon with the (Cactus array) parameters origin_x[n], origin_y[n] and origin_z[n] AHFinderDirect requires an initial guess for the apparent horizon\u2019s coordinate position and shape, for each apparent horizon you want to find. For AHFinderDirect there\u2019s no restriction on whether the initial guess is inside, outside, or crossing the actual apparent horizon: the only important thing is that it should be \u201cclose\u201d. If we succeed in finding a given apparent horizon, than that apparent horizon position is automatically reused as the initial guess the next time we try to find the same apparent horizon. There are a number of parameters for specifying the initial guess: initial_guess_method[n] This sets what type of the initial guess is used for each apparent horizon position. There are several possibilities, most with their own sets of subparameters \"read from file\": This reads the initial-guess h(angle) function from a data \ufb01le. The file format is currently hard-wired to be that written with file_format = \"ASCII (gnuplot)\". The subparameter initial_guess__read_from_named_file__file_name specifies the \ufb01le name. \"Kerr/Kerr\": This sets the initial guess to the analytically-known apparent horizon position in a Kerr spacetime in Kerr coordinates. \"Kerr/Kerr-Schild\": This sets the initial guess to the analytically-known apparent horizon position in a Kerr spacetime in Kerr-Schild coordinates. \"coordinate sphere\": This sets the initial guess to a coordinate sphere. \"coordinate ellipsoid\": This sets the initial guess to a coordinate ellipsoid The main output of this thorn is the computed horizon shape function h(angle), and correspondingly the (x, y, z) coordinate positions of the apparent-horizon-surface (angular) grid points. There are several parameters controlling if, how often, and how these should be written to data files: output_h_every You can control how often (if at all) the apparent horizon shape(s) are written to data files. file_format This specifies the \ufb01le format for horizon-shape (and other angular-grid-function) data files. Unfortunately, at the moment only a single format is implemented, \"ASCII (gnuplot)\" h_directory This specifies the directory in which the h data files are to be written. If it doesn\u2019t already exist, this directory is created before writing the data files. h_base_file_name This specifies the base \ufb01le name for h data files, as described above. This thorn can optionally set a mask grid function (or functions) at each point of the Cactus grid, to indicate where that point is with respect to the apparent horizon(s). This is usually used for excision. set_mask_for_all_horizons and set_mask_for_individual_horizon[n]. Parameter Key Defaults Describe Option find_every 1 how often should we try to find apparent horizons? 0 :: \"don't find AHs at all (this thorn is a no-op)\"; 1: :: \"any integer >= 1\" run_at_CCTK_ANALYSIS false should we run at CCTK_ANALYSIS? run_at_CCTK_POSTSTEP true should we run at CCTK_POSTSTEP? run_at_CCTK_POSTINITIAL false should we run at CCTK_POSTINITIAL? run_at_CCTK_POSTPOSTINITIAL false should we run at CCTK_POSTPOSTINITIAL? method \"find what should this thorn do for each apparent horizon? # these options are mostly for testing/debugging; # ... in a multiprocessor Cactus run, the horizons are done sequentually; # on processor #0; the other processors do dummy computations; \"evaluate expansions\" :: \"evaluate the LHS function Theta(h)\"; ; # ... in a multiprocessor Cactus run, the Jacobian is computed on; # processor #0; the other processors do dummy computations; \"test expansion Jacobians\" :: \\; \"compute/print horizon 1's J[Theta(h)] Jacobian matrix (possibly in \\; multiple ways, depending on thetest_all_Jacobian_methodsparameter)\"; ; # this is for normal apparent horizon finding; # ... in a multiprocessor Cactus run, the horizons are done in parallel; # across processors; see src/driver/README.parallel for details; \"find horizons\" :: \"find the apparent horizon\" N_horizons 1 number of apparent horizons to search for 0 :: \"turn this thorn into a fancy no-op :)\"; 1:100 :: \"search for this many apparent horizons\" want_expansion_gradients \"false\" should we print the gradients of the expansions? just \"\" base \".+\" :: \"any nonempty string\"; \"^$\" :: \"an empty string to default to IO::out_dir\" output_ASCII_files \"yes\" output h and Theta(h) as ASCII files output_HDF5_files \"no\" output h and Theta(h) as HDF5 files this \"gp\" gnuplot \".+\" :: \"any nonempty string\" HDF5_file_name_extension \"h5\" extension for HDF5 data files \".+\" :: \"any nonempty string\" just \"\" base \".+\" :: \"any nonempty string\"; \"^$\" :: \"an empty string to default to IO::out_dir\" Theta_base_file_name \"Theta\" base file name for Theta(h) output file(s) \".+\" :: \"any nonempty string\" mean_curvature_base_file_name \"mean_curvature\" base file name for mean_curvature(h) output file(s) \".+\" :: \"any nonempty string\" a \"true\" control file with \"false\" .it%d Jacobian_base_file_name \"Jacobian.dat\" base file name for Jacobian output file(s) \".+\" :: \"any valid file name\" an 0.8 outside (0:) :: \\; \"any positive real number; typically this will be slightly less than 1.0\" be -1.0e10 not too small : :: \"any real number\" old_style_mask_gridfn_name \"SpaceMask::emask\" name of the old-style mask grid function \".+\" :: \"any valid Cactus grid function name\" new_style_mask_gridfn_name \"SpaceMask::space_mask\" name of the new-style mask grid function \".+\" :: \"any valid Cactus grid function name\" currently 1 handle -1: :: \"any valid Cactus warning level\" probably 2 just -1: :: \"any valid Cactus warning level\" the 3 check that the geometry is finite -1: :: \"any valid Cactus warning level\" be 1.0e10 not found (0.0: :: \"any positive real number\" be 1.0e10 not found (0.0: :: \"any positive real number\" move_origins \"no\" move the origins with the horizons reshape_while_moving \"no\" reshape the horizons when moving them predict_origin_movement \"no\" predict origin movement when moving the origins than 18 full sphere 1: :: \"any integer >= 1; must be even for patch systems other than full-sphere\" max_N_zones_per_right_angle 18 the maximum of all N_zones_per_right_angle -- calculated automatically; do not set this parameter directly 1: :: \"must be at least the maximum of all N_zones_per_right_angle\" terminology 2 ghost zone 0: :: \"any integer >= 0\" Jacobian_compute_method \"symbolic how do we compute the Jacobian matrix? # for debugging only\"; \"numerical perturbation\":: \"n.b. this is very slow\"; ; # use this for normal apparent horizon finding; \"symbolic differentiation with finite diff d/dr\" :: \\; \"fast, tricky programming, uses only gij, dx gij, Kij\"; ; # alas, this isn't implemented yet :(; \"symbolic differentiation\":: \\; \"fast, tricky programming, uses gij, dx gij, dxx gij, Kij, dx Kij\" ILUCG__error_tolerance 1.0e-10 error tolerance for conjugate gradient iteration (:0.0) :: \\; \"negative ==> scale the absolute value by the floating point roundoff \\; threshold, e.g. -256.0 means to allow the last 8 bits of \\; the solution to be in error\"; (0.0:) :: \\; \"positive ==> error tolerance\" have \"cart3d\" spikes \".+\" :: \"any nonempty string\" geometry__Schwarzschild_EF__mass 1.0 mass of Schwarzschild BH (0.0: :: \"BH mass = any real number > 0\" geometry__Schwarzschild_EF__x_posn 0.0 x coordinate of Schwarzschild BH : :: \"any real number\" geometry__Schwarzschild_EF__y_posn 0.0 y coordinate of Schwarzschild BH : :: \"any real number\" geometry__Schwarzschild_EF__z_posn 0.0 z coordinate of Schwarzschild BH : :: \"any real number\" the 1.0e-6 grid spacing (0.0: :: \"any real number > 0\" integral_method \"automatic how do we compute integrals over the horizon? \"trapezoid\" :: \"alternate name for trapezoid rule\"; \"trapezoid rule\" :: \"trapezoid rule (2 nd order for smooth functions)\"; \"Simpson\" :: \"alternate name for Simpson's rule\"; \"Simpson's rule\" :: \\; \"Simpson's rule (4 th order for smooth fns, requires N to be even)\"; \"Simpson (variant)\" :: \"alternate name for Simpson's rule variant\"; \"Simpson's rule (variant)\":: \\; \"Simpson's rule variant (4 th order for smooth fns, requires N >= 7)\"; ; # choose this for normal use (assuming FINITE_DIFF_ORDER is set to 4; # in \"src/include/config.hh\"); \"automatic choice\" :: \\; \"choose Simpson's rule or variant if applicable, otherwise trapezoid rule\" driver \"gridfn\" src/patch/test_patch_system.cc ##\"gridfn\" :: \"set up test fn(x,y,z), print it\"; ##\"read gridfn\" :: \"read in ghosted test fn(x,y,z), print it\"; ##\"synchronize\" :: \"set up test fn(x,y,z), synchronize it, print errors\"; ##\"ghost zone Jacobian\":: \\; ##\"set up test fn(x,y,z), compute Jacobian of gz.synchronize(), compare with NP\"; ##\"derivatives\" :: \"set up test fn(rho,sigma), take derivs, print errors\"; ## which_derivs 63 bit flags to specify which derivatives to test ##0:63 :: \"any set of bit flags\"; ## Examples 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 cactus::cctk_itlast = 0 ActiveThorns = \"PUGH\" driver::ghost_size = 2 driver::global_nx = 31 driver::global_ny = 31 driver::global_nz = 19 ActiveThorns = \"CoordBase CartGrid3D\" grid::domain = \"bitant\" grid::avoid_origin = false grid::type = \"byspacing\" grid::dxyz = 0.2 ActiveThorns = \"ADMBase ADMCoupling StaticConformal Spacemask CoordGauge Exact\" ADMBase::initial_lapse = \"exact\" ADMBase::initial_shift = \"exact\" ADMBase::initial_data = \"exact\" ADMBase::lapse_evolution_method = \"static\" ADMBase::shift_evolution_method = \"static\" ADMBase::metric_type = \"physical\" Exact::exact_model = \"Kerr/Kerr-Schild\" Exact::Kerr_KerrSchild__mass = 1.0 Exact::Kerr_KerrSchild__spin = 0.6 ######################################## ActiveThorns = \"IOUtil\" IOUtil::parfile_write = \"no\" ######################################## ActiveThorns = \"SphericalSurface\" ActiveThorns = \"AEILocalInterp PUGHInterp PUGHReduce AHFinderDirect\" AHFinderDirect::h_base_file_name = \"Kerr-tiny.h\" AHFinderDirect::N_horizons = 1 AHFinderDirect::origin_x[1] = 0.5 AHFinderDirect::origin_y[1] = 0.7 AHFinderDirect::origin_z[1] = 0.0 AHFinderDirect::initial_guess_method[1] = \"coordinate sphere\" AHFinderDirect::initial_guess__coord_sphere__x_center[1] = -0.2 AHFinderDirect::initial_guess__coord_sphere__y_center[1] = 0.3 AHFinderDirect::initial_guess__coord_sphere__z_center[1] = 0.0 AHFinderDirect::initial_guess__coord_sphere__radius[1] = 2.0 Extract Gravitational Wave To measure the flux of energy and angular momentum carried away by GWs, we use a modi\ufb01ed version of the Psikadelia thorn. https://arxiv.org/pdf/1502.05674.pdf https://arxiv.org/pdf/1809.08237.pdf https://arxiv.org/pdf/gr-qc/0306056.pdf https://arxiv.org/pdf/gr-qc/0206008.pdf Output IO method Description Providing thorn Viz Tools Scalar output of scalars or grid array reductions in xgraph or gnuplot format CactusBase/IOBasic gnuplot Info screen output of scalars or grid array reductions CactusBase/IOBasic gnuplot IOASCII_nD nD line output of grid arrays in xgraph or gnuplot format CactusBase/IOASCII gnuplot IOHDF5_nD nD slice output of grid arrays in HDF5 format CactusPUGHIO/IOHDF5 VisIt IOUtil Input and output of data (I/O) in Cactus is provided by infrastructure thorns, which interact with the flesh via a fixed interface. Thorn IOUtil by itself provides no I/O methods. Description IO::out_dir The name of the directory to be used for output. All the I/O methods described here will write by default to this directory (which itself defaults to the current working directory). Individual methods have parameters which can direct their output to a different directory. IO::out_criterion The criterion that decides when to output. The default is to output every so many iterations. IO::out_every How often, in terms of iterations, each of the Cactus I/O methods will write output. Again, individual methods can set their own parameters to override this. The default is to never write output. IO::out_dt How often, in terms of simulation time, each of the Cactus I/O methods will write output. Again, individual methods can set their own parameters to override this. The default is to never write output. Saving/Generating Parameter Files IO::parfile_write=\"copy\" This is the default option, and makes an exact replica of the input parameter file in the standard output directory (this is particularly useful when the output directory is going to be archived). IO::parfile_write=\"generate\" Generate a new parameter file from runtime information, containing the Cactus version, the name of the original parameter file, the run time/date, the host to run on, and the number of processors - all on comment lines. Following this the parameter file contains the ActiveThorns list plus a sorted list of all active thorns\u2019 parameters which have been set in the original parameter file. IO::parfile_write=\"no\" Switch off writing of a new parameter file. I/O Modes IO::out_mode = \"onefile\" As for the 1D and 2D I/O methods, writing to file is performed only by processor zero. This processor gathers all the output data from the other processors and then writes to a single file. IO::out_mode = \"np\" Output is written in parallel for groups of processors. Each group consists of IO::out_proc_every processors which have assigned one I/O processor which gathers data from the group and writes it to file. IO::out mode = \"proc\" Every processor writes its own chunk of data into a separate output file. While the \"np\" and \"proc\" I/O modes are fast for outputting large amounts of data from all or a group of processors in parallel, they have the disadvantage of writing chunked files. These files then have to be recombined during a postprocessing phase so that the final unchunked data can be visualized by standard tools. Checkpointing and Recovery in Cactus Each checkpoint is saved into a checkpoint file which can be used to restart a new simulation at a later time, recreating the exact state at which it was checkpointed. IO::checkpoint_every specifies how often to write a evolution checkpoint in terms of iteration number. IO::checkpoint_every_walltime_hours specifies how often to write a evolution checkpoint in terms of wall time. Checkpointing will be triggered if either of these conditions is met. IO::checkpoint_next triggers a checkpoint at the end of the current iteration. This flag will be reset afterwards. IO::checkpoint_ID triggers a checkpoint of initial data. IO::checkpoint_on_terminate triggers a checkpoint at the end of the last iteration of a simulation run. IO::checkpoint_file holds the basename for evolution checkpoint file(s) to create Iteration number and file extension are appended by the individual I/O method used to write the checkpoint. IO::checkpoint_ID_file holds the basename for initial data checkpoint file(s) to create Iteration number and file extension are appended by the individual I/O method used to write the checkpoint. IO::checkpoint_dir names the directory where checkpoint files are stored IO::checkpoint_keep specifies how many evolution checkpoints should be kept. The default value of 1 means that only the latest evolution checkpoint is kept and older checkpoints are removed in order to save disk space. Setting IO::checkpoint keep to a positive value will keep so many evolution checkpoints around. A value of \u22121 will keep all (future) checkpoints. IO::recover_and_remove determines whether the checkpoint file that the current simulation has been successfully recovered from, should also be subject of removal, according to the setting of IO::checkpoint_keep IO::recover keyword parameter telling if/how to recover. Choices are \"no\", \"manual\", \"auto\", and \"autoprobe\". IO::recover_file basename of the recovery file. Iteration number and file extension are appended by the individual I/O method used to recover from the recovery file. IO::recover_dir directory where the recovery file is located IO::truncate_files_after_recovering whether or not to truncate already existing output files after recovering. Parameter Key Defaults Describe Option out_dir \".\" Default output directory \".+\" :: \"A valid directory name\" max_entries_per_subdir 0 Number of processes that can access the same directory 0 :: \"unlimited\"; 2: :: \"at most that many processes\" out_criterion \"iteration\" Criterion to select output intervals \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"time\":: \"Output every that much coordinate time\" out_every -1 How often to do output by default 1: :: \"Every so many iterations\"; -1:0 :: \"Disable output\" out_dt -2 How often to do output by default (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Disable output\" verbose \"standard\" Level of screen output for I/O \"none\" :: \"No output\"; \"standard\" :: \"Initial description for each I/O method\"; \"full\" :: \"Maximal output\" print_timing_info \"no\" Print timing information on I/O operations. new_filename_scheme \"yes\" Use the new filename scheme for output files ? require_empty_output_directory \"no\" Require that IO::out_dir is empty at startup ? strict_io_parameter_check \"yes\" Stop on errors while parsing I/O parameters from parameter file ? abort_on_io_errors \"no\" Abort on I/O errors (rather than just print a warning) ? out_fileinfo \"all\" Add some useful file information to output files ? \"none\" :: \"no file information\"; \"creation date\":: \"add creation date\"; \"parameter filename\" :: \"add parameter filename\"; \"axis labels\":: \"add axis labels information to output files\"; \"all\":: \"add all available file information\" out_group_separator \"-\" String to separate group name from variable name in file name \"\" :: \"Note: The old default was'::'\" out_mode \"proc\" Which mode to use for output \"proc\":: \"Every processor writes its share of data into a separate file\"; \"np\":: \"Data is collected and written by every N'th processor into a separate file, where N is specified by the parameter IO::out_proc_every\"; \"onefile\" :: \"All output is written into a single file by processor 0\" out_proc_every 8 Do output on every N processors 1: :: \"A number between [1, nprocs)\" out_timesteps_per_file -1 How many timesteps to write to a single file # 1: :: \"Number of timesteps per file\"; 1:1 :: \"Number of timesteps per file (can only be 1 so far)\"; -1::: \"All timesteps in a single file\" out3D_septimefiles \"no\" Write one file per time slice, as opposed to all data in one file out_unchunked \"no\" Don't write data in chunks. This parameter is ignored for single-processor runs where output is always done in unchunked mode. out_save_parameters \"only Save current parameter settings in output files ? \"all\":: \"Save all parameter settings\"; \"only set\" :: \"Only save parameters which have been set before\"; \"no\" :: \"Don't save parameter settings\" out_downsample_x 1 Factor by which to downsample output in x direction. Point (0,0,0) is always included. 1: :: \"A positive integer\" out_downsample_y 1 Factor by which to downsample output in y direction. Point (0,0,0) is always included. 1: :: \"A positive integer\" out_downsample_z 1 Factor by which to downsample output in z direction. Point (0,0,0) is always included. 1: :: \"A positive integer\" out_single_precision \"no\" Output data in single precision ? checkpoint_ID \"no\" Checkpoint initial data ? recover \"no\" Recover from a checkpoint file ? \"no\":: \"Don't recover\"; \"manual\":: \"Recover from the checkpoint file as given in IO::recover_dir and IO::recover_file\"; \"auto\":: \"Automatically recover from the latest checkpoint file found in \"; \"autoprobe\" :: \"Probe for checkpoint files and automatically recover, continue as usual if nothing was found\" checkpoint_every -1 How often to checkpoint 1: :: \"Every so many iterations\"; -1:0 :: \"Disable periodic checkpointing\" checkpoint_every_walltime_hours -1 How often to checkpoint (0: :: \"After so much walltime has passed\"; -1 :: \"Disable periodic walltime checkpointing\" checkpoint_on_terminate \"no\" Checkpoint after last iteration checkpoint_keep 1 How many checkpoint files to keep 1: :: \"1 overwrites the latest checkpoint file\"; -1::: \"Keep all checkpoint files\" checkpoint_file \"checkpoint.chkpt\" File name for regular checkpoint \".+\" :: \"A valid filename\" checkpoint_ID_file \"checkpoint.chkpt\" File name for initial data checkpoint \".+\" :: \"A valid filename\" recover_file \"checkpoint.chkpt\" Basename of recovery file \".+\" :: \"A valid filename\" checkpoint_dir \".\" Output directory for checkpoint files \".+\" :: \"A valid directory name\" recover_dir \".\" Directory to look for recovery files \".+\" :: \"A valid directory name\" filereader_ID_dir \".\" Directory to look for input files \".+\" :: \"A valid directory name\" filereader_ID_files \"\" List of basenames of files to read in as initial data (e.g. omit the filename extention here) \".+\" :: \"Space-separated list of initial data filenames (basenames, e.g. excluding the file name extention)\"; \"^$\" :: \"An empty string for not recovering initial data\" filereader_ID_vars \"all\" List of variables to read in from the given initial data files \"all\" :: \"Read all variables contained in the initial data files\"; \".+\":: \"Space-separated list of fully qualified variable/group names\"; \"^$\":: \"An empty string for not recovering initial data\" recover_and_remove \"no\" Remove checkpoint file after successful recovery ? parfile_write \"copy\" Write a parameter file to 'IO::out_dir' \"no\" :: \"Do not write a parameter file\"; \"copy\" :: \"Copy the original parameter file\"; \"generate\" :: \"Generate a parameter file from the current settings\"; #\"verbose generate\" :: \"Like \\\"generate\\\" but describe all parameters in detail\" parfile_name \"\" Filename for the parameter file to be written \".+\" :: \"A valid filename\"; \"^$\" :: \"An empty string to choose the original parameter filename\" parfile_update_every 0 How often to update the parameter file for steered parameters 1: :: \"Every so many iterations\"; 0::: \"Disable updating\" out_xline_y 0.0 y-coord for 1D lines in x-direction : :: \"A value between [ymin, ymax]\" out_xline_z 0.0 z-coord for 1D lines in x-direction : :: \"A value between [zmin, zmax]\" out_yline_x 0.0 x-coord for 1D lines in y-direction : :: \"A value between [xmin, xmax]\" out_yline_z 0.0 z-coord for 1D lines in y-direction : :: \"A value between [zmin, zmax]\" out_zline_x 0.0 x-coord for 1D lines in z-direction : :: \"A value between [xmin, xmax]\" out_zline_y 0.0 y-coord for 1D lines in z-direction : :: \"A value between [ymin, ymax]\" out_xline_yi -2 y-index (from 0) for 1D lines in x-direction, overrides IO::out_xline_y 0: :: \"An index between [0, ny)\"; -1::: \"Default to physical coordinate IO::out_xline_y if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_xline_y if it is within grid bounds, otherwise revert to using the y-center of the box\" out_xline_zi -2 z-index (from 0) for 1D lines in x-direction, overrides IO::out_xline_z 0: :: \"An index between [0, nz)\"; -1::: \"Default to physical coordinate IO::out_xline_z if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_xline_z if it is within grid bounds, otherwise revert to using the z-center of the box\" out_yline_xi -2 x-index (from 0) for 1D lines in y-direction, overrides IO::out_yline_x 0: :: \"An index between [0, nx)\"; -1::: \"Default to physical coordinate IO::out_yline_x if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_yline_x if it is within grid bounds, otherwise revert to using the x-center of the box\" out_yline_zi -2 z-index (from 0) for 1D lines in y-direction, overrides IO::out_yline_z 0: :: \"An index between [0, nz)\"; -1::: \"Default to physical coordinate IO::out_yline_z if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_yline_z if it is within grid bounds, otherwise revert to using the z-center of the box\" out_zline_xi -2 x-index (from 0) for 1D lines in z-direction, overrides IO::out_zline_x 0: :: \"An index between [0, nx)\"; -1::: \"Default to physical coordinate IO::out_zline_x if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_zline_x if it is within grid bounds, otherwise revert to using the x-center of the box\" out_zline_yi -2 y-index (from 0) for 1D lines in z-direction, overrides IO::out_zline_y 0: :: \"An index between [0, ny)\"; -1::: \"Default to physical coordinate IO::out_zline_y if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_zline_y if it is within grid bounds, otherwise revert to using the y-center of the box\" out_yzplane_x 0.0 x-coord for 2D planes in yz : :: \"A value between [xmin, xmax]\" out_xzplane_y 0.0 y-coord for 2D planes in xz : :: \"A value between [ymin, ymax]\" out_xyplane_z 0.0 z-coord for 2D planes in xy : :: \"A value between [zmin, zmax]\" out_yzplane_xi -2 x-index (from 0) for 2D planes in yz, overrrides IO::out_yzplane_x 0: :: \"An index between [0, nx)\"; -1::: \"Default to physical coordinate IO::out_yzplane_x if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_yzplane_x if it is within grid bounds, otherwise revert to using the x-center of the box\" out_xzplane_yi -2 y-index (from 0) for 2D planes in xz, overrrides IO::out_xzplane_y 0: :: \"An index between [0, ny)\"; -1::: \"Default to physical coordinate IO::out_xzplane_y if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_xzplane_y if it is within grid bounds, otherwise revert to using the y-center of the box\" out_xyplane_zi -2 z-index (from 0) for 2D planes in xy, overrrides IO::out_xyplane_z 0: :: \"An index between [0, nz)\"; -1::: \"Default to physical coordinate IO::out_xyplane_z if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_xyplane_z if it is within grid bounds, otherwise revert to using the z-center of the box\" truncate_files \"yes\" Truncate existing output files from previous runs (except when recovering) ? truncate_files_after_recovering \"no\" Truncate existing output files after recovering ? Example Output information to screen using IOBasic\u2019s \"Info\" I/O method 1 2 3 4 5 6 ActiveThorns = \"IOBasic IOUtil PUGHReduce ...\" # Output using all methods on iteration 0, 10, 20, ... IO::out_every = 10 # Group of variables to output to screen IOBasic::outInfo_vars = \"evolve::vars\" Scalar Output from IOBasic\u2019s \"Scalar\" I/O method 1 2 3 4 5 6 ActiveThorns = \"IOBasic IOUtil PUGHReduce ...\" # Output vars using scalar method on iteration 0, 10, 20, ... IOBasic::outScalar_every = 10 # Group of variables to output to file IOBasic::outScalar_vars = \"evolve::vars\" ASCII 1D and 2D Output with IOASCII\u2019s \"IOASCII_1D\" and \"IOASCII_2D\" I/O methods 1 2 3 4 5 6 ActiveThorns = \"IOASCII IOUtil PUGHSlab ...\" # Output vars in 1D on iteration 0, 10, 20, ... IOASCII::out1D_every = 10 # Output vars in 2D on iteration 0, 50, 100, ... IOASCII::out2D_every = 50 HDF5 Output with IOHDF5\u2019s \"IOHDF5\" I/O method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ActiveThorns = \"IOHDF5 IOUtil PUGHSlab ...\" # Output vars in HDF5 format on iteration 0, 5, 10, ... IOHDF5::out_every = 5 # Group of variables to output IOHDF5::out_vars = \"evolve::vars\" # Special I/O directory for HDF5 output IOHDF5::out_dir = \"/scratch/tmp\" # Full output unchunked to one file (Only using a small number of processors) IO::out_mode = \"onefile\" IO::out_unchunked = \"yes\" # Downsample full data by a factor of 3 in each direction IO::out_downsample_x = 3 IO::out_downsample_y = 3 IO::out_downsample_z = 3 Recovering from a checkpoint file 1 2 3 4 5 6 ActiveThorns = \"IOFlexIO FlexIO IOUtil PUGHSlab ...\" # automatically choose the latest checkpoint file IO::recover = \"auto\" # Name and directory of checkpoint file to recover from IO::recover_file = \"run5\" IO::recover_dir = \"/scratch/tmp\" IOBasic This thorn provides two I/O methods \"Info\" and \"Scalar\" which output grid variables as scalars as a function on time. Scalar This method outputs the information into ASCII files named \" .{asc|xg}\" (for CCTK_SCALAR variables) and \" _ .{asc|xg}\" (for CCTK_GF and CCTK_ARRAY variables where reduction would stand for the type of reduction value that is output). The output data can be plotted by using either xgraph (for *.xg files) or gnuplot (for *.asc files). The output style can be selected via parameter settings. Info This method prints the data as runtime information to stdout. The output occurs as a table with columns containing the current iteration number, the physical time at this iteration, and more columns for scalar/reduction values of each variable to be output. Description Parameters to control the Scalar I/O method are: IOBasic::outScalar_criterion The criterion that decides when to Scalar output. If this parameter is set in the parameter file, it will override the setting of the shared IO::out_criterion parameter. IOBasic::outScalar_every How often, in terms of iterations, to do Scalar output. If this parameter is set in the parameter file, it will override the setting of the shared IO::out_every parameter. IOBasic::outScalar_dt How often, in terms of simulation time, to do Scalar output. If this parameter is set in the parameter file, it will override the setting of the shared IO::out_dt parameter. IOBasic::out_dir The directory in which to place the Scalar ASCII output files. If the directory doesn\u2019t exist at startup it will be created. If this parameter is set to an empty string Scalar output will go to the standard output directory as specified in IO::out_dir . IOBasic::outScalar_style How to start comments in the Scalar ASCII output files. Possible choices for this keywork parameter are xgraph and gnuplot. IOBasic::out_format The output format for floating-point numbers in Scalar output. IOBasic::outScalar_vars The list of variables to output into individual ASCII files. IOBasic::outScalar_reductions The list of global reduction operations to perform on CCTK_GF and CCTK_ARRAY variables for Scalar output. This setting can be overridden for individual variables using an option string. Multiple reduction names must be separated by spaces. IOBasic::outInfo_criterion The criterion that decides when to Info output. If this parameter is set in the parameter file, it will override the setting of the shared IO::out_criterion parameter. IOBasic::outInfo_every How often, in terms of iterations, to do Info output. If this parameter is set in the parameter file, it will override the setting of the shared IO::out every parameter. IOBasic::outInfo_dt How often, in terms of simulation time, to do Info output. If this parameter is set in the parameter file, it will override the setting of the shared IO::out_dt parameter. IOBasic::outInfo_vars The list of variables to output to screen. IOBasic::outInfo_reductions The default list of global reduction operations to perform on CCTK_GF and CCTK_ARRAY variables. Parameter Key Defaults Describe Option out_dir \"\" Output directory for IOBasic's scalar files, overrides IO::out_dir \".+\" :: \"A valid directory name\"; \"^$\" :: \"An empty string to choose the default from IO::out_dir\" outInfo_vars \"\" Variables to output as Info to screen \".+\" :: \"Space-separated list of fully qualified variable/group names\"; \"^$\" :: \"An empty string to output nothing\" outScalar_vars \"\" Variables to output into files \".+\" :: \"Space-separated list of fully qualified variable/group names\"; \"^$\" :: \"An empty string to output nothing\" outInfo_reductions \"minimum List of reductions to output as Info to screen \".+\" :: \"Space-separated list of reduction operators\" outScalar_reductions \"minimum List of reductions to output into files \".+\" :: \"Space-separated list of reduction operators\" outInfo_criterion \"iteration\" Criterion to select Info output intervals \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"time\":: \"Output every that much coordinate time\" outInfo_every -1 How often to do Info output 1: :: \"Every so many iterations\"; 0::: \"Disable Info output\"; -1::: \"Default to IO::out_every\" outInfo_dt -2 How often to do Info output (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" outScalar_criterion \"iteration\" Criterion to select Scalar output intervals \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"time\":: \"Output every that much coordinate time\" outScalar_every -1 How often to do Scalar output 1: :: \"Every so many iterations\"; 0::: \"Disable Scalar output\"; -1::: \"Default to IO::out_every\" outScalar_dt -2 How often to do Scalar output (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" outScalar_style \"xgraph\" Which style for Scalar output \"gnuplot\" :: \"1D output readable by gnuplot\"; \"xgraph\":: \"1D output readable by xgraph\" out_format \".13f\" Which format for Scalar floating-point number output \"^(.[1]?[0-9])?[EGefg]$\" :: \"output with given precision in exponential / floating point notation\" Examples The minimum and maximum of grid::r is printed according to the list of default reductions for info output (parameter IOBasic::outInfo_reductions ). This list is overridden for wavetoy::phi where only the L2 norm is output as specified in the option string for this variable. You can also add other reduction operators within the {} braces. For the scalar variable mythorn::complex both the real and imaginary part are printed. 1 2 3 4 5 IOBasic::outInfo_every = 2 IOBasic::outInfo_vars = \"grid::r wavetoy::phi{reductions = \u2019norm2\u2019} mythorn::complex\" IOBasic::outInfo_reductions = \"minimum maximum\" The resulting screen output would look like this: The following parameter settings request scalar output Output occurs every 10 th iteration. gnuplot output style is selected for the ASCII files which are placed into a subdirectory scalar_output . 1 2 3 4 5 6 7 IOBasic::outScalar_every =10 IOBasic::outScalar_vars = \"grid::coordinates grid::coarse_dx wavetoy::phi{\u2019norm1\u2019}\" IOBasic::outScalar_reductions = \"minimum maximum\" IOBasic::outScalar_style = \"gnuplot\" IOBasic::out_dir = \"scalar_output\" This would create the following ASCII files: CarpetIOBasic This thorn provides info output for Carpet. Parameter Key Defaults Describe Option outInfo_vars \"\" Variables to output in scalar form \"\" :: \"A regex which matches everything\" outInfo_reductions \"minimum List of reductions to output in scalar form \"\" :: \"A regex which matches everything\" outInfo_criterion \"iteration\" Criterion to select scalar output intervals, overrides out_every \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if iteration mod divisor == 0.\"; \"time\":: \"Output every that much coordinate time\" outInfo_every -2 How often to do scalar output, overrides IO::out_every 1: :: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Default to IO::out_every\" outInfo_dt -2 How often to do scalar output, overrides out_dt (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" outHeader_every 20 How often to print the header 1: :: \"Output every so many time steps\" ; -1 :: \"No header output\" iter_width 9 Field width for the current iteration 1: :: \"\" time_width 9 Field width for the simulation time 1: :: \"\" time_prec 3 Precision for the simulation time 0: :: \"\" int_width 9 Field width for integer values 1: :: \"\" real_width 12 Field width for real values 1: :: \"\" real_prec 7 Precision for real values 0: :: \"\" real_prec_sci 6 Precision for real values in scientific notation 0: :: \"\" real_min 1.0e-8 Lower bound for numbers that are displayed in fixed notation (0.0: :: \"\" real_max 1.0e+3 Upper bound for numbers that are displayed in fixed notation (0.0: :: \"\" CarpetIOScalar This thorn provides scalar output for Carpet. Parameter Key Defaults Describe Option one_file_per_group \"no\" Write one file per group instead of per variable all_reductions_in_one_file \"no\" Write all requested reductions in one file instead of per reduction out_precision 15 How many digits to output floating-point numbers with 0: :: \"Number of precision digits\" outScalar_dir \"\" Name of scalar output directory, overrides out_dir \"^$\" :: \"Empty: use IO::out_dir\"; \".+\" :: \"Not empty: directory name\" outScalar_vars \"\" Variables to output in scalar form \"\" :: \"A regex which matches everything\" outScalar_reductions \"count List of reductions to output in scalar form \"\" :: \"A regex which matches everything\" outScalar_criterion \"iteration\" Criterion to select scalar output intervals, overrides out_every \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if iteration mod divisor == 0.\"; \"time\":: \"Output every that much coordinate time\" outScalar_every -2 How often to do scalar output, overrides IO::out_every 1: :: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Default to IO::out_every\" outScalar_dt -2 How often to do scalar output, overrides out_dt (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" IOHDF5 This thorn does output of arbitrary Cactus variables in HDF5 file format. It also provides checkpointing/recovery functionality. Parameter Key Defaults Describe Option out_every -1 How often to do IOHDF5 output, overrides IO::out_every 1: :: \"Every so many iterations\"; 0::: \"Disable IOHDF5 output\"; -1::: \"Default to IO::out_every\" out_dir \"\" Output directory for IOHDF5 files, overrides IO::out_dir \".+\" :: \"A valid directory name\"; \"^$\" :: \"An empty string to choose the default from IO::out_dir\" out_vars \"\" Variables to output in HDF5 file format \".+\" :: \"Space-separated list of fully qualified variable/group names\"; \"^$\" :: \"An empty string to output nothing\" checkpoint \"no\" Do checkpointing with HDF5 checkpoint_next \"no\" Checkpoint at next iteration CarpetIOHDF5 The CarpetIOHDF5 I/O method can output any type of CCTK grid variables (grid scalars, grid functions, and grid arrays of arbitrary dimension); data is written into separate files named \" .h5\". Such data\ufb01les can be used for further postprocessing or fed back into Cactus via the filereader capabilities of thorn IOUtil. Checkpointing for thorn CarpetIOHDF5 is enabled by setting the parameter IOHDF5::checkpoint = \"yes\" . Description IOHDF5::out_every How often to do periodic CarpetIOHDF5 output. If this parameter is set in the parameter \ufb01le, it will override the setting of the shared IO::out_every parameter. IOHDF5::out_dt output in intervals of that much coordinate time. IOHDF5::out_criterion criterion to select output intervals IOHDF5::out_vars The list of variables to output using the CarpetIOHDF5 I/O method. The variables must be given by their fully qualified variable or group name. Multiple names must be separated by whitespaces. Each group/variable name can have an option string attached in which you can specify a different output frequency for that individual variable, a set of individual refinement levels to be output, the compression level, or an individual output mode. 1 IOHDF5::out_vars = \"wavetoy::phi{ out_every = 4 refinement_levels = { 1 2 } }\" IOHDF5::out_dir The directory in which to place the CarpetIOHDF5 output files. If the directory doesn\u2019t exist at startup it will be created. If this parameter is set to an empty string CarpetIOHDF5 output will go to the standard output directory as specified in IO::out_dir . IOHDF5::compression_level Compression level to use for writing HDF5 datasets. Automatic gzip dataset compression can be enabled by setting this integer parameter to values between 1 and 9 (inclusive), with increasing values requesting higher compression rates (at the cost of additional runtime for outputting HDF5 data); a value of zero (which is the default setting for this parameter) disables compression. The output compression level can also be set for individual variables using the compression_level option in an option string appended to the IOHDF5::out_vars parameter. IO::out_single_precision whether to output double-precision data in single precision. According to the ouptput mode parameter settings of ( IO::out_mode , IO::out_unchunked , IO::out_proc_every ) of thorn IOUtil, thorn CarpetIOHDF5 will output distributed grid variables either in serial from processor 0 into a single unchunked \ufb01le 1 2 IO::out_mode = \"onefile\" IO::out_unchunked = \"yes\" in serial from processor 0 into a single chunked \ufb01le 1 2 IO::out_mode = \"onefile\" IO::out_unchunked = \"no\" in parallel, that is, into separate chunked files (one per processor) containing the individual processors\u2019 patches of the distributed grid variable 1 IO::out_mode = \"proc\" The default is to output distributed grid variables in parallel, each processor writing a file <varname>.file_<processor ID>.h5 . The chunked/unchunked mode can also be set individually in a key/value option string (with the key out_unchunked and possible string values \"true|false|yes|no\") appended to a group/variable name in the out_vars parameter, 1 IOHDF5::out_vars = \"wavetoy::phi{out_unchunked = \u2019true\u2019} grid::coordinates\" will cause the variable phi to be output into a single unchunked file whereas other variables will still be output into separate chunked files. When visualising chunked datasets, they probably need to be recombined for a global view on the data. This needs to be done within the visualisation tool, Cactus itself does not provide its own recombiner utility program for CarpetIOHDF5\u2019s output files. Parameter Key Defaults Describe Option out_dir \"\" Name of CarpetIOHDF5 output directory, overrides 'IO::out_dir' \"^$\" :: \"Empty: use IO::out_dir\"; \".+\" :: \"Not empty: directory name\" out0D_dir \"\" Name of 0D HDF5 slice output directory, overrides IO::out_dir \"^$\" :: \"Empty: use IO::out_dir\"; \".+\" :: \"Not empty: directory name\" out1D_dir \"\" Name of 1D HDF5 slice output directory, overrides IO::out_dir \"^$\" :: \"Empty: use IO::out_dir\"; \".+\" :: \"Not empty: directory name\" out2D_dir \"\" Name of 2D HDF5 slice output directory, overrides IO::out_dir \"^$\" :: \"Empty: use IO::out_dir\"; \".+\" :: \"Not empty: directory name\" out3D_dir \"\" Name of 3D HDF5 slice output directory, overrides IO::out_dir \"^$\" :: \"Empty: use IO::out_dir\"; \".+\" :: \"Not empty: directory name\" out_vars \"\" Variables to output in CarpetIOHDF5 file format \"\" :: \"List of group or variable names\" out0D_vars \"\" Variables to output in 0D HDF5 file format \"\" :: \"List of group or variable names\" out1D_vars \"\" Variables to output in 1D HDF5 file format \"\" :: \"List of group or variable names\" out2D_vars \"\" Variables to output in 2D HDF5 file format \"\" :: \"List of group or variable names\" out3D_vars \"\" Variables to output in 3D HDF5 file format \"\" :: \"List of group or variable names\" out_extension \".h5\" File extension to use for CarpetIOHDF5 output \"\" :: \"File extension (including a leading dot, if desired)\" out_criterion \"default\" Criterion to select CarpetIOHDF5 output intervals, overrides out_every \"default\" :: \"Use 'IO::out_criterion'\"; \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if (iteration % out_every) == 0.\"; \"time\":: \"Output every that much coordinate time\" out0D_criterion \"default\" Criterion to select 0D HDF5 slice output intervals, overrides out_every \"default\" :: \"Use IO::out_criterion\"; \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if iteration mod divisor == 0.\"; \"time\":: \"Output every that much coordinate time\" out1D_criterion \"default\" Criterion to select 1D HDF5 slice output intervals, overrides out_every \"default\" :: \"Use IO::out_criterion\"; \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if (iteration % out_every) == 0.\"; \"time\":: \"Output every that much coordinate time\" out2D_criterion \"default\" Criterion to select 2D HDF5 slice output intervals, overrides out_every \"default\" :: \"Use IO::out_criterion\"; \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if (iteration % out_every) == 0.\"; \"time\":: \"Output every that much coordinate time\" out3D_criterion \"default\" Criterion to select 3D HDF5 slice output intervals, overrides out_every \"default\" :: \"Use IO::out_criterion\"; \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if (iteration % out_every) == 0.\"; \"time\":: \"Output every that much coordinate time\" out_every -2 How often to do CarpetIOHDF5 output, overrides out_every 1::: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Use 'IO::out_every'\" out0D_every -2 How often to do 0D HDF5 slice output, overrides out_every 1::: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Use IO::out_every\" out1D_every -2 How often to do 1D HDF5 slice output, overrides out_every 1::: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Use IO::out_every\" out2D_every -2 How often to do 2D HDF5 slice output, overrides out_every 1::: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Use IO::out_every\" out3D_every -2 How often to do 3D HDF5 slice output, overrides out_every 1::: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Use IO::out_every\" out_dt -2 How often to do CarpetIOHDF5 output, overrides 'IO::out_dt' (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to 'IO::out_dt'\" out0D_dt -2 How often to do 0D HDF5 slice output, overrides IO::out_dt (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" out1D_dt -2 How often to do 1D HDF5 slice output, overrides IO::out_dt (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" out2D_dt -2 How often to do 2D HDF5 slice output, overrides IO::out_dt (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" out3D_dt -2 How often to do 3D HDF5 slice output, overrides IO::out_dt (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" out0D_point_xi 0 x-index (counting from 0) for 0D points 0: :: \"\" out0D_point_yi 0 y-index (counting from 0) for 0D points 0: :: \"\" out0D_point_zi 0 z-index (counting from 0) for 0D points 0: :: \"\" out0D_point_x 0 x coordinate for 0D points : :: \"\" out0D_point_y 0 y coordinate for 0D points : :: \"\" out0D_point_z 0 z coordinate for 0D points : :: \"\" out1D_x \"yes\" Do 1D HDF5 slice output in the x-direction out1D_y \"yes\" Do 1D HDF5 slice output in the y-direction out1D_z \"yes\" Do 1D HDF5 slice output in the z-direction out1D_xline_yi 0 y-index (counting from 0) for 1D lines in x-direction 0: :: \"\" out1D_xline_zi 0 z-index (counting from 0) for 1D lines in x-direction 0: :: \"\" out1D_yline_xi 0 x-index (counting from 0) for 1D lines in y-direction 0: :: \"\" out1D_yline_zi 0 z-index (counting from 0) for 1D lines in y-direction 0: :: \"\" out1D_zline_xi 0 x-index (counting from 0) for 1D lines in z-direction 0: :: \"\" out1D_zline_yi 0 y-index (counting from 0) for 1D lines in z-direction 0: :: \"\" out1D_xline_y 0 y coordinate for 1D lines in x-direction : :: \"\" out1D_xline_z 0 z coordinate for 1D lines in x-direction : :: \"\" out1D_yline_x 0 x coordinate for 1D lines in y-direction : :: \"\" out1D_yline_z 0 z coordinate for 1D lines in y-direction : :: \"\" out1D_zline_x 0 x coordinate for 1D lines in z-direction : :: \"\" out1D_zline_y 0 y coordinate for 1D lines in z-direction : :: \"\" out2D_xy \"yes\" Do 2D HDF5 slice output in the xy-direction out2D_xz \"yes\" Do 2D HDF5 slice output in the xz-direction out2D_yz \"yes\" Do 2D HDF5 slice output in the yz-direction out2D_xyplane_zi 0 z-index (counting from 0) for 2D planes in xy-direction 0: :: \"\" out2D_xzplane_yi 0 y-index (counting from 0) for 2D planes in xz-direction 0: :: \"\" out2D_yzplane_xi 0 x-index (counting from 0) for 2D planes in yz-direction 0: :: \"\" out2D_xyplane_z 0 z coordinate for 2D planes in xy-direction : :: \"\" out2D_xzplane_y 0 y coordinate for 2D planes in xz-direction : :: \"\" out2D_yzplane_x 0 x coordinate for 2D planes in yz-direction : :: \"\" output_all_timelevels \"no\" Output all timelevels instead of only the current output_symmetry_points \"yes\" Output symmetry points (assuming that there are nghostzones symmetry points) output_ghost_points \"yes\" Output ghost points output_boundary_points \"yes\" Output outer boundary points (assuming that there are nghostzones boundary points) output_buffer_points \"yes\" Output refinement buffer points out3D_ghosts \"yes\" Output ghost zones (DEPRECATED) out3D_outer_ghosts \"yes\" Output outer boundary zones (assuming that there are nghostzones boundary points) (DEPRECATED) out1D_d \"yes\" Do output along the diagonal checkpoint \"no\" Do checkpointing with CarpetIOHDF5 ? checkpoint_next \"no\" Checkpoint at next iteration ? checkpoint_every_divisor -1 Checkpoint if (iteration % out_every) == 0 1: :: \"Every so many iterations\"; -1:0 :: \"Disable periodic checkpointing\" use_reflevels_from_checkpoint \"no\" Use 'CarpetRegrid::refinement_levels' from the checkpoint file rather than from the parameter file ? use_grid_structure_from_checkpoint \"yes\" Use the grid structure stored in the checkpoint file one_file_per_proc \"no\" Write one file per process instead of per variable one_file_per_group \"no\" Write one file per group instead of per variable open_one_input_file_at_a_time \"no\" Open only one HDF5 file at a time when reading data from multiple chunked checkpoint/data files \"no\":: \"Open all input files first, then import data (most efficient)\"; \"yes\" :: \"Process input files one after another (reduces memory requirements)\" skip_recover_variables \"\" Skip these variables while recovering \"\" :: \"\" compression_level 0 Compression level to use for writing HDF5 data 0:9 :: \"Higher numbers compress better, a value of zero disables compression\" minimum_size_for_compression 32768 Only compress datasets larger than this many bytes 0: :: \"This should to be large enough so that compression gains outweigh the overhead\" use_checksums \"no\" Use checksums for the HDF5 data output_index \"no\" Output an index file for each output file Example Serial (unchunked) Output of Grid Variables 1 2 3 4 5 6 7 8 9 10 # how often to output and where output files should go IO::out_every = 2 IO::out_dir = \"wavetoy-data\" # request output for wavetoy::psi at every other iteration for timelevel 0, for wavetoy::phi every 4th iteration with timelevels 1 and 2 IOHDF5::out_vars = \"wavetoy::phi{ out_every = 4 refinement_levels = { 1 2 } } wavetoy::psi\" # we want unchunked output (because the visualisation tool cannot deal with chunked data files) IO::out_mode = \"onefile\" IO::out_unchunked = 1 Checkpointing & Recovery 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # say how often we want to checkpoint, how many checkpoints should be kept, how the checkpoints should be named, and they should be written to IO::checkpoint_every = 100 IO::checkpoint_keep = 2 IO::checkpoint_file = \"wavetoy\" IO::checkpoint_dir = \"wavetoy-checkpoints\" # enable checkpointing for CarpetIOHDF5 IOHDF5::checkpoint = \"yes\" ####################################################### # recover from the latest checkpoint found IO::recover_file = \"wavetoy\" IO::recover_dir = \"wavetoy-checkpoints\" IO::recover = \"auto\" TimerReport This thorn provides mechanisms for obtaining different information from timers during a Cactus run. Parameter Key Defaults Describe Option out_every 0 How often to output timer report to screen 0 :: \"No periodic output (default)\"; 1: :: \"Every so many iterations\" out_at -1 Output timer information at a given iteration -1 :: \"Do not output at specific iteration (default)\"; 0::: \"At this iteration\" out_filename \"\" File name for timer reports \" ^$ \" :: \"empty filename: print to stdout\"; \" ^.+$ \" :: \"otherwise: print to that file\" before_checkpoint \"no\" Before a checkpoint next \"no\" On next iteration output_schedule_timers \"yes\" Output the schedule timers in a formatted tabular format output_all_timers \"no\" Output one file per processor containing all the Cactus timers output_all_timers_together \"no\" Output three files (formats .txt, .csv, and .tsv), containing information about all the Cactus timers (average, minimum, and maximum over all processors) output_all_timers_readable \"no\" Output one file containing information about all the Cactus timers (average, minimum, and maximum over all processors), in a format that is readable by humans all_timers_clock \"gettimeofday\" Which clock to use for the all timers output \".\" :: \"any clock name allowed\" n_top_timers 0 How many timers to include in the top timer report 0 :: \"Do not print the report\"; 1: :: \"Any number of timers\" Extension NaNChecker The NaNChecker thorn can be used to analyze Cactus grid variables (that is grid functions, arrays or scalars) of real or complex data type for NaN (Not-a-Number) and in\ufb01nite values. Parameter Key Defaults Describe Option check_every 0 How often to check for NaNs 0 :: \"Never (default)\"; 1: :: \"Every so many iterations\" check_after 0 Start checking for NaNs after so many iterations 0: :: \"Any valid iteration number\" report_max -1 How many NaNs to report for a single variable -1 :: \"Report all (default)\"; 0: :: \"Do not report more than report_max number of NaNs\" check_vars \"\" Groups and/or variables to check for NaNs . :: \"List of full group and/or variable names, or 'all' for everything\" check_for \"both\" Check for NaNs and/or infinite numbers (only evaluated if finite(3) is available) \"NaN\":: \"Check only for NaNs\"; \"Inf\":: \"Check only for infinite numbers\"; \"both\" :: \"Check for both NaNs and infinite numbers\" out_NaNmask \"yes\" Dump the NaN grid function mask into an HDF5 file action_if_found \"just What to do if a NaN was found \"just warn\" :: \"Just print a level 1 warning\"; \"terminate\" :: \"Warn and terminate Cactus gracefully as soon as possible\"; \"abort\" :: \"Warn and abort Cactus immediately\" verbose \"standard\" How much information to give \"all\":: \"All information\"; \"standard\" :: \"Standard information\" ignore_restricted_points \"no\" do not check grid points whose values will be restricted away setup_test \"no\" set up grid function with NaNs TerminationTrigger This thorn watches the elapsed walltime. If only n minutes are left before the some limit set by the user, it triggers termination of the simulation. Parameter Key Defaults Describe Option on_remaining_walltime 0.0 When to trigger termination in MINUTES 0.0:: \"Don't trigger termination\"; (0.0: :: \"So many minutes before your job walltime is over\" max_walltime 0.0 Walltime in HOURS allocated for this job 0.0:: \"Don't trigger termination\"; (0.0: :: \"Should be positive, right\" termination_from_file \"no\" Use termination file; specified by termination_filename create_termination_file \"no\" Create an empty termination file at startup termination_file \"/tmp/cactus_terminate\" Termination file name (either full path or relative to IO::out_dir) \"\" ::\"Termination file\" check_file_every 1 Check termination file every n timesteps 1: :: \"\" output_remtime_every_minutes 60.0 Output remaining wall time every n minutes 0.0:: \"No output\"; (0.0: :: \"Output\" testsuite \"no\" manually trigger termination","title":"Parameter"},{"location":"ET/parameter/#flesh","text":"The Cactus flesh knows about everything in schedule.ccl files, and handles sorting scheduled routines into an order which is consistent with the BEFORE and AFTER clauses in all the schedule groups. The flesh also handles repeatedly calling scheduled routines which are scheduled with a WHILE clause. In addition, the flesh determines when storage is turned on/off for grid scalars, functions, and arrays and when grid arrays and functions are synchronised, based on the STORAGE: and SYNC: statements in schedule blocks. 1 2 # Flesh parameters Cactus::<Flesh parameters> = <Value> The default value is shown in square brackets, while curly braces show allowed parameter values. Value Describe Cactus::cctk_run_title Description of this simulation [\"\"] Cactus::cctk_full_warnings Give detailed information for each warning statement [yes] Cactus::highlight_warning_messages Highlight CCTK warning messages [yes] Cactus::cctk_timer_output Give timing information [off] {off, full} Cactus::allow_mixeddim_gfs Allow use of GFs from different dimensions [no] Cactus::cctk_brief_output Give only brief output [no] Cactus::cctk_show_banners Show any registered banners for the different thorns [yes] Cactus::cctk_show_schedule Print the scheduling tree to standard output [yes] Cactus::cctk_strong_param_check Die on parameter errors in CCTK_PARAMCHECK [yes] Cactus::recovery_mode How to behave when recovering from a checkpoint [strict] {strict, relaxed} Cactus::info_format Specifies the content and format of CCTK_INFO()/CCTK_VINFO messages. [basic] {\"basic\", \"numeric time stamp\", \"human-readable time stamp\", \"full time stamp\"} Cactus::terminate Condition on which to terminate evolution loop [iteration] {never, iteration, time, runtime, any, all} Cactus::cctk_final_time Final time for evolution, overridden by cctk_itlast unless it is positive [-1.0] Cactus::cctk_initial_time Initial time for evolution [0.0] Cactus::cctk_itlast Final iteration number [10] Cactus::max_runtime Terminate evolution loop after a certain elapsed runtime (in minutes); set to zero to disable this termination condition [0] Cactus::terminate_next Terminate on next iteration ? [no]","title":"Flesh"},{"location":"ET/parameter/#coordinate-systems","text":"","title":"Coordinate Systems"},{"location":"ET/parameter/#coordbase","text":"The CoordBase thorn provides a method of registering coordinate systems and their properties. The data describing coordinate systems are held on Cactus key-value tables. Thorns which provide coordinates will inherit from CoordBase. The coordinate values themselves can be specified in a number of ways, depending on the nature of the coordinate system. This way symmetries of the coordinates on the computational grid can be exploited to minimize memory consumption. Since computations performed with Cactus are done on a discrete lattice, only a discrete set of coordinate values are used for any coordinate system. The symmetries of how the coordinate values vary on the grid points make coordinates fall into three types: uniform, nonuniform, and warped. For a uniform coordinate system, it is sufficient to specify the origin and spacing for a uniform coordinate. A nonuniform coordinate can be specified with a 1D grid variable. A warped coordinate system will always need a nD grid variable. FMR and AMR will need an nD grid variable to specify the coordinate values. CoordBase provides a way for specifying the extent of the simulation domain that is independent of the actual coordinate and symmetry thorns. This is necessary because the size of the physical domain is not necessarily the same as the size of the computational grid, which is usually enlarged by symmetry zones and/or boundary zones. CoordBase also provides a way for specifying the discretisation of the boundary that is independent of the actual boundary thorns. This defines the locations of the boundary points and thus the extent of the computational grid. When it is necessary to increase the number of boundary points, then boundary_size_x_lower is the only parameter that needs to be changed. The boolean parameter boundary_internal_x_lower specifies whether the boundary points extend inwards at the lower x face. The boundary points should either be staggered about the physical boundary, or the last boundary point should be located exactly on the physical boundary. This is specified by the boolean parameter boundary_staggered_x_lower . The integer parameter boundary_shiftout_x_lower can be used to shift the boundary points outwards (or inwards with negative values) by multiples of the grid spacing.","title":"CoordBase"},{"location":"ET/parameter/#parameter","text":"Key Defaults Describe Option domainsize \"minmax\" Domain size specification \"minmax\":: \"lower and upper boundary locations\"; \"extent\":: \"coordinate extent\"; \"spacing\" :: \"grid spacing and number of grid cells\" spacing \"gridspacing\" Grid spacing specification \"gridspacing\" :: \"grid spacing\"; \"numcells\":: \"number of grid cells\" zero_origin_x \"no\" Is the lower boundary located at x=0? xmin 0.0 Location of lower x boundary (:) :: \"\" xmax 1.0 Location of upper x boundary (:) :: \"\" xextent 1.0 Domain extent in x direction (0:) :: \"\" dx 1.0 Grid spacing in x direction (0:) :: \"\" ncells_x 1 Number of grid cells in x direction 0: :: \"\" zero_origin_y \"no\" Is the lower boundary located at y=0? ymin 0.0 Location of lower y boundary (:) :: \"\" ymax 1.0 Location of upper y boundary (:) :: \"\" yextent 1.0 Domain extent in y direction (0:) :: \"\" dy 1.0 Grid spacing in y direction (0:) :: \"\" ncells_y 1 Number of grid cells in y direction 0: :: \"\" zero_origin_z \"no\" Is the lower boundary located at z=0? zmin 0.0 Location of lower z boundary (:) :: \"\" zmax 1.0 Location of upper z boundary (:) :: \"\" zextent 1.0 Domain extent in z direction (0:) :: \"\" dz 1.0 Grid spacing in z direction (0:) :: \"\" ncells_z 1 Number of grid cells in z direction 0: :: \"\" boundary_size_x_lower 1 Boundary zones at the lower x face 0: :: \"\" boundary_internal_x_lower \"no\" Do the boundary points extend inwards at the lower x face? boundary_staggered_x_lower \"no\" Is the boundary is staggered about the grid points at the lower x face? boundary_shiftout_x_lower 0 Offset between the boundary location and the first boundary point at the lower x face : :: \"when not staggered: use 0 for an open, 1 for a closed manifold\" boundary_size_x_upper 1 Boundary zones at the upper x face 0: :: \"\" boundary_internal_x_upper \"no\" Do the boundary points extend inwards at the upper x face? boundary_staggered_x_upper \"no\" Is the boundary is staggered about the grid points at the upper x face? boundary_shiftout_x_upper 0 Offset between the boundary location and the first boundary point at the upper x face : :: \"when not staggered: use 0 for an open, 1 for a closed manifold\" boundary_size_y_lower 1 Boundary zones at the lower y face 0: :: \"\" boundary_internal_y_lower \"no\" Do the boundary points extend inwards at the lower y face? boundary_staggered_y_lower \"no\" Is the boundary is staggered about the grid points at the lower y face? boundary_shiftout_y_lower 0 Offset between the boundary location and the first boundary point at the lower y face : :: \"when not staggered: use 0 for an open, 1 for a closed manifold\" boundary_size_y_upper 1 Boundary zones at the upper y face 0: :: \"\" boundary_internal_y_upper \"no\" Do the boundary points extend inwards at the upper y face? boundary_staggered_y_upper \"no\" Is the boundary is staggered about the grid points at the upper y face? boundary_shiftout_y_upper 0 Offset between the boundary location and the first boundary point at the upper y face : :: \"when not staggered: use 0 for an open, 1 for a closed manifold\" boundary_size_z_lower 1 Boundary zones at the lower z face 0: :: \"\" boundary_internal_z_lower \"no\" Do the boundary points extend inwards at the lower z face? boundary_staggered_z_lower \"no\" Is the boundary is staggered about the grid points at the lower z face? boundary_shiftout_z_lower 0 Offset between the boundary location and the first boundary point at the lower z face : :: \"when not staggered: use 0 for an open, 1 for a closed manifold\" boundary_size_z_upper 1 Boundary zones at the upper z face 0: :: \"\" boundary_internal_z_upper \"no\" Do the boundary points extend inwards at the upper z face? boundary_staggered_z_upper \"no\" Is the boundary is staggered about the grid points at the upper z face? boundary_shiftout_z_upper 0 Offset between the boundary location and the first boundary point at the upper z face : :: \"when not staggered: use 0 for an open, 1 for a closed manifold\"","title":"Parameter"},{"location":"ET/parameter/#cartgrid3d","text":"This thorn sets up a Cartesian grid, for a given domain. It also provides a method for registering symmetries of Grid Functions across the grid axes, and a call for applying symmetry boundary conditions.","title":"CartGrid3D"},{"location":"ET/parameter/#specifying-the-grid-size-range-and-spacing","text":"CartGrid3D provides several different methods for setting up the integer grid size, floating-point grid spacing, and floating-point grid range. You specify which method to use, with the grid::type parameter. Value Describe byrange You specify the x, y, and z grid ranges, either with separate grid::xmin , grid::xmax , grid::ymin , grid::ymax , grid::zmin , and grid::zmax parameters, or with the grid::xyzmin and grid::xyzmax parameters. box This is a special case of grid::type = \"byrange\" with the grid ranges hard-wired to grid::xyzmin = -0.5 and grid::xyzmax = +0.5 . byspacing You specify the x, y, and z grid spacings, either with separate grid::dx , grid::dy , and grid::dz parameters, or with the grid::dxyz parameter. grid::avoid_originx This is a Boolean parameter; if set to true then the grid will be \u201chalf-centered\u201d across x = 0 x = 0 , ie there will be grid points at \\ldots, x=-\\frac{3}{2} \\Delta x, x=-\\frac{1}{2} \\Delta x, x=+\\frac{1}{2} \\Delta x, x=+\\frac{3}{2} \\Delta x, \\ldots \\ldots, x=-\\frac{3}{2} \\Delta x, x=-\\frac{1}{2} \\Delta x, x=+\\frac{1}{2} \\Delta x, x=+\\frac{3}{2} \\Delta x, \\ldots , but not at x = 0 x = 0 .","title":"Specifying the Grid Size, Range, and Spacing"},{"location":"ET/parameter/#specifying-the-grid-symmetry","text":"CartGrid3D allows you to specify the grid symmetry with the grid::domain parameter. Value Describe full There are no symmetries. bitant The grid includes only the z \\geq 0 z \\geq 0 half-space; there is a reflection symmetry across the z = 0 z = 0 plane. quadrant The grid includes only the \\{x \\geq 0, y \\geq 0\\} \\{x \\geq 0, y \\geq 0\\} quadrant. ; there is a reflection symmetry across both the x = 0 x = 0 plane and the y = 0 y = 0 plane. octant The grid includes only the \\{x \\geq 0, y \\geq 0, z \\geq 0\\} \\{x \\geq 0, y \\geq 0, z \\geq 0\\} octant; there is a reflection symmetry across each of the x = 0 x = 0 plane, the y = 0 y = 0 plane and the z = 0 z = 0 plane.","title":"Specifying the Grid Symmetry"},{"location":"ET/parameter/#parameter_1","text":"Key Defaults Describe Option no_origin \"yes\" DEPRECATED: Don't place grid points on the coordinate origin/axes : :: \"\" no_originx \"yes\" DEPRECATED: Don't place grid points on the x-coordinate origin/axes : :: \"\" no_originy \"yes\" DEPRECATED: Don't place grid points on the y-coordinate origin/axes : :: \"\" no_originz \"yes\" DEPRECATED: Don't place grid points on the z-coordinate origin/axes : :: \"\" avoid_originx \"yes\" Don't place grid points on the x-coordinate origin/axes : :: \"\" avoid_originy \"yes\" Don't place grid points on the y-coordinate origin/axes : :: \"\" avoid_originz \"yes\" Don't place grid points on the z-coordinate origin/axes : :: \"\" avoid_origin \"yes\" Don't place grid points on the coordinate origin/axes : :: \"\" register_default_coordinate_systems \"yes\" register cartnd as the default coordinate systems dx 0.3 Coarse grid spacing in x-direction 0: :: \"Positive\" dy 0.3 Coarse grid spacing in y-direction 0: :: \"Positive\" dz 0.3 Coarse grid spacing in z-direction 0: :: \"Positive\" dxyz 0.0 Coarse grid spacing in x,y,z-directions 0: :: \"Positive\" xmin -1.0 Coordinate minimum in x-direction : :: \"Anything\" ymin -1.0 Coordinate minimum in y-direction : :: \"Anything\" zmin -1.0 Coordinate minimum in z-direction : :: \"Anything\" xyzmin -424242 Coordinate minimum in x,y,z-directions : :: \"Anything\" xmax 1.0 Coordinate maximum in x-direction : :: \"Anything\" ymax 1.0 Coordinate maximum in y-direction : :: \"Anything\" zmax 1.0 Coordinate maximum in z-direction : :: \"Anything\" xyzmax -424242 Coordinate maximum in xyz-directions : :: \"Anything\" type \"box\" Grid type \"box\":: \"Box grid from -0.5 to 0.5\"; \"byrange\":: \"Specify min and max values\"; \"byspacing\":: \"Specify grid spacings\"; \"coordbase\":: \"Get specification from CoordBase\"; \"multipatch\" :: \"Get specification from MultiPatch\" domain \"full\" Domain type \"octant\" :: \"Use an octant about the origin\"; \"quadrant\" :: \"Use a quadrant in x-y plane\"; \"quadrant_reflect_rotate\" :: \"Use a quadrant with rotation symmetry about an axis\"; \"bitant\" :: \"Use a bitant about the x-y plane\"; \"bitant_rotate\" :: \"Use a bitant with rotation symmetry about an axis\"; \"full\" :: \"Use the full domain\" bitant_plane \"xy\" Plane defining bitant domain \"xy\" :: \"xy-plane\"; \"xz\" :: \"xz-plane\"; \"yz\" :: \"yz-plane\" quadrant_direction \"z\" Direction defining quadrant domain \"x\":: \"x-direction\"; \"y\":: \"y-direction\"; \"z\":: \"z-direction\" rotation_axis \"z\" Axis about which the rotation symmetry is to be applied \"x\":: \"x-axis\"; \"y\":: \"y-axis\"; \"z\":: \"z-axis\" symmetry_xmin \"no\" Symmetry boundary condition on lower x boundary : :: \"Logical\" symmetry_ymin \"no\" Symmetry boundary condition on lower y boundary : :: \"Logical\" symmetry_zmin \"no\" Symmetry boundary condition on lower z boundary : :: \"Logical\" symmetry_xmax \"no\" Symmetry boundary condition on upper x boundary : :: \"Logical\" symmetry_ymax \"no\" Symmetry boundary condition on upper y boundary : :: \"Logical\" symmetry_zmax \"no\" Symmetry boundary condition on upper z boundary : :: \"Logical\" set_coordinate_ranges_on \"all On which grids to set the coordinate ranges \"all grids\" :: \"set ranges in local mode, on the coarsest level\"; \"all maps\":: \"set ranges in singlemap mode, on the coarsest level\"; \"first level\" :: \"set ranges in level mode, on the first level\"","title":"Parameter"},{"location":"ET/parameter/#symbase","text":"Provide generic handling of symmetries for grids and grid arrays.","title":"SymBase"},{"location":"ET/parameter/#parameter_2","text":"Key Defaults Describe Option verbose \"yes\" Output symmetry boundary face descriptions after registration","title":"Parameter"},{"location":"ET/parameter/#coordinates","text":"Llama is a multipatch infrastructure for Cactus. This thorn provides definition of patch systems and coordinates.","title":"Coordinates"},{"location":"ET/parameter/#parameter_3","text":"Key Defaults Describe Option coordinate_system \"Cartesian\" Available patch systems \"Cartesian\" :: \"Cartesian coordinates (unit Jacobian)\"; \"TwoPatchCartesian\" :: \"Two Cartesian patches with one common face\"; \"TwoPatchDistorted\" :: \"One Cartesian and one distorted patch, overlapping\"; \"Thornburg04\" :: \"Jonathan's AHFinderDirect coordinates\"; \"Thornburg13\" :: \"Jonathan's AHFinderDirect coordinates as a 13 patch system (Do not use with radial stretch)\"; \"Thornburg04nc\" :: \"Jonathan's system without a central Cartesian patch\"; \"CylinderInBox\" :: \"A hollow (spherical) cylinder in a (Cartesian) box\"; \"Sphere+Column\" :: \"Excision type overlapping sphere + column grid\"; \"Cylinder+Column\" :: \"Cylindrical grid + central column\" symmetry \"full\" Select a symmetry \"full\":: \"full domain\"; \"+z bitant\" :: \"bitant mode (positive z)\"; \"+xyz octant\" :: \"octant mode (positive xyz)\" verbose \"yes\" Output information periodically store_jacobian \"yes\" Numerically evaluate and store the transformation da i/dx k (a: local, x: global) store_inverse_jacobian \"no\" Numerically evaluate and store the transformation dx i/da k (a: local, x: global) store_jacobian_derivative \"yes\" Store the derivative of the Jacobian d 2[global]/d[local] 2 store_volume_form \"no\" Store determinant of Jacobian patch_boundary_size 1 Number of inter-patch boundary points which are filled via interpolation (should be >= nghostzones) 0: :: \"\" stagger_patch_boundaries \"no\" Stagger the grid at the inter-patch boundaries? additional_overlap_size 0 Additional overlap between patches; this overlap is evolved, not interpolated 0: :: \"\" register_symmetry \"yes\" Register patch boundaries as symmetries outer_boundary_size 1 Number of outer boundary points 0: :: \"\" internal_outer_boundaries \"no\" Do the outer boundary points extend inwards? stagger_outer_boundaries \"no\" Stagger the grid at the outer boundaries shiftout_outer_boundaries 0 Offset between the boundary location and the first outer boundary point : :: \"\" additional_symmetry_size 0 Additional shiftout for symmetry boundaries 0:1 :: \"Must be 0 for staggered boundaries (cell-centered AMR); otherwise 1\" nMonteCarloParticles 500000 Number of Monte-Carlo particles for determining fraction of cells that are on the nominal grid. This is used for the computation of the volume form. 0::: \"the larger the better\" MonteCarloSeed 1 A seed for random number generator to get Monte Carlo particle distribution. 0::: \"Something positive\" ncells_x 10 Number of cells in the x direction 0: :: \"\" ncells_y 10 Number of cells in the x direction 0: :: \"\" ncells_z 10 Number of cells in the x direction 0: :: \"\" patch_xmin 0.0 xmin for the patch : :: \"\" patch_ymin -0.5 ymin for the patch : :: \"\" patch_zmin -0.5 zmin for the patch : :: \"\" patch_xmax 1.0 xmin for the patch : :: \"\" patch_ymax 0.5 ymin for the patch : :: \"\" patch_zmax 0.5 zmin for the patch : :: \"\" patch_one_ncells_x 10 Number of cells in the x direction for patch one 0: :: \"\" patch_one_ncells_y 10 Number of cells in the y direction for patch one 0: :: \"\" patch_one_ncells_z 10 Number of cells in the z direction for patch one 0: :: \"\" patch_one_xmin 0.0 xmin for patch one : :: \"\" patch_one_ymin -0.5 ymin for patch one : :: \"\" patch_one_zmin -0.5 zmin for patch one : :: \"\" patch_one_xmax 1.0 xmin for patch one : :: \"\" patch_one_ymax 0.5 ymin for patch one : :: \"\" patch_one_zmax 0.5 zmin for patch one : :: \"\" patch_two_ncells_x 10 Number of cells in the x direction for patch two 0: :: \"\" patch_two_ncells_y 10 Number of cells in the y direction for patch two 0: :: \"\" patch_two_ncells_z 10 Number of cells in the z direction for patch two 0: :: \"\" patch_two_xmin -1.0 xmin for patch two : :: \"\" patch_two_ymin -0.5 ymin for patch two : :: \"\" patch_two_zmin -0.5 zmin for patch two : :: \"\" patch_two_xmax 0.0 xmin for patch two : :: \"\" patch_two_ymax 0.5 ymin for patch two : :: \"\" patch_two_zmax 0.5 zmin for patch two : :: \"\" h_cartesian 0.0 Inner cube resolution 0: :: \"positive\" h_radial 0.0 Radial resolution 0: :: \"positive\" sphere_inner_radius 0.0 Inner radius for the spherical grids 0: :: \"positive\" sphere_outer_radius 0.0 Location of the physical outer boundary. 0: :: \"positive\" n_angular 0 Number of grid cells in the angular directions on the outer grids 0::2 :: \"even numbers required when bitant symmetry is used with non-staggered boundaries\"; 1::2 :: \"odd numbers required when bitant symmetry is used with non-staggered boundaries\" h_radial_inner 0.0 Radial resolution for patches 1-6 of Thornburg13 0: :: \"positive\" h_radial_outer 0.0 Radial resolution for patches 7-13 of Thornburg13 0: :: \"positive\" sphere_medium_radius 0.0 Medium radius for the 13 patch system spherical grids 0: :: \"positive\" n_angular_inner 0 Number of gridpoints in angular directions on the patches 1-6 0: :: \"positive\" n_angular_outer 0 Number of gridpoints in angular directions on the patches 7-13 0: :: \"positive\" cubical_inner_boundary \"no\" give the inner boundary a cubical shape radial_stretch \"no\" Stretch the radial coordinate stretch_rmin_1 1e10 Inner radius of first stretching region 0: :: \"positive\" stretch_rmax_1 2e10 Outer radius of first stretching region 0: :: \"positive\" h_radial_1 -1 Intended radial resolution of the first stretched domain :: \"negative turns off stretching\" box_radius 3.0 Half-size of Cartesian box 0: :: \"\" cylinder_radius 1.0 Inner radius of cylinder 0: :: \"\" transition_radius 2.0 Transition radius between box and cylinder (0: :: \"\" theta_min 10 Minimal polar angle to cover by the spherical grid patch, in degrees (0:90) :: \"positive please\" n_angular_phi 40 Number of angular points in the phi direction 0: :: \"positive\" n_angular_theta 10 Number of angular points in the theta direction 0: :: \"positive\" n_xy 10 Number of points in xy-direction on the column patches 0: :: \"positive\" cylinder_inner_radius 1.0 Inner radius of the cylinder 0: :: \"\" cylinder_outer_radius 2.0 Outer radius of the cylinder 0: :: \"\" cylinder_zmin -2.0 Minimum z for cylinder and column : :: \"\" cylinder_zmax 2.0 Maximum z for cylinder and column : :: \"\" h_z 0.1 Spacing in z direction 0: :: \"\"","title":"Parameter"},{"location":"ET/parameter/#time-integration","text":"","title":"Time Integration"},{"location":"ET/parameter/#time","text":"Calculates the timestep used for an evolution.","title":"Time"},{"location":"ET/parameter/#description","text":"The method is chosen using the keyword parameter time::timestep method. given The timestep is fixed to the value of the parameter time::timestep . courant_static Calculates the timestep once at the start of the simulation, based on a simple courant type condition using the spatial gridsizes and the parameter time::dtfac . \\Delta t=\\operatorname{dt} \\mathrm{fac} * \\min \\left(\\Delta x^{i}\\right) \\Delta t=\\operatorname{dt} \\mathrm{fac} * \\min \\left(\\Delta x^{i}\\right) Note that it is up to the user to custom dtfac to take into account the dimension of the space being used, and the wave speed. - courant_speed The timestep being set before each iteration using the spatial dimension of the grid, the spatial grid sizes, the parameter courant_fac and the grid variable courant_wave_speed . The algorithm used is \\Delta t=\\operatorname{courant}\\_ \\mathrm{fac} * \\min \\left(\\Delta x^{i}\\right) / \\mathrm{courant}\\_\\mathrm{wave}\\_ \\text { speed } / \\sqrt{\\mathrm{dim}} \\Delta t=\\operatorname{courant}\\_ \\mathrm{fac} * \\min \\left(\\Delta x^{i}\\right) / \\mathrm{courant}\\_\\mathrm{wave}\\_ \\text { speed } / \\sqrt{\\mathrm{dim}} For this algorithm to be successful, the variable courant_wave_speed must have been set by some thorn to the maximum propagation speed on the grid before this thorn sets the timestep, - courant_time the timestep is chosen using \\Delta t=\\operatorname{courant}\\_ \\mathrm{fac} * \\mathrm{courant}\\_\\mathrm{min}\\_ \\text { time } / \\sqrt{\\mathrm{dim}} \\Delta t=\\operatorname{courant}\\_ \\mathrm{fac} * \\mathrm{courant}\\_\\mathrm{min}\\_ \\text { time } / \\sqrt{\\mathrm{dim}} where the grid variable courant_min_time must be set by some thorn to the minimum time for a wave to cross a gridzone before this thorn sets the timestep,","title":"Description"},{"location":"ET/parameter/#parameter_4","text":"Key Defaults Describe Option timestep_method \"courant_static\" Method for calculating timestep \"given\":: \"Use given timestep\"; \"courant_static\" :: \"Courant condition at BASEGRID (using dtfac)\"; \"courant_speed\":: \"Courant condition at POSTSTEP (using wavespeed and courant_fac)\"; \"courant_time\" :: \"Courant condition at POSTSTEP (using min time and courant_fac)\" timestep_outonly \"no\" Don't set a dynamic timestep, just output what it would be timestep 0.0 Absolute value for timestep : :: \"Could be anything\" dtfac 0.5 The standard timestep condition dt = dtfac*max(delta_space) 0: :: \"For positive timestep\"; :0 :: \"For negative timestep\" courant_fac 0.9 The courant timestep condition dt = courant_fac*max(delta_space)/speed/sqrt(dim) 0: :: \"For positive timestep\"; :0 :: \"For negative timestep\" timestep_outevery 1 How often to output courant timestep 1: :: \"Zero means no output\" verbose \"no\" Give selective information about timestep setting","title":"Parameter"},{"location":"ET/parameter/#examples","text":"1 2 3 4 5 6 7 8 9 # Fixed Value Timestep time::timestep_method = \"given\" time::timestep = 0.1 # Calculate Static Timestep Based on Grid Spacings. The following parameters set the timestep to be 0.25 grid::dx grid::dy grid::dz time::timestep_method = \"courant_static\" time::dtfac = 0.5","title":"Examples"},{"location":"ET/parameter/#mol","text":"This thorn provides generic time integrators.","title":"MoL"},{"location":"ET/parameter/#description_1","text":"The Method of Lines (MoL) converts a (system of) partial differential equation(s) into an ordinary differential equation containing some spatial differential operator. \\partial_{t} \\mathbf{q}+\\mathbf{A}^{i}(\\mathbf{q}) \\partial_{i} \\mathbf{B}(\\mathbf{q})=\\mathbf{s}(\\mathbf{q}) \\partial_{t} \\mathbf{q}+\\mathbf{A}^{i}(\\mathbf{q}) \\partial_{i} \\mathbf{B}(\\mathbf{q})=\\mathbf{s}(\\mathbf{q}) Given this separation of the time and space discretizations, well known stable ODE integrators such as Runge-Kutta can be used to do the time integration. The keyword MoL::ODE_Method chooses between the different methods. To switch between the different types of generic methods there is also the keyword MoL::Generic_Type . The parameter MoL::MoL_Intermediate_Steps controls the number of intermediate steps for the ODE solver. For the generic Runge-Kutta solvers it controls the order of accuracy of the method. For the ICN methods this parameter controls the number of iterations taken, which does not check for stability. The parameter MoL::MoL_Num_Scratch_Levels controls the amount of scratch space used. Time evolution methods provided by MoL The standard \"ICN\" $$ \\begin{aligned} \\mathbf{q}^{(0)} &=\\mathbf{q}^{n} \\ \\mathbf{q}^{(i)} &=\\mathbf{q}^{(0)}+\\frac{\\Delta t}{2} \\mathbf{L}\\left(\\mathbf{q}^{(i-1)}\\right), \\quad i=1, \\ldots, N-1 \\ \\mathbf{q}^{(N)} &=\\mathbf{q}^{(N-1)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(N-1)}\\right) \\ \\mathbf{q}^{n+1} &=\\mathbf{q}^{(N)} \\end{aligned} $$ he \u201caveraging\u201d ICN method \"ICN-avg\" instead calculates intermediate steps before averaging $$ \\begin{aligned} \\mathbf{q}^{(0)} &=\\mathbf{q}^{n} \\ \\tilde{\\mathbf{q}}^{(i)} &=\\frac{1}{2}\\left(\\mathbf{q} {(i)}+\\mathbf{q} {n}\\right), \\quad i=0, \\ldots, N-1 \\ \\mathbf{q}^{(i)} &=\\mathbf{q}^{(0)}+\\Delta t \\mathbf{L}\\left(\\tilde{\\mathbf{q}}^{(N-1)}\\right) \\ \\mathbf{q}^{n+1} &=\\mathbf{q}^{(N)} \\end{aligned} $$ The Runge-Kutta methods are those typically used in hydrodynamics Explicitly the first order method is the Euler method: $$ \\begin{aligned} \\mathbf{q}^{(0)} &=\\mathbf{q}^{n} \\ \\mathbf{q}^{(1)} &=\\mathbf{q}^{(0)}+\\Delta t \\mathbf{L}\\left(\\tilde{\\mathbf{q}}^{(0)}\\right) \\ \\mathbf{q}^{n+1} &=\\mathbf{q}^{(1)} \\end{aligned} $$ The second order method is: $$ \\begin{aligned} \\mathbf{q}^{(0)} &=\\mathbf{q}^{n} \\ \\mathbf{q}^{(1)} &=\\mathbf{q}^{(0)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(0)}\\right) \\ \\mathbf{q}^{(2)} &=\\frac{1}{2}\\left(\\mathbf{q} {(0)}+\\mathbf{q} {(1)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(1)}\\right)\\right) \\ \\mathbf{q}^{n+1} &=\\mathbf{q}^{(2)} \\end{aligned} $$ The third order method is: $$ \\begin{aligned} \\mathbf{q}^{(0)} &=\\mathbf{q}^{n} \\ \\mathbf{q}^{(1)} &=\\mathbf{q}^{(0)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(0)}\\right) \\ \\mathbf{q}^{(2)} &=\\frac{1}{4}\\left(3 \\mathbf{q} {(0)}+\\mathbf{q} {(1)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(1)}\\right)\\right) \\ \\mathbf{q}^{(3)} &=\\frac{1}{3}\\left(\\mathbf{q}^{(0)}+2 \\mathbf{q}^{(2)}+2 \\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(2)}\\right)\\right) \\ \\mathbf{q}^{n+1} &=\\mathbf{q}^{(3)} \\end{aligned} $$ The fourth order method, which is not strictly TVD, is: $$ \\begin{aligned} \\mathbf{q}^{(0)} &=\\mathbf{q}^{n} \\ \\mathbf{q}^{(1)} &=\\mathbf{q}^{(0)}+\\frac{1}{2} \\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(0)}\\right) \\ \\mathbf{q}^{(2)} &=\\mathbf{q}^{(0)}+\\frac{1}{2} \\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(1)}\\right) \\ \\mathbf{q}^{(3)} &=\\mathbf{q}^{(0)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(2)}\\right) \\ \\mathbf{q}^{n+1} &=\\frac{1}{6}\\left(-2 \\mathbf{q}^{(0)}+2 \\mathbf{q}^{(1)}+4 \\mathbf{q}^{(2)}+2 \\mathbf{q}^{(3)}+\\Delta t \\mathbf{L}\\left(\\mathbf{q}^{(3)}\\right)\\right) \\ \\mathbf{q}^{n+1} &=\\mathbf{q}^{(4)} \\end{aligned} $$","title":"Description"},{"location":"ET/parameter/#parameter_5","text":"Key Defaults Describe Option MoL_Num_Evolved_Vars 0 The maximum number of variables to be evolved by MoL (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Num_Evolved_Vars_Slow 0 The maximum number of 'slow' variables to be evolved by MoL (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Num_Constrained_Vars 0 The maximum number of constrained variables with timelevels that MoL needs to know about (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Num_SaveAndRestore_Vars 0 The maximum number of variables to be evolved outside of MoL but that MoL needs to know about (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Max_Evolved_Array_Size 0 The maximum total size of any grid arrays to be evolved 0: :: \"Anything non negative. Accumulated by other thorns\" MoL_Num_ArrayEvolved_Vars 0 The maximum number of array variables to be evolved by MoL (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Num_ArrayConstrained_Vars 0 The maximum number of array constrained variables with timelevels that MoL needs to know about (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Num_ArraySaveAndRestore_Vars 0 The maximum number of array variables to be evolved outside of MoL but that MoL needs to know about (DPRECATED) 0: :: \"Anything non negative. Added to by other thorns.\" MoL_Num_Scratch_Levels 0 Number of scratch levels required by the ODE method 0: :: \"Anything non negative\" ODE_Method \"ICN\" The ODE method use by MoL to do time integration \"Generic\" :: \"Generic Shu-Osher Runge-Kutta type\"; \"ICN\" :: \"Iterative Crank Nicholson\"; \"ICN-avg\" :: \"Iterative Crank Nicholson with averaging\"; \"Euler\" :: \"Euler\"; \"RK2\" :: \"Efficient RK2\"; \"RK2-central\" :: \"Central RK2\"; \"RK3\" :: \"Efficient RK3\"; \"RK4\" :: \"Efficient RK4\"; \"RK45\":: \"RK45 (Fehlberg) with error estimation\"; \"RK45CK\":: \"RK45CK (Cash-Karp) with error estimation\"; \"RK65\":: \"RK65 with error estimation\"; \"RK87\":: \"RK87 with error estimation\"; \"AB\":: \"Adams-Bashforth\"; \"RK2-MR-2:1\":: \"2 nd order 2:1 multirate RK scheme based on RK2 due to Schlegel et al 2009. This requires init_RHS_zero='no'.\"; \"RK4-MR-2:1\":: \"3 rd order 2:1 multirate RK scheme based on RK43 due to Schlegel et al 2009. This requires init_RHS_zero='no'.\"; \"RK4-RK2\" :: \"RK4 as fast method and RK2 as slow method\" Generic_Type \"RK\" If using the generic method, which sort \"RK\" :: \"One of the standard TVD Runge-Kutta methods\"; \"ICN\" :: \"Iterative Crank Nicholson as a generic method\"; \"Table\" :: \"Given from the generic method descriptor parameter\"; \"Classic RK3\" :: \"Efficient RK3 - classical version\" ICN_avg_theta 0.5 theta of averaged ICN method, usually 0.5 0:1 :: \"0 <= theta <= 1\" ICN_avg_swapped \"no\" Use swapped averages in ICN method? AB_Type \"1\" If using the the AB method, which sort \"1\" :: \"same as forward Euler\"; \"2\" :: \"second order\"; \"3\" :: \"third order\"; \"4\" :: \"fourth order\"; \"5\" :: \"fifth order\" AB_initially_reduce_order \"yes\" Reduce order of accuracy initially so that no past timelevels of initial data are required MoL_Intermediate_Steps 3 Number of intermediate steps taken by the ODE method 1: :: \"Anything greater than 1\" MoL_Memory_Always_On \"yes\" Do we keep the scratch arrays allocated all the time? MoL_Tiny 1.e-15 Effective local machine zero; required by generic solvers 0: :: \"Defaults to 1.e-15\" initial_data_is_crap \"no\" If the initial data routine fails to set up the previous time levels, copy the current backwards run_MoL_PostStep_in_Post_Recover_Variables \"yes\" Schedule the PostStep parts after recovery so that symmetries are automatically done correctly. set_ID_boundaries \"yes\" Should boundaries be overwritten (via synchronization, prolongation, boundary conditions) by MoL? Generic_Method_Descriptor \"GenericIntermediateSteps A string used to create a table containing the description of the generic method \".\":: \"Should contain the Alpha and Beta arrays, and the number of intermediate steps\" MoL_NaN_Check \"no\" Should the RHS GFs be checked for NaNs? disable_prolongation \"yes\" If Mesh refinement is enabled should we use buffer zones in intermediate steps? skip_initial_copy \"no\" Skip initial copy from previous to current time level init_RHS_zero \"yes\" Initialise the RHS to zero adaptive_stepsize \"no\" Choose the time step size adaptively maximum_absolute_error 1.0e-6 Maximum allowed absolute error for adaptive stepsize control 0.0:) :: \"\" maximum_relative_error 1.0e-6 Maximum allowed relative error for adaptive stepsize control 0.0:) :: \"\" RHS_error_weight 1.0 Weight of the RHS in the relative error calculation 0.0: :: \"should be between zero and one\" safety_factor 0.9 Safety factor for stepsize control (0.0:) :: \"should be less than one\" maximum_decrease 10.0 Maximum stepsize decrease factor (1.0:) :: \"should be larger than one\" maximum_increase 5.0 Maximum stepsize increase factor (1.0:) :: \"should be larger than one\" verbose \"normal\" How verbose should MoL be? \"none\" :: \"No output at all (not implemented)\"; \"normal\" :: \"Standard verbosity\"; \"register\" :: \"List the variables registered as well\"; \"extreme\":: \"Everything you never wanted to know\"","title":"Parameter"},{"location":"ET/parameter/#boundary-condtition","text":"","title":"Boundary Condtition"},{"location":"ET/parameter/#boundary","text":"Provides a generic interface to boundary conditions, and provides a set of standard boundary conditions for one, two, and three dimensional grid variables. In addition, it allows all considerations of symmetry to be separated from those of physical boundary conditions. Boundary conditions can be local, meaning that the boundary point can be updated based on data in its immediate vicinity, or non-local, meaning that the new value on the boundary depends on data from a remote region of the computational domain Currently thorn Boundary allows a separate boundary condition to be applied to each face of the domain, however this is only implemented at the moment using the older deprecated interface. Thorn Boundary also provides seven standard boundary conditions, which can be applied to one, two, or three dimensional grid variables. The boundary conditions available are Scalar: the value of the given field or fields at the boundary is set to a given scalar value, for example zero. Flat: the value of the given field or fields at the boundary is copied from the value one grid point in, in any direction. Radiation: Grid functions are given for the current time level as well as grid functions from a past timelevel which are needed for constructing the boundary condition. Copy: Copy the boundary values from a different grid function, for example the previous timelevel. The two grid functions (or groups of grid functions) must have the same geometry. Robin: The Robin boundary condition is f(r)=f_{0}+\\frac{k}{r^{n}} f(r)=f_{0}+\\frac{k}{r^{n}} Static: The static boundary condition ensures that the boundary values do not evolve in time, by copying their values from previous timelevels. None: The \u201cNone\u201d boundary condition does just that, nothing. Grid variables should have symmetry boundary conditions applied to them, but do not have their physical boundary conditions applied using a properly registered function.","title":"Boundary"},{"location":"ET/parameter/#parameter_6","text":"Key Defaults Describe Option radpower -1 Power of decay rate in extrapolation used in radiative boundaries : :: \"A negative value switches off this feature\" register_scalar \"yes\" Register routine to handle the 'Scalar' boundary condition register_flat \"yes\" Register routine to handle the 'Flat' boundary condition register_radiation \"yes\" Register routine to handle the 'Radiation' boundary condition register_copy \"yes\" Register routine to handle the 'Copy' boundary condition register_robin \"yes\" Register routine to handle the 'Robin' boundary condition register_static \"yes\" Register routine to handle the 'Static' boundary condition register_none \"yes\" Register routine to handle the 'None' boundary condition","title":"Parameter"},{"location":"ET/parameter/#reflectionsymmetry","text":"Provide reflection symmetries, i.e., bitant, quadrant, and octant mode.","title":"ReflectionSymmetry"},{"location":"ET/parameter/#parameter_7","text":"Key Defaults Describe Option verbose \"no\" Produce screen output while applying boundary conditions reflection_x \"no\" Reflection symmetry at the lower x boundary reflection_y \"no\" Reflection symmetry at the lower y boundary reflection_z \"no\" Reflection symmetry at the lower z boundary reflection_upper_x \"no\" Reflection symmetry at the upper x boundary reflection_upper_y \"no\" Reflection symmetry at the upper y boundary reflection_upper_z \"no\" Reflection symmetry at the upper z boundary avoid_origin_x \"yes\" Stagger about the origin on the lower x boundary? avoid_origin_y \"yes\" Stagger about the origin on the lower y boundary? avoid_origin_z \"yes\" Stagger about the origin on the lower z boundary? avoid_origin_upper_x \"yes\" Stagger about the origin on the upper x boundary? avoid_origin_upper_y \"yes\" Stagger about the origin on the upper y boundary? avoid_origin_upper_z \"yes\" Stagger about the origin on the upper z boundary?","title":"Parameter"},{"location":"ET/parameter/#mesh-refinement","text":"","title":"Mesh refinement"},{"location":"ET/parameter/#pugh","text":"This thorn provides a unigrid parallel driver with MPI.","title":"PUGH"},{"location":"ET/parameter/#description_2","text":"Grid Size 1 2 3 4 5 6 7 8 9 10 # To set the global size of a N-D grid to be 40 grid points in each direction use PUGH::global_nsize = 40 # To set the global size of a 2D grid to be 40\u00d720 use PUGH::global_nx = 40 PUGH::global_ny = 20 # To set the local size of a 2D grid to be 40 \u00d7 20 on each processor, use PUGH::local_nx = 40 PUGH::local_ny = 20 Periodic Boundary Conditions 1 2 3 4 5 6 # By default, no periodic boundary conditions are applied. To apply periodic boundary conditions in all directions, set PUGH::periodic = \"yes\" # To apply periodic boundary conditions in just the x- and y- directions in a 3 dimensional domain, use PUGH::periodic = \"yes\" PUGH::periodic_z = \"no\" Processor Decomposition By default PUGH will distribute the computational grid evenly across all processors To manually specify the load distribution, set PUGH::partition = \"manual\" and then, depending on the grid dimension, set the remaining parameters to distribute the load in each direction. The computational grid can be manually distributed using PUGH\u2019s string parameters partition_[1d_x|2d_x|2d_y|3d_x|3d_y|3d_z]","title":"Description"},{"location":"ET/parameter/#parameter_8","text":"Key Defaults Describe Option periodic \"no\" Periodic boundary conditions periodic_x \"yes\" Periodic boundary conditions in x-direction periodic_y \"yes\" Periodic boundary conditions in y-direction periodic_z \"yes\" Periodic boundary conditions in z-direction global_nx 10 The size of the grid in the x direction 0: :: \"Grid of this size distributed across all processors\" global_ny 10 The size of the grid in the y direction 0: :: \"Grid of this size distributed across all processors\" global_nz 10 The size of the grid in the z direction 0: :: \"Grid of this size distributed across all processors\" global_nsize -1 The size of the grid in each spatial direction -1: :: \"Grid of this size in each dir distributed across all processors\" ghost_size_x 1 The width of the ghost zone in the x direction 0: :: \"Must be a positive integer\" ghost_size_y 1 The width of the ghost zone in the y direction 0: :: \"Must be a positive integer\" ghost_size_z 1 The width of the ghost zone in the z direction 0: :: \"Must be a positive integer\" ghost_size -1 The width of the ghost zone in each direction -1: :: \"Any positive number to override the ghost_size_[xyz] parameters\" info \"none\" Provide additional information about what PUGH is doing \"none\" :: \"No extra information\"; \"load\" :: \"Load on each processor\" local_nx -1 The size of the grid in the x direction -1: :: \"Grid of this size on each processor\" local_ny -1 The size of the grid in the y direction -1: :: \"Grid of this size on each processor\" local_nz -1 The size of the grid in the z direction -1: :: \"Grid of this size on each processor\" local_nsize -1 The size of the grid in each spatial direction -1: :: \"Grid of this size in each dir on each processor\" local_size_includes_ghosts \"yes\" Does the local grid size include the ghost zones? enable_all_storage \"no\" Enable storage for all GFs? physical2logical \"direct\" Physical process to logical process mapping method to use \"direct\":: \"Maps MPI IDs directly to IJKs\"; \"example\" :: \"Maps MPI IDs directly to IJKs using a lookup table\" processor_topology \"automatic\" How to determine the processor topology \"manual\":: \"Specified by proc_top_nx etc\"; \"automatic\" :: \"Automatically generated\"; \"automatic_old\" :: \"Automatically generated (old method)\" processor_topology_1d_x 0 Number of processors in X direction 0::: \"See proc_topology\" processor_topology_2d_x 0 Number of processors in X direction 0::: \"See proc_topology\" processor_topology_2d_y 0 Number of processors in Y direction 0::: \"See proc_topology\" processor_topology_3d_x 0 Number of processors in X direction 0::: \"See proc_topology\" processor_topology_3d_y 0 Number of processors in Y direction 0::: \"See proc_topology\" processor_topology_3d_z 0 Number of processors in Z direction 0::: \"See proc_topology\" initialize_memory \"none\" How to initialize memory for grid variables at allocation time \"none\" :: \"Do not initialize storage for allocated grid variables (default)\"; \"zero\" :: \"Zero out all elements of all allocated grid variables\"; \"NaN\":: \"Set all elements of allocated floating point grid variables to Not-a-Number values\" partition \"automatic\" Is the partition manual \"automatic\":: \"even\"; \"manual\" :: \"specified by partition_XYZ ..\" partition_1d_x \"\" Tells how to partition on direction X . :: \"A regex which matches anything\" partition_2d_x \"\" Tells how to partition on direction X . :: \"A regex which matches anything\" partition_2d_y \"\" Tells how to partition on direction y . :: \"A regex which matches anything\" partition_3d_x \"\" Tells how to partition on direction X . :: \"A regex which matches anything\" partition_3d_y \"\" Tells how to partition on direction y . :: \"A regex which matches anything\" partition_3d_z \"\" Tells how to partition on direction z . :: \"A regex which matches anything\" storage_verbose \"no\" Report on memory assignment \"yes\":: \"Standard storage information\"; \"report\" :: \"Provide a report of storage every storage_report_every iterations and at termination\"; \"no\" :: \"Provide no information\" storage_report_every 0 How often to provide a report on storage information 0:0 :: \"Never report\"; 1: :: \"Report at intervals\" cacheline_mult 4001 Multiplier for cacheline number 0:::\"Any positive number\" overloadevolve \"yes\" Overload Evolve driver function overloadsyncgroup \"no\" Overload SyncGroup driver function overloadsyncgroupsbydiri \"yes\" Overload SyncGroupsByDirI driver function overloadenablegroupstorage \"yes\" Overload EnableGroupStorage driver function overloaddisablegroupstorage \"yes\" Overload DisableGroupStorage driver function overloadenablegroupcomm \"yes\" Overload EnableGroupComm driver function overloaddisablegroupcomm \"yes\" Overload DisableGroupComm driver function overloadbarrier \"yes\" Overload Barrier driver function overloadparallelinit \"yes\" Overload ParallelInit driver function overloadexit \"yes\" Overload Exit driver function overloadabort \"yes\" Overload Abort driver function overloadmyproc \"yes\" Overload MyProc driver function overloadnprocs \"yes\" Overload nProcs driver function overloadarraygroupsizeb \"yes\" Overload ArrayGroupSizeB driver function overloadquerygroupstorageb \"yes\" Overload QueryGroupStorageB driver function overloadgroupdynamicdata \"yes\" Overload GroupDynamicData driver function","title":"Parameter"},{"location":"ET/parameter/#carpet","text":"https://arxiv.org/pdf/gr-qc/0310042.pdf The Carpet driver, which lives in the Carpet arrangement, is divided into several parts. The thorn Carpet is the main driver piece; it provides all the routines and structures that Cactus expects from it. The thorn CarpetLib is the workhorse that does all the bookkeeping and data shuffling. Those two alone form a valid Cactus driver; the other thorns provide additional functionality. The thorns CarpetInterp, CarpetReduce, and CarpetSlab provide the corresponding interpolation, reduction, and slabbing interfaces. The thorns CarpetIOASCII and CarpetIOFlexIO provide I/O methods. Finally, thorn CarpetRegrid provides a user interface to select where and what to refine. (The actual refinement is handled in CarpetLib.) Carpet is a mesh refinement driver. It knows about a hierarchy of refinement levels, where each level is decomposed into a set of cuboid grid patches. For historic reasons it also has a notion of multigrid levels, but those are currently unused. In order to allow multiple processors to run efficiently in parallel, the grid is broken down into several rectangular components, and each processor is assigned one of these components. The components will usually overlap by a few grid points, so as to allow the processors to calculate spatial derivatives (which require neighbouring grid points) without having to communicate for every grid point. From time to time it is then necessary to synchronise the overlapping region, which is the only time at which communication happens. Setting up a grid hierarch is in Carpet handled by three different entities: Carpet itself decides the extent of the domain, the type of outer boundary conditions, and distributes the domain onto processors. a regridding thorn is responsible for deciding the shape of the grid hierarchy. CarpetLib handles the details and actually manages the data. A regridding thorn, such as CarpetRegrid or CarpetRegrid2, sets up the grid hierarchy. The grid hierarchy consists of several refinement levels, and each refinement level consists of several refined regions. We assume that boundary location and boundary discretisation are set up via CoordBase. This is necessary since other methods do not allow specifying sufficient details to handle e.g. refined regions intersecting mesh refinement boundaries. The main distinction between an outer boundary point and an interior point from Carpet\u2019s point of view is that an outer boundary point is not evolved in time. Instead, the value of boundary points must be completely determined by the value of interior points.","title":"Carpet"},{"location":"ET/parameter/#parameter_9","text":"Key Defaults Describe Option domain_from_coordbase \"no\" Use the domain description from CoordBase domain_from_multipatch \"no\" Use the domain description from MultiPatch global_nx 10 Grid size in x direction 0: :: \"must be nonnegative\" global_ny 10 Grid size in y direction 0: :: \"must be nonnegative\" global_nz 10 Grid size in z direction 0: :: \"must be nonnegative\" global_nsize -1 Grid size in each spatial direction 0: :: \"must be nonnegative\"; -1:: \"use the per-dimension parameters\" ghost_size_x 1 Ghost zones in x direction 0: :: \"must be nonnegative\" ghost_size_y 1 Ghost zones in y direction 0: :: \"must be nonnegative\" ghost_size_z 1 Ghost zones in z direction 0: :: \"must be nonnegative\" ghost_size -1 Ghost zones in each spatial direction 0: :: \"must be nonnegative\"; -1:: \"use the per-dimension parameters\" ghost_sizes \"\" Number of ghost zones for each refinement level periodic \"no\" do not use this parameter periodic_x \"yes\" do not use this parameter periodic_y \"yes\" do not use this parameter periodic_z \"yes\" do not use this parameter refinement_centering \"vertex\" Centering \"vertex\" :: \"use a vertex centred grid structure\"; \"cell\" :: \"use a cell centred grid structure\" eno_interpolation_type \"samples\" What is represented by values in cells DEPRECATED \"samples\":: \"grid values a sample values of the solution\" max_refinement_levels 1 Maximum number of refinement levels (including the base level) 1: :: \"must be positive\" max_timelevels -1 Maximum number of time levels (including the current time level) -1 :: \"Set automatically to prolonation_order_time+1\"; 1: :: \"Set this explicitly\" refinement_factor 2 Refinement factor 1: :: \"must be positive\" space_refinement_factors \"\" Spatial refinement factors over the coarsest level \" ^$ \" :: \"Use the value of refinement_factor\" time_refinement_factors \"\" Temporal refinement factors over the coarsest level \" ^$ \" :: \"Use the value of refinement_factor\" refine_timestep \"no\" Correct Time::dtfac for spacings on finer grids convergence_level 0 Convergence level : :: \"negative for finer, positive for coarser resolutions\" num_convergence_levels 1 Number of convergence levels (including the base level) 1: :: \"must be positive\" convergence_factor 2 Multigrid factor 1: :: \"must be positive\" num_maps 1 Number of maps 1: :: \"\" model \"world\" Model name for multi-model simulations -- the model name is used to distribute the processors onto the models \".+\" :: \"\" prolongation_order_space 1 Order of prolongation operator in space 0: :: \"vertex centred orders must be odd\" prolongation_orders_space \"\" Order of prolongation operator in space for each refinement level \" ^$ \" :: \"Use the value of prolongation_order_space\" prolongation_order_time 1 Order of prolongation operator in time 0: :: \"\" use_buffer_zones \"no\" Use buffer zones additional_buffer_zones 0 Additional buffer zones : :: \"\" use_overlap_zones \"no\" Use overlap zones additional_overlap_zones 0 Additional overlap zones : :: \"\" use_tapered_grids \"no\" Use tapered grids, avoiding time interpolation during evolution num_integrator_substeps -1 Number of substeps of the time integrator -1: :: \"Call MoLNumIntegratorSubsteps\"; 0: :: \"\" sync_during_time_integration \"yes\" Synchronise during time integration, even when prolongation is switched off base_extents braces Extents of base grid components, in grid point units of the finest level \" ^$ \" :: \"leave empty for one grid component covering the whole region (default)\" base_outerbounds \"\" Outer boundaries of base grid components \"^$\" :: \"leave empty for using the default, which depends on cctk_gsh\" enable_all_storage \"no\" Enable storage for all grid functions enable_no_storage \"no\" Exit before beginning to enable storage for grid functions poison_new_timelevels \"yes\" Try to catch uninitialised grid elements by setting new timelevels to values that will catch your attention check_for_poison \"no\" Explicitely check for the poison value after every time step poison_value 0 UNUSED; use CarpetLib::poison_value instead :: \"\" max_poison_locations 10 Maximum number of poison locations that are printed to the screen -1:: \"print all locations\"; 0: :: \"print only that many locations\" checksum_timelevels \"no\" Try to catch unintentionally changed timelevels by taking checksums and comparing against these suppress_restriction \"no\" Suppress the restriction operations. This makes the coarser refinement levels independent of the finer ones. verbose \"no\" Display more info on the screen veryverbose \"no\" Display a lot of info on the screen storage_verbose \"no\" Display verbose storage information if veryverbose barriers \"no\" Insert barriers at strategic places for debugging purposes (slows down execution) schedule_barriers \"no\" Insert barriers between scheduled items, so that timer statistics become more reliable (slows down execution) sync_barriers \"no\" Insert barriers before and after syncs, so that the sync timer is more reliable (slows down execution) output_internal_data \"no\" Periodically print internal data to the screen for debugging purposes timing_average_window_minutes 10.0 Time interval (in wall time minutes) for calculating the current physics time per hour (0.0: :: \"\" print_timestats_every 0 Print interesting timing statistics periodically -1:: \"don't report\"; 0 :: \"don't report\"; 1: :: \"report every so many iterations\" print_grid_info yes Print information about the grids on regridding output_timers_every 0 Print detailed statistics periodically -1:: \"don't report\"; 0 :: \"don't report\"; 1: :: \"report every so many iterations\" timer_file \"carpet-timing-statistics\" File name in which detailed timing statistics are collected \" ^$ \" :: \"empty filename: no file output\"; \" ^.+$ \" :: \"file name\" output_initialise_timer_tree \"no\" Output timing information in tree form to standard output for Initialise output_timer_tree_every 0 Output timing information in tree form to standard output for Evolve every so many iterations 0 :: \"don't report\"; 1: :: \"report every so many iterations\" output_xml_timer_tree \"no\" Output timing information in tree form as XML recompose_verbose \"no\" Output debug information during recomposing processor_topology \"automatic\" How to determine the processor topology \"manual\":: \"Specified by processor_topology_\"; \"along-z\" :: \"Split the region along the z direction only\"; \"along-dir\" :: \"Split the region along one direction only\"; \"automatic\" :: \"Choose the topology automatically\"; \"recursive\" :: \"Choose the topology automatically, using a different algorithm that may lead to better load balancing\"; \"balanced\":: \"Choose the topology automatically, ensuring a maximum load balance\" processor_topology_3d_x 1 Number of processors in x-direction 1: :: \"must be positive\" processor_topology_3d_y 1 Number of processors in y-direction 1: :: \"must be positive\" processor_topology_3d_z 1 Number of processors in z-direction 1: :: \"must be positive\" split_direction 2 Direction in which the domain should be split (for processor_topology=along-dir) 0: :: \"0 for x, 1 for y, 2 for z, etc.\" no_split_direction -1 Direction in which the domain must not be split (for processor_topology=automatic) -1:: \"split in all directions\"; 0: :: \"0 for x, 1 for y, 2 for z, etc.\" constant_load_per_processor \"no\" Keep the load per processor constant -- this is meant for benchmarks aspect_ratio_x 1.0 Desired aspect ratio for each processor's domain (0: :: \"\" aspect_ratio_y 1.0 Desired aspect ratio for each processor's domain (0: :: \"\" aspect_ratio_z 1.0 Desired aspect ratio for each processor's domain (0: :: \"\" min_points_per_proc 0 Minimum number of grid points per processor 0: :: \"that many\" split_components \"yes\" Split components onto processes; without this, one needs many components and few processes granularity 1 When splitting components, create sizes that are multiples of this granularity 1: :: \"TODO: query CoordBase or related thorns for this information\" granularity_boundary 0 When splitting components, assume this many boundary points that don't count towards the granularity 0: :: \"TODO: use CoordBase's number of boundary points for this\" ghost_zone_cost 0.025 Relative cost of ghost zones for 'recursive' load balancing 0: :: \"\" maximum_imbalance 0.1 Maximum load imbalance (0.0: :: \"\" same_number_of_components_on_each_process \"yes\" Ensure that each process has the same number of components, adding empty dummy components if necessary num_threads -1 Number of threads per process -1:: \"use system default, probably influenced by OMP_NUM_THREADS\"; 1: :: \"use this many threads\" set_cpu_affinity \"no\" Set the process CPU affinity, overwriting the respective system setting grid_structure_filename \"\" File name to output grid structure to (empty = no output) \".\" :: \"must be a legal file name\" grid_coordinates_filename \"\" File name to output grid coordinates to (empty = no output) \".\" :: \"must be a legal file name\" init_each_timelevel \"no\" Call initial data routines once for each timelevel init_fill_timelevels \"no\" Fill past time levels from current time level after calling initial data routines prolongate_initial_data \"no\" Prolongate the refined regions during initial data generation regrid_during_initialisation \"no\" Regrid while initialising regrid_during_recovery \"no\" Regrid while recovering regrid_in_level_mode \"yes\" Regrid in level mode (instead of singlemap mode), enabling more efficient processor distributions when there are multiple maps time_interpolation_during_regridding \"yes\" Interpolate finer levels in time during regridding output_after_regridding \"no\" Call OutputGH after regridding init_3_timelevels \"no\" Set up 3 timelevels of initial data adaptive_stepsize \"no\" Allow adaptive timestep sizes use_unusedpoints_mask \"no\" Turn on storage and usage of 'unusedpoints_mask'","title":"Parameter"},{"location":"ET/parameter/#carpetlib","text":"This thorn contains the backend library that provides mesh refinement.","title":"CarpetLib"},{"location":"ET/parameter/#parameter_10","text":"Key Defaults Describe Option verbose \"no\" Print info to the screen barriers \"no\" Insert barriers at strategic places for debugging purposes (slows down execution) commstate_verbose \"no\" Print debug info from the commstate class omit_prolongation_points_when_restricting \"no\" Do not restrict to points which are used to prolongate the boundary proper_nesting_distance 4 Minimum distance (in grid points) between two level interfaces 0: :: \"any non-negative value is fine; the default value is just a guess\" use_dgfe \"no\" Use DGFE operators instead of Lagrange operators interpolate_from_buffer_zones \"no\" Use buffer points for interpolation use_loopcontrol_in_operators \"no\" Use LoopControl to parallelize AMR operators use_openmp \"yes\" Use OpenMP to parallelize AMR operators use_higher_order_restriction \"no\" Use third order cell centered restriction operators instead of first order restriction_order_space 3 Order of restriction operator to use with use_higher_order_restriction 1 :: \"linear interpolation, this is Carpet's original implementation\"; 3 :: \"third order accurate restriction for grid functions where prolongation is not (W)ENO\"; 5 :: \"fifth order accurate restriction for grid functions where prolongation is not (W)ENO\" support_staggered_operators \"no\" Provide one extra ghost point during restriction for staggered operators - EXPERIMENTAL output_bboxes \"no\" Output bounding box information to the screen check_bboxes \"yes\" Check bounding box information for self-consistency poison_new_memory \"no\" Try to catch uninitialised data by setting newly allocated memory to values that will catch your attention electric_fence \"no\" Surround each allocated memory block by canaries to check for out-of-bounds accesses fence_width 1 number of guard cells to use 1: :: \"any number of cells\" poison_value 255 Integer value (0..255) used to poison new timelevels (with memset) 0:255 :: \"Must fit into a byte.Use 0 for zero, 255 for nan, and e.g. 113 for a large value.\" deadbeef 666 A strange integer value that indicates that something has gone wrong; the integer equivalent of a nan : :: \"should be large and positive\" max_core_size_MB -2 Maximum size of a core file, set via setrlimit -2:: \"unchanged\"; -1:: \"unlimited\"; 0: :: \"limited\" max_memory_size_MB -2 Maximum amount of memory per MPI process, set via setrlimit -2:: \"unchanged\"; -1:: \"unlimited\"; 0: :: \"limited\" test_backtrace \"no\" Kill yourself to test the backtrace mechanism print_timestats_every -1 Print timing statistics periodically -1:: \"don't report\"; 0 :: \"report after initialisation\"; 1: :: \"report every so many iterations\" timestat_file \"carpetlib-timing-statistics\" File name in which timestat output is collected (because stdout from the root node may not be enough) \" ^$ \" :: \"empty filename: no file output\"; \" ^.+$ \" :: \"file name\" use_ipm_timing_regions no Call IPM (via MPI_Pcontrol) to define regions print_memstats_every -1 Report periodically how much memory is used per process -1:: \"don't report\"; 0 :: \"report after setting up initial data\"; 1: :: \"report every so many iterations\" max_allowed_memory_MB 0 Maximum allowed amount of memory per process that can be allocated for grid variables (in Megabytes) -1:: \"no maximum\"; 0 :: \"no maximum\"; 1: :: \"abort if more memory is used\" memstat_file \"carpetlib-memory-statistics\" File name in which memstat output is collected (because stdout from the root node may not be enough) \" ^$ \" :: \"empty filename: no file output\"; \" ^.+$ \" :: \"file name\" combine_recompose \"yes\" Recompose all grid functions of one refinement levels at once avoid_arraysize_bytes 0 Avoid array sizes that are multiples of this 0 :: \"don't avoid anything\"; # 2: :: \"\" message_size_multiplier 1 Enlarge size of transmitted messages by this factor 1: :: \"\" message_count_multiplier 1 Transmit messages this many times 1: :: \"\" interleave_communications \"no\" Try to interleave communications with each other; each processor begins to communicate with its 'right neighbour' in rank, instead of with the root processor barrier_between_stages \"no\" Add a barrier between the communication stages (slows down, but may make timing numbers easier to interpret) check_communication_schedule \"no\" Check the communication schedule at run time (expensive) combine_sends \"no\" Send data together and in order of processor ranks use_mpi_send \"no\" Use MPI_Send instead of MPI_Isend use_mpi_ssend \"no\" Use MPI_Ssend instead of MPI_Isend pad_to_cachelines \"yes\" Pad arrays to the cache line size (only when VECTORISE_ALIGNED_ARRAYS is set)","title":"Parameter"},{"location":"ET/parameter/#carpetregrid2","text":"Set up refined regions by specifying a set of centres and radii about them. The refined regions are then the conjunction of these regions. The grid hierarchy consists of several refinement levels, and each refinement level consists of several refined regions.","title":"CarpetRegrid2"},{"location":"ET/parameter/#parameter_11","text":"Key Defaults Describe Option verbose \"no\" Display regridding information on the terminal veryverbose \"no\" Display much regridding information on the terminal min_distance 4 Minimum distance (in grid points) between coarse and fine grid boundaries 0: :: \"\" ensure_proper_nesting \"yes\" Ensure proper nesting automatically freeze_unaligned_levels \"no\" Do not change refinement levels that do not exist at this time freeze_unaligned_parent_levels \"no\" Do not change refinement levels where the parent does not exist at this time min_fraction 0.9 Minimum fraction of required refined points that need to be present in a refined region 0: :: \"\" snap_to_coarse \"no\" Ensure that the fine grid extent coincides with coarse grid points granularity 1 Granularity of size of refined regions 1: :: \"\" boundary_shiftout 0 Number of grid points added to the refinement boundary radius : :: \"\" regrid_every 0 Regrid every n time steps -1 :: \"regrid never\"; 0 :: \"regrid during initial data calculation only\"; 1: :: \"regrid every n time steps\" symmetry_rotating90 no Ensure a 90 degree rotating symmetry about the z axis symmetry_rotating180 no Ensure a 180 degree rotating symmetry about the z axis symmetry_parity no parity symmetry_periodic_x no Ensure a periodicity symmetry in the x direction symmetry_periodic_y no Ensure a periodicity symmetry in the y direction symmetry_periodic_z no Ensure a periodicity symmetry in the z direction expect_symmetric_grids \"no\" Expect a grid structure that is symmetric about the origin, and abort if it is not adaptive_refinement \"no\" Use level_mask for adaptive refinement adaptive_block_size 8 Block size for adaptive refinement 1: :: \"\" adaptive_block_size_x -1 Block size in x direction for adaptive refinement -1 :: \"use adaptive_block_size\"; 1: :: \"\" adaptive_block_size_y -1 Block size in y direction for adaptive refinement -1 :: \"use adaptive_block_size\"; 1: :: \"\" adaptive_block_size_z -1 Block size in z direction for adaptive refinement -1 :: \"use adaptive_block_size\"; 1: :: \"\" num_centres 0 Number of refinement centres 0:10 :: \"\" add_levels_automatically \"no\" Automatically add a new refinement level at each regrid num_levels_1 1 Number of refinement levels for this centre 1:30 :: \"\" active_1 \"yes\" Is this region active? position_x_1 0.0 Position of this centre : :: \"\" position_y_1 0.0 Position of this centre : :: \"\" position_z_1 0.0 Position of this centre : :: \"\" movement_threshold_1 0.0 Minimum movement to trigger a regridding 0: :: \"\" radius_rel_change_threshold_1 0.0 Minimum RELATIVE change in radius to trigger a regridding 0.0: :: \"\" num_levels_2 1 Number of refinement levels for this centre 1:30 :: \"\" active_2 \"yes\" Is this region active? position_x_2 0.0 Position of this centre : :: \"\" position_y_2 0.0 Position of this centre : :: \"\" position_z_2 0.0 Position of this centre : :: \"\" movement_threshold_2 0.0 Minimum movement to trigger a regridding 0: :: \"\" radius_rel_change_threshold_2 0.0 Minimum change in radius to trigger a regridding 0.0: :: \"\"","title":"Parameter"},{"location":"ET/parameter/#carpetinterp","text":"This thorn provides a parallel interpolator for Carpet.","title":"CarpetInterp"},{"location":"ET/parameter/#parameter_12","text":"Key Defaults Describe Option barriers \"no\" Insert barriers at strategic places for debugging purposes (slows down execution) poison -4.20042e+30 Poison value : :: \"\" ipoison -420042 Integer poison value : :: \"\" tree_search \"yes\" Use a tree search to find the source processor check_tree_search \"no\" Cross-check the result of the tree search","title":"Parameter"},{"location":"ET/parameter/#carpetreduce","text":"This thorn provides parallel reduction operators for Carpet. This thorn now uses a weight function. This makes it possible to perform physically meaningful spatial reduction operations. The weight is 1 for all \"normal\" grid points. The weight is set to 0 on symmetry and possible the outer boundary, and it might be set to \u00bd on the edge of the boundary. Setting this depends on the coordinate thorn, and currently works only when the coordinates are defined via CoordBase. The weight is also reduced or set to 0 on coarser grids that are overlaid by finer grid. The weight should also be reduced or set to 0 near and in excised regions. This should happen in conjunction with an excision boundary thorn.","title":"CarpetReduce"},{"location":"ET/parameter/#parameter_13","text":"Key Defaults Describe Option verbose \"no\" Produce screen output while running debug_iweight \"no\" Allow debugging iweight grid function by keeping it allocated min_max_time_interpolation \"yes\" Interpolate in time for min/max reductions","title":"Parameter"},{"location":"ET/parameter/#partial-differential-equation-pde","text":"","title":"Partial Differential Equation (PDE)"},{"location":"ET/parameter/#ct_multilevel","text":"This thorn implements a multigrid solver for systems of elliptic partial differential equations. This thorn requires Carpet, which it uses to manage the access to the grid structure and to pass information between the different levels (via the restriction and prolongation operators). The thorn also inherits from boundary and grid for boundary APIs and coordinate labels. Multigrid schemes are designed to solve elliptic equations on a hierarchy of grids. Each equation in the system to solve is parametrized as follows: \\begin{array}{c}{c_{x x} \\partial_{x x} \\psi+c_{x y} \\partial_{x y} \\psi+c_{x z} \\partial_{x z} \\psi+c_{y y} \\partial_{y y} \\psi+c_{y z} \\partial_{y z} \\psi+c_{z z} \\partial_{z z} \\psi} \\\\ {c_{x} \\partial_{x} \\psi+c_{y} \\partial_{y} \\psi+c_{z} \\partial_{z} \\psi+c_{0} \\psi^{n_{0}}+c_{1} \\psi^{n_{1}}+c_{2} \\psi^{n_{2}}+c_{3} \\psi^{n_{3}}+c_{4} \\psi^{n_{4}}=0}\\end{array} \\begin{array}{c}{c_{x x} \\partial_{x x} \\psi+c_{x y} \\partial_{x y} \\psi+c_{x z} \\partial_{x z} \\psi+c_{y y} \\partial_{y y} \\psi+c_{y z} \\partial_{y z} \\psi+c_{z z} \\partial_{z z} \\psi} \\\\ {c_{x} \\partial_{x} \\psi+c_{y} \\partial_{y} \\psi+c_{z} \\partial_{z} \\psi+c_{0} \\psi^{n_{0}}+c_{1} \\psi^{n_{1}}+c_{2} \\psi^{n_{2}}+c_{3} \\psi^{n_{3}}+c_{4} \\psi^{n_{4}}=0}\\end{array} All the coefficients c_\u2217 c_\u2217 and the powers n_\u2217 n_\u2217 can be specified by setting the parameters *_gfname[*] to the desired grid function name. These parameters are arrays to allow for the solution of systems of equations. The only other parameter which must be set to ensure correct operation is CT_MultiLevel::topMGlevel , which tells the solver which is the \ufb01nest refinement level that covers the entire domain in which the equation is to be solved. CT_MultiLevel needs at least one external thorn to set the PDE coefficients CT_Analytic .","title":"CT_MultiLevel"},{"location":"ET/parameter/#parameter_14","text":"Key Defaults Describe Option mode \"generic\" Which equation should we solve? \"generic\" :: \"Generic elliptic operator, to be defined via the coefficients\"; \"constraints\" :: \"The GR constraints\" model \"None\" Model used to populate the auxiliary functions \"Bowen-York\" :: \"Bowen-York extrinsic curvature for multiple punctures\"; \"Expanding BH lattice\" :: \"An expanding black-hole lattice\"; \"Lump\" :: \"Generic compact source in Tmunu\"; \"Inhomogeneous Helmholtz\":: \"Inhomogeneous Helmholtz equation\"; \"None\" :: \"No auxiliaries needed\" cycle_type \"V How should be cycle over the refinement levels? \"V cycle\" :: \"A V cycle\"; \"FMG cycle\" :: \"A FMG cycle\" verbose \"no\" Output debugging information? \"no\" :: \"no\"; \"yes\" :: \"yes\" veryverbose \"no\" Output more debugging information? \"no\" :: \"no\"; \"yes\" :: \"yes\" output_norms \"no\" Output the norms of psi and residual, and those of their errors? \"no\" :: \"no\"; \"yes\" :: \"yes\" compare_to_exact \"no\" Output a file with the difference between the solution at each iteration and the exact solution, if known \"no\" :: \"no\"; \"yes\" :: \"yes\" output_walk \"no\" Output a file with the parameter-space walk followed by the algorithm? \"no\" :: \"no\"; \"yes\" :: \"yes\" fill_ADM \"no\" Should the equation solution be used to fill the ADM variables? \"no\" :: \"no\"; \"yes\" :: \"yes\" boundary_conditions \"none\" Which boundary conditions to apply to psi \"Robin\":: \"Robin\"; \"TwoPunctures\" :: \"Dirichlet BCs from TwoPunctures\"; \"none\" :: \"This thorn will apply no boundary conditions\" exact_offset 0.0 Offset between exact solution and grid function pointed by exact_solution_gfname ::: \"Any real number\" fd_order 2 Order of FD 2:4:2 :: \"Order of differencing\" number_of_equations 1 How many equations are to be solved concurrently? 1:10:: \"A positive integer smaller than or equal to 10\" number_of_auxiliaries 0 How many auxiliary functions do we need? 0::: \"A non-negative integer\" nrelsteps_up 2 How many times should we relax each level inside the upward leg of a cycle? 0::: \"Any non-negative integer\" nrelsteps_down 2 How many times should we relax each level inside the downward leg of a cycle? 0::: \"Any non-negative integer\" nrelsteps_bottom 2 How many times should we relax each level at the bottom of a cycle? 0::: \"Any non-negative integer\" nrelsteps_top 2 How many times should we relax each level at the top of a cycle? 0::: \"Any non-negative integer\" integral_refinement 1 How much to refine the grid via interpolation before calculating integrals 1: :: \"Any integer greater than zero\" tol 1e-06 Maximum residual tolerated 0: ::\"Any non-negative real\" eps 1e-06 Regularization factor at the punctures 0: ::\"Any non-negative real\" omega 1 Overrelaxation factor 0:2 ::\"Real larger than zero and smaller than 2\" reset_psi \"no\" Reset psi after each relaxation step? How? \"no\":: \"Do not reset\"; \"to value\":: \"Reset to the value specified by reset_value\"; \"through integrability\" :: \"Reset so that the integrability condition is satisfied\" reset_every 1 How often should we reset psi? 1: :: \"Any positive integer\" reset_x 0 x-coordinate of point of reference for variable resetting : ::\"Any real number (contained in the domain!)\" reset_y 0 y-coordinate of point of reference for variable resetting : ::\"Any real number (contained in the domain!)\" reset_z 0 z-coordinate of point of reference for variable resetting : ::\"Any real number (contained in the domain!)\" enforce_int 0 Enforce the integral compatibility condition? 0:1:1 :: \"True or false\" topMGlevel 0 Finest level that covers the entire domain 0::: \"Any non-negative integer (< Carpet::reflevels!)\" fill_Aij \"Analytic Where does the final Aij come from? \"Solver\" :: \"Aij is solved for as well\"; \"Analytic Xi\":: \"Aij comes from differentiating an analytic Xi\"; \"Analytic Aij\" :: \"Aij comes from an exact solution\"","title":"Parameter"},{"location":"ET/parameter/#ct_analytic","text":"","title":"CT_Analytic"},{"location":"ET/parameter/#parameter_15","text":"Key Defaults Describe Option verbose 0 verbose : :: \"\" other_timelevels 1 Number of active timelevels for non-evolved grid functions 0:3 :: \"\" kx 0 Wavelength parameter along x : :: \"\" ky 0 Wavelength parameter along y : :: \"\" kz 0 Wavelength parameter along z : :: \"\" ampG 0 Coefficient of the gaussian term in the exact solution : :: \"\" ampS 0 Coefficient of the sine term in the exact solution : :: \"\" ampC 0 Constant coefficient in the exact solution : :: \"\" ampI 0 Multiplication factor between initial guess and exact solution : :: \"\" ampC1 0 Initial value for testc1 : :: \"\" ampSg 0 Coefficient of the 1/r term in the exact solution : :: \"\" ampV 0 Coefficient of the vector part in the exact solution : :: \"\" ampVG 0 Coefficient of the vector part in the exact solution (gaussian term) : :: \"\" sigma 1 Width of transition function in extrinsic curvature : :: \"\" l 0 Location of transition function in extrinsic curvature : :: \"\" phasex 0 Phase in the initial data for psi along x : :: \"\" phasey 0 Phase in the initial data for psi along y : :: \"\" phasez 0 Phase in the initial data for psi along z : :: \"\" Kc 0 Coefficient of extrinsic curvature : :: \"\" Ke 0 Coefficient of extrinsic curvature in exact solution : :: \"\" massa 0 mass of first black hole : :: \"\" massb 0 mass of second black hole : :: \"\" xa 0 x-coordinate of first black hole for BY initial data : :: \"\" ya 0 y-coordinate of first black hole for BY initial data : :: \"\" za 0 z-coordinate of first black hole for BY initial data : :: \"\" xb 0 x-coordinate of second black hole for BY initial data : :: \"\" yb 0 y-coordinate of second black hole for BY initial data : :: \"\" zb 0 z-coordinate of second black hole for BY initial data : :: \"\" Pax 0 x-component of linear momentum of first black hole for BY initial data : :: \"\" Pay 0 y-component of linear momentum of first black hole for BY initial data : :: \"\" Paz 0 z-component of linear momentum of first black hole for BY initial data : :: \"\" Pbx 0 x-component of linear momentum of second black hole for BY initial data : :: \"\" Pby 0 y-component of linear momentum of second black hole for BY initial data : :: \"\" Pbz 0 z-component of linear momentum of second black hole for BY initial data : :: \"\" eps 1.e-6 Smoothing factor : :: \"\" edgeL 10 Coordinate length of cell edge : :: \"\" rBall 1 Coordinate radius of ball of density for Poisson's equation : :: \"\" vecA 1 Coordinate center of gaussian representing the X^i vector in the CTT decomposition of the constraints : :: \"\" imaxF 1 Max number of Fourier modes to include in x direction : :: \"\" jmaxF 1 Max number of Fourier modes to include in y direction : :: \"\" kmaxF 1 Max number of Fourier modes to include in z direction : :: \"\" tile_size -1 Loop tile size : :: \"\" free_data \"exact\" How to set the free data for the extrinsic curvature? \"exact\" :: \"\"; \"Expanding BH lattice\" :: \"\"; \"Bowen-York\" :: \"\"; \"Poisson\" :: \"\"; \"Lump\" :: \"\" CT_Analytic_MaxNumEvolvedVars 0 Number of evolved variables used by this thorn 0:0 :: \"Number of evolved variables used by this thorn\" CT_Analytic_MaxNumArrayEvolvedVars 0 Number of Array evolved variables used by this thorn 0:0 :: \"Number of Array evolved variables used by this thorn\" timelevels 3 Number of active timelevels 0:3 :: \"\" rhs_timelevels 1 Number of active RHS timelevels 0:3 :: \"\" CT_Analytic_Poisson_Calc_calc_every 1 CT_Analytic_Poisson_Calc_calc_every : :: \"\" CT_Analytic_Exact_Calc_calc_every 1 CT_Analytic_Exact_Calc_calc_every : :: \"\" CT_Analytic_ExpandingLattice_Calc_calc_every 1 CT_Analytic_ExpandingLattice_Calc_calc_every : :: \"\" CT_Analytic_BY_Calc_calc_every 1 CT_Analytic_BY_Calc_calc_every : :: \"\" CT_Analytic_Lump_Calc_calc_every 1 CT_Analytic_Lump_Calc_calc_every : :: \"\" CT_Analytic_ExactBoundary_calc_every 1 CT_Analytic_ExactBoundary_calc_every : :: \"\" CT_Analytic_LumpBoundary_calc_every 1 CT_Analytic_LumpBoundary_calc_every : :: \"\" CT_Analytic_Poisson_Calc_calc_offset 0 CT_Analytic_Poisson_Calc_calc_offset : :: \"\" CT_Analytic_Exact_Calc_calc_offset 0 CT_Analytic_Exact_Calc_calc_offset : :: \"\" CT_Analytic_ExpandingLattice_Calc_calc_offset 0 CT_Analytic_ExpandingLattice_Calc_calc_offset : :: \"\" CT_Analytic_BY_Calc_calc_offset 0 CT_Analytic_BY_Calc_calc_offset : :: \"\" CT_Analytic_Lump_Calc_calc_offset 0 CT_Analytic_Lump_Calc_calc_offset : :: \"\" CT_Analytic_ExactBoundary_calc_offset 0 CT_Analytic_ExactBoundary_calc_offset : :: \"\" CT_Analytic_LumpBoundary_calc_offset 0 CT_Analytic_LumpBoundary_calc_offset : :: \"\"","title":"Parameter"},{"location":"ET/parameter/#ioascii","text":"Thorn IOASCII provides I/O methods for 1D, 2D, and 3D output of grid arrays and grid functions into files in ASCII format.","title":"IOASCII"},{"location":"ET/parameter/#einstein","text":"The basic variables are those of the ADM formulation of Einstein\u2019s equations, namely the spatial 3-metric \\gamma_{i j} \\gamma_{i j} , the lapse \\alpha \\alpha , the shift \\beta \\beta , and the extrinsic curvature K_{i j} K_{i j} . The 4-metric is given by d s^{2}=-\\left(\\alpha^{2}-\\beta^{i} \\beta_{i}\\right) d t^{2}+\\beta_{i} d t d x^{i}+\\gamma_{i j} d x^{i} d x^{j} d s^{2}=-\\left(\\alpha^{2}-\\beta^{i} \\beta_{i}\\right) d t^{2}+\\beta_{i} d t d x^{i}+\\gamma_{i j} d x^{i} d x^{j} If \\gamma_{i j} \\gamma_{i j} is the 3-metric of a spacelike Cauchy surface with normal n, then K_{i j}=\\frac{1}{2} \\mathcal{L}_{n} \\gamma_{i j} K_{i j}=\\frac{1}{2} \\mathcal{L}_{n} \\gamma_{i j} The ADM equations then evolve the spatial three metric \\gamma_{i j} \\gamma_{i j} and the extrinsic curvature K_{i j} K_{i j} using \\begin{aligned} \\frac{d}{d t} \\gamma_{i j}=&-2 \\alpha K_{i j} \\\\ \\frac{d}{d t} K_{i j}=&-D_{i} D_{j} \\alpha+\\alpha\\left(R_{i j}+K K_{i j}\\right.\\\\ &-2 K_{i k} K_{j}^{k} - ^{(4)} R_{i j} ) \\end{aligned} \\begin{aligned} \\frac{d}{d t} \\gamma_{i j}=&-2 \\alpha K_{i j} \\\\ \\frac{d}{d t} K_{i j}=&-D_{i} D_{j} \\alpha+\\alpha\\left(R_{i j}+K K_{i j}\\right.\\\\ &-2 K_{i k} K_{j}^{k} - ^{(4)} R_{i j} ) \\end{aligned} with \\frac{d}{d t}=\\partial_{t}-\\mathcal{L}_{\\beta} \\frac{d}{d t}=\\partial_{t}-\\mathcal{L}_{\\beta} These variables are defined in the thorn ADMBase, and are the ones that are used to communicate the geometry to other thorns. It is not necessary to use all of these thorns to make use of CactusEinstein, however. The only thorn which is necessary is ADMBase, since it defines the variables and parameters on which the rest of the CactusEinstein thorns depend. ADMConstraints: computes the 3 + 1 Hamiltonian (energy) and momentum constraints ADMCoupling: allows thorns to \u2018register\u2019 their matter field contributions to the stress energy tensor ADMMacros: macros for computing various quantities which are commonly used in 3 + 1 numerical relativity, such as Christoffel symbols, covariant derivatives, the Ricci tensor, etc etc; some of these support both 2 nd and 4 th order finite differencing AHFinder: searches for apparent horizons CoordGauge: manages gauge quantities EvolSimple: a demo evolution thorn Extract: \u2018extracts\u2019 gravitational-wave waveforms IDAnalyticBH: analytic black hole initial data IDAxiBrillBH: axisymmetric Brill wave with black hole initial data IDBrillData: Brill wave initial data IDLinearWaves: linearized wave initial data IDSimple: a demo initial data thorn, provides Minkowski space with conformal factor Maximal: maximal slicing gauge condition PsiKadelia: computes various Neumann-Penrose quantities SpaceMask: provides a \u2018mask\u2019 for the spatial grid StaticConformal: provides for a static conformal factor TimeGeodesic: computes timelike geodesics Exact: analytical solutions where the full 4-metric is known throughout the entire spacetime, eg. Schwarzschild, Kerr, various cosmological solutions.","title":"Einstein"},{"location":"ET/parameter/#admbase","text":"This thorn provides the basic variables used to communicate between thorns doing General Relativity in the 3+1 formalism.","title":"ADMBase"},{"location":"ET/parameter/#description_3","text":"It provides the basic variables (3-metric, extrinsic curvature, lapse and shift vector) for the 3 + 1 formalism, in addition to a set of parameters to regulate the methods used for their evolution. These variables are used to communicate between thorns providing initial data, evolution methods and analysis routines for the 3 + 1 formalism. The variables provided by ADMBase are: - The 3-metric tensor, g_{i j} g_{i j} gxx, gxy, gxz, gyy, gyz, gzz - The extrinsic curvature tensor, K_{i j} K_{i j} kxx, kxy, kxz, kyy, kyz, kzz - The lapse function, \\alpha \\alpha alp - The (optional) shift vector \\beta^{i} \\beta^{i} betax, betay, betaz Initial data for the 3 + 1 variables is specified by the initial_data (3-metric and extrinsic curvature), initial_lapse (lapse), and initial_shift (shift) parameters. By default, ADMBase initialises the 3- metric and extrinsic curvature to Minkowski and the lapse to one. Analogous to specifying initial data, evolution methods are chosen by the evolution method (3-metric and extrinsic curvature), lapse_evolution_method (lapse), and shift_evolution_method (shift) parameters. By default, ADMBase does not evolve the 3-metric or extrinsic curvature, and holds the lapse and shift static.","title":"Description"},{"location":"ET/parameter/#parameter_16","text":"Key Defaults Describe Option initial_data \"Cartesian Initial metric and extrinsic curvature datasets \"Cartesian Minkowski\" :: \"Minkowski values in cartesian coordinates\" initial_lapse \"one\" Initial lapse value \"one\" :: \"Uniform lapse\" initial_shift \"zero\" Initial shift value \"none\" :: \"Shift is inactive\"; \"zero\" :: \"Shift is zero\" initial_dtlapse \"none\" Initial dtlapse value \"none\" :: \"Dtlapse is inactive\"; \"zero\" :: \"Dtlapse is zero\" initial_dtshift \"none\" Initial dtshift value \"none\" :: \"Dtshift is inactive\"; \"zero\" :: \"Dtshift is zero\" evolution_method \"static\" The metric an extrinsic curvature evolution method \"none\" :: \"The metric and extrinsic curvature are not evolved\"; \"static\" :: \"The metric and extrinsic curvature are not evolved\"; \"ID-apply-regrid\" :: \"The metric and extrinsic curvature are not evolved and initial data is used to fill in new grid points after regridding\"; \"ID-apply-always\" :: \"The metric and extrinsic curvature are not evolved and initial data is used to fill in new grid points before each step and after grid changes\" lapse_evolution_method \"static\" The lapse evolution method \"static\" :: \"lapse is not evolved\"; \"ID-apply-regrid\" :: \"lapse is not evolved and initial data is used to fill in new grid points after regridding\"; \"ID-apply-always\" :: \"lapse is not evolved and initial data is used to fill in new grid points before each step and after grid changes\" shift_evolution_method \"static\" The shift evolution method \"static\" :: \"dtlapse is not evolved\"; \"ID-apply-regrid\" :: \"dtlapse is not evolved and initial data is used to fill in new grid points after regridding\"; \"ID-apply-always\" :: \"dtlapse is not evolved and initial data is used to fill in new grid points before each step and after grid changes\" dtshift_evolution_method \"flat\" The dtshift evolution method \"\" :: \"must be a registered boundary condition\" metric_type \"physical\" The semantics of the metric variables (physical, static conformal, etc) \"physical\" :: \"metric and extrinsic curvature are the physical ones\" lapse_prolongation_type \"Lagrange\" The kind of boundary prolongation for the lapse \"Lagrange\" :: \"standard prolongation (requires several time levels)\"; \"none\" :: \"no prolongation (use this if you do not have enough time levels active)\" shift_prolongation_type \"Lagrange\" The kind of boundary prolongation for the shift \"Lagrange\" :: \"standard prolongation (requires several time levels)\"; \"none\" :: \"no prolongation (use this if you do not have enough time levels active)\" metric_prolongation_type \"Lagrange\" The kind of boundary prolongation for the metric and extrinsic curvature \"Lagrange\" :: \"standard prolongation (requires several time levels)\"; \"none\" :: \"no prolongation (use this if you do not have enough time levels active)\" lapse_timelevels 1 Number of time levels for the lapse 0:3 :: \"\" shift_timelevels 1 Number of time levels for the shift 0:3 :: \"\" metric_timelevels 1 Number of time levels for the metric and extrinsic curvature 0:3 :: \"\"","title":"Parameter"},{"location":"ET/parameter/#admanalysis","text":"This thorn does basic analysis of the metric and extrinsic curvature tensors. It calculates if output is requested for them. the trace of the extrinsic curvature (t r K) (t r K) the determinant of the metric (\\operatorname{detg}) (\\operatorname{detg}) the components of the metric in spherical coordinates \\left(g_{r r}, g_{r \\theta}, g_{r \\phi}, g_{\\theta \\theta}, g_{\\phi \\theta}, g_{\\phi \\phi}\\right) \\left(g_{r r}, g_{r \\theta}, g_{r \\phi}, g_{\\theta \\theta}, g_{\\phi \\theta}, g_{\\phi \\phi}\\right) the components of the extrinsic curvature in spherical coordinates \\left(K_{r r}, K_{r \\theta}, K_{r \\phi}, K_{\\theta \\theta}, K_{\\theta \\phi}, K_{\\phi \\phi}\\right) \\left(K_{r r}, K_{r \\theta}, K_{r \\phi}, K_{\\theta \\theta}, K_{\\theta \\phi}, K_{\\phi \\phi}\\right) components of the Ricci tensor \\left(\\mathcal{R}_{i j}\\right) \\left(\\mathcal{R}_{i j}\\right) for i, j \\in\\{1,2,3\\} i, j \\in\\{1,2,3\\} the Ricci scalar (\\mathcal{R}) (\\mathcal{R}) The trace of the extrinsic curvature at each point on the grid is placed in the grid function trK . The algorithm for calculating the trace uses the physical metric, that is it includes any conformal factor. \\operatorname{trK} \\equiv \\operatorname{tr} K=\\frac{1}{\\psi^{4}} g^{i j} K_{i j} \\operatorname{trK} \\equiv \\operatorname{tr} K=\\frac{1}{\\psi^{4}} g^{i j} K_{i j} The determinant of the 3-metric at each point on the grid is placed in the grid function detg . This is always the determinant of the conformal metric, that is it does not include any conformal factor. \\operatorname{detg} \\equiv \\operatorname{detg}=-g_{13}^{2} * g_{22}+2 * g_{12} * g_{13} * g_{23}-g_{11} * g_{23}^{2}-g_{12}^{2} * g_{33}+g_{11} * g_{22} * g_{33} \\operatorname{detg} \\equiv \\operatorname{detg}=-g_{13}^{2} * g_{22}+2 * g_{12} * g_{13} * g_{23}-g_{11} * g_{23}^{2}-g_{12}^{2} * g_{33}+g_{11} * g_{22} * g_{33} If the parameter 'normalize_dtheta_dphi' is true, the thorn projects the spherical components onto ( r*dtheta , r*sin(theta)*dphi ) instead of the default vector ( dtheta , dphi ).","title":"ADMAnalysis"},{"location":"ET/parameter/#parameter_17","text":"Key Defaults Describe Option normalize_dtheta_dphi \"no\" Project angular components onto r*dtheta and r*sin(theta)*dphi ricci_persist \"no\" Keep storage of the Ricci tensor and scalar around? ricci_timelevels 1 Number of time levels for the Ricci tensor and scalar 1:3 :: \"\" ricci_prolongation_type \"none\" The kind of boundary prolongation for the Ricci tensor and scalar \"Lagrange\" :: \"standard prolongation (requires several time levels)\"; \"copy\" :: \"use data from the current time level (requires only one time level)\"; \"none\" :: \"no prolongation (use this if you do not have enough time levels active)\"","title":"Parameter"},{"location":"ET/parameter/#admmacros","text":"This thorn provides various macros which can be used to calculate quantities, such as the Christoffel Symbol or Riemann Tensor components, using the basic variables of thorn ADMBase. The macros work pointwise to calculate quantities at the grid point (i, j, k); it\u2019s up to you to loop over all the grid points where you want computations done.","title":"ADMMacros"},{"location":"ET/parameter/#description_4","text":"By default, the macros use centered 2 nd order finite differencing, with 3-point finite difference molecules. That is, when finite differencing the the grid-point indices i \u00b1 1, j \u00b1 1, and k \u00b1 1 must also be valid, and driver::ghost_size must be set to at least 1. Some of the macros also support centered 4 th order finite differencing; This is selected with the parameter spatial_order . This may be set to either 2 or 4; it defaults to 2. If it\u2019s set to 4, then 5-point finite difference molecules are used, so the grid-point indices i \u00b1 2, j \u00b1 2, and k \u00b1 2 must also be valid, and driver::ghost size must be set to at least 2.","title":"Description"},{"location":"ET/parameter/#parameter_18","text":"Key Defaults Describe Option spatial_order 2 Order of spatial differencing 2 :: \"2 nd order finite differencing\"; 4 :: \"4 th order finite differencing\"","title":"Parameter"},{"location":"ET/parameter/#initial-data","text":"The initial data are computed using the Compact Object CALculator (COCAL)","title":"Initial data"},{"location":"ET/parameter/#initbase","text":"Thorn InitBase specifies how initial data are to be set up. It does not set up any initial data by itself, nor does it contain any routines which are to be called. It is merely a convenient repository remembering how initial data are to be set up, so that other thorns can check their actions against this thorn. There are several possibilities: The initial data thorn sets up data on one time level, while other time levels are scratch space. The time evolution method must start up from a single time level. (This is the default.) The initial data thorn sets up data on exactly one time level, and is called once for each active time level. (This means that the initial data thorn can only access the current time level.) The initial data thorn sets up data on exactly two time levels, and is called once for each active time level. (This means that the initial data thorn can only access the current and the first past time level.) The initial data thorn sets up data on all active time levels. (This makes it necessary that the initial data thorn checks the number of active time levels.)","title":"InitBase"},{"location":"ET/parameter/#parameter_19","text":"Key Defaults Describe Option initial_data_setup_method \"init_some_levels\" Procedure for setting up initial data \"init_some_levels\":: \"Set up at least one time level; other time levels are scratch space\"; \"init_single_level\" :: \"Set up exactly one time level; other time levels are not accessed\"; \"init_two_levels\" :: \"Set up exactly two time levels; other time levels are not accessed\"; \"init_all_levels\" :: \"Set up all active time levels\"","title":"Parameter"},{"location":"ET/parameter/#tovsolver","text":"The Tolman-Oppenheimer-Volkoff solution is a static perfect fluid \u201cstar\u201d. Here it is intended for use without evolving the matter terms. This provides a compact strong \ufb01eld solution which is static but does not contain singularities. The equations for a TOV star are usually derived in Schwarzschild coordinates. In these coordinates, the metric can be brought into the form d s^{2}=-e^{2 \\phi} d t^{2}+\\left(1-\\frac{2 m}{r}\\right)^{-1} d r^{2}+r^{2} d \\Omega^{2} d s^{2}=-e^{2 \\phi} d t^{2}+\\left(1-\\frac{2 m}{r}\\right)^{-1} d r^{2}+r^{2} d \\Omega^{2} Here we are assuming that the stress energy tensor is given by T^{\\mu \\nu}=(\\mu+P) u^{\\mu} u^{\\nu}+P g^{\\mu \\nu} T^{\\mu \\nu}=(\\mu+P) u^{\\mu} u^{\\nu}+P g^{\\mu \\nu}","title":"TOVSolver"},{"location":"ET/parameter/#description_5","text":"","title":"Description"},{"location":"ET/parameter/#parameter_20","text":"Key Defaults Describe Option TOV_Num_TOVs 1 The number of TOVs 1: :: \"Greater than 0\" TOV_Solve_for_TOVs 3 Solve for TOVs even if no TOV initial data was requested? 0:3 :: \"depreciated in favour of TOVSolver::TOV_Enforce_Interpolation\" TOV_Enforce_Interpolation \"no\" Enforce the interpolation of the data onto the Hydro GFs even without tov as specified initial data TOV_Num_Radial 100000 The number of radial points for the ODE integration 1: :: \"Greater than 0\" TOV_Gamma 2.0 The polytropic constant in P = K rho^Gamma 1.0: :: \"The physical range at high Lorentz factors is [1,2], but otherwise higher values of gamma can also be used\" TOV_K 100.0 The polytropic constant in P = K rho^Gamma (0.0: :: \"Greater than 0\" TOV_ProperPosition \"no\" For use only with two NSs, atm only handles equal mass TOV_Fast_Interpolation \"yes\" Use faster interpolation algorithm? Default is yes. TOV_Clear_Initial_Data \"yes\" Clear initial data (spacetime)? Default is yes. TOV_Use_Old_Initial_Data \"no\" Take old initial data into account (spacetime)? Default is no. TOV_Use_Old_Matter_Initial_Data \"no\" Use also old matter initial data? Default is no. TOV_Conformal_Flat_Three_Metric \"no\" Use conformal factor to get the 3-metric flat. default is no TOV_Combine_Method \"average\" Which combine method should be used. \"maximum\" :: \"Take the maximum of rho and gxx as clue for the rest as clue.\"; \"average\" :: \"Take the average of all available parts.\" TOV_Populate_Timelevels 1 Populate that amount of timelevels 1:3 :: \"1 (default) to 3\" TOV_Momentum_Psi_Power 0 Power of Psi to be multiplied with J^i for Mom : :: \"anything, 0 as default\" TOV_fake_evolution 0 Fake evolution by setting ID at every step : :: \"anything, 0 as off (default), everything else as on\" TOV_save_to_datafile \"\" Only save data to file and exit \".\" :: \"Any filename, not used if empty\"","title":"Parameter"},{"location":"ET/parameter/#evolution","text":"","title":"Evolution"},{"location":"ET/parameter/#admcoupling","text":"This thorn allows seamless coupling of evolution and analysis thorns to any thorns which contribute matter terms to the stress energy tensor T_{a b} T_{a b} .","title":"ADMCoupling"},{"location":"ET/parameter/#description_6","text":"The point is to allow clean coupling of matter thorns and spacetime evolution thorns. This avoids explicit dependencies between the spacetime and matter evolution thorns. Spacetime evolution thorns and various analysis thorns may need to know the value of the stress-energy tensor.","title":"Description"},{"location":"ET/parameter/#ml_bssn","text":"","title":"ML_BSSN"},{"location":"ET/parameter/#parameter_21","text":"Key Defaults Describe Option evolution_method evolution_method \"ML_BSSN\" :: \"\" lapse_evolution_method lapse_evolution_method \"ML_BSSN\" :: \"\" shift_evolution_method shift_evolution_method \"ML_BSSN\" :: \"\" dtlapse_evolution_method dtlapse_evolution_method \"ML_BSSN\" :: \"\" dtshift_evolution_method dtshift_evolution_method \"ML_BSSN\" :: \"\" verbose 0 verbose : :: \"\" other_timelevels 1 Number of active timelevels for non-evolved grid functions 0:4 :: \"\" harmonicF 1 d/dt alpha = - f alpha^n K (harmonic: f=1, 1+log: f=2) : :: \"\" alphaDriver 0 d/dt alpha = ... - alphaDriver (alpha - 1) (use 1/M (?)) : :: \"\" shiftGammaCoeff 0 d/dt beta^i = C Xt^i (use C=0.75/M) : :: \"\" betaDriver 0 d/dt beta^i = ... - betaDriver alpha^shiftAlphaPower beta^i (use 1/M (?)) : :: \"\" shiftAlphaPower 0 d/dt beta^i = ... - betaDriver alpha^shiftAlphaPower beta^i (use 0 (?)) : :: \"\" spatialBetaDriverRadius 1000000000000 Radius at which the betaDriver starts to be reduced (0: :: \"positive\" spatialShiftGammaCoeffRadius 1000000000000 Radius at which shiftGammaCoeff starts to be reduced (0: :: \"positive\" minimumLapse 0 Enforced minimum of the lapse function 0: :: \"non-negative\" epsDiss 0 Dissipation strength 0: :: \"non-negative\" LapseACoeff -1. (OUTDATED) Evolve time derivative of lapse A? (now evolveA) 0. :: \"off\"; 1. :: \"on\"; -1. :: \"default\" ShiftBCoeff -1. (OUTDATED) Evolve time derivative of shift B^i? (now evolveB) 0. :: \"off\"; 1. :: \"on\"; -1. :: \"default\" LapseAdvectionCoeff -1. (OUTDATED) Advect lapse? (now advectLapse) 0. :: \"off\"; 1. :: \"on\"; -1. :: \"default\" ShiftAdvectionCoeff -1. (OUTDATED) Advect shift? (now advectShift) 0. :: \"off\"; 1. :: \"on\"; -1. :: \"default\" fdOrder 4 Finite differencing order 2 :: \"\"; 4 :: \"\"; 6 :: \"\"; 8 :: \"\" conformalMethod 0 Treatment of conformal factor 0 :: \"phi method\"; 1 :: \"W method\" evolveA 0 Evolve time derivative of lapse A? (former LapseACoeff) 0 :: \"off\"; 1 :: \"on\" evolveB 1 Evolve time derivative of shift B^i? (former ShiftBCoeff) 0 :: \"off\"; 1 :: \"on\" harmonicN 2 d/dt alpha = - f alpha^n K (harmonic: n=2, 1+log: n=1) : :: \"\" shiftFormulation 0 shift formulation 0 :: \"Gamma driver\"; 1 :: \"harmonic\" useSpatialBetaDriver 0 Enable spatially varying betaDriver 0 :: \"off\"; 1 :: \"on\" useSpatialShiftGammaCoeff 0 Enable spatially varying shiftGammaCoeff 0 :: \"off\"; 1 :: \"on\" advectLapse 1 Advect lapse? (former LapseAdvectionCoeff) 0 :: \"off\"; 1 :: \"on\" advectShift 1 Advect shift? (former ShiftAdvectionCoeff) 0 :: \"off\"; 1 :: \"on\" fixAdvectionTerms 0 Modify driver and advection terms to work better? 0 :: \"off\"; 1 :: \"on\" tile_size -1 Loop tile size : :: \"\" initial_boundary_condition \"scalar\" Boundary condition for initial condition for some of the BSSN variables \"scalar\" :: \"not recommended; use ML_BSSN_Helper's value 'extrapolate-gammas' instead\" rhs_boundary_condition \"scalar\" Boundary condition for BSSN RHS and some of the ADMBase variables \"scalar\" :: \"not recommended; use ML_BSSN_Helper's option 'NewRad' instead\" rhs_evaluation \"splitBy\" Whether and how the RHS routine should be split to improve performance \"combined\" :: \"use a single routine (probably slow)\"; \"splitBy\" :: \"split into 3 routines via Kranc\" my_initial_data \"default\" (OUTDATED) \"ADMBase\" :: \"from ADMBase\"; \"default\" :: \"do nothing\" my_initial_boundary_condition \"default\" (OUTDATED) \"none\" :: \"none\"; \"default\" :: \"do nothing\" my_rhs_boundary_condition \"default\" (OUTDATED) \"none\" :: \"none\"; \"static\" :: \"static\"; \"default\" :: \"do nothing\" my_boundary_condition \"default\" (OUTDATED) \"none\" :: \"none\"; \"Minkowski\" :: \"Minkowski\"; \"default\" :: \"do nothing\" dt_lapse_shift_method \"default\" (OUTDATED) Treatment of ADMBase dtlapse and dtshift \"correct\" :: \"(unused)\"; \"noLapseShiftAdvection\" :: \"(unused)\"; \"default\" :: \"do nothing\" apply_dissipation \"default\" (OUTDATED) Whether to apply dissipation to the RHSs \"always\" :: \"yes\"; \"never\" :: \"no\"; \"default\" :: \"do nothing\" ML_BSSN_MaxNumEvolvedVars 25 Number of evolved variables used by this thorn 25:25 :: \"Number of evolved variables used by this thorn\" ML_BSSN_MaxNumArrayEvolvedVars 0 Number of Array evolved variables used by this thorn 0:0 :: \"Number of Array evolved variables used by this thorn\" timelevels 3 Number of active timelevels 0:4 :: \"\" rhs_timelevels 1 Number of active RHS timelevels 0:4 :: \"\" ML_BSSN_InitialADMBase1Everywhere_calc_every 1 ML_BSSN_InitialADMBase1Everywhere_calc_every : :: \"\" ML_BSSN_InitialADMBase2Interior_calc_every 1 ML_BSSN_InitialADMBase2Interior_calc_every : :: \"\" ML_BSSN_InitialADMBase2BoundaryScalar_calc_every 1 ML_BSSN_InitialADMBase2BoundaryScalar_calc_every : :: \"\" ML_BSSN_EnforceEverywhere_calc_every 1 ML_BSSN_EnforceEverywhere_calc_every : :: \"\" ML_BSSN_ADMBaseEverywhere_calc_every 1 ML_BSSN_ADMBaseEverywhere_calc_every : :: \"\" ML_BSSN_ADMBaseInterior_calc_every 1 ML_BSSN_ADMBaseInterior_calc_every : :: \"\" ML_BSSN_ADMBaseBoundaryScalar_calc_every 1 ML_BSSN_ADMBaseBoundaryScalar_calc_every : :: \"\" ML_BSSN_EvolutionInterior_calc_every 1 ML_BSSN_EvolutionInterior_calc_every : :: \"\" ML_BSSN_EvolutionInteriorSplitBy1_calc_every 1 ML_BSSN_EvolutionInteriorSplitBy1_calc_every : :: \"\" ML_BSSN_EvolutionInteriorSplitBy2_calc_every 1 ML_BSSN_EvolutionInteriorSplitBy2_calc_every : :: \"\" ML_BSSN_EvolutionInteriorSplitBy3_calc_every 1 ML_BSSN_EvolutionInteriorSplitBy3_calc_every : :: \"\" ML_BSSN_EvolutionBoundaryScalar_calc_every 1 ML_BSSN_EvolutionBoundaryScalar_calc_every : :: \"\" ML_BSSN_EvolutionAnalysisInit_calc_every 1 ML_BSSN_EvolutionAnalysisInit_calc_every : :: \"\" ML_BSSN_EvolutionAnalysisInterior_calc_every 1 ML_BSSN_EvolutionAnalysisInterior_calc_every : :: \"\" ML_BSSN_ConstraintsEverywhere_calc_every 1 ML_BSSN_ConstraintsEverywhere_calc_every : :: \"\" ML_BSSN_ConstraintsInterior_calc_every 1 ML_BSSN_ConstraintsInterior_calc_every : :: \"\" ML_BSSN_InitialADMBase1Everywhere_calc_offset 0 ML_BSSN_InitialADMBase1Everywhere_calc_offset : :: \"\" ML_BSSN_InitialADMBase2Interior_calc_offset 0 ML_BSSN_InitialADMBase2Interior_calc_offset : :: \"\" ML_BSSN_InitialADMBase2BoundaryScalar_calc_offset 0 ML_BSSN_InitialADMBase2BoundaryScalar_calc_offset : :: \"\" ML_BSSN_EnforceEverywhere_calc_offset 0 ML_BSSN_EnforceEverywhere_calc_offset : :: \"\" ML_BSSN_ADMBaseEverywhere_calc_offset 0 ML_BSSN_ADMBaseEverywhere_calc_offset : :: \"\" ML_BSSN_ADMBaseInterior_calc_offset 0 ML_BSSN_ADMBaseInterior_calc_offset : :: \"\" ML_BSSN_ADMBaseBoundaryScalar_calc_offset 0 ML_BSSN_ADMBaseBoundaryScalar_calc_offset : :: \"\" ML_BSSN_EvolutionInterior_calc_offset 0 ML_BSSN_EvolutionInterior_calc_offset : :: \"\" ML_BSSN_EvolutionInteriorSplitBy1_calc_offset 0 ML_BSSN_EvolutionInteriorSplitBy1_calc_offset : :: \"\" ML_BSSN_EvolutionInteriorSplitBy2_calc_offset 0 ML_BSSN_EvolutionInteriorSplitBy2_calc_offset : :: \"\" ML_BSSN_EvolutionInteriorSplitBy3_calc_offset 0 ML_BSSN_EvolutionInteriorSplitBy3_calc_offset : :: \"\" ML_BSSN_EvolutionBoundaryScalar_calc_offset 0 ML_BSSN_EvolutionBoundaryScalar_calc_offset : :: \"\" ML_BSSN_EvolutionAnalysisInit_calc_offset 0 ML_BSSN_EvolutionAnalysisInit_calc_offset : :: \"\" ML_BSSN_EvolutionAnalysisInterior_calc_offset 0 ML_BSSN_EvolutionAnalysisInterior_calc_offset : :: \"\" ML_BSSN_ConstraintsEverywhere_calc_offset 0 ML_BSSN_ConstraintsEverywhere_calc_offset : :: \"\" ML_BSSN_ConstraintsInterior_calc_offset 0 ML_BSSN_ConstraintsInterior_calc_offset : :: \"\" phi_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" gt11_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" gt12_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" gt13_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" gt22_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" gt23_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" gt33_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" Xt1_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" Xt2_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" Xt3_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" trK_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" At11_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" At12_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" At13_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" At22_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" At23_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" At33_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" alpha_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" A_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" beta1_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" beta2_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" beta3_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" B1_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" B2_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" B3_bound \"skip\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_log_confac_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_metric_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_Gamma_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_trace_curv_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_curv_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_lapse_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_dtlapse_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_shift_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" ML_dtshift_bound \"none\" Boundary condition to implement \"flat\" :: \"Flat boundary condition\"; \"none\" :: \"No boundary condition\"; \"static\" :: \"Boundaries held fixed\"; \"radiative\" :: \"Radiation boundary condition\"; \"scalar\" :: \"Dirichlet boundary condition\"; \"newrad\" :: \"Improved radiative boundary condition\"; \"skip\" :: \"skip boundary condition code\" phi_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" gt11_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" gt12_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" gt13_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" gt22_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" gt23_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" gt33_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" Xt1_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" Xt2_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" Xt3_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" trK_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" At11_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" At12_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" At13_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" At22_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" At23_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" At33_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" alpha_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" A_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" beta1_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" beta2_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" beta3_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" B1_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" B2_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" B3_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_log_confac_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_metric_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_Gamma_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_trace_curv_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_curv_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_lapse_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_dtlapse_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_shift_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" ML_dtshift_bound_speed 1. characteristic speed at boundary 0: :: \"outgoing characteristic speed > 0\" phi_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" gt11_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" gt12_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" gt13_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" gt22_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" gt23_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" gt33_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" Xt1_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" Xt2_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" Xt3_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" trK_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" At11_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" At12_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" At13_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" At22_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" At23_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" At33_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" alpha_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" A_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" beta1_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" beta2_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" beta3_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" B1_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" B2_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" B3_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_log_confac_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_metric_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_Gamma_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_trace_curv_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_curv_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_lapse_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_dtlapse_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_shift_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" ML_dtshift_bound_limit 0. limit value for r -> infinity : :: \"value of limit value is unrestricted\" phi_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" gt11_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" gt12_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" gt13_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" gt22_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" gt23_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" gt33_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" Xt1_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" Xt2_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" Xt3_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" trK_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" At11_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" At12_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" At13_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" At22_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" At23_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" At33_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" alpha_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" A_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" beta1_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" beta2_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" beta3_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" B1_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" B2_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" B3_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_log_confac_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_metric_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_Gamma_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_trace_curv_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_curv_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_lapse_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_dtlapse_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_shift_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\" ML_dtshift_bound_scalar 0. Dirichlet boundary value : :: \"unrestricted\"","title":"Parameter"},{"location":"ET/parameter/#hydro","text":"Thorn locate in /Users/yuliu/Cactus/arrangements/EinsteinBase/TmunuBase","title":"Hydro"},{"location":"ET/parameter/#tmunubase","text":"Provide grid functions for the stress-energy tensor T_{\\mu \\nu} T_{\\mu \\nu} . Thorn TmunuBase is for the stress-energy tensor what thorn ADMBase is for the metric tensor.","title":"TmunuBase"},{"location":"ET/parameter/#description_7","text":"The variables provided by TmunuBase are: The \u201cscalar\u201d part of T_{\\mu \\nu} T_{\\mu \\nu} , its time-time component: eTtt The \u201cvector\u201d part of T_{\\mu \\nu} T_{\\mu \\nu} , its time-space components: eTtx, eTty, eTtz The \u201ctensor\u201d part of T_{\\mu \\nu} T_{\\mu \\nu} , its space-space components: eTxx, eTxy, eTxz, eTyy, eTyz, eTzz These components have the pre\ufb01x e to avoid naming conflicts with existing variables. Many thorns dealing with matter already use variable names such as Ttt. Several parameters choose how TmunuBase behaves at run time: The parameter stress_energy_storage activates storage for T_{\\mu \\nu} T_{\\mu \\nu} . The parameter stress_energy_at_RHS moves calculating the T_{\\mu \\nu} T_{\\mu \\nu} from the evol bin into the MoL_PostStep group. This increases the order of accuracy of the spacetime\u2013matter coupling, but is only possible when thorn MoL is used. The parameter timelevels chooses the number of time levels for T_{\\mu \\nu} T_{\\mu \\nu} . The default is a single time level, which is sufficient for unigrid simulation. Mesh refinement simulation may require several time levels if mesh refinement boundaries require correct values. The parameter prolongation_type defines the prolongation operator for mesh refinement boundaries. Since the values of T_{\\mu \\nu} T_{\\mu \\nu} change at each time step. T_{\\mu \\nu} T_{\\mu \\nu} needs to be recalculated frequently. This happens either in the schedule bin evol or in the schedule group MoL_PostStep.","title":"Description"},{"location":"ET/parameter/#parameter_22","text":"Key Defaults Describe Option stress_energy_storage no Should the stress-energy tensor have storage? stress_energy_at_RHS no Should the stress-energy tensor be calculated for the RHS evaluation? support_old_CalcTmunu_mechanism no Should the old CalcTmunu.inc mechanism be supported? This is deprecated. timelevels 1 Number of time levels 0:3 :: \"\" prolongation_type \"Lagrange\" The kind of boundary prolongation for the stress-energy tensor \" ^Lagrange$ \" :: \"standard prolongation (requires several time levels)\"; \" ^none$ \" :: \"no prolongation (use this if you do not have enough time levels active)\"; \"\" :: \"any other supported prolongation type\"","title":"Parameter"},{"location":"ET/parameter/#hydrobase","text":"The idea behind this thorn is to create a slim, common set of variables, parameters and scheduling groups which can then be used by different hydrodynamics codes. Currently the de\ufb01ned primitive variables are rho: rest mass density \\rho \\rho press: pressure P eps: specific internal energy \\epsilon \\epsilon vel[3]: contravariant fluid three velocity v^{i} v^{i} with respect to the Eulerian observer Y_e: electron fraction Y_{e} Y_{e} temperature: temperature T entropy: specific entropy per particle s Bvec[3]: contravariant magnetic \ufb01eld vector Currently the scheduling blocks are: Initializing the primitive variables Converting primitive variables to conservative variables Calculating the right hand side (RHS) in the method of lines (MoL) Setting and updating an excision mask Applying boundary conditions HydroBase does not require a specific set of units itself. These units are derived from the conventions M_{\\mathrm{sun}}=1 ; c=G=1 M_{\\mathrm{sun}}=1 ; c=G=1 which are commonly used in astrophysics and in relativity. The former sets the mass scale to the solar one and the latter adopts the same units for time, length and mass.","title":"HydroBase"},{"location":"ET/parameter/#parameter_23","text":"Key Defaults Describe Option initial_hydro \"zero\" The hydro initial data \"zero\" :: \"hydro variables are set to vacuum (without atmosphere)\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" evolution_method \"none\" The hydro evolution method \"none\" :: \"hydro variables are not evolved\" timelevels 1 Number of time levels in evolution scheme 1:3 :: \"\" prolongation_type \"ENO\" The prolongation operator used by Carpet for HydroBase variables \"ENO\":: \"Third order ENO operators; only third order is implemented\"; \"WENO\" :: \"Fifth order WENO operators; only fifth order is implemented\"; \".\" :: \"Anything else\" initial_Y_e \"none\" Initial value for Y_e \"none\" :: \"inactive\"; \"one\":: \"initially set to one\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" initial_Abar \"none\" Initial value for Abar \"none\" :: \"inactive\"; \"zero\" :: \"initially set to zero\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" Y_e_evolution_method \"none\" Evolution method for Y_e \"none\" :: \"Evolution for Y_e is disabled\" Abar_evolution_method \"none\" Evolution method for Abar \"none\" :: \"Evolution for Abar is disabled\" temperature_evolution_method \"none\" Evolution method for temperature \"none\" :: \"Evolution for temperature is disabled\" entropy_evolution_method \"none\" Evolution method for entropy \"none\" :: \"Evolution for entropy is disabled\" initial_Bvec \"none\" Initial value for Bvec \"none\" :: \"inactive\"; \"zero\" :: \"initially set to zero\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" initial_Avec \"none\" Initial value for Avec \"none\" :: \"inactive\"; \"zero\" :: \"initially set to zero\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" initial_Aphi \"none\" Initial value for Aphi \"none\" :: \"inactive\"; \"zero\" :: \"initially set to zero\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" Bvec_evolution_method \"none\" Evolution method for Bvec \"none\" :: \"Evolution for Bvec is disabled\" hydro_excision 0 Turn on of off (default) storage for hydro excision 0: :: \"Anything else than 0 turns hydro_excision on, added to by other thorns\" initial_temperature \"none\" Initial value for temperature \"none\":: \"inactive\"; \"zero\":: \"initially set to zero\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\" initial_entropy \"none\" Initial value for entropy \"none\":: \"inactive\"; \"zero\":: \"initially set to zero\"; \"read from file\" :: \"Read the initial data using the IOUtil file reader.Note that this only allows you to read the data from a file, it does not actually do it.You still have to programme the IOUtil file reader accordingly.\"","title":"Parameter"},{"location":"ET/parameter/#grhydro","text":"GRHydro is a fully general-relativistic three-dimensional hydrodynamics code. It evolves the hydrodynamics using High Resolution Shock Capturing methods and can work with realistic equations of state. GRHydro uses the hydro variables de\ufb01ned in HydroBase and provides own \u201cconserved\u201d hydro variables and methods to evolve them. It does not provide any information about initial data or equations of state. For these, other thorns are required. Initial data for shocks can be set using GRHydro_Init_Data and will include the essential thorns GRHydro EOS_Omni ADMBase ADMCoupling MoL. The actual evolution in time is controlled by the Method of Lines thorn MoL. The equations of general relativistic hydrodynamics can be written in the flux conservative form \\partial_{t} q+\\partial_{x^{i}} f^{(i)}(q)=s(q) \\partial_{t} q+\\partial_{x^{i}} f^{(i)}(q)=s(q) where q is a set of conserved variables, f^{(i)}(q) f^{(i)}(q) the fluxes and s(q) s(q) the source terms. The 8 conserved variables are labeled D the generalized particle number density, S_{i} S_{i} the generalized momenta in each direction, \\tau \\tau internal energy term and \\mathscr{B}^{k} \\mathscr{B}^{k} the densitized magnetic field.","title":"GRHydro"},{"location":"ET/parameter/#description_8","text":"recon_method: The type of reconstruction method to use. tvd is the standard. ppm is more accurate but it requires more resources. eno gives in theory arbitrary order of accuracy but it is practically unworthy to go beyond fifth order. tvd_limiter: When using tvd reconstruction the choice of limiter can have a large effect. vanleerffC2 is probably the best to use, but the extremes of minmod and Superbee are also interesting. ppm_detect: When using ppm reconstruction with shocks, the shock detection algorithm can notably sharpen the pro\ufb01le. Riemann solvers: Marquina is the standard solver used. HLLE is significantly faster, but sometimes provides cruder approximation. Equations of state: These are controlled by the GRHydro_eos_type and GRHydro_eos_table parameters. Changing these parameters will depend on which equation of state thorns you have compiled in. Initial data parameters: GRHydro_rho_central is inherited by many initial data thorns to set the central density of compact fluid objects such as single stars.","title":"Description"},{"location":"ET/parameter/#parameter_24","text":"Key Defaults Describe Option initial_shift \"never\" \"Comoving\" :: \"Set the shift so the matter is approximately comoving\"; \"GRHydro\" :: \"Use GRHydro to evolve the hydro variables\"; \"GRHydro_Avec\" :: \"Use GRHydro to evolve the MHD variables, evolving the Vector Potential\"; \"Bvec_from_Avec\" :: \"Calculate B^i for an initially specified A_i\"; \"always\" :: \"use the mask\"; \"auto\" :: \"check if CarpetEvolutionMask is active, then use the mask\"; \"never\":: \"do not use the mask\" GRHydro_enable_internal_excision \"true\" Set this to 'false' to disable the thorn-internal excision. GRHydro_hydro_excision 1 Turns excision automatically on in HydroBase 1:1 :: \"Only '1' allowed\" sources_spatial_order 2 Order of spatial differencing of the source terms 2 :: \"2 nd order finite differencing\"; 4 :: \"4 th order finite differencing\" GRHydro_MaxNumEvolvedVars 5 The maximum number of evolved variables used by GRHydro 0 :: \"when using multirate\"; 5:12 :: \"dens scon[3] tau (B/A)vec[3] psidc ye entropy Aphi\" GRHydro_MaxNumEvolvedVarsSlow 0 The maximum number of evolved variables used by GRHydro 0 :: \"do not use multirate\"; 5:12 :: \"dens scon[3] tau (B/A)vec[3] psidc ye entropy Aphi\" GRHydro_MaxNumConstrainedVars 37 The maximum number of constrained variables used by GRHydro 7:48 :: \"A small range, depending on testing or not\" GRHydro_MaxNumSandRVars 16 The maximum number of save and restore variables used by GRHydro 0:16 :: \"A small range, depending on testing or not\" recon_method \"tvd\" Which reconstruction method to use \"tvd\" :: \"Slope limited TVD\"; \"ppm\":: \"PPM reconstruction\"; \"eno\":: \"ENO reconstruction\"; \"weno\" :: \"WENO reconstruction\"; \"weno-z\" :: \"WENO-Z reconstruction\"; \"mp5\":: \"MP5 reconstruction\" method_type \"RSA Which type of method to use \"RSA FV\":: \"Reconstruct-Solve-Average finite volume method\"; \"Flux Split FD\" :: \"Finite difference using Lax-Friedrichs flux splitting\" check_for_trivial_rp \"yes\" Do check for trivial Riemann Problem recon_vars \"primitive\" Which type of variables to reconstruct \"primitive\" :: \"Reconstruct the primitive variables\"; \"conservative\" :: \"Reconstruct the conserved variables\" tvd_limiter \"minmod\" Which slope limiter to use \"minmod\" :: \"Minmod\"; \"vanleerMC2\" :: \"Van Leer MC - Luca\"; \"Superbee\" :: \"Superbee\" myfloor 1.e-10 A minimum number for the TVD reconstruction routine 0.0: :: \"Must be positive\" use_optimized_ppm \"no\" use C++ templated version of PPM. Experimental ppm_detect \"no\" Should the PPM solver use shock detection? ppm_flatten \"stencil_3\" Which flattening procedure should the PPM solver use? \"stencil_3\" :: \"our flattening procedure, which requires only stencil 3 and which may work\"; \"stencil_4\" :: \"original C&W flattening procedure, which requires stencil 4\" ppm_epsilon 0.33 Epsilon for PPM zone flattening 0.0: :: \"Must be positive. Default is from Colella & Woodward\" ppm_omega1 0.75 Omega1 for PPM zone flattening : :: \"Anything goes. Default is from Colella & Woodward\" ppm_omega2 10.0 Omega2 for PPM zone flattening : :: \"Anything goes. Default is from Colella & Woodward\" ppm_omega_tracer 0.50 Omega for tracer PPM zone flattening : :: \"Anything goes. Default is from Plewa & Mueller\" ppm_epsilon_shock 0.01 Epsilon for PPM shock detection : :: \"Anything goes. Default is from Colella & Woodward\" ppm_eta1 20.0 Eta1 for PPM shock detection : :: \"Anything goes. Default is from Colella & Woodward\" ppm_eta2 0.05 Eta2 for PPM shock detection : :: \"Anything goes. Default is from Colella & Woodward\" ppm_k0 0.2 K0 for PPM shock detection : :: \"Anything goes. Default suggested by Colella & Woodward is: (polytropic constant)/10.0\" ppm_small 1.e-7 A floor used by PPM shock detection 0.0:1.0 :: \"In [0,1]\" ppm_mppm 0 Use modified (enhanced) ppm scheme 0:1 :: \"0 (off, default) or 1 (on)\" ppm_mppm_debug_eigenvalues 0 write eigenvalues into debug grid variables 0:1 :: \"0 (off, default) or 1 (on)\" mp5_alpha 4.0 alpha parameter for MP5 reconstruction 0: :: \"positive\" mp5_eps 0.0 epsilon parameter for MP5 reconstruction 0: :: \"0.0 or very small and positive. 1e-10 is suggested by Suresh&Huynh. TOV star requires 0.0\" mp5_adaptive_eps no Same as WENO adaptive epsilon: adaptively reduce mp5_eps according to norm of stencil. Original algorithm does not use this. use_enhanced_ppm no Use the enhanced ppm reconstruction method proposed by Colella & Sekora 2008 and McCorquodale & Colella 2011 GRHydro_oppm_reflevel -1 Ref level where oPPM is used instead of ePPM (used with use_enhaced_ppm=yes). -1:10 :: \"0-10 (the reflevel number) or -1 (off)\" enhanced_ppm_C2 1.25 Parameter for enhancecd ppm limiter. Default from McCorquodale & Colella 2011 : :: \"must be greater than 1. According to Colella&Sekora 2008, enhanced ppm is insensitive to C in [1.25,5]\" enhanced_ppm_C3 0.1 Parameter for enhancecd ppm limiter. Default from McCorquodale & Colella 2011 0: :: \"must be greater than 0.\" reconstruct_Wv no Reconstruct the primitive velocity W_Lorentz*vel, rather than just vel. eno_order 2 The order of accuracy of the ENO reconstruction 1: :: \"Anything above 1, but above 5 is pointless\" WENO_order 5 The order of accuracy of the WENO reconstruction 5:: \"Fifth-order\" weno_eps 1e-26 WENO epsilon parameter. For WENO-z, 1e-40 is recommended 0::: \"small and positive\" weno_adaptive_epsilon yes use modified smoothness indicators that take into account scale of solution (adaptive epsilon) riemann_solver \"HLLE\" Which Riemann solver to use \"Roe\" :: \"Standard Roe solver\"; \"Marquina\" :: \"Marquina flux\"; \"HLLE\" :: \"HLLE\"; \"HLLC\" :: \"HLLC\"; \"LLF\" :: \"Local Lax-Friedrichs (MHD only at the moment)\" HLLE_type \"Standard\" Which HLLE type to use \"Standard\" :: \"Standard HLLE solver\"; \"Tadmor\" :: \"Tadmor's simplification of HLLE\" left_eigenvectors \"analytical\" How to compute the left eigenvectors \"analytical\" :: \"Analytical left eigenvectors\"; \"numerical\" :: \"Numerical left eigenvectors\" numerical_viscosity \"fast\" How to compute the numerical viscosity \"fast\" :: \"Fast numerical viscosity\"; \"normal\" :: \"Normal numerical viscosity\" apply_H_viscosity no H viscosity is useful to fix the carbuncle instability seen at strong shocks bound \"none\" Which boundary condition to use - FIXME \"flat\" :: \"Zero order extrapolation\"; \"none\" :: \"None\"; \"static\" :: \"Static, no longer supported\"; \"scalar\" :: \"Constant\" GRHydro_stencil 2 Width of the stencil 0: :: \"Must be positive\" GRHydro_eos_type \"General\" Type of Equation of State \"Polytype\" :: \"P = P(rho) or P = P(eps)\"; \"General\" :: \"P = P(rho, eps)\" GRHydro_eos_table \"Ideal_Fluid\" Name for the Equation of State . :: \"Can be anything\" GRHydro_eos_rf_prec 1.0e-8 Precision to which root finding should be carried out (0.0: :: \"anything larger than 0 goes\" GRHydro_eos_hot_eps_fix \"no\" Activate quasi-failsafe mode for hot EOSs GRHydro_eos_hot_prim2con_warn \"yes\" Warn about temperature workaround in prim2con GRHydro_c2p_reset_eps_tau_hot_eos \"no\" As a last resort, reset tau reconstruct_temper \"no\" if set to true, temperature will be reconstructed GRHydro_hot_atmo_temp 0.1e0 Temperature of the hot atmosphere in MeV (0.0: :: \"Larger than 0 MeV\" GRHydro_max_temp 90.0e0 maximum temperature we allow (0.0: :: \"Larger than 0 MeV\" GRHydro_hot_atmo_Y_e 0.5e0 Y_e of the hot atmosphere 0.0: :: \"Larger than 0\" GRHydro_Y_e_min 0.0 minimum allowed Y_e 0.0: :: \"Larger than or equal to zero\" GRHydro_Y_e_max 1.0 maximum allowed Y_e 0.0: :: \"Larger than or equal to zero; 1 is default\" GRHydro_c2p_warnlevel 0 Warnlevel for Con2Prim warnings 0:1 :: \"Either 0 or 1\" GRHydro_c2p_failed_action \"abort\" what to do when we detect a c2p failure \"abort\" :: \"abort with error\"; \"terminate\" :: \"request termination\" sqrtdet_thr -1.0 Threshold to apply cons rescalings deep inside the horizon 1.0::: \"Larger values guarantees this sort of rescaling only deep inside the horizon\"; -1.0:: \"Do not apply limit\" max_magnetic_to_gas_pressure_ratio -1.0 consider pressure to be magnetically dominated if magnetic pressure to gas pressure ratio is higher than this (0::: \"any positive value, eg. 100.\"; -1.0:: \"disable\" c2p_reset_pressure \"no\" If the pressure guess is unphysical should we recompute it? c2p_reset_pressure_to_value 1.e-20 The value to which the pressure is reset to when a failure occurrs in C2P 0: :: \"greater than zero\" c2p_resort_to_bisection no If the pressure guess is unphysical, should we try with bisection (slower, but more robust) GRHydro_eps_min 1.e-10 Minimum value of specific internal energy - this is now only used in GRHydro_InitData's GRHydro_Only_Atmo routine 0: :: \"Positive\" GRHydro_perc_ptol 1.e-8 Tolerance for primitive variable solve (percent) 0: :: \"Do we really want both tolerances?\" GRHydro_del_ptol 1.e-18 Tolerance for primitive variable solve (absolute) 0: :: \"Do we really want both tolerances?\" GRHydro_countmax 100 Maximum number of iterations for Con2Prim solve 1: :: \"Must be positive\" GRHydro_countmin 1 Minimum number of iterations for Con2Prim solve 0: :: \"Must be non negative\" GRHydro_polish 0 Number of extra iterations after root found 0: :: \"Must be non negative\" GRHydro_rho_central 1.e-5 Central Density for Star : :: \"\" tau_rel_min 1.e-10 A minimum relative tau (taumin = maxtau(t=0) * tau_rel_min) below which tau is reschaled 0: :: \"\" rho_abs_min -1.0 A minimum rho below which evolution is turned off (atmosphere). If negative, the relative minimum will be used instead. -1.0: :: \"\" rho_rel_min 1.e-9 A minimum relative rho (rhomin = centden * rho_rel_min) below which evolution is turned off (atmosphere). Only used if rho_abs_min < 0.0 0: :: \"\" initial_rho_abs_min -1.0 An absolute value for rho in the atmosphere. To be used by initial data routines only. Unused if negative. -1.0: :: \"\" initial_rho_rel_min -1.0 A relative (to the central density) value for rho in the atmosphere. To be used by initial data routines only. Unused if negative. -1.0: :: \"\" initial_atmosphere_factor -1.0 A relative (to the initial atmosphere) value for rho in the atmosphere. This is used at initial time only. Unused if negative. -1.0: :: \"\" rho_abs_min_after_recovery -1.0 A new absolute value for rho in the atmosphere. To be used after recovering. Unused if negative. -1.0: :: \"\" GRHydro_atmo_tolerance A point is set to atmosphere in the Con2Prim's if its rho < GRHydro_rho_min *(1+GRHydro_atmo_tolerance) . This avoids occasional spurious oscillations in carpet buffer zones lying in the atmosphere (because prolongation happens on conserved variables) 0.0: :: \"Zero or larger. A useful value could be 0.0001\" atmo_falloff_radius 50.0 The radius for which the atmosphere starts to falloff as (atmo_falloff_radius/r)**atmo_falloff_power 0: :: \"Anything positive\" atmo_falloff_power 0.0 The power at which the atmosphere level falls off as (atmo_falloof_radius/r)**atmo_falloff_power 0: :: \"Anything positive\" atmo_tolerance_radius 50.0 The radius for which the atmosphere tolerance starts to increase as (r/atmo_tolerance_radius)**atmo_tolerance_power 0: :: \"Anything positive\" atmo_tolerance_power 0.0 The power at which the atmosphere tolerance increases as (r/atmo_tolerance_radius)**atmo_tolerance_power 0: :: \"Anything positive\" wk_atmosphere \"no\" Use some of Wolfgang Kastauns atmosphere tricks Check_Rho_Minimum \"no\" Should a check on rho < GRHydro_rho_min be performed and written as WARNING level 2? EoS_Change \"no\" Recalculate fluid quantities if changing the EoS EoS_Change_type \"Gamma\" Change polytropic K or Gamma? \"K\" :: \"Change the K\"; \"Gamma\" :: \"Change the Gamma\"; \"GammaKS\":: \"Change K and Gamma, Shibata et al. 2004 3-D GR Core Collapse style\" initial_Gamma 1.3333 If changing Gamma, what was the value used in the initial data routine? (0.0: :: \"Positive\" initial_k 100.0 If changing K, what was the value used in the initial data routine? (0.0: :: \"Positive\" use_weighted_fluxes \"no\" Weight the flux terms by the cell surface areas comoving_factor 0.0 Factor multiplying the velocity for the comoving shift 0.0:2.0 :: \"[0,2] is allowed, but [0,1] is probably reasonable\" comoving_attenuate \"tanh\" Which attenuation method for the comoving shift \"sqrt\" :: \"Multiply by sqrt(rho/rho_max)\"; \"tanh\" :: \"Multiply by \u00bd(1+tanh(factor(rho/rho_max - offset)))\" comoving_v_method \"projected\" Which method for getting the radial velocity \"projected\" :: \"vr = x_i . v^i / r\"; \"components\" :: \"vr = sqrt(v_i v^i)\" comoving_tanh_factor 10.0 The factor in the above tanh attenuation (0.0: :: \"Any positive number\" comoving_tanh_offset 0.05 The offset in the above tanh attenuation 0.0:1.0 :: \"Only makes sense in [0,1]\" set_trivial_rp_grid_function 0 set gf for triv. rp (only for debugging) 0:1 :: \"0 for no (default), 1 for yes\" evolve_tracer \"no\" Should we advect tracers? number_of_tracers 0 Number of tracer variables to be advected 0: :: \"positive or zero\" use_min_tracer \"no\" Should there be a floor on the tracer? min_tracer 0.0 The floor placed on the tracer : :: \"Anything\" number_of_particles 0 Number of particles to track 0: :: \"0 switches off particle tracking\" number_of_arrays 0 Number of arrays to evolve 0:3 :: \"Either zero or three, depending on the particles\" particle_interpolator \"Lagrange What interpolator should be used for the particles \".+\":: \"A valid interpolator name\" particle_interpolation_order 2 What order should be used for the particle interpolation 1: :: \"A valid positive interpolation order\" gradient_method \"First Which method is used to set GRHydro::DiffRho? \"First diff\":: \"Standard first differences\"; \"Curvature\" :: \"Curvature based method of Paramesh / FLASH\"; \"Rho weighted\":: \"Based on the size of rho\" GRHydro_NaN_verbose 2 The warning level for NaNs occuring within GRHydro 0: :: \"The warning level\" GRHydro_lorentz_overshoot_cutoff 1.e100 Set the Lorentz factor to this value in case it overshoots (1/0) 0: :: \"Some big value\" clean_divergence \"no\" Use hyperbolic divergence cleaning kap_dc 10.0 The kap parameter for divergence cleaning 0: :: \"Any non-negative value, but 1.0 to 10.0 seems preferred\" psidcspeed \"light Which speed to set for psidc \"char speed\":: \"Based on the characteristic speeds\"; \"light speed\" :: \"Set the characteristic speeds to speed of light\"; \"set speed\" :: \"Manually set the characteristic speeds: [setcharmin,setcharmax]\" setcharmax 1.0 Maximum characteristic speed for psidc if psidcspeed is set 0:1 :: \"Any value smaller than speed of light\" setcharmin -1.0 Minimum characteristic speed for psidc if psidcspeed is set -1:0 :: \"Any value smaller than speed of light - sign should be negative\" decouple_normal_Bfield yes when using divergence cleaning properly decouple Bx,psidc subsystem track_divB \"no\" Track the magnetic field constraint violations transport_constraints \"no\" Use constraint transport for magnetic field Avec_gauge \"lorenz\" Which gauge condition to use when evolving the vector potential \"algebraic\":: \"Algebraic gauge\"; \"lorenz\" :: \"Lorenz gauge\" Tmunu_damping_radius_min -1 damping radius at which we start to damp with a tanh function -1:: \"damping switched off\"; 0: :: \"damping radius at which we start to damp\" Tmunu_damping_radius_max -1 damping radius at which Tmunu becomes 0 -1:: \"damping switched off\"; 0: :: \"greater than minimum radius above\" con2prim_oct_hack \"no\" Disregard c2p failures in oct/rotsym90 boundary cells with xyz < 0 GRHydro_c2p_warn_from_reflevel 0 Start warning on given refinement level and on higher levels 0: :: \"Greater or equal to 0\" sync_conserved_only no Only sync evolved conserved quantities during evolution. use_MoL_slow_multirate_sector no Whether to make use of MoL's slow multirate sector verbose no Some debug output constrain_to_1D no Set fluid velocities to zero for non-radial motion use_cxx_code yes Use experimental C++ code?","title":"Parameter"},{"location":"ET/parameter/#grhydro_initdata","text":"This thorn generates some initial data for the GRHydro code.","title":"GRHydro_InitData"},{"location":"ET/parameter/#parameter_25","text":"Key Defaults Describe Option initial_hydro \"xshock\" \"shocktube\" :: \"Shocktube type\"; \"shocktube_hot\" :: \"Shocktube with hot nuclear EOS\"; \"only_atmo\":: \"Set only a low atmosphere\"; \"read_conformal\":: \"After reading in initial alp, rho and gxx from h5 files, sets the other quantities\"; \"simple_wave\" :: \"Set initial data from Anile Miller Motta, Phys.Fluids. 26, 1450 (1983)\"; \"monopole\":: \"Monopole at the center\"; \"cylexp\":: \"Cylindrical Explosion\"; \"rotor\" :: \"Magnetic Rotor test from DelZanna,Bucciantini, and Londrillo A&A 400, 397-413 (2003)\"; \"advectedloop\":: \"Magnetic advected loop test\"; \"alfvenwave\":: \"Circularly polarized Alfven wave\"; \"hydro_bondi_solution\" :: \"Spherical single black hole Bondi solution\"; \"hydro_bondi_solution_iso\" :: \"Spherical single black hole Bondi solution - TEST ISO CASE!!!!!!\"; \"magnetized_bondi_solution\" :: \"Magnetized Spherical single black hole Bondi solution\"; \"magnetized_bondi_solution_iso\" :: \"Magnetized Spherical single black hole Bondi solution - TEST ISO CASE!!!!!!\"; }; ; EXTENDS KEYWORD initial_Bvec; {; \"shocktube\":: \"Shocktube type\"; \"cylexp\" :: \"Poloidal Magnetic Field\"; \"poloidalmagfield\" :: \"Poloidal Magnetic Field\"; \"magnetized Bondi\" :: \"radial magnetic field appropriate for Bondi test\"; }; ; EXTENDS KEYWORD initial_Avec; {; \"poloidalmagfield\" :: \"Poloidal Magnetic Field\"; }; ; EXTENDS KEYWORD initial_entropy; {; \"magnetized Bondi\" :: \"Initial entropy for a radial magnetic field appropriate for Bondi test\"; }; ; ; shares:ADMBase; ; EXTENDS KEYWORD initial_data \"\"; {; #\"shocktube\":: \"Shock tube initial data for GRHydro\"; \"con2primtest\":: \"Testing the con -> prim conversion\"; \"con2prim2con_test\" :: \"Testing the con -> prim -> con conversion\"; \"prim2con2prim_test\":: \"Testing the prim -> con -> prim conversion\"; \"prim2con2prim_polytype_test\":: \"Testing the prim -> con -> prim conversion - polytype version\"; \"reconstruction_test\" :: \"Testing reconstruction\"; }; ; private:; ; KEYWORD shocktube_type \"Diagonal or parallel shock?\"; {; \"diagshock\":: \"Diagonal across all axes\"; \"diagshock2d\" :: \"Diagonal across x-y axes\"; \"xshock\":: \"Parallel to x axis\"; \"yshock\":: \"Parallel to y axis\"; \"zshock\":: \"Parallel to z axis\"; \"sphere\":: \"spherically symmetric shock\" shock_case \"Sod\" Simple, Sod's problem or other? \"Simple\":: \"GRAstro_Hydro test case\"; \"Sod\" :: \"Sod's problem\"; \"Blast\" :: \"Strong blast wave\"; \"Balsaralike1\" :: \"Hydro version of Balsara Test #1\"; \"Balsara0\":: \"Balsara Test #1, but unmagnetized\"; \"Balsara1\":: \"Balsara Test #1\"; \"Balsara2\":: \"Balsara Test #2\"; \"Balsara3\":: \"Balsara Test #3\"; \"Balsara4\":: \"Balsara Test #4\"; \"Balsara5\":: \"Balsara Test #5\"; \"Alfven\":: \"Generical Alfven Test\"; \"Komissarov1\" :: \"Komissarov Test #1\"; \"Komissarov2\" :: \"Komissarov Test #2\"; \"Komissarov3\" :: \"Komissarov Test #3\"; \"Komissarov4\" :: \"Komissarov Test #4\"; \"Komissarov5\" :: \"Komissarov Test #5\"; \"Komissarov6\" :: \"Komissarov Test #6\"; \"Komissarov7\" :: \"Komissarov Test #7\"; \"Komissarov8\" :: \"Komissarov Test #8\"; \"Komissarov9\" :: \"Komissarov Test #9\" shock_xpos 0.0 Position of shock plane: x ::: \"Anything\" shock_ypos 0.0 Position of shock plane: y ::: \"Anything\" shock_zpos 0.0 Position of shock plane: z ::: \"Anything\" shock_radius 1.0 Radius of sperical shock 0.0: :: \"Anything positive\" change_shock_direction 0.3 Change the shock direction 0:1 :: \"It is the sound speed where the fluid velocity is zero\" simple_wave_v_max 0.7 The v_max constant in Anile Miller Motta, Phys.Fluids. 26, 1450 (1983) 0:1 :: \"It is the maximum velocity in the initial configuration (see p. 1457, bottom of first column)\" the 0.0 atmosphere : :: \"Anything\" attenuate_atmosphere \"no\" Attenuate the velocity in the atmosphere Bx_init 0.0 Initial B-field in the x-dir : :: \"Anything\" By_init 0.0 Initial B-field in the y-dir : :: \"Anything\" Bz_init 0.0 Initial B-field in the z-dir : :: \"Anything\" rho_init 1.0d-6 Initial rest mass density (0::: \"Anything positive.\" velx_init 1.0d-1 Initial x velocity ::: \"Anything.\" vely_init 1.0d-1 Initial y velocity ::: \"Anything.\" velz_init 1.0d-1 Initial z velocity ::: \"Anything.\" eps_init 1.0d-6 Initial specific internal energy (0::: \"Anything positive.\" press_init 6.666666666666667d-7 Initial pressure (0::: \"Anything positive.\" use_c2p_with_entropy_eqn no Use the con2prim routine that uses the entropy equation instead of the energy equation dens_init 1.29047362 Initial conserved mass density (0::: \"Anything positive.\" sx_init 0.166666658 Initial x component of conserved momentum density ::: \"Anything.\" sy_init 0.166666658 Initial y component of conserved momentum density ::: \"Anything.\" sz_init 0.166666658 Initial z component of conserved momentum density ::: \"Anything.\" tau_init 0.484123939 Initial conserved total energy density (0::: \"Anything positive.\" gxx_init 1.0 Initial xx metric componenent ::: \"Anything, but be carefull to set a positive definite 3-metric!\" gxy_init 0.0 Initial xy metric componenent ::: \"Anything, but be carefull to set a positive definite 3-metric!\" gxz_init 0.0 Initial xz metric componenent ::: \"Anything, but be carefull to set a positive definite 3-metric!\" gyy_init 1.0 Initial yy metric componenent ::: \"Anything, but be carefull to set a positive definite 3-metric!\" gyz_init 0.0 Initial yz metric componenent ::: \"Anything, but be carefull to set a positive definite 3-metric!\" gzz_init 1.0 Initial zz metric componenent ::: \"Anything, but be carefull to set a positive definite 3-metric!\" monopole_type \"Point\" Which kind of monopole? \"Point\" :: \"Single point with Bx /= 0\"; \"Gauss\" :: \"Gaussian w/radius R_Gauss\"; \"1dalt\" :: \"1-d alternating\"; \"2dalt\" :: \"2-d alternating\"; \"3dalt\" :: \"3-d alternating\" R_Gauss 1.0 Radius for a Gaussian monopole 0: :: \"Any positive number\" Monopole_point_Bx 1.0 Pointlike Monopole Bx value : :: \"Any number\" cyl_r_inner 0.8 Inner Radius (0: :: \"Any positive number\" cyl_r_outer 1.0 Outer Radius (0: :: \"Any positive number\" cyl_rho_inner 1.d-2 density in inner core (0: :: \"any positive number\" cyl_press_inner 1.d0 pressure in inner core (0: :: \"any positive number\" cyl_rho_outer 1.d-4 density in outer region (0: :: \"any positive number\" cyl_press_outer 3.d-5 pressure in outer region (0: :: \"any positive number\" advectedloop_type \"2D\" 2-dimensional or 3-dimensional? \"2D\":: \"2-dimensional (B^z=0)\"; \"3D\":: \"3-dimensional (B^3=0, where B^3 advectedloop_case \"V^z=0\" V^z=0 or not? \"V^z=0\":: \"Useful to evaluate divB deviations\"; \"V^z/=0\" :: \"Useful to evaluate con2prim robustness in keeping V^z const.\" advectedloop_delA \"Exact\" How to calculate B^i field from the potential A^b \"Exact\" :: \"Analytic, exact closed formula applied\"; \"Numeric\" :: \"Finite difference approximation of the derivatives applied\" alfvenwave_type \"1D\" 1-dimensional or 2-dimensional? \"1D\":: \"1-dimensional\"; \"2D\":: \"2-dimensional (in x-y plane)\" alfvenwave_pressure 1.0 P_gas for the Alfven wave (0: :: \"positive\" mdot_sonicpt_bondi 12.566370614359172954 Accretion rate at sonic point in hydro units (0: :: \"positive\" solution 1.e-15 { (-1.:1.) :: (0::: \"dimensionless inner radius for Bondi solution\" bondi_bmag 0.01 B_0 parameter for magnetized Bondi 0: :: \"Anything positive\" bondi_radial_offset 0.0 redefine r_grid=r_KS-r0 to avoid singularity on grid 0: :: \"Any positive number\" set_bondi_beta_sonicpt no Set plasma beta parameter instead of bondi_bmag bondi_Bvec_method \"direct\" how to compute the magnetic field vector \"direct\":: \"directly from Cartesian metric\"; \"transform\" :: \"transform Schwarzschild solution to Kerr Schild\" bondi_evolve_only_annulus \"no\" reset to initial data outside of bondi_freeze_inner_radius and bondi_freeze_outer_radius bondi_freeze_inner_radius -1. reset to initial at radii below this : :: \"any value\" bondi_freeze_outer_radius 1e300 reset to initial at radii above this : :: \"any value\" bondi_overwrite_boundary \"no\" reset data to initial data in outer boundary in boundary condition poloidal_P_p 1 Index of pressure factor (0: :: \"Any non-negative integer\" rotor_xc 0.5 center of rotation : :: \"Any location\" rotor_yc 0.5 center of rotation : :: \"Any location\" rotor_bvcxl 1.0 intial component of Bvec[0] : :: \"any real number\" rotor_bvcyl 0.0 intial component of Bvec[1] : :: \"any real number\" rotor_bvczl 0.0 intial component of Bvec[2] : :: \"any real number\" rotor_r_rot 0.1 radius of rotor (0: :: \"any positive number\" rotor_v_max 0.995 Maximum velocity (-1:1) :: \"any subluminal speed (negative is clockwise)\" rotor_rhoin 10.d0 initial density inside rotor (0: :: \"any positive number\" rotor_pressin 1.d0 initial pressure inside rotor (0: :: \"any positive number\" rotor_rhoout 1.d0 initial density outside rotor (0: :: \"any positive number\" rotor_pressout 1.d0 initial pressure outside rotor (0: :: \"any positive number\" rotor_use_smoothing yes Smooth the edge? rotor_rsmooth_rel 0.05 Define the radius in relative terms if so (0: :: \"any positive number\"","title":"Parameter"},{"location":"ET/parameter/#black-hole","text":"","title":"Black Hole"},{"location":"ET/parameter/#ahfinder","text":"This thorn looks for apparent horizons (AH) in 3D. An AH is defined as a surface where the expansion of outgoing null geodesics is zero. It calulates various quantities like horizon area and its corresponding mass.","title":"AHFinder"},{"location":"ET/parameter/#description_9","text":"ahfinder::ahf_active To activate the thorn set ahf_active = \u201dyes\u201d . This parameter is set by default to \u201dno\u201d. ahfinder::ahf_flow By default the minimization algorithm is used. To switch to the flow algorithm one has to set ahf_flow = \u201dyes\u201d . ahfinder::ahf_findevery Specifies how often the finder is called. The default is to find horizons at every iteration. ahfinder::ahf_findafter The number of iterations after which the thorn is called the first time can be specified by this parameter. ahfinder::ahf_findaftertime Instead of specifying the number of iterations, one can specify after how much coordinate time the thorn is called the first time. ahfinder::ahf_lmax The maximal number of terms in the expansion in \u03b8. The default value is 8. The maximal value is 19. ahfinder::ahf_phi If axisymmetry is expected the surface does not need to be expanded in phi. This is the default. To look for non-axisymmetric surface use ahf_phi = \u201dyes\u201d . ahfinder::ahf_[xyz]c Sets the x-, y-, and z-coordinates of the center of the expansion. The default is the origin (ahf_xc = 0, ahf_yc = 0, ahf_zc = 0). The center of the expansion should be set inside the expected apparent horizon, otherwise the algorithm will fail. ahfinder::ahf_wander The center of the expansion can also be allowed to move. To do this use ahf_wander = \u201dyes\u201d . However, this only works with the minimization algorithm. ahfinder::ahf_r0 Sets the radius of the initial sphere. The default is 0.0, forcing the largest sphere possible in the grid. ahfinder::ahf_find3 Set ahf_find3 = \u201dyes\u201d to search for three horizons. The default is to look for only one horizon. ahfinder::ahf_[xyz]_[012] Sets the x-, y-, and z-coordinates of the center of the expansion for horizon 0, 1 and 2. The default in each case is the origin. ahfinder::ahf_r0_[0-2] Sets the radius of the initial spheres for horizon 0, 1 and 2. The default in all cases is 0.0, forcing the largest sphere possible in the grid. ahfinder::ahf_guessold To use on old horizon as initial guess set ahf_guessold = \u201dyes\u201d . However, if during the evolution the apparent horizon jumps discontinuously it might be lost by using this option. ahfinder::ahf_nn0, ahfinder::ahf_nn2 If no old horizon is used the inital guess can be specified further for the minimization algorithm. This algorithm is sensitive to the initial guess, so this is important. ahfinder::ahf_sloppyguess It is also possible to use only a sphere as initial guess. This is much faster and is done by using ahf_sloppyguess = \u201dyes\u201d . ahfinder::ahf_inner If one wants to look for an inner horizon instead of an outer one, use ahfinder::ahf_inner = \u201dyes\u201d . This only works with the minimization algorithm. ahfinder::ahf_ntheta The number of subdivisions in \u03b8. ahfinder::ahf_nphi The number of subdivisions in \\phi \\phi .","title":"Description"},{"location":"ET/parameter/#parameter_26","text":"Key Defaults Describe Option ahf_active \"no\" Activate AHFinder? ahf_persists \"no\" Do the finder grid functions stay around? ahf_ReportAlways \"no\" Report for all surfaces found (yes) or just for apparent horizons (no) ahf_find3 \"no\" Searching for 3 surfaces? ahf_trapped_surface \"no\" Minimize (expansion + delta) to find trapped surface? ahf_findevery 1 How often to look for horizons 1: :: \"Set to 1 for searching each iteration\" ahf_findafter 0 After how many iterations look for horizons 0: :: \"Any positive integer\" ahf_findaftertime 0.0 After how much time look for horizons 0.0: :: \"Any positive real number. If non-zero overides ahf_findafter\" trapped_surface_delta 0.0 find (expansion = delta) surface : :: \"Just a real number\" ahf_phi \"no\" Expand also in phi? (seach for non-axisymmetric surface) ahf_offset \"no\" Center offset from origin? ahf_wander \"no\" Allow the center to wander? ahf_lmax 8 Maximum number of terms in theta expansion 0:19 :: \"Range from 0 to 19\" ahf_xc 0.0 x-coordinate of center of expansion : :: \"Anything\" ahf_yc 0.0 y-coordinate of center of expansion : :: \"Anything\" ahf_zc 0.0 z-coordinate of center of expansion : :: \"Anything\" ahf_xc_0 0.0 x-coordinate of center of expansion for first surface with find3 : :: \"Anything\" ahf_yc_0 0.0 y-coordinate of center of expansion for first surface with find3 : :: \"Anything\" ahf_zc_0 0.0 z-coordinate of center of expansion for first surface with find3 : :: \"Anything\" ahf_xc_1 0.0 x-coordinate of center of expansion for second surface with find3 : :: \"Anything\" ahf_yc_1 0.0 y-coordinate of center of expansion for second surface with find3 : :: \"Anything\" ahf_zc_1 0.0 z-coordinate of center of expansion for second surface with find3 : :: \"Anything\" ahf_xc_2 0.0 x-coordinate of center of expansion for third surface with find3 : :: \"Anything\" ahf_yc_2 0.0 y-coordinate of center of expansion for third surface with find3 : :: \"Anything\" ahf_zc_2 0.0 z-coordinate of center of expansion for third surface with find3 : :: \"Anything\" ahf_ntheta 100 Number of subdivisions in theta 1: :: \"Any sensible integer\" ahf_nphi 100 Number of subdivisions in phi 1: :: \"Any sensible integer\" ahf_refx \"no\" Reflection symmetry x->-x? ahf_refy \"no\" Reflection symmetry y->-y? ahf_refz \"no\" Reflection symmetry z->-z? ahf_cartoon \"no\" Cartoon mode? ahf_octant \"no\" Octant symmetry? \"no\" :: \"No octant symmetry\"; \"yes\":: \"Octant symmetry: reflection symmetry on all three coordinate planes\"; \"high\" :: \"Octant symmetry + symmetry of rotation of pi/2 around z axis\" ahf_minarea \"no\" Minimize area instead of expansion? ahf_maxiter 10 Maximum number of iterations of POWELL : :: \"Any sensible integer value\" ahf_tol 0.1 Tolerance for minimization routines 0: :: \"A sensible positive number\" ahf_sloppyguess \"no\" Use sphere as initial guess? ahf_guess_absmin \"no\" Use absolute min to start minimization? ahf_guessold \"no\" Use old horizon as initial guess? ahf_inner \"no\" Look for inner horizon? ahf_manual_guess \"no\" Use specified coefficients for guess? ahf_nn0 10 Number of subdivisions of c0(0) for initial guess : :: \"Some positive integer\" ahf_nn2 10 Number of subdivisions of c0(2) for initial guess : :: \"Some positive integer\" ahf_r0 0.0 Radius of initial sphere (0 forces largest sphere) : :: \"Anything\" ahf_r0_0 0.0 Radius of first initial sphere for find3 (0 forces largest sphere) : :: \"Anything\" ahf_r0_1 0.0 Radius of second initial sphere for find3 (0 forces largest sphere) : :: \"Anything\" ahf_r0_2 0.0 Radius of third initial sphere for find3 (0 forces largest sphere) : :: \"Anything\" ahf_flow \"no\" Use flow instead of minimization? ahf_flowiter 200 Maximum number of iterations for flow 0: :: \"Anything\" ahf_flowa 0.01 alpha parameter for flow : ::\"Anything\" ahf_flowb 0.5 beta parameter for flow : :: \"Anything\" ahf_flowh 0.0 Weight of H flow : :: \"Anything\" ahf_flowc 1.0 Weight of C flow : :: \"Anything\" ahf_flown 0.0 Weight of N flow : :: \"Anything\" ahf_flowtol 0.0001 Tolerance for flow : :: \"Anything\" ahf_maxchange 0.1 Maximum relative difference between 1 big and 2 small steps : :: \"Anything\" ahf_minchange 0.01 Minimum relative difference between 1 big and 2 small steps : :: \"Anything\" ahf_logfile \"no\" Write log file? ahf_verbose \"yes\" Print messages to screen? ahf_veryverbose \"no\" Print messages at each iteration step to screen? ahf_guessverbose \"no\" Print info on initial guess? ahf_1Doutput \"no\" 1D output of grid functions? ahf_2Doutput \"no\" 2D output of grid functions? ahf_3Doutput \"no\" 3D output of grid functions? ahf_HDF5output \"no\" HDF5 output of AHFinder data? ahf_areamap \"no\" Find area map? ahf_gaussout \"yes\" Output gaussian curvature of horizon? ahf_mask \"off\" Use mask? \"off\":: \"Mask is off\"; \"strong\" :: \"Mask set only for definite horizons\"; \"weak\" :: \"Mask set for both definite and probable horizons\" ahf_masktype \"cube\" Type of mask \"lego\" :: \"Mask is a lego sphere\"; \"cube\" :: \"Mask is a cube\"; \"poly\" :: \"Mask is a polyhedra\" ahf_mask_time -1.0 Time after which to start setting the mask : :: \"Anything goes. Negative number means setting the mask as soon as possible\" ahf_mask_0 \"yes\" Mask for first horizon with find3? ahf_mask_1 \"yes\" Mask for second horizon with find3? ahf_mask_2 \"yes\" Mask for third horizon with find3? ahf_maskbuffer 5 Number of grid points in mask buffer zone 0 :: \"Positive please\" ahf_maskshrink 0.8 Shrink factor for mask 0.0:1.0 :: \"Must be positive and not larger than 1\" ahf_shiftcoeff 0.0 Coefficient for shift : :: \"Anything goes\" interpolation_order 2 Order for interpolation 1:4 :: \"Choose between first and fourth order interpolation\" interpolation_operator \"uniform Name of interpolation operator to use \".+\" :: \"A valid name for a registered interpolation operator\"","title":"Parameter"},{"location":"ET/parameter/#example","text":"Minimal parameter settings 1 2 3 4 5 # The simplest parameter settings for using the flow algorithm for a full 3D horizon with a large sphere as initial guess interpolation_order = 2 # Second order interpolation ahf_active = \"yes\" ahf_flow = \"yes\" ahf_phi = \"yes\"","title":"Example"},{"location":"ET/parameter/#ahfinderdirect","text":"The BH apparent horizon is located and monitored through the AHFinderDirect thorn. We estimate the BH mass M_{\\mathrm{BH}} M_{\\mathrm{BH}} and the BH dimensionless spin parameter a / M_{\\mathrm{BH}} a / M_{\\mathrm{BH}} using the isolated horizon formalism. Thorn AHFinderDirect finds an apparent horizon by numerically solving equation \\Theta \\equiv \\nabla_{i} n^{i}+K_{i j} n^{i} n^{j}-K=0 \\Theta \\equiv \\nabla_{i} n^{i}+K_{i j} n^{i} n^{j}-K=0 It requires as input the usual Cactus 3-metric g_{i j} g_{i j} and extrinsic curvature K_{i j} K_{i j} , (and optionally the conformal factor \\psi \\psi if the StaticConformal metric semantics are used), and produces as output the Cactus(x, y, z) coordinates of a large number of points on the apparent horizon, together with some auxiliary information like the apparent horizon area and centroid position, and the irreducable mass associated with the area. There are some restrictions on the spacetime, or more precisely on each slice where you want to find apparent horizons, which are necessary in order for AHFinderDirect to work: AHFinderDirect requires that the Cactus geometry ( g_{i j} g_{i j} , K_{i j} K_{i j} and \\psi \\psi ) be nonsingular in a neighborhood of the apparent horizon. In particular, this means that it quite certainly will not work for spacetimes/slicings which have a singular geometry on the horizon, such as Schwarzschild/Schwarzschild and Kerr/Boyer-Lindquist. Less obviously, this also means that if there is a singularity in the geometry somewhere near the apparent horizon, then you need to have a high enough Cactus 3-D grid resolution that the geometry interpolation doesn\u2019t \u201csee\u201d the singularity. At the moment AHFinderDirect and the Cactus interpolators don\u2019t know how to avoid an excised region, so if the apparent horizon gets too close to an excised region, you\u2019ll get garbage results as the interpolator tries to interpolate data from the excised region.","title":"AHFinderDirect"},{"location":"ET/parameter/#description_10","text":"This thorn has lots of parameters, but most of them have reasonable default values which you probably won\u2019t need to change. Here I describe the parameters which you are likely to want to at least look at, and possibly set explicitly. find_every This is an integer parameter specifying how often AHFinderDirect should try to find apparent horizons. N_horizons How many apparent horizons do you want to find in each slice? Note that N_horizons sets the number of apparent horizons you want to find in the Cactus 3-D numerical grid, not in the whole spacetime. verbose_level This controls how verbose this thorn is in printing informational (non-error) messages describing what it\u2019s doing. In order from tersest to most verbose, the allowable values are \"no output\": Don\u2019t print anything. \"physics highlights\": Print only a single line each time AHFinderDirect runs, giving which horizons were found. \"physics details\": Print two lines for each horizon found, giving the horizon area, centroid position, and irreducible mass. \"algorithm highlights\": Also print a single line for each Newton iteration giving the 2-norm and \u221e-norm of the \\Theta(h) \\Theta(h) \"algorithm details\": Print lots of detailed messages tracing what the code is doing. \"algorithm debug\": Print even more detailed messages tracing what the code is doing, mainly useful for debugging purposes. For each apparent horizon you want to \ufb01nd, you need to specify the Cactus (x, y, z) coordinates of a local coordinate system origin. You specify the local coordinate system origin for each horizon with the (Cactus array) parameters origin_x[n], origin_y[n] and origin_z[n] AHFinderDirect requires an initial guess for the apparent horizon\u2019s coordinate position and shape, for each apparent horizon you want to find. For AHFinderDirect there\u2019s no restriction on whether the initial guess is inside, outside, or crossing the actual apparent horizon: the only important thing is that it should be \u201cclose\u201d. If we succeed in finding a given apparent horizon, than that apparent horizon position is automatically reused as the initial guess the next time we try to find the same apparent horizon. There are a number of parameters for specifying the initial guess: initial_guess_method[n] This sets what type of the initial guess is used for each apparent horizon position. There are several possibilities, most with their own sets of subparameters \"read from file\": This reads the initial-guess h(angle) function from a data \ufb01le. The file format is currently hard-wired to be that written with file_format = \"ASCII (gnuplot)\". The subparameter initial_guess__read_from_named_file__file_name specifies the \ufb01le name. \"Kerr/Kerr\": This sets the initial guess to the analytically-known apparent horizon position in a Kerr spacetime in Kerr coordinates. \"Kerr/Kerr-Schild\": This sets the initial guess to the analytically-known apparent horizon position in a Kerr spacetime in Kerr-Schild coordinates. \"coordinate sphere\": This sets the initial guess to a coordinate sphere. \"coordinate ellipsoid\": This sets the initial guess to a coordinate ellipsoid The main output of this thorn is the computed horizon shape function h(angle), and correspondingly the (x, y, z) coordinate positions of the apparent-horizon-surface (angular) grid points. There are several parameters controlling if, how often, and how these should be written to data files: output_h_every You can control how often (if at all) the apparent horizon shape(s) are written to data files. file_format This specifies the \ufb01le format for horizon-shape (and other angular-grid-function) data files. Unfortunately, at the moment only a single format is implemented, \"ASCII (gnuplot)\" h_directory This specifies the directory in which the h data files are to be written. If it doesn\u2019t already exist, this directory is created before writing the data files. h_base_file_name This specifies the base \ufb01le name for h data files, as described above. This thorn can optionally set a mask grid function (or functions) at each point of the Cactus grid, to indicate where that point is with respect to the apparent horizon(s). This is usually used for excision. set_mask_for_all_horizons and set_mask_for_individual_horizon[n].","title":"Description"},{"location":"ET/parameter/#parameter_27","text":"Key Defaults Describe Option find_every 1 how often should we try to find apparent horizons? 0 :: \"don't find AHs at all (this thorn is a no-op)\"; 1: :: \"any integer >= 1\" run_at_CCTK_ANALYSIS false should we run at CCTK_ANALYSIS? run_at_CCTK_POSTSTEP true should we run at CCTK_POSTSTEP? run_at_CCTK_POSTINITIAL false should we run at CCTK_POSTINITIAL? run_at_CCTK_POSTPOSTINITIAL false should we run at CCTK_POSTPOSTINITIAL? method \"find what should this thorn do for each apparent horizon? # these options are mostly for testing/debugging; # ... in a multiprocessor Cactus run, the horizons are done sequentually; # on processor #0; the other processors do dummy computations; \"evaluate expansions\" :: \"evaluate the LHS function Theta(h)\"; ; # ... in a multiprocessor Cactus run, the Jacobian is computed on; # processor #0; the other processors do dummy computations; \"test expansion Jacobians\" :: \\; \"compute/print horizon 1's J[Theta(h)] Jacobian matrix (possibly in \\; multiple ways, depending on thetest_all_Jacobian_methodsparameter)\"; ; # this is for normal apparent horizon finding; # ... in a multiprocessor Cactus run, the horizons are done in parallel; # across processors; see src/driver/README.parallel for details; \"find horizons\" :: \"find the apparent horizon\" N_horizons 1 number of apparent horizons to search for 0 :: \"turn this thorn into a fancy no-op :)\"; 1:100 :: \"search for this many apparent horizons\" want_expansion_gradients \"false\" should we print the gradients of the expansions? just \"\" base \".+\" :: \"any nonempty string\"; \"^$\" :: \"an empty string to default to IO::out_dir\" output_ASCII_files \"yes\" output h and Theta(h) as ASCII files output_HDF5_files \"no\" output h and Theta(h) as HDF5 files this \"gp\" gnuplot \".+\" :: \"any nonempty string\" HDF5_file_name_extension \"h5\" extension for HDF5 data files \".+\" :: \"any nonempty string\" just \"\" base \".+\" :: \"any nonempty string\"; \"^$\" :: \"an empty string to default to IO::out_dir\" Theta_base_file_name \"Theta\" base file name for Theta(h) output file(s) \".+\" :: \"any nonempty string\" mean_curvature_base_file_name \"mean_curvature\" base file name for mean_curvature(h) output file(s) \".+\" :: \"any nonempty string\" a \"true\" control file with \"false\" .it%d Jacobian_base_file_name \"Jacobian.dat\" base file name for Jacobian output file(s) \".+\" :: \"any valid file name\" an 0.8 outside (0:) :: \\; \"any positive real number; typically this will be slightly less than 1.0\" be -1.0e10 not too small : :: \"any real number\" old_style_mask_gridfn_name \"SpaceMask::emask\" name of the old-style mask grid function \".+\" :: \"any valid Cactus grid function name\" new_style_mask_gridfn_name \"SpaceMask::space_mask\" name of the new-style mask grid function \".+\" :: \"any valid Cactus grid function name\" currently 1 handle -1: :: \"any valid Cactus warning level\" probably 2 just -1: :: \"any valid Cactus warning level\" the 3 check that the geometry is finite -1: :: \"any valid Cactus warning level\" be 1.0e10 not found (0.0: :: \"any positive real number\" be 1.0e10 not found (0.0: :: \"any positive real number\" move_origins \"no\" move the origins with the horizons reshape_while_moving \"no\" reshape the horizons when moving them predict_origin_movement \"no\" predict origin movement when moving the origins than 18 full sphere 1: :: \"any integer >= 1; must be even for patch systems other than full-sphere\" max_N_zones_per_right_angle 18 the maximum of all N_zones_per_right_angle -- calculated automatically; do not set this parameter directly 1: :: \"must be at least the maximum of all N_zones_per_right_angle\" terminology 2 ghost zone 0: :: \"any integer >= 0\" Jacobian_compute_method \"symbolic how do we compute the Jacobian matrix? # for debugging only\"; \"numerical perturbation\":: \"n.b. this is very slow\"; ; # use this for normal apparent horizon finding; \"symbolic differentiation with finite diff d/dr\" :: \\; \"fast, tricky programming, uses only gij, dx gij, Kij\"; ; # alas, this isn't implemented yet :(; \"symbolic differentiation\":: \\; \"fast, tricky programming, uses gij, dx gij, dxx gij, Kij, dx Kij\" ILUCG__error_tolerance 1.0e-10 error tolerance for conjugate gradient iteration (:0.0) :: \\; \"negative ==> scale the absolute value by the floating point roundoff \\; threshold, e.g. -256.0 means to allow the last 8 bits of \\; the solution to be in error\"; (0.0:) :: \\; \"positive ==> error tolerance\" have \"cart3d\" spikes \".+\" :: \"any nonempty string\" geometry__Schwarzschild_EF__mass 1.0 mass of Schwarzschild BH (0.0: :: \"BH mass = any real number > 0\" geometry__Schwarzschild_EF__x_posn 0.0 x coordinate of Schwarzschild BH : :: \"any real number\" geometry__Schwarzschild_EF__y_posn 0.0 y coordinate of Schwarzschild BH : :: \"any real number\" geometry__Schwarzschild_EF__z_posn 0.0 z coordinate of Schwarzschild BH : :: \"any real number\" the 1.0e-6 grid spacing (0.0: :: \"any real number > 0\" integral_method \"automatic how do we compute integrals over the horizon? \"trapezoid\" :: \"alternate name for trapezoid rule\"; \"trapezoid rule\" :: \"trapezoid rule (2 nd order for smooth functions)\"; \"Simpson\" :: \"alternate name for Simpson's rule\"; \"Simpson's rule\" :: \\; \"Simpson's rule (4 th order for smooth fns, requires N to be even)\"; \"Simpson (variant)\" :: \"alternate name for Simpson's rule variant\"; \"Simpson's rule (variant)\":: \\; \"Simpson's rule variant (4 th order for smooth fns, requires N >= 7)\"; ; # choose this for normal use (assuming FINITE_DIFF_ORDER is set to 4; # in \"src/include/config.hh\"); \"automatic choice\" :: \\; \"choose Simpson's rule or variant if applicable, otherwise trapezoid rule\" driver \"gridfn\" src/patch/test_patch_system.cc ##\"gridfn\" :: \"set up test fn(x,y,z), print it\"; ##\"read gridfn\" :: \"read in ghosted test fn(x,y,z), print it\"; ##\"synchronize\" :: \"set up test fn(x,y,z), synchronize it, print errors\"; ##\"ghost zone Jacobian\":: \\; ##\"set up test fn(x,y,z), compute Jacobian of gz.synchronize(), compare with NP\"; ##\"derivatives\" :: \"set up test fn(rho,sigma), take derivs, print errors\"; ## which_derivs 63 bit flags to specify which derivatives to test ##0:63 :: \"any set of bit flags\"; ##","title":"Parameter"},{"location":"ET/parameter/#examples_1","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 cactus::cctk_itlast = 0 ActiveThorns = \"PUGH\" driver::ghost_size = 2 driver::global_nx = 31 driver::global_ny = 31 driver::global_nz = 19 ActiveThorns = \"CoordBase CartGrid3D\" grid::domain = \"bitant\" grid::avoid_origin = false grid::type = \"byspacing\" grid::dxyz = 0.2 ActiveThorns = \"ADMBase ADMCoupling StaticConformal Spacemask CoordGauge Exact\" ADMBase::initial_lapse = \"exact\" ADMBase::initial_shift = \"exact\" ADMBase::initial_data = \"exact\" ADMBase::lapse_evolution_method = \"static\" ADMBase::shift_evolution_method = \"static\" ADMBase::metric_type = \"physical\" Exact::exact_model = \"Kerr/Kerr-Schild\" Exact::Kerr_KerrSchild__mass = 1.0 Exact::Kerr_KerrSchild__spin = 0.6 ######################################## ActiveThorns = \"IOUtil\" IOUtil::parfile_write = \"no\" ######################################## ActiveThorns = \"SphericalSurface\" ActiveThorns = \"AEILocalInterp PUGHInterp PUGHReduce AHFinderDirect\" AHFinderDirect::h_base_file_name = \"Kerr-tiny.h\" AHFinderDirect::N_horizons = 1 AHFinderDirect::origin_x[1] = 0.5 AHFinderDirect::origin_y[1] = 0.7 AHFinderDirect::origin_z[1] = 0.0 AHFinderDirect::initial_guess_method[1] = \"coordinate sphere\" AHFinderDirect::initial_guess__coord_sphere__x_center[1] = -0.2 AHFinderDirect::initial_guess__coord_sphere__y_center[1] = 0.3 AHFinderDirect::initial_guess__coord_sphere__z_center[1] = 0.0 AHFinderDirect::initial_guess__coord_sphere__radius[1] = 2.0","title":"Examples"},{"location":"ET/parameter/#extract-gravitational-wave","text":"To measure the flux of energy and angular momentum carried away by GWs, we use a modi\ufb01ed version of the Psikadelia thorn. https://arxiv.org/pdf/1502.05674.pdf https://arxiv.org/pdf/1809.08237.pdf https://arxiv.org/pdf/gr-qc/0306056.pdf https://arxiv.org/pdf/gr-qc/0206008.pdf","title":"Extract Gravitational Wave"},{"location":"ET/parameter/#output","text":"IO method Description Providing thorn Viz Tools Scalar output of scalars or grid array reductions in xgraph or gnuplot format CactusBase/IOBasic gnuplot Info screen output of scalars or grid array reductions CactusBase/IOBasic gnuplot IOASCII_nD nD line output of grid arrays in xgraph or gnuplot format CactusBase/IOASCII gnuplot IOHDF5_nD nD slice output of grid arrays in HDF5 format CactusPUGHIO/IOHDF5 VisIt","title":"Output"},{"location":"ET/parameter/#ioutil","text":"Input and output of data (I/O) in Cactus is provided by infrastructure thorns, which interact with the flesh via a fixed interface. Thorn IOUtil by itself provides no I/O methods.","title":"IOUtil"},{"location":"ET/parameter/#description_11","text":"IO::out_dir The name of the directory to be used for output. All the I/O methods described here will write by default to this directory (which itself defaults to the current working directory). Individual methods have parameters which can direct their output to a different directory. IO::out_criterion The criterion that decides when to output. The default is to output every so many iterations. IO::out_every How often, in terms of iterations, each of the Cactus I/O methods will write output. Again, individual methods can set their own parameters to override this. The default is to never write output. IO::out_dt How often, in terms of simulation time, each of the Cactus I/O methods will write output. Again, individual methods can set their own parameters to override this. The default is to never write output. Saving/Generating Parameter Files IO::parfile_write=\"copy\" This is the default option, and makes an exact replica of the input parameter file in the standard output directory (this is particularly useful when the output directory is going to be archived). IO::parfile_write=\"generate\" Generate a new parameter file from runtime information, containing the Cactus version, the name of the original parameter file, the run time/date, the host to run on, and the number of processors - all on comment lines. Following this the parameter file contains the ActiveThorns list plus a sorted list of all active thorns\u2019 parameters which have been set in the original parameter file. IO::parfile_write=\"no\" Switch off writing of a new parameter file. I/O Modes IO::out_mode = \"onefile\" As for the 1D and 2D I/O methods, writing to file is performed only by processor zero. This processor gathers all the output data from the other processors and then writes to a single file. IO::out_mode = \"np\" Output is written in parallel for groups of processors. Each group consists of IO::out_proc_every processors which have assigned one I/O processor which gathers data from the group and writes it to file. IO::out mode = \"proc\" Every processor writes its own chunk of data into a separate output file. While the \"np\" and \"proc\" I/O modes are fast for outputting large amounts of data from all or a group of processors in parallel, they have the disadvantage of writing chunked files. These files then have to be recombined during a postprocessing phase so that the final unchunked data can be visualized by standard tools. Checkpointing and Recovery in Cactus Each checkpoint is saved into a checkpoint file which can be used to restart a new simulation at a later time, recreating the exact state at which it was checkpointed. IO::checkpoint_every specifies how often to write a evolution checkpoint in terms of iteration number. IO::checkpoint_every_walltime_hours specifies how often to write a evolution checkpoint in terms of wall time. Checkpointing will be triggered if either of these conditions is met. IO::checkpoint_next triggers a checkpoint at the end of the current iteration. This flag will be reset afterwards. IO::checkpoint_ID triggers a checkpoint of initial data. IO::checkpoint_on_terminate triggers a checkpoint at the end of the last iteration of a simulation run. IO::checkpoint_file holds the basename for evolution checkpoint file(s) to create Iteration number and file extension are appended by the individual I/O method used to write the checkpoint. IO::checkpoint_ID_file holds the basename for initial data checkpoint file(s) to create Iteration number and file extension are appended by the individual I/O method used to write the checkpoint. IO::checkpoint_dir names the directory where checkpoint files are stored IO::checkpoint_keep specifies how many evolution checkpoints should be kept. The default value of 1 means that only the latest evolution checkpoint is kept and older checkpoints are removed in order to save disk space. Setting IO::checkpoint keep to a positive value will keep so many evolution checkpoints around. A value of \u22121 will keep all (future) checkpoints. IO::recover_and_remove determines whether the checkpoint file that the current simulation has been successfully recovered from, should also be subject of removal, according to the setting of IO::checkpoint_keep IO::recover keyword parameter telling if/how to recover. Choices are \"no\", \"manual\", \"auto\", and \"autoprobe\". IO::recover_file basename of the recovery file. Iteration number and file extension are appended by the individual I/O method used to recover from the recovery file. IO::recover_dir directory where the recovery file is located IO::truncate_files_after_recovering whether or not to truncate already existing output files after recovering.","title":"Description"},{"location":"ET/parameter/#parameter_28","text":"Key Defaults Describe Option out_dir \".\" Default output directory \".+\" :: \"A valid directory name\" max_entries_per_subdir 0 Number of processes that can access the same directory 0 :: \"unlimited\"; 2: :: \"at most that many processes\" out_criterion \"iteration\" Criterion to select output intervals \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"time\":: \"Output every that much coordinate time\" out_every -1 How often to do output by default 1: :: \"Every so many iterations\"; -1:0 :: \"Disable output\" out_dt -2 How often to do output by default (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Disable output\" verbose \"standard\" Level of screen output for I/O \"none\" :: \"No output\"; \"standard\" :: \"Initial description for each I/O method\"; \"full\" :: \"Maximal output\" print_timing_info \"no\" Print timing information on I/O operations. new_filename_scheme \"yes\" Use the new filename scheme for output files ? require_empty_output_directory \"no\" Require that IO::out_dir is empty at startup ? strict_io_parameter_check \"yes\" Stop on errors while parsing I/O parameters from parameter file ? abort_on_io_errors \"no\" Abort on I/O errors (rather than just print a warning) ? out_fileinfo \"all\" Add some useful file information to output files ? \"none\" :: \"no file information\"; \"creation date\":: \"add creation date\"; \"parameter filename\" :: \"add parameter filename\"; \"axis labels\":: \"add axis labels information to output files\"; \"all\":: \"add all available file information\" out_group_separator \"-\" String to separate group name from variable name in file name \"\" :: \"Note: The old default was'::'\" out_mode \"proc\" Which mode to use for output \"proc\":: \"Every processor writes its share of data into a separate file\"; \"np\":: \"Data is collected and written by every N'th processor into a separate file, where N is specified by the parameter IO::out_proc_every\"; \"onefile\" :: \"All output is written into a single file by processor 0\" out_proc_every 8 Do output on every N processors 1: :: \"A number between [1, nprocs)\" out_timesteps_per_file -1 How many timesteps to write to a single file # 1: :: \"Number of timesteps per file\"; 1:1 :: \"Number of timesteps per file (can only be 1 so far)\"; -1::: \"All timesteps in a single file\" out3D_septimefiles \"no\" Write one file per time slice, as opposed to all data in one file out_unchunked \"no\" Don't write data in chunks. This parameter is ignored for single-processor runs where output is always done in unchunked mode. out_save_parameters \"only Save current parameter settings in output files ? \"all\":: \"Save all parameter settings\"; \"only set\" :: \"Only save parameters which have been set before\"; \"no\" :: \"Don't save parameter settings\" out_downsample_x 1 Factor by which to downsample output in x direction. Point (0,0,0) is always included. 1: :: \"A positive integer\" out_downsample_y 1 Factor by which to downsample output in y direction. Point (0,0,0) is always included. 1: :: \"A positive integer\" out_downsample_z 1 Factor by which to downsample output in z direction. Point (0,0,0) is always included. 1: :: \"A positive integer\" out_single_precision \"no\" Output data in single precision ? checkpoint_ID \"no\" Checkpoint initial data ? recover \"no\" Recover from a checkpoint file ? \"no\":: \"Don't recover\"; \"manual\":: \"Recover from the checkpoint file as given in IO::recover_dir and IO::recover_file\"; \"auto\":: \"Automatically recover from the latest checkpoint file found in \"; \"autoprobe\" :: \"Probe for checkpoint files and automatically recover, continue as usual if nothing was found\" checkpoint_every -1 How often to checkpoint 1: :: \"Every so many iterations\"; -1:0 :: \"Disable periodic checkpointing\" checkpoint_every_walltime_hours -1 How often to checkpoint (0: :: \"After so much walltime has passed\"; -1 :: \"Disable periodic walltime checkpointing\" checkpoint_on_terminate \"no\" Checkpoint after last iteration checkpoint_keep 1 How many checkpoint files to keep 1: :: \"1 overwrites the latest checkpoint file\"; -1::: \"Keep all checkpoint files\" checkpoint_file \"checkpoint.chkpt\" File name for regular checkpoint \".+\" :: \"A valid filename\" checkpoint_ID_file \"checkpoint.chkpt\" File name for initial data checkpoint \".+\" :: \"A valid filename\" recover_file \"checkpoint.chkpt\" Basename of recovery file \".+\" :: \"A valid filename\" checkpoint_dir \".\" Output directory for checkpoint files \".+\" :: \"A valid directory name\" recover_dir \".\" Directory to look for recovery files \".+\" :: \"A valid directory name\" filereader_ID_dir \".\" Directory to look for input files \".+\" :: \"A valid directory name\" filereader_ID_files \"\" List of basenames of files to read in as initial data (e.g. omit the filename extention here) \".+\" :: \"Space-separated list of initial data filenames (basenames, e.g. excluding the file name extention)\"; \"^$\" :: \"An empty string for not recovering initial data\" filereader_ID_vars \"all\" List of variables to read in from the given initial data files \"all\" :: \"Read all variables contained in the initial data files\"; \".+\":: \"Space-separated list of fully qualified variable/group names\"; \"^$\":: \"An empty string for not recovering initial data\" recover_and_remove \"no\" Remove checkpoint file after successful recovery ? parfile_write \"copy\" Write a parameter file to 'IO::out_dir' \"no\" :: \"Do not write a parameter file\"; \"copy\" :: \"Copy the original parameter file\"; \"generate\" :: \"Generate a parameter file from the current settings\"; #\"verbose generate\" :: \"Like \\\"generate\\\" but describe all parameters in detail\" parfile_name \"\" Filename for the parameter file to be written \".+\" :: \"A valid filename\"; \"^$\" :: \"An empty string to choose the original parameter filename\" parfile_update_every 0 How often to update the parameter file for steered parameters 1: :: \"Every so many iterations\"; 0::: \"Disable updating\" out_xline_y 0.0 y-coord for 1D lines in x-direction : :: \"A value between [ymin, ymax]\" out_xline_z 0.0 z-coord for 1D lines in x-direction : :: \"A value between [zmin, zmax]\" out_yline_x 0.0 x-coord for 1D lines in y-direction : :: \"A value between [xmin, xmax]\" out_yline_z 0.0 z-coord for 1D lines in y-direction : :: \"A value between [zmin, zmax]\" out_zline_x 0.0 x-coord for 1D lines in z-direction : :: \"A value between [xmin, xmax]\" out_zline_y 0.0 y-coord for 1D lines in z-direction : :: \"A value between [ymin, ymax]\" out_xline_yi -2 y-index (from 0) for 1D lines in x-direction, overrides IO::out_xline_y 0: :: \"An index between [0, ny)\"; -1::: \"Default to physical coordinate IO::out_xline_y if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_xline_y if it is within grid bounds, otherwise revert to using the y-center of the box\" out_xline_zi -2 z-index (from 0) for 1D lines in x-direction, overrides IO::out_xline_z 0: :: \"An index between [0, nz)\"; -1::: \"Default to physical coordinate IO::out_xline_z if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_xline_z if it is within grid bounds, otherwise revert to using the z-center of the box\" out_yline_xi -2 x-index (from 0) for 1D lines in y-direction, overrides IO::out_yline_x 0: :: \"An index between [0, nx)\"; -1::: \"Default to physical coordinate IO::out_yline_x if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_yline_x if it is within grid bounds, otherwise revert to using the x-center of the box\" out_yline_zi -2 z-index (from 0) for 1D lines in y-direction, overrides IO::out_yline_z 0: :: \"An index between [0, nz)\"; -1::: \"Default to physical coordinate IO::out_yline_z if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_yline_z if it is within grid bounds, otherwise revert to using the z-center of the box\" out_zline_xi -2 x-index (from 0) for 1D lines in z-direction, overrides IO::out_zline_x 0: :: \"An index between [0, nx)\"; -1::: \"Default to physical coordinate IO::out_zline_x if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_zline_x if it is within grid bounds, otherwise revert to using the x-center of the box\" out_zline_yi -2 y-index (from 0) for 1D lines in z-direction, overrides IO::out_zline_y 0: :: \"An index between [0, ny)\"; -1::: \"Default to physical coordinate IO::out_zline_y if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_zline_y if it is within grid bounds, otherwise revert to using the y-center of the box\" out_yzplane_x 0.0 x-coord for 2D planes in yz : :: \"A value between [xmin, xmax]\" out_xzplane_y 0.0 y-coord for 2D planes in xz : :: \"A value between [ymin, ymax]\" out_xyplane_z 0.0 z-coord for 2D planes in xy : :: \"A value between [zmin, zmax]\" out_yzplane_xi -2 x-index (from 0) for 2D planes in yz, overrrides IO::out_yzplane_x 0: :: \"An index between [0, nx)\"; -1::: \"Default to physical coordinate IO::out_yzplane_x if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_yzplane_x if it is within grid bounds, otherwise revert to using the x-center of the box\" out_xzplane_yi -2 y-index (from 0) for 2D planes in xz, overrrides IO::out_xzplane_y 0: :: \"An index between [0, ny)\"; -1::: \"Default to physical coordinate IO::out_xzplane_y if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_xzplane_y if it is within grid bounds, otherwise revert to using the y-center of the box\" out_xyplane_zi -2 z-index (from 0) for 2D planes in xy, overrrides IO::out_xyplane_z 0: :: \"An index between [0, nz)\"; -1::: \"Default to physical coordinate IO::out_xyplane_z if it is within grid bounds, otherwise revert to using 0\"; -2::: \"Default to physical coordinate IO::out_xyplane_z if it is within grid bounds, otherwise revert to using the z-center of the box\" truncate_files \"yes\" Truncate existing output files from previous runs (except when recovering) ? truncate_files_after_recovering \"no\" Truncate existing output files after recovering ?","title":"Parameter"},{"location":"ET/parameter/#example_1","text":"Output information to screen using IOBasic\u2019s \"Info\" I/O method 1 2 3 4 5 6 ActiveThorns = \"IOBasic IOUtil PUGHReduce ...\" # Output using all methods on iteration 0, 10, 20, ... IO::out_every = 10 # Group of variables to output to screen IOBasic::outInfo_vars = \"evolve::vars\" Scalar Output from IOBasic\u2019s \"Scalar\" I/O method 1 2 3 4 5 6 ActiveThorns = \"IOBasic IOUtil PUGHReduce ...\" # Output vars using scalar method on iteration 0, 10, 20, ... IOBasic::outScalar_every = 10 # Group of variables to output to file IOBasic::outScalar_vars = \"evolve::vars\" ASCII 1D and 2D Output with IOASCII\u2019s \"IOASCII_1D\" and \"IOASCII_2D\" I/O methods 1 2 3 4 5 6 ActiveThorns = \"IOASCII IOUtil PUGHSlab ...\" # Output vars in 1D on iteration 0, 10, 20, ... IOASCII::out1D_every = 10 # Output vars in 2D on iteration 0, 50, 100, ... IOASCII::out2D_every = 50 HDF5 Output with IOHDF5\u2019s \"IOHDF5\" I/O method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ActiveThorns = \"IOHDF5 IOUtil PUGHSlab ...\" # Output vars in HDF5 format on iteration 0, 5, 10, ... IOHDF5::out_every = 5 # Group of variables to output IOHDF5::out_vars = \"evolve::vars\" # Special I/O directory for HDF5 output IOHDF5::out_dir = \"/scratch/tmp\" # Full output unchunked to one file (Only using a small number of processors) IO::out_mode = \"onefile\" IO::out_unchunked = \"yes\" # Downsample full data by a factor of 3 in each direction IO::out_downsample_x = 3 IO::out_downsample_y = 3 IO::out_downsample_z = 3 Recovering from a checkpoint file 1 2 3 4 5 6 ActiveThorns = \"IOFlexIO FlexIO IOUtil PUGHSlab ...\" # automatically choose the latest checkpoint file IO::recover = \"auto\" # Name and directory of checkpoint file to recover from IO::recover_file = \"run5\" IO::recover_dir = \"/scratch/tmp\"","title":"Example"},{"location":"ET/parameter/#iobasic","text":"This thorn provides two I/O methods \"Info\" and \"Scalar\" which output grid variables as scalars as a function on time. Scalar This method outputs the information into ASCII files named \" .{asc|xg}\" (for CCTK_SCALAR variables) and \" _ .{asc|xg}\" (for CCTK_GF and CCTK_ARRAY variables where reduction would stand for the type of reduction value that is output). The output data can be plotted by using either xgraph (for *.xg files) or gnuplot (for *.asc files). The output style can be selected via parameter settings. Info This method prints the data as runtime information to stdout. The output occurs as a table with columns containing the current iteration number, the physical time at this iteration, and more columns for scalar/reduction values of each variable to be output.","title":"IOBasic"},{"location":"ET/parameter/#description_12","text":"Parameters to control the Scalar I/O method are: IOBasic::outScalar_criterion The criterion that decides when to Scalar output. If this parameter is set in the parameter file, it will override the setting of the shared IO::out_criterion parameter. IOBasic::outScalar_every How often, in terms of iterations, to do Scalar output. If this parameter is set in the parameter file, it will override the setting of the shared IO::out_every parameter. IOBasic::outScalar_dt How often, in terms of simulation time, to do Scalar output. If this parameter is set in the parameter file, it will override the setting of the shared IO::out_dt parameter. IOBasic::out_dir The directory in which to place the Scalar ASCII output files. If the directory doesn\u2019t exist at startup it will be created. If this parameter is set to an empty string Scalar output will go to the standard output directory as specified in IO::out_dir . IOBasic::outScalar_style How to start comments in the Scalar ASCII output files. Possible choices for this keywork parameter are xgraph and gnuplot. IOBasic::out_format The output format for floating-point numbers in Scalar output. IOBasic::outScalar_vars The list of variables to output into individual ASCII files. IOBasic::outScalar_reductions The list of global reduction operations to perform on CCTK_GF and CCTK_ARRAY variables for Scalar output. This setting can be overridden for individual variables using an option string. Multiple reduction names must be separated by spaces. IOBasic::outInfo_criterion The criterion that decides when to Info output. If this parameter is set in the parameter file, it will override the setting of the shared IO::out_criterion parameter. IOBasic::outInfo_every How often, in terms of iterations, to do Info output. If this parameter is set in the parameter file, it will override the setting of the shared IO::out every parameter. IOBasic::outInfo_dt How often, in terms of simulation time, to do Info output. If this parameter is set in the parameter file, it will override the setting of the shared IO::out_dt parameter. IOBasic::outInfo_vars The list of variables to output to screen. IOBasic::outInfo_reductions The default list of global reduction operations to perform on CCTK_GF and CCTK_ARRAY variables.","title":"Description"},{"location":"ET/parameter/#parameter_29","text":"Key Defaults Describe Option out_dir \"\" Output directory for IOBasic's scalar files, overrides IO::out_dir \".+\" :: \"A valid directory name\"; \"^$\" :: \"An empty string to choose the default from IO::out_dir\" outInfo_vars \"\" Variables to output as Info to screen \".+\" :: \"Space-separated list of fully qualified variable/group names\"; \"^$\" :: \"An empty string to output nothing\" outScalar_vars \"\" Variables to output into files \".+\" :: \"Space-separated list of fully qualified variable/group names\"; \"^$\" :: \"An empty string to output nothing\" outInfo_reductions \"minimum List of reductions to output as Info to screen \".+\" :: \"Space-separated list of reduction operators\" outScalar_reductions \"minimum List of reductions to output into files \".+\" :: \"Space-separated list of reduction operators\" outInfo_criterion \"iteration\" Criterion to select Info output intervals \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"time\":: \"Output every that much coordinate time\" outInfo_every -1 How often to do Info output 1: :: \"Every so many iterations\"; 0::: \"Disable Info output\"; -1::: \"Default to IO::out_every\" outInfo_dt -2 How often to do Info output (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" outScalar_criterion \"iteration\" Criterion to select Scalar output intervals \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"time\":: \"Output every that much coordinate time\" outScalar_every -1 How often to do Scalar output 1: :: \"Every so many iterations\"; 0::: \"Disable Scalar output\"; -1::: \"Default to IO::out_every\" outScalar_dt -2 How often to do Scalar output (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" outScalar_style \"xgraph\" Which style for Scalar output \"gnuplot\" :: \"1D output readable by gnuplot\"; \"xgraph\":: \"1D output readable by xgraph\" out_format \".13f\" Which format for Scalar floating-point number output \"^(.[1]?[0-9])?[EGefg]$\" :: \"output with given precision in exponential / floating point notation\"","title":"Parameter"},{"location":"ET/parameter/#examples_2","text":"The minimum and maximum of grid::r is printed according to the list of default reductions for info output (parameter IOBasic::outInfo_reductions ). This list is overridden for wavetoy::phi where only the L2 norm is output as specified in the option string for this variable. You can also add other reduction operators within the {} braces. For the scalar variable mythorn::complex both the real and imaginary part are printed. 1 2 3 4 5 IOBasic::outInfo_every = 2 IOBasic::outInfo_vars = \"grid::r wavetoy::phi{reductions = \u2019norm2\u2019} mythorn::complex\" IOBasic::outInfo_reductions = \"minimum maximum\" The resulting screen output would look like this: The following parameter settings request scalar output Output occurs every 10 th iteration. gnuplot output style is selected for the ASCII files which are placed into a subdirectory scalar_output . 1 2 3 4 5 6 7 IOBasic::outScalar_every =10 IOBasic::outScalar_vars = \"grid::coordinates grid::coarse_dx wavetoy::phi{\u2019norm1\u2019}\" IOBasic::outScalar_reductions = \"minimum maximum\" IOBasic::outScalar_style = \"gnuplot\" IOBasic::out_dir = \"scalar_output\" This would create the following ASCII files:","title":"Examples"},{"location":"ET/parameter/#carpetiobasic","text":"This thorn provides info output for Carpet.","title":"CarpetIOBasic"},{"location":"ET/parameter/#parameter_30","text":"Key Defaults Describe Option outInfo_vars \"\" Variables to output in scalar form \"\" :: \"A regex which matches everything\" outInfo_reductions \"minimum List of reductions to output in scalar form \"\" :: \"A regex which matches everything\" outInfo_criterion \"iteration\" Criterion to select scalar output intervals, overrides out_every \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if iteration mod divisor == 0.\"; \"time\":: \"Output every that much coordinate time\" outInfo_every -2 How often to do scalar output, overrides IO::out_every 1: :: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Default to IO::out_every\" outInfo_dt -2 How often to do scalar output, overrides out_dt (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" outHeader_every 20 How often to print the header 1: :: \"Output every so many time steps\" ; -1 :: \"No header output\" iter_width 9 Field width for the current iteration 1: :: \"\" time_width 9 Field width for the simulation time 1: :: \"\" time_prec 3 Precision for the simulation time 0: :: \"\" int_width 9 Field width for integer values 1: :: \"\" real_width 12 Field width for real values 1: :: \"\" real_prec 7 Precision for real values 0: :: \"\" real_prec_sci 6 Precision for real values in scientific notation 0: :: \"\" real_min 1.0e-8 Lower bound for numbers that are displayed in fixed notation (0.0: :: \"\" real_max 1.0e+3 Upper bound for numbers that are displayed in fixed notation (0.0: :: \"\"","title":"Parameter"},{"location":"ET/parameter/#carpetioscalar","text":"This thorn provides scalar output for Carpet.","title":"CarpetIOScalar"},{"location":"ET/parameter/#parameter_31","text":"Key Defaults Describe Option one_file_per_group \"no\" Write one file per group instead of per variable all_reductions_in_one_file \"no\" Write all requested reductions in one file instead of per reduction out_precision 15 How many digits to output floating-point numbers with 0: :: \"Number of precision digits\" outScalar_dir \"\" Name of scalar output directory, overrides out_dir \"^$\" :: \"Empty: use IO::out_dir\"; \".+\" :: \"Not empty: directory name\" outScalar_vars \"\" Variables to output in scalar form \"\" :: \"A regex which matches everything\" outScalar_reductions \"count List of reductions to output in scalar form \"\" :: \"A regex which matches everything\" outScalar_criterion \"iteration\" Criterion to select scalar output intervals, overrides out_every \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if iteration mod divisor == 0.\"; \"time\":: \"Output every that much coordinate time\" outScalar_every -2 How often to do scalar output, overrides IO::out_every 1: :: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Default to IO::out_every\" outScalar_dt -2 How often to do scalar output, overrides out_dt (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\"","title":"Parameter"},{"location":"ET/parameter/#iohdf5","text":"This thorn does output of arbitrary Cactus variables in HDF5 file format. It also provides checkpointing/recovery functionality.","title":"IOHDF5"},{"location":"ET/parameter/#parameter_32","text":"Key Defaults Describe Option out_every -1 How often to do IOHDF5 output, overrides IO::out_every 1: :: \"Every so many iterations\"; 0::: \"Disable IOHDF5 output\"; -1::: \"Default to IO::out_every\" out_dir \"\" Output directory for IOHDF5 files, overrides IO::out_dir \".+\" :: \"A valid directory name\"; \"^$\" :: \"An empty string to choose the default from IO::out_dir\" out_vars \"\" Variables to output in HDF5 file format \".+\" :: \"Space-separated list of fully qualified variable/group names\"; \"^$\" :: \"An empty string to output nothing\" checkpoint \"no\" Do checkpointing with HDF5 checkpoint_next \"no\" Checkpoint at next iteration","title":"Parameter"},{"location":"ET/parameter/#carpetiohdf5","text":"The CarpetIOHDF5 I/O method can output any type of CCTK grid variables (grid scalars, grid functions, and grid arrays of arbitrary dimension); data is written into separate files named \" .h5\". Such data\ufb01les can be used for further postprocessing or fed back into Cactus via the filereader capabilities of thorn IOUtil. Checkpointing for thorn CarpetIOHDF5 is enabled by setting the parameter IOHDF5::checkpoint = \"yes\" .","title":"CarpetIOHDF5"},{"location":"ET/parameter/#description_13","text":"IOHDF5::out_every How often to do periodic CarpetIOHDF5 output. If this parameter is set in the parameter \ufb01le, it will override the setting of the shared IO::out_every parameter. IOHDF5::out_dt output in intervals of that much coordinate time. IOHDF5::out_criterion criterion to select output intervals IOHDF5::out_vars The list of variables to output using the CarpetIOHDF5 I/O method. The variables must be given by their fully qualified variable or group name. Multiple names must be separated by whitespaces. Each group/variable name can have an option string attached in which you can specify a different output frequency for that individual variable, a set of individual refinement levels to be output, the compression level, or an individual output mode. 1 IOHDF5::out_vars = \"wavetoy::phi{ out_every = 4 refinement_levels = { 1 2 } }\" IOHDF5::out_dir The directory in which to place the CarpetIOHDF5 output files. If the directory doesn\u2019t exist at startup it will be created. If this parameter is set to an empty string CarpetIOHDF5 output will go to the standard output directory as specified in IO::out_dir . IOHDF5::compression_level Compression level to use for writing HDF5 datasets. Automatic gzip dataset compression can be enabled by setting this integer parameter to values between 1 and 9 (inclusive), with increasing values requesting higher compression rates (at the cost of additional runtime for outputting HDF5 data); a value of zero (which is the default setting for this parameter) disables compression. The output compression level can also be set for individual variables using the compression_level option in an option string appended to the IOHDF5::out_vars parameter. IO::out_single_precision whether to output double-precision data in single precision. According to the ouptput mode parameter settings of ( IO::out_mode , IO::out_unchunked , IO::out_proc_every ) of thorn IOUtil, thorn CarpetIOHDF5 will output distributed grid variables either in serial from processor 0 into a single unchunked \ufb01le 1 2 IO::out_mode = \"onefile\" IO::out_unchunked = \"yes\" in serial from processor 0 into a single chunked \ufb01le 1 2 IO::out_mode = \"onefile\" IO::out_unchunked = \"no\" in parallel, that is, into separate chunked files (one per processor) containing the individual processors\u2019 patches of the distributed grid variable 1 IO::out_mode = \"proc\" The default is to output distributed grid variables in parallel, each processor writing a file <varname>.file_<processor ID>.h5 . The chunked/unchunked mode can also be set individually in a key/value option string (with the key out_unchunked and possible string values \"true|false|yes|no\") appended to a group/variable name in the out_vars parameter, 1 IOHDF5::out_vars = \"wavetoy::phi{out_unchunked = \u2019true\u2019} grid::coordinates\" will cause the variable phi to be output into a single unchunked file whereas other variables will still be output into separate chunked files. When visualising chunked datasets, they probably need to be recombined for a global view on the data. This needs to be done within the visualisation tool, Cactus itself does not provide its own recombiner utility program for CarpetIOHDF5\u2019s output files.","title":"Description"},{"location":"ET/parameter/#parameter_33","text":"Key Defaults Describe Option out_dir \"\" Name of CarpetIOHDF5 output directory, overrides 'IO::out_dir' \"^$\" :: \"Empty: use IO::out_dir\"; \".+\" :: \"Not empty: directory name\" out0D_dir \"\" Name of 0D HDF5 slice output directory, overrides IO::out_dir \"^$\" :: \"Empty: use IO::out_dir\"; \".+\" :: \"Not empty: directory name\" out1D_dir \"\" Name of 1D HDF5 slice output directory, overrides IO::out_dir \"^$\" :: \"Empty: use IO::out_dir\"; \".+\" :: \"Not empty: directory name\" out2D_dir \"\" Name of 2D HDF5 slice output directory, overrides IO::out_dir \"^$\" :: \"Empty: use IO::out_dir\"; \".+\" :: \"Not empty: directory name\" out3D_dir \"\" Name of 3D HDF5 slice output directory, overrides IO::out_dir \"^$\" :: \"Empty: use IO::out_dir\"; \".+\" :: \"Not empty: directory name\" out_vars \"\" Variables to output in CarpetIOHDF5 file format \"\" :: \"List of group or variable names\" out0D_vars \"\" Variables to output in 0D HDF5 file format \"\" :: \"List of group or variable names\" out1D_vars \"\" Variables to output in 1D HDF5 file format \"\" :: \"List of group or variable names\" out2D_vars \"\" Variables to output in 2D HDF5 file format \"\" :: \"List of group or variable names\" out3D_vars \"\" Variables to output in 3D HDF5 file format \"\" :: \"List of group or variable names\" out_extension \".h5\" File extension to use for CarpetIOHDF5 output \"\" :: \"File extension (including a leading dot, if desired)\" out_criterion \"default\" Criterion to select CarpetIOHDF5 output intervals, overrides out_every \"default\" :: \"Use 'IO::out_criterion'\"; \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if (iteration % out_every) == 0.\"; \"time\":: \"Output every that much coordinate time\" out0D_criterion \"default\" Criterion to select 0D HDF5 slice output intervals, overrides out_every \"default\" :: \"Use IO::out_criterion\"; \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if iteration mod divisor == 0.\"; \"time\":: \"Output every that much coordinate time\" out1D_criterion \"default\" Criterion to select 1D HDF5 slice output intervals, overrides out_every \"default\" :: \"Use IO::out_criterion\"; \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if (iteration % out_every) == 0.\"; \"time\":: \"Output every that much coordinate time\" out2D_criterion \"default\" Criterion to select 2D HDF5 slice output intervals, overrides out_every \"default\" :: \"Use IO::out_criterion\"; \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if (iteration % out_every) == 0.\"; \"time\":: \"Output every that much coordinate time\" out3D_criterion \"default\" Criterion to select 3D HDF5 slice output intervals, overrides out_every \"default\" :: \"Use IO::out_criterion\"; \"never\" :: \"Never output\"; \"iteration\" :: \"Output every so many iterations\"; \"divisor\" :: \"Output if (iteration % out_every) == 0.\"; \"time\":: \"Output every that much coordinate time\" out_every -2 How often to do CarpetIOHDF5 output, overrides out_every 1::: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Use 'IO::out_every'\" out0D_every -2 How often to do 0D HDF5 slice output, overrides out_every 1::: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Use IO::out_every\" out1D_every -2 How often to do 1D HDF5 slice output, overrides out_every 1::: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Use IO::out_every\" out2D_every -2 How often to do 2D HDF5 slice output, overrides out_every 1::: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Use IO::out_every\" out3D_every -2 How often to do 3D HDF5 slice output, overrides out_every 1::: \"Output every so many time steps\"; -1:0 :: \"No output\"; -2 :: \"Use IO::out_every\" out_dt -2 How often to do CarpetIOHDF5 output, overrides 'IO::out_dt' (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to 'IO::out_dt'\" out0D_dt -2 How often to do 0D HDF5 slice output, overrides IO::out_dt (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" out1D_dt -2 How often to do 1D HDF5 slice output, overrides IO::out_dt (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" out2D_dt -2 How often to do 2D HDF5 slice output, overrides IO::out_dt (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" out3D_dt -2 How often to do 3D HDF5 slice output, overrides IO::out_dt (0: :: \"In intervals of that much coordinate time\"; 0 :: \"As often as possible\"; -1 :: \"Disable output\"; -2 :: \"Default to IO::out_dt\" out0D_point_xi 0 x-index (counting from 0) for 0D points 0: :: \"\" out0D_point_yi 0 y-index (counting from 0) for 0D points 0: :: \"\" out0D_point_zi 0 z-index (counting from 0) for 0D points 0: :: \"\" out0D_point_x 0 x coordinate for 0D points : :: \"\" out0D_point_y 0 y coordinate for 0D points : :: \"\" out0D_point_z 0 z coordinate for 0D points : :: \"\" out1D_x \"yes\" Do 1D HDF5 slice output in the x-direction out1D_y \"yes\" Do 1D HDF5 slice output in the y-direction out1D_z \"yes\" Do 1D HDF5 slice output in the z-direction out1D_xline_yi 0 y-index (counting from 0) for 1D lines in x-direction 0: :: \"\" out1D_xline_zi 0 z-index (counting from 0) for 1D lines in x-direction 0: :: \"\" out1D_yline_xi 0 x-index (counting from 0) for 1D lines in y-direction 0: :: \"\" out1D_yline_zi 0 z-index (counting from 0) for 1D lines in y-direction 0: :: \"\" out1D_zline_xi 0 x-index (counting from 0) for 1D lines in z-direction 0: :: \"\" out1D_zline_yi 0 y-index (counting from 0) for 1D lines in z-direction 0: :: \"\" out1D_xline_y 0 y coordinate for 1D lines in x-direction : :: \"\" out1D_xline_z 0 z coordinate for 1D lines in x-direction : :: \"\" out1D_yline_x 0 x coordinate for 1D lines in y-direction : :: \"\" out1D_yline_z 0 z coordinate for 1D lines in y-direction : :: \"\" out1D_zline_x 0 x coordinate for 1D lines in z-direction : :: \"\" out1D_zline_y 0 y coordinate for 1D lines in z-direction : :: \"\" out2D_xy \"yes\" Do 2D HDF5 slice output in the xy-direction out2D_xz \"yes\" Do 2D HDF5 slice output in the xz-direction out2D_yz \"yes\" Do 2D HDF5 slice output in the yz-direction out2D_xyplane_zi 0 z-index (counting from 0) for 2D planes in xy-direction 0: :: \"\" out2D_xzplane_yi 0 y-index (counting from 0) for 2D planes in xz-direction 0: :: \"\" out2D_yzplane_xi 0 x-index (counting from 0) for 2D planes in yz-direction 0: :: \"\" out2D_xyplane_z 0 z coordinate for 2D planes in xy-direction : :: \"\" out2D_xzplane_y 0 y coordinate for 2D planes in xz-direction : :: \"\" out2D_yzplane_x 0 x coordinate for 2D planes in yz-direction : :: \"\" output_all_timelevels \"no\" Output all timelevels instead of only the current output_symmetry_points \"yes\" Output symmetry points (assuming that there are nghostzones symmetry points) output_ghost_points \"yes\" Output ghost points output_boundary_points \"yes\" Output outer boundary points (assuming that there are nghostzones boundary points) output_buffer_points \"yes\" Output refinement buffer points out3D_ghosts \"yes\" Output ghost zones (DEPRECATED) out3D_outer_ghosts \"yes\" Output outer boundary zones (assuming that there are nghostzones boundary points) (DEPRECATED) out1D_d \"yes\" Do output along the diagonal checkpoint \"no\" Do checkpointing with CarpetIOHDF5 ? checkpoint_next \"no\" Checkpoint at next iteration ? checkpoint_every_divisor -1 Checkpoint if (iteration % out_every) == 0 1: :: \"Every so many iterations\"; -1:0 :: \"Disable periodic checkpointing\" use_reflevels_from_checkpoint \"no\" Use 'CarpetRegrid::refinement_levels' from the checkpoint file rather than from the parameter file ? use_grid_structure_from_checkpoint \"yes\" Use the grid structure stored in the checkpoint file one_file_per_proc \"no\" Write one file per process instead of per variable one_file_per_group \"no\" Write one file per group instead of per variable open_one_input_file_at_a_time \"no\" Open only one HDF5 file at a time when reading data from multiple chunked checkpoint/data files \"no\":: \"Open all input files first, then import data (most efficient)\"; \"yes\" :: \"Process input files one after another (reduces memory requirements)\" skip_recover_variables \"\" Skip these variables while recovering \"\" :: \"\" compression_level 0 Compression level to use for writing HDF5 data 0:9 :: \"Higher numbers compress better, a value of zero disables compression\" minimum_size_for_compression 32768 Only compress datasets larger than this many bytes 0: :: \"This should to be large enough so that compression gains outweigh the overhead\" use_checksums \"no\" Use checksums for the HDF5 data output_index \"no\" Output an index file for each output file","title":"Parameter"},{"location":"ET/parameter/#example_2","text":"Serial (unchunked) Output of Grid Variables 1 2 3 4 5 6 7 8 9 10 # how often to output and where output files should go IO::out_every = 2 IO::out_dir = \"wavetoy-data\" # request output for wavetoy::psi at every other iteration for timelevel 0, for wavetoy::phi every 4th iteration with timelevels 1 and 2 IOHDF5::out_vars = \"wavetoy::phi{ out_every = 4 refinement_levels = { 1 2 } } wavetoy::psi\" # we want unchunked output (because the visualisation tool cannot deal with chunked data files) IO::out_mode = \"onefile\" IO::out_unchunked = 1 Checkpointing & Recovery 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # say how often we want to checkpoint, how many checkpoints should be kept, how the checkpoints should be named, and they should be written to IO::checkpoint_every = 100 IO::checkpoint_keep = 2 IO::checkpoint_file = \"wavetoy\" IO::checkpoint_dir = \"wavetoy-checkpoints\" # enable checkpointing for CarpetIOHDF5 IOHDF5::checkpoint = \"yes\" ####################################################### # recover from the latest checkpoint found IO::recover_file = \"wavetoy\" IO::recover_dir = \"wavetoy-checkpoints\" IO::recover = \"auto\"","title":"Example"},{"location":"ET/parameter/#timerreport","text":"This thorn provides mechanisms for obtaining different information from timers during a Cactus run.","title":"TimerReport"},{"location":"ET/parameter/#parameter_34","text":"Key Defaults Describe Option out_every 0 How often to output timer report to screen 0 :: \"No periodic output (default)\"; 1: :: \"Every so many iterations\" out_at -1 Output timer information at a given iteration -1 :: \"Do not output at specific iteration (default)\"; 0::: \"At this iteration\" out_filename \"\" File name for timer reports \" ^$ \" :: \"empty filename: print to stdout\"; \" ^.+$ \" :: \"otherwise: print to that file\" before_checkpoint \"no\" Before a checkpoint next \"no\" On next iteration output_schedule_timers \"yes\" Output the schedule timers in a formatted tabular format output_all_timers \"no\" Output one file per processor containing all the Cactus timers output_all_timers_together \"no\" Output three files (formats .txt, .csv, and .tsv), containing information about all the Cactus timers (average, minimum, and maximum over all processors) output_all_timers_readable \"no\" Output one file containing information about all the Cactus timers (average, minimum, and maximum over all processors), in a format that is readable by humans all_timers_clock \"gettimeofday\" Which clock to use for the all timers output \".\" :: \"any clock name allowed\" n_top_timers 0 How many timers to include in the top timer report 0 :: \"Do not print the report\"; 1: :: \"Any number of timers\"","title":"Parameter"},{"location":"ET/parameter/#extension","text":"","title":"Extension"},{"location":"ET/parameter/#nanchecker","text":"The NaNChecker thorn can be used to analyze Cactus grid variables (that is grid functions, arrays or scalars) of real or complex data type for NaN (Not-a-Number) and in\ufb01nite values.","title":"NaNChecker"},{"location":"ET/parameter/#parameter_35","text":"Key Defaults Describe Option check_every 0 How often to check for NaNs 0 :: \"Never (default)\"; 1: :: \"Every so many iterations\" check_after 0 Start checking for NaNs after so many iterations 0: :: \"Any valid iteration number\" report_max -1 How many NaNs to report for a single variable -1 :: \"Report all (default)\"; 0: :: \"Do not report more than report_max number of NaNs\" check_vars \"\" Groups and/or variables to check for NaNs . :: \"List of full group and/or variable names, or 'all' for everything\" check_for \"both\" Check for NaNs and/or infinite numbers (only evaluated if finite(3) is available) \"NaN\":: \"Check only for NaNs\"; \"Inf\":: \"Check only for infinite numbers\"; \"both\" :: \"Check for both NaNs and infinite numbers\" out_NaNmask \"yes\" Dump the NaN grid function mask into an HDF5 file action_if_found \"just What to do if a NaN was found \"just warn\" :: \"Just print a level 1 warning\"; \"terminate\" :: \"Warn and terminate Cactus gracefully as soon as possible\"; \"abort\" :: \"Warn and abort Cactus immediately\" verbose \"standard\" How much information to give \"all\":: \"All information\"; \"standard\" :: \"Standard information\" ignore_restricted_points \"no\" do not check grid points whose values will be restricted away setup_test \"no\" set up grid function with NaNs","title":"Parameter"},{"location":"ET/parameter/#terminationtrigger","text":"This thorn watches the elapsed walltime. If only n minutes are left before the some limit set by the user, it triggers termination of the simulation.","title":"TerminationTrigger"},{"location":"ET/parameter/#parameter_36","text":"Key Defaults Describe Option on_remaining_walltime 0.0 When to trigger termination in MINUTES 0.0:: \"Don't trigger termination\"; (0.0: :: \"So many minutes before your job walltime is over\" max_walltime 0.0 Walltime in HOURS allocated for this job 0.0:: \"Don't trigger termination\"; (0.0: :: \"Should be positive, right\" termination_from_file \"no\" Use termination file; specified by termination_filename create_termination_file \"no\" Create an empty termination file at startup termination_file \"/tmp/cactus_terminate\" Termination file name (either full path or relative to IO::out_dir) \"\" ::\"Termination file\" check_file_every 1 Check termination file every n timesteps 1: :: \"\" output_remtime_every_minutes 60.0 Output remaining wall time every n minutes 0.0:: \"No output\"; (0.0: :: \"Output\" testsuite \"no\" manually trigger termination","title":"Parameter"},{"location":"Example/BBH/","text":"https://arxiv.org/abs/gr-qc/0104020 https://arxiv.org/abs/gr-qc/0008067","title":"BBH"},{"location":"Example/Minkowski_Multipole/","text":"We present 3D simulations of a scalar field propagating in a Schwarzschild black hole background. The mass of the scalar field is considered negligible compared to the mass of the black hole and so the back reaction of the scalar field on the metric is not considered. https://arxiv.org/pdf/gr-qc/0302072.pdf IBVP Numerical solutions of Einstein\u2019s equations involve solving a nonlinear set of partial differential equations on a bounded domain, and formally constitute an initial-boundary-value problem (IBVP). An IBVP consists of three ingredients: a partial differential equation, initial and boundary data. It is well-posed if a solution exists, is unique, and depends continuously on the initial and boundary data. Consider the linear IBVP on a domain [0, \\infty) \\times \\Omega [0, \\infty) \\times \\Omega \\begin{aligned} \\partial_{t} u &=A(t, \\vec{x})^{i} \\partial_{i} u+B(t, \\vec{x}) u \\\\ u(0, \\vec{x}) &=f(\\vec{x}) \\\\ w_{+}(t, \\vec{x}) &=S w_{-}(t, \\vec{x})+g(t, \\vec{x}), \\vec{x} \\in \\partial \\Omega \\end{aligned} \\begin{aligned} \\partial_{t} u &=A(t, \\vec{x})^{i} \\partial_{i} u+B(t, \\vec{x}) u \\\\ u(0, \\vec{x}) &=f(\\vec{x}) \\\\ w_{+}(t, \\vec{x}) &=S w_{-}(t, \\vec{x})+g(t, \\vec{x}), \\vec{x} \\in \\partial \\Omega \\end{aligned} The equations are discretized on a domain \\Omega \\Omega with an inner boundary to accommodate for black hole excision. We introduce the grid points \\vec{r}_{i j k}=(i \\Delta x, j \\Delta y, k \\Delta z) \\in \\Omega \\vec{r}_{i j k}=(i \\Delta x, j \\Delta y, k \\Delta z) \\in \\Omega and assume that some of these points lie on the boundary \\partial \\Omega \\partial \\Omega .","title":"Minkowski Multipole"},{"location":"Example/Minkowski_Multipole/#ibvp","text":"Numerical solutions of Einstein\u2019s equations involve solving a nonlinear set of partial differential equations on a bounded domain, and formally constitute an initial-boundary-value problem (IBVP). An IBVP consists of three ingredients: a partial differential equation, initial and boundary data. It is well-posed if a solution exists, is unique, and depends continuously on the initial and boundary data. Consider the linear IBVP on a domain [0, \\infty) \\times \\Omega [0, \\infty) \\times \\Omega \\begin{aligned} \\partial_{t} u &=A(t, \\vec{x})^{i} \\partial_{i} u+B(t, \\vec{x}) u \\\\ u(0, \\vec{x}) &=f(\\vec{x}) \\\\ w_{+}(t, \\vec{x}) &=S w_{-}(t, \\vec{x})+g(t, \\vec{x}), \\vec{x} \\in \\partial \\Omega \\end{aligned} \\begin{aligned} \\partial_{t} u &=A(t, \\vec{x})^{i} \\partial_{i} u+B(t, \\vec{x}) u \\\\ u(0, \\vec{x}) &=f(\\vec{x}) \\\\ w_{+}(t, \\vec{x}) &=S w_{-}(t, \\vec{x})+g(t, \\vec{x}), \\vec{x} \\in \\partial \\Omega \\end{aligned} The equations are discretized on a domain \\Omega \\Omega with an inner boundary to accommodate for black hole excision. We introduce the grid points \\vec{r}_{i j k}=(i \\Delta x, j \\Delta y, k \\Delta z) \\in \\Omega \\vec{r}_{i j k}=(i \\Delta x, j \\Delta y, k \\Delta z) \\in \\Omega and assume that some of these points lie on the boundary \\partial \\Omega \\partial \\Omega .","title":"IBVP"},{"location":"Example/Poisson/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Domain size specification: lower and upper boundary locations CoordBase::domainsize = \"minmax\" # Location of x, y, z boundary CoordBase::xmin = -1.00 CoordBase::ymin = -1.00 CoordBase::zmin = -1.00 CoordBase::xmax = +1.00 CoordBase::ymax = +1.00 CoordBase::zmax = +1.00 # Grid spacing in x, y, z direction CoordBase::dx = 0.25 CoordBase::dy = 0.25 CoordBase::dz = 0.25 1 2 3 4 5 6 CoordBase::boundary_size_x_lower = 3 CoordBase::boundary_size_y_lower = 3 CoordBase::boundary_size_z_lower = 3 CoordBase::boundary_size_x_upper = 3 CoordBase::boundary_size_y_upper = 3 CoordBase::boundary_size_z_upper = 3","title":"Poisson"},{"location":"Example/single neutron star/","text":"This simulation shows how to evolve a stable, single neutron star. What can be seen is the initial perturbation (due to numerical errors) ringing down (look at the density maximum), and later numerical errors governing the solution. Try higher resolutions to decrease this error. Parameter File Flesh parameters \u65f6\u95f4\u6f14\u5316\u5230 800 \u65f6\u7ed3\u675f 1 2 Cactus::terminate = \"time\" Cactus::cctk_final_time = 800 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # Termination Trigger ActiveThorns = \"TerminationTrigger\" # Walltime in HOURS allocated for this job TerminationTrigger::max_walltime = 24 # hours # When to trigger termination in MINUTES TerminationTrigger::on_remaining_walltime = 15 # minutes # Check termination file every n timesteps TerminationTrigger::check_file_every = 512 # Termination file name TerminationTrigger::termination_file = \"TerminationTrigger.txt\" # Use termination file TerminationTrigger::termination_from_file = \"yes\" # Create an empty termination file at startup TerminationTrigger::create_termination_file = \"yes\" Time integration 1 2 3 4 5 6 7 8 9 time::dtfac = 0.25 MoL::ODE_Method = \"rk4\" # Number of intermediate steps taken by the ODE method MoL::MoL_Intermediate_Steps = 4 # Number of scratch levels required by the ODE metho MoL::MoL_Num_Scratch_Levels = 1 grid parameters 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # grid parameters Carpet::domain_from_coordbase = \"yes\" CartGrid3D::type = \"coordbase\" # Use the full domain CartGrid3D::domain = \"full\" # Don't place grid points on the coordinate origin CartGrid3D::avoid_origin = \"no\" CoordBase::xmin = 0.0 CoordBase::ymin = 0.0 CoordBase::zmin = 0.0 CoordBase::xmax = 48.0 CoordBase::ymax = 48.0 CoordBase::zmax = 48.0 # Change these parameters to change resolution. The max settings above have to be multiples of these. 'dx' is the size of one cell in x-direction. Making this smaller means using higher resolution, because more points will be used to cover the same space. CoordBase::dx = 4.0 CoordBase::dy = 4.0 CoordBase::dz = 4.0 CoordBase::boundary_size_x_lower = 3 CoordBase::boundary_size_y_lower = 3 CoordBase::boundary_size_z_lower = 3 CoordBase::boundary_size_x_upper = 3 CoordBase::boundary_size_y_upper = 3 CoordBase::boundary_size_z_upper = 3 CoordBase::boundary_shiftout_x_lower = 1 CoordBase::boundary_shiftout_y_lower = 1 CoordBase::boundary_shiftout_z_lower = 1 CoordBase::boundary_shiftout_x_upper = 0 CoordBase::boundary_shiftout_y_upper = 0 CoordBase::boundary_shiftout_z_upper = 0 Boundary 1 2 3 4 5 6 7 8 9 10 ActiveThorns = \"ReflectionSymmetry\" # Reflection symmetry at the lower x boundary ReflectionSymmetry::reflection_x = \"yes\" ReflectionSymmetry::reflection_y = \"yes\" ReflectionSymmetry::reflection_z = \"yes\" # Stagger about the origin on the lower x boundary? ReflectionSymmetry::avoid_origin_x = \"no\" ReflectionSymmetry::avoid_origin_y = \"no\" ReflectionSymmetry::avoid_origin_z = \"no\" Mesh refinement 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Carpet::enable_all_storage = no Carpet::use_buffer_zones = \"yes\" Carpet::poison_new_timelevels = \"yes\" Carpet::check_for_poison = \"no\" Carpet::init_3_timelevels = no Carpet::init_fill_timelevels = \"yes\" CarpetLib::poison_new_memory = \"yes\" CarpetLib::poison_value = 114 # system specific Carpet paramters Carpet::max_refinement_levels = 10 driver::ghost_size = 3 Carpet::prolongation_order_space = 3 Carpet::prolongation_order_time = 2 # regrid during initial data calculation only CarpetRegrid2::regrid_every = 0 # Number of refinement centres CarpetRegrid2::num_centres = 1 # Number of refinement levels for this centre CarpetRegrid2::num_levels_1 = 3 CarpetRegrid2::radius_1[1] = 24.0 CarpetRegrid2::radius_1[2] = 12.0 Hydro paramters 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ActiveThorns = \"HydroBase EOS_Omni GRHydro\" HydroBase::timelevels = 3 HydroBase::evolution_method = \"GRHydro\" # Which Riemann solver to use GRHydro::riemann_solver = \"HLLE\" # Type of Equation of State P = P(rho, eps) GRHydro::GRHydro_eos_type = \"General\" # Name for the Equation of State GRHydro::GRHydro_eos_table = \"Ideal_Fluid\" # PPM reconstruction method to use GRHydro::recon_method = \"ppm\" # Width of the stencil GRHydro::GRHydro_stencil = 3 # static boundary condition to use GRHydro::bound = \"none\" # A minimum rho below which evolution is turned off GRHydro::rho_abs_min = 1.e-10 # A point is set to atmosphere in the Con2Prim's if its rho < GRHydro_rho_min *(1+GRHydro_atmo_tolerance). This avoids occasional spurious oscillations in carpet buffer zones lying in the atmosphere (because prolongation happens on conserved variables) GRHydro::GRHydro_atmo_tolerance = 1.e-3 # Order of spatial differencing of the source terms GRHydro::sources_spatial_order = 4 1 2 3 4 5 # storage and coupling TmunuBase::stress_energy_storage = yes TmunuBase::stress_energy_at_RHS = yes TmunuBase::timelevels = 1 TmunuBase::prolongation_type = none evolution parameters 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ActiveThorns = \"GenericFD NewRad\" ActiveThorns = \"ML_BSSN ML_BSSN_Helper\" ADMBase::evolution_method = \"ML_BSSN\" ADMBase::lapse_evolution_method = \"ML_BSSN\" ADMBase::shift_evolution_method = \"ML_BSSN\" ADMBase::dtlapse_evolution_method= \"ML_BSSN\" ADMBase::dtshift_evolution_method= \"ML_BSSN\" ML_BSSN::timelevels = 3 # d/dt alpha = - f alpha^n K (harmonic: n=2, 1+log: n=1) ML_BSSN::harmonicN = 1 # 1+log # d/dt alpha = - f alpha^n K (harmonic: f=1, 1+log: f=2) ML_BSSN::harmonicF = 2.0 # 1+log # Evolve time derivative of shift B^i? ML_BSSN::ShiftBCoeff = 1 ML_BSSN::ShiftGammaCoeff = 0.75 ML_BSSN::BetaDriver = 2.66 ML_BSSN::LapseAdvectionCoeff = 0.0 ML_BSSN::ShiftAdvectionCoeff = 0.0 ML_BSSN::my_initial_boundary_condition = \"extrapolate-gammas\" ML_BSSN::my_rhs_boundary_condition = \"NewRad\" init parameters 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 InitBase::initial_data_setup_method = \"init_some_levels\" # Use TOV as initial data ActiveThorns = \"TOVSolver\" HydroBase::initial_hydro = \"tov\" ADMBase::initial_data = \"tov\" ADMBase::initial_lapse = \"tov\" ADMBase::initial_shift = \"tov\" ADMBase::initial_dtlapse = \"zero\" ADMBase::initial_dtshift = \"zero\" # Parameters for initial star TOVSolver::TOV_Rho_Central[0] = 1.28e-3 TOVSolver::TOV_Gamma = 2 TOVSolver::TOV_K = 100 # Set equation of state for evolution EOS_Omni::poly_gamma = 2 EOS_Omni::poly_k = 100 EOS_Omni::gl_gamma = 2 EOS_Omni::gl_k = 100","title":"Single neutron star"},{"location":"Example/single neutron star/#parameter-file","text":"","title":"Parameter File"},{"location":"Example/single neutron star/#flesh-parameters","text":"\u65f6\u95f4\u6f14\u5316\u5230 800 \u65f6\u7ed3\u675f 1 2 Cactus::terminate = \"time\" Cactus::cctk_final_time = 800 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # Termination Trigger ActiveThorns = \"TerminationTrigger\" # Walltime in HOURS allocated for this job TerminationTrigger::max_walltime = 24 # hours # When to trigger termination in MINUTES TerminationTrigger::on_remaining_walltime = 15 # minutes # Check termination file every n timesteps TerminationTrigger::check_file_every = 512 # Termination file name TerminationTrigger::termination_file = \"TerminationTrigger.txt\" # Use termination file TerminationTrigger::termination_from_file = \"yes\" # Create an empty termination file at startup TerminationTrigger::create_termination_file = \"yes\"","title":"Flesh parameters"},{"location":"Example/single neutron star/#time-integration","text":"1 2 3 4 5 6 7 8 9 time::dtfac = 0.25 MoL::ODE_Method = \"rk4\" # Number of intermediate steps taken by the ODE method MoL::MoL_Intermediate_Steps = 4 # Number of scratch levels required by the ODE metho MoL::MoL_Num_Scratch_Levels = 1","title":"Time integration"},{"location":"Example/single neutron star/#grid-parameters","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # grid parameters Carpet::domain_from_coordbase = \"yes\" CartGrid3D::type = \"coordbase\" # Use the full domain CartGrid3D::domain = \"full\" # Don't place grid points on the coordinate origin CartGrid3D::avoid_origin = \"no\" CoordBase::xmin = 0.0 CoordBase::ymin = 0.0 CoordBase::zmin = 0.0 CoordBase::xmax = 48.0 CoordBase::ymax = 48.0 CoordBase::zmax = 48.0 # Change these parameters to change resolution. The max settings above have to be multiples of these. 'dx' is the size of one cell in x-direction. Making this smaller means using higher resolution, because more points will be used to cover the same space. CoordBase::dx = 4.0 CoordBase::dy = 4.0 CoordBase::dz = 4.0 CoordBase::boundary_size_x_lower = 3 CoordBase::boundary_size_y_lower = 3 CoordBase::boundary_size_z_lower = 3 CoordBase::boundary_size_x_upper = 3 CoordBase::boundary_size_y_upper = 3 CoordBase::boundary_size_z_upper = 3 CoordBase::boundary_shiftout_x_lower = 1 CoordBase::boundary_shiftout_y_lower = 1 CoordBase::boundary_shiftout_z_lower = 1 CoordBase::boundary_shiftout_x_upper = 0 CoordBase::boundary_shiftout_y_upper = 0 CoordBase::boundary_shiftout_z_upper = 0","title":"grid parameters"},{"location":"Example/single neutron star/#boundary","text":"1 2 3 4 5 6 7 8 9 10 ActiveThorns = \"ReflectionSymmetry\" # Reflection symmetry at the lower x boundary ReflectionSymmetry::reflection_x = \"yes\" ReflectionSymmetry::reflection_y = \"yes\" ReflectionSymmetry::reflection_z = \"yes\" # Stagger about the origin on the lower x boundary? ReflectionSymmetry::avoid_origin_x = \"no\" ReflectionSymmetry::avoid_origin_y = \"no\" ReflectionSymmetry::avoid_origin_z = \"no\"","title":"Boundary"},{"location":"Example/single neutron star/#mesh-refinement","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Carpet::enable_all_storage = no Carpet::use_buffer_zones = \"yes\" Carpet::poison_new_timelevels = \"yes\" Carpet::check_for_poison = \"no\" Carpet::init_3_timelevels = no Carpet::init_fill_timelevels = \"yes\" CarpetLib::poison_new_memory = \"yes\" CarpetLib::poison_value = 114 # system specific Carpet paramters Carpet::max_refinement_levels = 10 driver::ghost_size = 3 Carpet::prolongation_order_space = 3 Carpet::prolongation_order_time = 2 # regrid during initial data calculation only CarpetRegrid2::regrid_every = 0 # Number of refinement centres CarpetRegrid2::num_centres = 1 # Number of refinement levels for this centre CarpetRegrid2::num_levels_1 = 3 CarpetRegrid2::radius_1[1] = 24.0 CarpetRegrid2::radius_1[2] = 12.0","title":"Mesh refinement"},{"location":"Example/single neutron star/#hydro-paramters","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ActiveThorns = \"HydroBase EOS_Omni GRHydro\" HydroBase::timelevels = 3 HydroBase::evolution_method = \"GRHydro\" # Which Riemann solver to use GRHydro::riemann_solver = \"HLLE\" # Type of Equation of State P = P(rho, eps) GRHydro::GRHydro_eos_type = \"General\" # Name for the Equation of State GRHydro::GRHydro_eos_table = \"Ideal_Fluid\" # PPM reconstruction method to use GRHydro::recon_method = \"ppm\" # Width of the stencil GRHydro::GRHydro_stencil = 3 # static boundary condition to use GRHydro::bound = \"none\" # A minimum rho below which evolution is turned off GRHydro::rho_abs_min = 1.e-10 # A point is set to atmosphere in the Con2Prim's if its rho < GRHydro_rho_min *(1+GRHydro_atmo_tolerance). This avoids occasional spurious oscillations in carpet buffer zones lying in the atmosphere (because prolongation happens on conserved variables) GRHydro::GRHydro_atmo_tolerance = 1.e-3 # Order of spatial differencing of the source terms GRHydro::sources_spatial_order = 4 1 2 3 4 5 # storage and coupling TmunuBase::stress_energy_storage = yes TmunuBase::stress_energy_at_RHS = yes TmunuBase::timelevels = 1 TmunuBase::prolongation_type = none","title":"Hydro paramters"},{"location":"Example/single neutron star/#evolution-parameters","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ActiveThorns = \"GenericFD NewRad\" ActiveThorns = \"ML_BSSN ML_BSSN_Helper\" ADMBase::evolution_method = \"ML_BSSN\" ADMBase::lapse_evolution_method = \"ML_BSSN\" ADMBase::shift_evolution_method = \"ML_BSSN\" ADMBase::dtlapse_evolution_method= \"ML_BSSN\" ADMBase::dtshift_evolution_method= \"ML_BSSN\" ML_BSSN::timelevels = 3 # d/dt alpha = - f alpha^n K (harmonic: n=2, 1+log: n=1) ML_BSSN::harmonicN = 1 # 1+log # d/dt alpha = - f alpha^n K (harmonic: f=1, 1+log: f=2) ML_BSSN::harmonicF = 2.0 # 1+log # Evolve time derivative of shift B^i? ML_BSSN::ShiftBCoeff = 1 ML_BSSN::ShiftGammaCoeff = 0.75 ML_BSSN::BetaDriver = 2.66 ML_BSSN::LapseAdvectionCoeff = 0.0 ML_BSSN::ShiftAdvectionCoeff = 0.0 ML_BSSN::my_initial_boundary_condition = \"extrapolate-gammas\" ML_BSSN::my_rhs_boundary_condition = \"NewRad\"","title":"evolution parameters"},{"location":"Example/single neutron star/#init-parameters","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 InitBase::initial_data_setup_method = \"init_some_levels\" # Use TOV as initial data ActiveThorns = \"TOVSolver\" HydroBase::initial_hydro = \"tov\" ADMBase::initial_data = \"tov\" ADMBase::initial_lapse = \"tov\" ADMBase::initial_shift = \"tov\" ADMBase::initial_dtlapse = \"zero\" ADMBase::initial_dtshift = \"zero\" # Parameters for initial star TOVSolver::TOV_Rho_Central[0] = 1.28e-3 TOVSolver::TOV_Gamma = 2 TOVSolver::TOV_K = 100 # Set equation of state for evolution EOS_Omni::poly_gamma = 2 EOS_Omni::poly_k = 100 EOS_Omni::gl_gamma = 2 EOS_Omni::gl_k = 100","title":"init parameters"},{"location":"GR/Differential geometry/","text":"A well-known feature of General Relativity is that space and time are relative but events are absolute. \u201cmatter tells spacetime how to curve, and curved spacetime tells matter how to move\u201d. Manifolds Vectors We define a tangent vector \\upsilon \\upsilon at point p \\in M p \\in M to be a map \\upsilon : \\mathcal{F}_M \\rightarrow R \\upsilon : \\mathcal{F}_M \\rightarrow R Linear \\upsilon (a f + b g) = a \\upsilon (f) + b \\upsilon (g) \\upsilon (a f + b g) = a \\upsilon (f) + b \\upsilon (g) Obeys the Leibnitz rule \\upsilon (f g) = f(p) \\upsilon (g) + g(p) \\upsilon (f) \\upsilon (f g) = f(p) \\upsilon (g) + g(p) \\upsilon (f) Let M be an n-dimensional manifold. Let p \\in M p \\in M and let V_p V_p denote the tangent space at p p . Then dim \\space V_p = n dim \\space V_p = n . If f \\in \\mathcal{F} f \\in \\mathcal{F} , For \\mu = 1, ..., n \\mu = 1, ..., n define X_{\\mu} : \\mathcal{F} \\rightarrow R X_{\\mu} : \\mathcal{F} \\rightarrow R by X_{\\mu}(f):= \\frac{\\partial f(x)}{\\partial x^{\\mu}}, \\forall f \\in \\mathcal{F}_M X_{\\mu}(f):= \\frac{\\partial f(x)}{\\partial x^{\\mu}}, \\forall f \\in \\mathcal{F}_M where (x^1, ... , x^n) (x^1, ... , x^n) are the Cartesian coordinates of R^n R^n . Then X_1, \\cdots, X_n X_1, \\cdots, X_n are tangent vectors. An arbitrary tangent vector \\upsilon \\upsilon as a sum of the X_{\\mu} X_{\\mu} , \\upsilon = \\sum^n_{\\mu = 1} \\upsilon^{\\mu} X_{\\mu} \\upsilon = \\sum^n_{\\mu = 1} \\upsilon^{\\mu} X_{\\mu} Dual Vector Let V V be any finite-dimensional vector space, linear maps \\omega : V \\rightarrow R \\omega : V \\rightarrow R are called dual vectors. df|_p(\\upsilon) := \\upsilon (f), \\space \\forall \\upsilon \\in V_p df|_p(\\upsilon) := \\upsilon (f), \\space \\forall \\upsilon \\in V_p If \\frac{\\partial}{\\partial x^{\\nu}} \\frac{\\partial}{\\partial x^{\\nu}} is a basis of V V , we can define elements dx^{\\mu} dx^{\\mu} dx^{\\mu}(\\frac{\\partial}{\\partial x^{\\nu}}) = \\frac{\\partial}{\\partial x^{\\nu}}(x^{\\mu}) = \\delta^{\\mu}_{\\nu} dx^{\\mu}(\\frac{\\partial}{\\partial x^{\\nu}}) = \\frac{\\partial}{\\partial x^{\\nu}}(x^{\\mu}) = \\delta^{\\mu}_{\\nu} {dx^{\\mu}} {dx^{\\mu}} is a basis of V^{*} V^{*} . Derivative Operators A derivative operator, \\nabla \\nabla , (sometimes called a covariant derivative) on a manifold M M is a map which takes each smooth tensor field of type (k, l) (k, l) to a smooth tensor field of type (k, l + 1) (k, l + 1) . Any tow derivative operators \\nabla_a \\nabla_a and \\tilde{\\nabla}_a \\tilde{\\nabla}_a must agree in their action on scalar fields. \\nabla_a f = \\tilde{\\nabla}_a f = (df)_a, \\forall f \\in \\cal{F}_M \\nabla_a f = \\tilde{\\nabla}_a f = (df)_a, \\forall f \\in \\cal{F}_M \\tilde{\\nabla}_a - \\nabla_a \\tilde{\\nabla}_a - \\nabla_a defines a map of dual vectors at p p to tensors of type (0, 2) (0, 2) at p p . Consequently (\\tilde{\\nabla}_a - \\nabla_a) (\\tilde{\\nabla}_a - \\nabla_a) defines a tensor of type (1, 2) (1, 2) at p p , which we will denote as C^c_{\\space ab} C^c_{\\space ab} . \\nabla_a \\omega_b = \\tilde{\\nabla}_a \\omega_b - C^{c}_{ab} \\omega_c \\nabla_a \\omega_b = \\tilde{\\nabla}_a \\omega_b - C^{c}_{ab} \\omega_c C^c_{\\space ab} C^c_{\\space ab} must also have this property C^c_{\\space ab} = C^c_{\\space ba} \\\\ \\nabla_a \\upsilon^b = C^b_{\\space ac} \\upsilon^c + \\tilde{\\nabla}_a \\upsilon^b \\\\ \\nabla_a T^b_{c} = \\tilde{\\nabla}_a T^b_c + C^b_{\\space ad} T^d_c - C^{d}_{\\space ac} T^b_d C^c_{\\space ab} = C^c_{\\space ba} \\\\ \\nabla_a \\upsilon^b = C^b_{\\space ac} \\upsilon^c + \\tilde{\\nabla}_a \\upsilon^b \\\\ \\nabla_a T^b_{c} = \\tilde{\\nabla}_a T^b_c + C^b_{\\space ad} T^d_c - C^{d}_{\\space ac} T^b_d This displays the possible disagreements of the actions of \\nabla_a \\nabla_a and \\tilde{\\nabla}_a \\tilde{\\nabla}_a on Tensor. Parallel Transport Given a derivative operator \\nabla_a \\nabla_a we can define the notion of the parallel transport of a vector along a curve C C with a tangent T^a T^a . A vector \\upsilon^a \\upsilon^a given at each point on the curve is said to be parallel transported as one moves along the curve if the equation T^b \\nabla_b \\upsilon^a = 0 T^b \\nabla_b \\upsilon^a = 0 is satisfied along the curve. Given two vectors u^a u^a and \\upsilon^a \\upsilon^a , we demand that their inner product g_{ab} u^a \\upsilon^a g_{ab} u^a \\upsilon^a remain unchanged if we parallel-transport them along any curve. Thus we require 0 = T^c \\nabla_c (g_{ab} u^a \\upsilon^b) = g_{ab} u^a T^c \\nabla_c (\\upsilon^b) + g_{ab} \\upsilon^b T^c \\nabla_c (u^a) + u^a \\upsilon^b T^c \\nabla_c (g_{ab}) 0 = T^c \\nabla_c (g_{ab} u^a \\upsilon^b) = g_{ab} u^a T^c \\nabla_c (\\upsilon^b) + g_{ab} \\upsilon^b T^c \\nabla_c (u^a) + u^a \\upsilon^b T^c \\nabla_c (g_{ab}) Equation will hold for all curves and parallel transported vectors if and only if \\nabla_c (g_{ab}) = 0 \\nabla_c (g_{ab}) = 0 which is the additional condition we wish to impose on \\nabla_a \\nabla_a . We attempt to solve for C^c_{\\space ab} C^c_{\\space ab} so that the derivative operator determined by \\tilde{\\nabla}_a \\tilde{\\nabla}_a and C^c_{\\space ab} C^c_{\\space ab} will satisfy the required property. C^c_{\\space ab} = \\frac{1}{2} g^{cd} (\\partial_a g_{bd} + \\partial_b g_{ad} - \\partial_d g_{ab}) C^c_{\\space ab} = \\frac{1}{2} g^{cd} (\\partial_a g_{bd} + \\partial_b g_{ad} - \\partial_d g_{ab}) Curvature Given a derivative operator, there exists a notion of how to parallel transport a vector from p to q along a curve C. However, the vector in V_q V_q which we get by this parallel transport procedure starting from a vector in V_p V_p will, in general, depend on the choice of curve connecting them. We can use the path dependence of parallel transport to define an intrinsic notion of curvature. The failure of a vector to return to its original value when parallel transported around a small closed loop is governed by the Riemann tensor. (\\nabla_a \\nabla_b - \\nabla_b \\nabla_a) (\\nabla_a \\nabla_b - \\nabla_b \\nabla_a) defines a linear map dual vectors at p p to type (0, 3) (0, 3) tensors at p p , its action is that of a tensor of (1, 3) (1, 3) . Thus, we have shown that there exists a tensor field R_{abc}^{\\space \\space \\space d} R_{abc}^{\\space \\space \\space d} such that for all dual vector fields \\omega_c \\omega_c , we have \\nabla_a \\nabla_b \\omega_c - \\nabla_b \\nabla_a \\omega_c = R_{abc}^{\\space \\space \\space d} \\omega_c \\nabla_a \\nabla_b \\omega_c - \\nabla_b \\nabla_a \\omega_c = R_{abc}^{\\space \\space \\space d} \\omega_c Properties of the Riemann tensor: R_{abc}^{\\space \\space \\space d} = - R_{bac}^{\\space \\space \\space d} R_{abc}^{\\space \\space \\space d} = - R_{bac}^{\\space \\space \\space d} R_{[abc]}^{\\space \\space \\space \\space \\space d} = 0 R_{[abc]}^{\\space \\space \\space \\space \\space d} = 0 R_{abcd} = - R_{abdc} R_{abcd} = - R_{abdc} \\nabla_{[a}R_{bc]d}^{\\space \\space \\space e} = 0\u200b \\nabla_{[a}R_{bc]d}^{\\space \\space \\space e} = 0\u200b R_{abcd} = R_{cdab} R_{abcd} = R_{cdab} Its trace over the second and fourth (or equivalently, the first and third) indices defines the Ricci tensor, R_{ac} R_{ac} , R_{ac} = R_{abc}^{\\space \\space \\space b} R_{ac} = R_{abc}^{\\space \\space \\space b} The scalar curvature, R, is defined as the trace of the Ricci tensor: R = R_a^{\\space a} R = R_a^{\\space a} We denote the symmetric and antisymmetric parts of a tensor with brackets () and [] around indices in the usual way. For example T_{(ab)} = \\frac{1}{2} (T_{ab} + T_{ba}) \\\\ T_{[ab]} = \\frac{1}{2} (T_{ab} - T_{ba}) T_{(ab)} = \\frac{1}{2} (T_{ab} + T_{ba}) \\\\ T_{[ab]} = \\frac{1}{2} (T_{ab} - T_{ba}) To calculate the curvature by the coordinate component method, we begin by choosing a coordinate system. We express the derivative operator \\nabla_a \\nabla_a in terms of the ordinary derivative \\partial_a \\partial_a of this coordinate system and the Christoffel symbol \\Gamma^c_{\\space ab} \\Gamma^c_{\\space ab} . R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma} = \\frac{\\partial}{\\partial x^{\\nu}} \\Gamma^{\\sigma}_{\\space \\mu \\rho} - \\frac{\\partial}{\\partial x^{\\mu}} \\Gamma^{\\sigma}_{\\space \\nu \\rho} + \\sum_a (\\Gamma^{a}_{\\space \\mu \\rho} \\Gamma^{\\sigma}_{\\space a \\nu} - \\Gamma^{a}_{\\space \\nu \\rho} \\Gamma^{\\sigma}_{\\space a \\mu}) R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma} = \\frac{\\partial}{\\partial x^{\\nu}} \\Gamma^{\\sigma}_{\\space \\mu \\rho} - \\frac{\\partial}{\\partial x^{\\mu}} \\Gamma^{\\sigma}_{\\space \\nu \\rho} + \\sum_a (\\Gamma^{a}_{\\space \\mu \\rho} \\Gamma^{\\sigma}_{\\space a \\nu} - \\Gamma^{a}_{\\space \\nu \\rho} \\Gamma^{\\sigma}_{\\space a \\mu}) Thus, to calculate R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b starting from g_{ab}\u200b g_{ab}\u200b , we first obtain the components, g_{\\mu \\nu}\u200b g_{\\mu \\nu}\u200b , of the metric in our coordinate basis. We then calculate \\Gamma^{\\sigma}_{\\space \\mu \\nu}\u200b \\Gamma^{\\sigma}_{\\space \\mu \\nu}\u200b . Finally we calculate the components R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b . The Lie Derivative Consider a (non-zero) vector \ufb01eld X^{a} X^{a} in a manifold M M . We can find the integral curves x^a(\\lambda) x^a(\\lambda) (or orbits, or trajectories) of X X a by integrating the ordinary differential equations \\frac{dx^{a}}{d \\lambda} = X^a (x^a(\\lambda)) \\frac{dx^{a}}{d \\lambda} = X^a (x^a(\\lambda)) Here \\lambda\u200b \\lambda\u200b is some affine parameter. We would now like to define a derivative of a tensor \ufb01eld. This involves comparing the tensor \ufb01eld at two different points along X^a X^a , say P P and Q Q , and taking the limit as Q Q tends to P P . This is where we encounter a conceptual problem: what do we mean by comparing two tensors at two different locations in the manifold M? In order to differentiate a tensor in a tensorial manner, we therefore have to evaluate the two tensors at the same point. To do so, we have to drag one tensor to the other point before we can compare the two tensors. However, this recipe still leaves open how we drag T^a_{\\space b} T^a_{\\space b} along X^a X^a . One approach would be to parallel-transport the tensor T^a_{\\space b} T^a_{\\space b} from P P to Q Q . This idea leads to the definition of the covariant derivative. Parallel-transporting is not the only way of dragging T^a_{\\space b} T^a_{\\space b} along X^a X^a . In other words, the Lie derivative along a vector field X^a X^a measures by how much the changes in a tensor \ufb01eld along X^a X^a differ from a mere infinitesimal coordinate transformation generated by X^a X^a . Unlike the covariant derivative, the Lie derivative does not require an affine connection, and hence requires less structure. For a scalar f f , the Lie derivative naturally reduces to the partial derivative L_X f = X^b \\nabla_b f = X^b \\partial_b f L_X f = X^b \\nabla_b f = X^b \\partial_b f Note that the Lie derivative satis\ufb01es the Leibnitz rule for outer products. L_X \\upsilon^a = X^b \\nabla_b \\upsilon^a - \\upsilon^b \\nabla_b X^a = [X, \\upsilon]^a \\\\ L_X \\omega_a = X^b \\nabla_b \\omega_a + \\omega_b \\nabla_a X^b L_X \\upsilon^a = X^b \\nabla_b \\upsilon^a - \\upsilon^b \\nabla_b X^a = [X, \\upsilon]^a \\\\ L_X \\omega_a = X^b \\nabla_b \\omega_a + \\omega_b \\nabla_a X^b Killing Vectors As an important application, consider the Lie derivative along X^a X^a of a metric g_{ab} g_{ab} . L_X g_{ab} = X^c \\nabla_c g_{ab} + g_{cb} \\nabla_a X^c + g_{ca} \\nabla_b X^c L_X g_{ab} = X^c \\nabla_c g_{ab} + g_{cb} \\nabla_a X^c + g_{ca} \\nabla_b X^c If \\nabla_a \\nabla_a is compatible with the metric, the first term vanishes, and we L_X g_{ab} = \\nabla_a X_b + \\nabla_b X_a L_X g_{ab} = \\nabla_a X_b + \\nabla_b X_a A Killing vector \ufb01eld \\xi^a \\xi^a can now be de\ufb01ned by L_{\\xi} g_{ab} = 0 L_{\\xi} g_{ab} = 0 In other words, a Killing \ufb01eld \\xi_a \\xi_a generates an isometry of the spacetime, and a displacement along \\xi^a \\xi^a leaves the metric invariant. Killing's equation \\nabla^a X^b + \\nabla^b X^a = 0 \\nabla^a X^b + \\nabla^b X^a = 0 In some cases it is very easy to identify a Killing vector. If the metric components are independent of a coordinate x^i x^i , then it follows from the property that the coordinate basis vector e^a e^a is a Killing vector.","title":"Differential geometry"},{"location":"GR/Differential geometry/#manifolds","text":"","title":"Manifolds"},{"location":"GR/Differential geometry/#vectors","text":"We define a tangent vector \\upsilon \\upsilon at point p \\in M p \\in M to be a map \\upsilon : \\mathcal{F}_M \\rightarrow R \\upsilon : \\mathcal{F}_M \\rightarrow R Linear \\upsilon (a f + b g) = a \\upsilon (f) + b \\upsilon (g) \\upsilon (a f + b g) = a \\upsilon (f) + b \\upsilon (g) Obeys the Leibnitz rule \\upsilon (f g) = f(p) \\upsilon (g) + g(p) \\upsilon (f) \\upsilon (f g) = f(p) \\upsilon (g) + g(p) \\upsilon (f) Let M be an n-dimensional manifold. Let p \\in M p \\in M and let V_p V_p denote the tangent space at p p . Then dim \\space V_p = n dim \\space V_p = n . If f \\in \\mathcal{F} f \\in \\mathcal{F} , For \\mu = 1, ..., n \\mu = 1, ..., n define X_{\\mu} : \\mathcal{F} \\rightarrow R X_{\\mu} : \\mathcal{F} \\rightarrow R by X_{\\mu}(f):= \\frac{\\partial f(x)}{\\partial x^{\\mu}}, \\forall f \\in \\mathcal{F}_M X_{\\mu}(f):= \\frac{\\partial f(x)}{\\partial x^{\\mu}}, \\forall f \\in \\mathcal{F}_M where (x^1, ... , x^n) (x^1, ... , x^n) are the Cartesian coordinates of R^n R^n . Then X_1, \\cdots, X_n X_1, \\cdots, X_n are tangent vectors. An arbitrary tangent vector \\upsilon \\upsilon as a sum of the X_{\\mu} X_{\\mu} , \\upsilon = \\sum^n_{\\mu = 1} \\upsilon^{\\mu} X_{\\mu} \\upsilon = \\sum^n_{\\mu = 1} \\upsilon^{\\mu} X_{\\mu}","title":"Vectors"},{"location":"GR/Differential geometry/#dual-vector","text":"Let V V be any finite-dimensional vector space, linear maps \\omega : V \\rightarrow R \\omega : V \\rightarrow R are called dual vectors. df|_p(\\upsilon) := \\upsilon (f), \\space \\forall \\upsilon \\in V_p df|_p(\\upsilon) := \\upsilon (f), \\space \\forall \\upsilon \\in V_p If \\frac{\\partial}{\\partial x^{\\nu}} \\frac{\\partial}{\\partial x^{\\nu}} is a basis of V V , we can define elements dx^{\\mu} dx^{\\mu} dx^{\\mu}(\\frac{\\partial}{\\partial x^{\\nu}}) = \\frac{\\partial}{\\partial x^{\\nu}}(x^{\\mu}) = \\delta^{\\mu}_{\\nu} dx^{\\mu}(\\frac{\\partial}{\\partial x^{\\nu}}) = \\frac{\\partial}{\\partial x^{\\nu}}(x^{\\mu}) = \\delta^{\\mu}_{\\nu} {dx^{\\mu}} {dx^{\\mu}} is a basis of V^{*} V^{*} .","title":"Dual Vector"},{"location":"GR/Differential geometry/#derivative-operators","text":"A derivative operator, \\nabla \\nabla , (sometimes called a covariant derivative) on a manifold M M is a map which takes each smooth tensor field of type (k, l) (k, l) to a smooth tensor field of type (k, l + 1) (k, l + 1) . Any tow derivative operators \\nabla_a \\nabla_a and \\tilde{\\nabla}_a \\tilde{\\nabla}_a must agree in their action on scalar fields. \\nabla_a f = \\tilde{\\nabla}_a f = (df)_a, \\forall f \\in \\cal{F}_M \\nabla_a f = \\tilde{\\nabla}_a f = (df)_a, \\forall f \\in \\cal{F}_M \\tilde{\\nabla}_a - \\nabla_a \\tilde{\\nabla}_a - \\nabla_a defines a map of dual vectors at p p to tensors of type (0, 2) (0, 2) at p p . Consequently (\\tilde{\\nabla}_a - \\nabla_a) (\\tilde{\\nabla}_a - \\nabla_a) defines a tensor of type (1, 2) (1, 2) at p p , which we will denote as C^c_{\\space ab} C^c_{\\space ab} . \\nabla_a \\omega_b = \\tilde{\\nabla}_a \\omega_b - C^{c}_{ab} \\omega_c \\nabla_a \\omega_b = \\tilde{\\nabla}_a \\omega_b - C^{c}_{ab} \\omega_c C^c_{\\space ab} C^c_{\\space ab} must also have this property C^c_{\\space ab} = C^c_{\\space ba} \\\\ \\nabla_a \\upsilon^b = C^b_{\\space ac} \\upsilon^c + \\tilde{\\nabla}_a \\upsilon^b \\\\ \\nabla_a T^b_{c} = \\tilde{\\nabla}_a T^b_c + C^b_{\\space ad} T^d_c - C^{d}_{\\space ac} T^b_d C^c_{\\space ab} = C^c_{\\space ba} \\\\ \\nabla_a \\upsilon^b = C^b_{\\space ac} \\upsilon^c + \\tilde{\\nabla}_a \\upsilon^b \\\\ \\nabla_a T^b_{c} = \\tilde{\\nabla}_a T^b_c + C^b_{\\space ad} T^d_c - C^{d}_{\\space ac} T^b_d This displays the possible disagreements of the actions of \\nabla_a \\nabla_a and \\tilde{\\nabla}_a \\tilde{\\nabla}_a on Tensor.","title":"Derivative Operators"},{"location":"GR/Differential geometry/#parallel-transport","text":"Given a derivative operator \\nabla_a \\nabla_a we can define the notion of the parallel transport of a vector along a curve C C with a tangent T^a T^a . A vector \\upsilon^a \\upsilon^a given at each point on the curve is said to be parallel transported as one moves along the curve if the equation T^b \\nabla_b \\upsilon^a = 0 T^b \\nabla_b \\upsilon^a = 0 is satisfied along the curve. Given two vectors u^a u^a and \\upsilon^a \\upsilon^a , we demand that their inner product g_{ab} u^a \\upsilon^a g_{ab} u^a \\upsilon^a remain unchanged if we parallel-transport them along any curve. Thus we require 0 = T^c \\nabla_c (g_{ab} u^a \\upsilon^b) = g_{ab} u^a T^c \\nabla_c (\\upsilon^b) + g_{ab} \\upsilon^b T^c \\nabla_c (u^a) + u^a \\upsilon^b T^c \\nabla_c (g_{ab}) 0 = T^c \\nabla_c (g_{ab} u^a \\upsilon^b) = g_{ab} u^a T^c \\nabla_c (\\upsilon^b) + g_{ab} \\upsilon^b T^c \\nabla_c (u^a) + u^a \\upsilon^b T^c \\nabla_c (g_{ab}) Equation will hold for all curves and parallel transported vectors if and only if \\nabla_c (g_{ab}) = 0 \\nabla_c (g_{ab}) = 0 which is the additional condition we wish to impose on \\nabla_a \\nabla_a . We attempt to solve for C^c_{\\space ab} C^c_{\\space ab} so that the derivative operator determined by \\tilde{\\nabla}_a \\tilde{\\nabla}_a and C^c_{\\space ab} C^c_{\\space ab} will satisfy the required property. C^c_{\\space ab} = \\frac{1}{2} g^{cd} (\\partial_a g_{bd} + \\partial_b g_{ad} - \\partial_d g_{ab}) C^c_{\\space ab} = \\frac{1}{2} g^{cd} (\\partial_a g_{bd} + \\partial_b g_{ad} - \\partial_d g_{ab})","title":"Parallel Transport"},{"location":"GR/Differential geometry/#curvature","text":"Given a derivative operator, there exists a notion of how to parallel transport a vector from p to q along a curve C. However, the vector in V_q V_q which we get by this parallel transport procedure starting from a vector in V_p V_p will, in general, depend on the choice of curve connecting them. We can use the path dependence of parallel transport to define an intrinsic notion of curvature. The failure of a vector to return to its original value when parallel transported around a small closed loop is governed by the Riemann tensor. (\\nabla_a \\nabla_b - \\nabla_b \\nabla_a) (\\nabla_a \\nabla_b - \\nabla_b \\nabla_a) defines a linear map dual vectors at p p to type (0, 3) (0, 3) tensors at p p , its action is that of a tensor of (1, 3) (1, 3) . Thus, we have shown that there exists a tensor field R_{abc}^{\\space \\space \\space d} R_{abc}^{\\space \\space \\space d} such that for all dual vector fields \\omega_c \\omega_c , we have \\nabla_a \\nabla_b \\omega_c - \\nabla_b \\nabla_a \\omega_c = R_{abc}^{\\space \\space \\space d} \\omega_c \\nabla_a \\nabla_b \\omega_c - \\nabla_b \\nabla_a \\omega_c = R_{abc}^{\\space \\space \\space d} \\omega_c Properties of the Riemann tensor: R_{abc}^{\\space \\space \\space d} = - R_{bac}^{\\space \\space \\space d} R_{abc}^{\\space \\space \\space d} = - R_{bac}^{\\space \\space \\space d} R_{[abc]}^{\\space \\space \\space \\space \\space d} = 0 R_{[abc]}^{\\space \\space \\space \\space \\space d} = 0 R_{abcd} = - R_{abdc} R_{abcd} = - R_{abdc} \\nabla_{[a}R_{bc]d}^{\\space \\space \\space e} = 0\u200b \\nabla_{[a}R_{bc]d}^{\\space \\space \\space e} = 0\u200b R_{abcd} = R_{cdab} R_{abcd} = R_{cdab} Its trace over the second and fourth (or equivalently, the first and third) indices defines the Ricci tensor, R_{ac} R_{ac} , R_{ac} = R_{abc}^{\\space \\space \\space b} R_{ac} = R_{abc}^{\\space \\space \\space b} The scalar curvature, R, is defined as the trace of the Ricci tensor: R = R_a^{\\space a} R = R_a^{\\space a} We denote the symmetric and antisymmetric parts of a tensor with brackets () and [] around indices in the usual way. For example T_{(ab)} = \\frac{1}{2} (T_{ab} + T_{ba}) \\\\ T_{[ab]} = \\frac{1}{2} (T_{ab} - T_{ba}) T_{(ab)} = \\frac{1}{2} (T_{ab} + T_{ba}) \\\\ T_{[ab]} = \\frac{1}{2} (T_{ab} - T_{ba}) To calculate the curvature by the coordinate component method, we begin by choosing a coordinate system. We express the derivative operator \\nabla_a \\nabla_a in terms of the ordinary derivative \\partial_a \\partial_a of this coordinate system and the Christoffel symbol \\Gamma^c_{\\space ab} \\Gamma^c_{\\space ab} . R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma} = \\frac{\\partial}{\\partial x^{\\nu}} \\Gamma^{\\sigma}_{\\space \\mu \\rho} - \\frac{\\partial}{\\partial x^{\\mu}} \\Gamma^{\\sigma}_{\\space \\nu \\rho} + \\sum_a (\\Gamma^{a}_{\\space \\mu \\rho} \\Gamma^{\\sigma}_{\\space a \\nu} - \\Gamma^{a}_{\\space \\nu \\rho} \\Gamma^{\\sigma}_{\\space a \\mu}) R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma} = \\frac{\\partial}{\\partial x^{\\nu}} \\Gamma^{\\sigma}_{\\space \\mu \\rho} - \\frac{\\partial}{\\partial x^{\\mu}} \\Gamma^{\\sigma}_{\\space \\nu \\rho} + \\sum_a (\\Gamma^{a}_{\\space \\mu \\rho} \\Gamma^{\\sigma}_{\\space a \\nu} - \\Gamma^{a}_{\\space \\nu \\rho} \\Gamma^{\\sigma}_{\\space a \\mu}) Thus, to calculate R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b starting from g_{ab}\u200b g_{ab}\u200b , we first obtain the components, g_{\\mu \\nu}\u200b g_{\\mu \\nu}\u200b , of the metric in our coordinate basis. We then calculate \\Gamma^{\\sigma}_{\\space \\mu \\nu}\u200b \\Gamma^{\\sigma}_{\\space \\mu \\nu}\u200b . Finally we calculate the components R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b .","title":"Curvature"},{"location":"GR/Differential geometry/#the-lie-derivative","text":"Consider a (non-zero) vector \ufb01eld X^{a} X^{a} in a manifold M M . We can find the integral curves x^a(\\lambda) x^a(\\lambda) (or orbits, or trajectories) of X X a by integrating the ordinary differential equations \\frac{dx^{a}}{d \\lambda} = X^a (x^a(\\lambda)) \\frac{dx^{a}}{d \\lambda} = X^a (x^a(\\lambda)) Here \\lambda\u200b \\lambda\u200b is some affine parameter. We would now like to define a derivative of a tensor \ufb01eld. This involves comparing the tensor \ufb01eld at two different points along X^a X^a , say P P and Q Q , and taking the limit as Q Q tends to P P . This is where we encounter a conceptual problem: what do we mean by comparing two tensors at two different locations in the manifold M? In order to differentiate a tensor in a tensorial manner, we therefore have to evaluate the two tensors at the same point. To do so, we have to drag one tensor to the other point before we can compare the two tensors. However, this recipe still leaves open how we drag T^a_{\\space b} T^a_{\\space b} along X^a X^a . One approach would be to parallel-transport the tensor T^a_{\\space b} T^a_{\\space b} from P P to Q Q . This idea leads to the definition of the covariant derivative. Parallel-transporting is not the only way of dragging T^a_{\\space b} T^a_{\\space b} along X^a X^a . In other words, the Lie derivative along a vector field X^a X^a measures by how much the changes in a tensor \ufb01eld along X^a X^a differ from a mere infinitesimal coordinate transformation generated by X^a X^a . Unlike the covariant derivative, the Lie derivative does not require an affine connection, and hence requires less structure. For a scalar f f , the Lie derivative naturally reduces to the partial derivative L_X f = X^b \\nabla_b f = X^b \\partial_b f L_X f = X^b \\nabla_b f = X^b \\partial_b f Note that the Lie derivative satis\ufb01es the Leibnitz rule for outer products. L_X \\upsilon^a = X^b \\nabla_b \\upsilon^a - \\upsilon^b \\nabla_b X^a = [X, \\upsilon]^a \\\\ L_X \\omega_a = X^b \\nabla_b \\omega_a + \\omega_b \\nabla_a X^b L_X \\upsilon^a = X^b \\nabla_b \\upsilon^a - \\upsilon^b \\nabla_b X^a = [X, \\upsilon]^a \\\\ L_X \\omega_a = X^b \\nabla_b \\omega_a + \\omega_b \\nabla_a X^b","title":"The Lie Derivative"},{"location":"GR/Differential geometry/#killing-vectors","text":"As an important application, consider the Lie derivative along X^a X^a of a metric g_{ab} g_{ab} . L_X g_{ab} = X^c \\nabla_c g_{ab} + g_{cb} \\nabla_a X^c + g_{ca} \\nabla_b X^c L_X g_{ab} = X^c \\nabla_c g_{ab} + g_{cb} \\nabla_a X^c + g_{ca} \\nabla_b X^c If \\nabla_a \\nabla_a is compatible with the metric, the first term vanishes, and we L_X g_{ab} = \\nabla_a X_b + \\nabla_b X_a L_X g_{ab} = \\nabla_a X_b + \\nabla_b X_a A Killing vector \ufb01eld \\xi^a \\xi^a can now be de\ufb01ned by L_{\\xi} g_{ab} = 0 L_{\\xi} g_{ab} = 0 In other words, a Killing \ufb01eld \\xi_a \\xi_a generates an isometry of the spacetime, and a displacement along \\xi^a \\xi^a leaves the metric invariant. Killing's equation \\nabla^a X^b + \\nabla^b X^a = 0 \\nabla^a X^b + \\nabla^b X^a = 0 In some cases it is very easy to identify a Killing vector. If the metric components are independent of a coordinate x^i x^i , then it follows from the property that the coordinate basis vector e^a e^a is a Killing vector.","title":"Killing Vectors"},{"location":"GR/Einstein Equation/","text":"We will use geometric units. In these units, the speed of light, c, and Newton\u2019s constant G, are taken to be 1. A consequence of this is that distances, time intervals, masses, and energy all have the same units. By convention, the unit of each of these is denoted by an arbitrary mass M. The geometry of a spacetime can be entirely described by a line element \\mathrm{d} s^{2} \\mathrm{d} s^{2} . In Minkowski spacetime, in Cartesian coordinates, the line element takes the form \\mathrm{d} s^{2}=-\\mathrm{d} t^{2}+\\mathrm{d} x^{2}+\\mathrm{d} y^{2}+\\mathrm{d} z^{2} \\mathrm{d} s^{2}=-\\mathrm{d} t^{2}+\\mathrm{d} x^{2}+\\mathrm{d} y^{2}+\\mathrm{d} z^{2} Note that \\mathrm{d} s^{2} \\mathrm{d} s^{2} is not necessarily positive. For timelike paths, the proper time along the path is given by the integral of \\mathrm{d} \\tau=\\sqrt{-\\mathrm{d} s^{2}} \\mathrm{d} \\tau=\\sqrt{-\\mathrm{d} s^{2}} . Equation can be written as \\mathrm{d} s^{2}=\\eta_{\\mu \\nu} \\mathrm{d} x^{\\mu} \\mathrm{d} x^{\\nu} \\mathrm{d} s^{2}=\\eta_{\\mu \\nu} \\mathrm{d} x^{\\mu} \\mathrm{d} x^{\\nu} where x^{\\mu}=(t, x, y, z) x^{\\mu}=(t, x, y, z) and the components of the symmetric tensor \\eta_{\\mu \\nu} \\eta_{\\mu \\nu} are given by \\operatorname{diag}(-1,1,1,1) \\operatorname{diag}(-1,1,1,1) . Here we used two standard conventions, the timelike coordinate is listed first and repeated Greek indices are summed over. By convention, the index of the timelike coordinate is 0, while the spatial coordinates have indices 1, 2, 3. A geodesic is the generalization of a straight line in Euclidean space. In Cartesian coordinates, the tangent vector to a straight line is a constant. This can be expressed as \\begin{array}{l}{t^{\\mu}=\\frac{\\mathrm{d}}{\\mathrm{d} \\lambda} x^{\\mu}(\\lambda)} \\\\ {\\frac{\\mathrm{d}}{\\mathrm{d} \\lambda} t^{\\mu}(\\lambda)=0}\\end{array} \\begin{array}{l}{t^{\\mu}=\\frac{\\mathrm{d}}{\\mathrm{d} \\lambda} x^{\\mu}(\\lambda)} \\\\ {\\frac{\\mathrm{d}}{\\mathrm{d} \\lambda} t^{\\mu}(\\lambda)=0}\\end{array} where t^{\\nu} t^{\\nu} is the tangent vector to the line and x^{\\mu}(\\lambda) x^{\\mu}(\\lambda) are the Cartesian coordinates of each point of the line. The equation for a geodesic in arbitrary coordinates, as well as flat and non-flat metrics, is \\begin{array}{c}{\\frac{\\mathrm{d}}{\\mathrm{d} \\lambda} x^{\\mu}(\\lambda)=t^{\\mu}(\\lambda)} \\\\ {t^{\\mu} \\nabla_{\\mu} t^{\\nu}=0}\\end{array} \\begin{array}{c}{\\frac{\\mathrm{d}}{\\mathrm{d} \\lambda} x^{\\mu}(\\lambda)=t^{\\mu}(\\lambda)} \\\\ {t^{\\mu} \\nabla_{\\mu} t^{\\nu}=0}\\end{array} General relativity extends the notion of spacetime to include non-flat metrics, where G_{\\mu \\nu}=8 \\pi T_{\\mu \\nu} G_{\\mu \\nu}=8 \\pi T_{\\mu \\nu} and T_{\\mu \\nu} T_{\\mu \\nu} is the stress energy tensor, a measure of the total energy and momentum flux from matter and non-gravitational interactions and radiation. Evolution of matter sources In general relativity, the curvature of spacetime possess its own dynamics, and indeed one of the most important phenomena treated by numerical relativity, the merger of two black holes, is a vacuum problem. That is, T_{\\mu \\nu}=0 T_{\\mu \\nu}=0 . Numerical relativity is also used to study phenomena involving matter flows in strongly-curved dynamical spacetimes. Two problems where such relativistic effects should be particularly important are compact object mergers involving neutron stars and the formation of black holes by stellar collapse. Matter and energy constitute the stress-energy tensor T_{\\mu \\nu} T_{\\mu \\nu} that is the source term in Einstein equations. The energy and momentum conservation equations \\nabla_{\\mu} T^{\\mu \\nu}=0 \\nabla_{\\mu} T^{\\mu \\nu}=0 provide evolution equations for the matter. Perfect fluid mean the mean free path is very small compared to the system\u2019s scale, making the collection a fluid, and viscosity and heat transport are small enough to be ignored. This fluid will have a stress tensor T_{\\mu \\nu}^{\\mathrm{gas}}=\\left(\\rho_{0}+u+P\\right) u_{\\mu} u_{\\nu}+P g_{\\mu \\nu} T_{\\mu \\nu}^{\\mathrm{gas}}=\\left(\\rho_{0}+u+P\\right) u_{\\mu} u_{\\nu}+P g_{\\mu \\nu} where \\rho_{0} \\rho_{0} , u u , P P and u_{\\mu} u_{\\mu} are the rest mass density, internal energy, pressure, and 4-velocity. (Note \\rho_{0} \\rho_{0} must be distinguished from the total energy density \\rho=\\rho_{0}+u \\rho=\\rho_{0}+u ) Black Hole A black hole is de\ufb01ned as a region of spacetime from which no null geodesic can escape to infinity. The surface of a black hole, the event horizon, acts as a one-way membrane through which light and matter can enter the black hole, but once inside, can never escape. It is the boundary in spacetime separating those events that can emit light rays that can propagate to infinity and those which cannot. More precisely, the event horizon is de\ufb01ned as the boundary of the causal past of future null infinity. It is a 2 + 1 dimensional hypersurface in spacetime formed by those outward-going, future-directed null geodesics that neither escape to infinity nor fall toward the center of the black hole. The event horizon is a gauge-invariant entity, and contains important geometric information about a black hole spacetime. The most general stationary black hole solution to Einstein\u2019s equations is the analytically known Kerr-Newman metric. It is uniquely specified by just three parameters: the mass M, angular momentum J and the charge Q of the black hole . Special cases are the Kerr metric (Q = 0), the Reissner-Nordstrom metric (J = 0) and the Schwarzschild metric (J = 0, Q = 0). Perhaps one of the most interesting predictions of general relativity is the existence of black holes. A black hole can be completely described by two parameters: its mass and spin. In geometric units the magnitude of the spin angular momentum S is bounded by the mass m, where S<m^{2} S<m^{2} . Typically one defines a specific spin a, where a=S / m a=S / m and a dimensionless spin \\chi \\chi , where \\chi=S / m^{2} \\chi=S / m^{2} . If the black hole is non-spinning, it is known as a Schwarzschild black hole, and if S is non-zero, it is known as a Kerr black hole. A black hole has no material surface, of course, but there is a boundary separating the region from which it is impossible ever to escape (the black hole interior) to the outside universe. This boundary is called the event horizon. In practice, numerical relativists find event horizons by evolving a cluster of null geodesics. We will see that some methods of numerically handling black hole interiors (excision methods) require some knowledge of the horizon location during the simulation. For these purposes, numerical relativists use the apparent horizon. Apparent horizons are two-dimensional surfaces that may exist at each time in a numerical simulation. They are defined to be surfaces from which outward-pointing null rays do not expand. This very unusual situation can only occur in the vicinity of a black hole, but finding such surfaces only requires information about the metric and extrinsic curvature at a given time. For a stationary black hole, the apparent horizon will coincide with the event horizon; in a dynamical spacetime, it will be inside the event horizon. Schwarzschild Black Holes The Schwarzschild solution for a vacuum spherical spacetime may be written as d s ^ { 2 } = - \\left( 1 - \\frac { 2 M } { r } \\right) d t ^ { 2 } + \\left( 1 - \\frac { 2 M } { r } \\right) ^ { - 1 } d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } d s ^ { 2 } = - \\left( 1 - \\frac { 2 M } { r } \\right) d t ^ { 2 } + \\left( 1 - \\frac { 2 M } { r } \\right) ^ { - 1 } d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } The black hole event horizon is located at r = 2M r = 2M and is sometimes called the Schwarzschild radius. It is also referred to as the \u201cstatic limit\u201d, because static observers cannot exist inside r = 2M r = 2M , and the \u201csurface of infinite redshift\u201d, because photons emitted by a static source just outside r = 2M r = 2M will have infinite wavelength when measured by a static observer at infinity. Circular orbits of test particles exist down to r = 3M r = 3M . The singularity in the metric at r = 2M r = 2M is a coordinate singularity, removable by coordinate transformation , while the singularity at r = 0 r = 0 is a physical spacetime singularity. In fact, the curvature invariant I \\equiv {}^ { ( 4 ) } R _ { a b c d } {}^ { ( 4 ) } R ^ { a b c d } = 48 M ^ { 2 } / r ^ { 6 } I \\equiv {}^ { ( 4 ) } R _ { a b c d } {}^ { ( 4 ) } R ^ { a b c d } = 48 M ^ { 2 } / r ^ { 6 } clearly blows up at the origin, showing that the tidal gravitational field becomes infinite at the center of the black hole. Note One alternative coordinate choice that removes the coordinate singularity at r = 2M r = 2M is the Kruskal-Szekeres coordinate system. d s ^ { 2 } = \\frac { 32 M ^ { 3 } } { r } e ^ { - r / 2 M } \\left( - d v ^ { 2 } + d u ^ { 2 } \\right) + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } d s ^ { 2 } = \\frac { 32 M ^ { 3 } } { r } e ^ { - r / 2 M } \\left( - d v ^ { 2 } + d u ^ { 2 } \\right) + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } The original Schwarzschild coordinate system covers only half of the spacetime manifold, while Kruskal-Szekeres coordinates cover the entire manifold. Kerr Black Holes The solution to Einstein\u2019s equations describing a stationary, rotating, uncharged black hole of mass M and angular momentum J in vacuum may be expressed in Boyer-Lindquist coordinates in the form d s ^ { 2 } = - \\left( 1 - \\frac { 2 M r } { \\Sigma } \\right) d t ^ { 2 } - \\frac { 4 a M r \\sin ^ { 2 } \\theta } { \\Sigma } d t d \\phi + \\frac { \\Sigma } { \\Delta } d r ^ { 2 } + \\Sigma d \\theta ^ { 2 } + \\left( r ^ { 2 } + a ^ { 2 } + \\frac { 2 a ^ { 2 } M r \\sin ^ { 2 } \\theta } { \\Sigma } \\right) \\sin ^ { 2 } \\theta d \\phi ^ { 2 } d s ^ { 2 } = - \\left( 1 - \\frac { 2 M r } { \\Sigma } \\right) d t ^ { 2 } - \\frac { 4 a M r \\sin ^ { 2 } \\theta } { \\Sigma } d t d \\phi + \\frac { \\Sigma } { \\Delta } d r ^ { 2 } + \\Sigma d \\theta ^ { 2 } + \\left( r ^ { 2 } + a ^ { 2 } + \\frac { 2 a ^ { 2 } M r \\sin ^ { 2 } \\theta } { \\Sigma } \\right) \\sin ^ { 2 } \\theta d \\phi ^ { 2 } where a \\equiv J / M , \\quad \\Delta \\equiv r ^ { 2 } - 2 M r + a ^ { 2 } , \\quad \\Sigma \\equiv r ^ { 2 } + a ^ { 2 } \\cos ^ { 2 } \\theta a \\equiv J / M , \\quad \\Delta \\equiv r ^ { 2 } - 2 M r + a ^ { 2 } , \\quad \\Sigma \\equiv r ^ { 2 } + a ^ { 2 } \\cos ^ { 2 } \\theta The horizon of the black hole is located at r_+ r_+ , the largest root of the equation \u2206 = 0 \u2206 = 0 , r _ { + } = M + \\left( M ^ { 2 } - a ^ { 2 } \\right) ^ { 1 / 2 } r _ { + } = M + \\left( M ^ { 2 } - a ^ { 2 } \\right) ^ { 1 / 2 } The static limit is the surface within which no static observers exist; it resides at r_0 r_0 , the largest root of g_{tt} = 0 g_{tt} = 0 : r _ { 0 } = M + \\left( M ^ { 2 } - a ^ { 2 } \\cos ^ { 2 } \\theta \\right) ^ { 1 / 2 } r _ { 0 } = M + \\left( M ^ { 2 } - a ^ { 2 } \\cos ^ { 2 } \\theta \\right) ^ { 1 / 2 } The region between the horizon and static limit is called the ergosphere; in this region all time-like observers are dragged around the hole with angular velocity \u03a9 > 0 \u03a9 > 0 . Innermost stable circular orbit The Innermost stable circular orbit (often called the ISCO ) is the smallest circular orbit in which a test particle can stably orbit a massive object in general relativity. The location of the ISCO, the ISCO-radius ( r_{isco} r_{isco} ), depends on the angular momentum (spin) of the central object. The ISCO plays an important role in black hole accretion disks since it marks the inner edge of the disk . For a non-spinning massive object, the ISCO is located at, r_{isco} = \\frac{6 G M}{c^2} = 3 R_S r_{isco} = \\frac{6 G M}{c^2} = 3 R_S For a rotating black holes Global Theorems In an isolated system, the sum of the surface areas of all black holes can never decrease. Schwarzschild black hole The fact that the event horizon area cannot decrease motivates the definition of the irreducible mass M_{irr} = (\\frac{\\mathcal{A}}{16 \\pi})^{\\frac{1}{2}} M_{irr} = (\\frac{\\mathcal{A}}{16 \\pi})^{\\frac{1}{2}} The definition then implies that the irreducible mass of the black hole cannot decrease, which motivates its name. The area theorem can be used to place a strict upper limit on the amount of energy that is emitted in gravitational radiation in black hole collisions. Example Consider two widely separated, non-rotating black holes of masses M_1 M_1 and M_2 M_2 , initially at rest with respect to some distant observer. Use the area theorem to find an upper limit on the energy emitted in gravitational radiation that arises from the head-on collision of the two black holes. Verify that for equal mass black holes at most 29% of the total initial energy can be emitted in gravitational radiation. Kerr black holes Given the irreducible mass M_{irr} M_{irr} and the angular momentum J of an isolated, stationary black hole, we can compute the Kerr mass M ( = M_{ADM} = M_{ADM} ) from M^2 = M^2_{irr} + \\frac{1}{4} \\frac{J^2}{M^2_{irr}} M^2 = M^2_{irr} + \\frac{1}{4} \\frac{J^2}{M^2_{irr}} According to the area theorem, only the rotational energy contribution can be tapped as a source of energy by an external system interacting with the hole, since the irreducible mass can never decrease. Alternative Theories of Gravity The simplest scenario that one could consider in this context is the addition of an extra scalar \ufb01eld, but one might also choose to consider extra vectors, tensors, or even higher rank fields. Of course, the effect of such additional \ufb01eld needs to be suppressed at scales where General Relativity has been well tested, such as in the lab or solar system . Scalar-Tensor Theories A general form of the scalar-tensor theory can be derived from the Lagrangian density \\mathcal{L}=\\frac{1}{16 \\pi } \\sqrt{-g} \\left[ f\\left( \\phi \\right) R-g\\left( \\phi \\right) \\nabla _{\\mu }\\phi \\nabla ^{\\mu }\\phi -2\\Lambda \\left( \\phi \\right) \\right] +\\mathcal{L}_{m}\\left( \\psi ,h\\left( \\phi \\right) g_{\\mu \\nu}\\right) \\mathcal{L}=\\frac{1}{16 \\pi } \\sqrt{-g} \\left[ f\\left( \\phi \\right) R-g\\left( \\phi \\right) \\nabla _{\\mu }\\phi \\nabla ^{\\mu }\\phi -2\\Lambda \\left( \\phi \\right) \\right] +\\mathcal{L}_{m}\\left( \\psi ,h\\left( \\phi \\right) g_{\\mu \\nu}\\right) \\mathcal{L}_m \\mathcal{L}_m is the Lagrangian density of the matter fields \\psi \\psi .","title":"Einstein Equation"},{"location":"GR/Einstein Equation/#evolution-of-matter-sources","text":"In general relativity, the curvature of spacetime possess its own dynamics, and indeed one of the most important phenomena treated by numerical relativity, the merger of two black holes, is a vacuum problem. That is, T_{\\mu \\nu}=0 T_{\\mu \\nu}=0 . Numerical relativity is also used to study phenomena involving matter flows in strongly-curved dynamical spacetimes. Two problems where such relativistic effects should be particularly important are compact object mergers involving neutron stars and the formation of black holes by stellar collapse. Matter and energy constitute the stress-energy tensor T_{\\mu \\nu} T_{\\mu \\nu} that is the source term in Einstein equations. The energy and momentum conservation equations \\nabla_{\\mu} T^{\\mu \\nu}=0 \\nabla_{\\mu} T^{\\mu \\nu}=0 provide evolution equations for the matter. Perfect fluid mean the mean free path is very small compared to the system\u2019s scale, making the collection a fluid, and viscosity and heat transport are small enough to be ignored. This fluid will have a stress tensor T_{\\mu \\nu}^{\\mathrm{gas}}=\\left(\\rho_{0}+u+P\\right) u_{\\mu} u_{\\nu}+P g_{\\mu \\nu} T_{\\mu \\nu}^{\\mathrm{gas}}=\\left(\\rho_{0}+u+P\\right) u_{\\mu} u_{\\nu}+P g_{\\mu \\nu} where \\rho_{0} \\rho_{0} , u u , P P and u_{\\mu} u_{\\mu} are the rest mass density, internal energy, pressure, and 4-velocity. (Note \\rho_{0} \\rho_{0} must be distinguished from the total energy density \\rho=\\rho_{0}+u \\rho=\\rho_{0}+u )","title":"Evolution of matter sources"},{"location":"GR/Einstein Equation/#black-hole","text":"A black hole is de\ufb01ned as a region of spacetime from which no null geodesic can escape to infinity. The surface of a black hole, the event horizon, acts as a one-way membrane through which light and matter can enter the black hole, but once inside, can never escape. It is the boundary in spacetime separating those events that can emit light rays that can propagate to infinity and those which cannot. More precisely, the event horizon is de\ufb01ned as the boundary of the causal past of future null infinity. It is a 2 + 1 dimensional hypersurface in spacetime formed by those outward-going, future-directed null geodesics that neither escape to infinity nor fall toward the center of the black hole. The event horizon is a gauge-invariant entity, and contains important geometric information about a black hole spacetime. The most general stationary black hole solution to Einstein\u2019s equations is the analytically known Kerr-Newman metric. It is uniquely specified by just three parameters: the mass M, angular momentum J and the charge Q of the black hole . Special cases are the Kerr metric (Q = 0), the Reissner-Nordstrom metric (J = 0) and the Schwarzschild metric (J = 0, Q = 0). Perhaps one of the most interesting predictions of general relativity is the existence of black holes. A black hole can be completely described by two parameters: its mass and spin. In geometric units the magnitude of the spin angular momentum S is bounded by the mass m, where S<m^{2} S<m^{2} . Typically one defines a specific spin a, where a=S / m a=S / m and a dimensionless spin \\chi \\chi , where \\chi=S / m^{2} \\chi=S / m^{2} . If the black hole is non-spinning, it is known as a Schwarzschild black hole, and if S is non-zero, it is known as a Kerr black hole. A black hole has no material surface, of course, but there is a boundary separating the region from which it is impossible ever to escape (the black hole interior) to the outside universe. This boundary is called the event horizon. In practice, numerical relativists find event horizons by evolving a cluster of null geodesics. We will see that some methods of numerically handling black hole interiors (excision methods) require some knowledge of the horizon location during the simulation. For these purposes, numerical relativists use the apparent horizon. Apparent horizons are two-dimensional surfaces that may exist at each time in a numerical simulation. They are defined to be surfaces from which outward-pointing null rays do not expand. This very unusual situation can only occur in the vicinity of a black hole, but finding such surfaces only requires information about the metric and extrinsic curvature at a given time. For a stationary black hole, the apparent horizon will coincide with the event horizon; in a dynamical spacetime, it will be inside the event horizon.","title":"Black Hole"},{"location":"GR/Einstein Equation/#schwarzschild-black-holes","text":"The Schwarzschild solution for a vacuum spherical spacetime may be written as d s ^ { 2 } = - \\left( 1 - \\frac { 2 M } { r } \\right) d t ^ { 2 } + \\left( 1 - \\frac { 2 M } { r } \\right) ^ { - 1 } d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } d s ^ { 2 } = - \\left( 1 - \\frac { 2 M } { r } \\right) d t ^ { 2 } + \\left( 1 - \\frac { 2 M } { r } \\right) ^ { - 1 } d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } The black hole event horizon is located at r = 2M r = 2M and is sometimes called the Schwarzschild radius. It is also referred to as the \u201cstatic limit\u201d, because static observers cannot exist inside r = 2M r = 2M , and the \u201csurface of infinite redshift\u201d, because photons emitted by a static source just outside r = 2M r = 2M will have infinite wavelength when measured by a static observer at infinity. Circular orbits of test particles exist down to r = 3M r = 3M . The singularity in the metric at r = 2M r = 2M is a coordinate singularity, removable by coordinate transformation , while the singularity at r = 0 r = 0 is a physical spacetime singularity. In fact, the curvature invariant I \\equiv {}^ { ( 4 ) } R _ { a b c d } {}^ { ( 4 ) } R ^ { a b c d } = 48 M ^ { 2 } / r ^ { 6 } I \\equiv {}^ { ( 4 ) } R _ { a b c d } {}^ { ( 4 ) } R ^ { a b c d } = 48 M ^ { 2 } / r ^ { 6 } clearly blows up at the origin, showing that the tidal gravitational field becomes infinite at the center of the black hole. Note One alternative coordinate choice that removes the coordinate singularity at r = 2M r = 2M is the Kruskal-Szekeres coordinate system. d s ^ { 2 } = \\frac { 32 M ^ { 3 } } { r } e ^ { - r / 2 M } \\left( - d v ^ { 2 } + d u ^ { 2 } \\right) + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } d s ^ { 2 } = \\frac { 32 M ^ { 3 } } { r } e ^ { - r / 2 M } \\left( - d v ^ { 2 } + d u ^ { 2 } \\right) + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } The original Schwarzschild coordinate system covers only half of the spacetime manifold, while Kruskal-Szekeres coordinates cover the entire manifold.","title":"Schwarzschild Black Holes"},{"location":"GR/Einstein Equation/#kerr-black-holes","text":"The solution to Einstein\u2019s equations describing a stationary, rotating, uncharged black hole of mass M and angular momentum J in vacuum may be expressed in Boyer-Lindquist coordinates in the form d s ^ { 2 } = - \\left( 1 - \\frac { 2 M r } { \\Sigma } \\right) d t ^ { 2 } - \\frac { 4 a M r \\sin ^ { 2 } \\theta } { \\Sigma } d t d \\phi + \\frac { \\Sigma } { \\Delta } d r ^ { 2 } + \\Sigma d \\theta ^ { 2 } + \\left( r ^ { 2 } + a ^ { 2 } + \\frac { 2 a ^ { 2 } M r \\sin ^ { 2 } \\theta } { \\Sigma } \\right) \\sin ^ { 2 } \\theta d \\phi ^ { 2 } d s ^ { 2 } = - \\left( 1 - \\frac { 2 M r } { \\Sigma } \\right) d t ^ { 2 } - \\frac { 4 a M r \\sin ^ { 2 } \\theta } { \\Sigma } d t d \\phi + \\frac { \\Sigma } { \\Delta } d r ^ { 2 } + \\Sigma d \\theta ^ { 2 } + \\left( r ^ { 2 } + a ^ { 2 } + \\frac { 2 a ^ { 2 } M r \\sin ^ { 2 } \\theta } { \\Sigma } \\right) \\sin ^ { 2 } \\theta d \\phi ^ { 2 } where a \\equiv J / M , \\quad \\Delta \\equiv r ^ { 2 } - 2 M r + a ^ { 2 } , \\quad \\Sigma \\equiv r ^ { 2 } + a ^ { 2 } \\cos ^ { 2 } \\theta a \\equiv J / M , \\quad \\Delta \\equiv r ^ { 2 } - 2 M r + a ^ { 2 } , \\quad \\Sigma \\equiv r ^ { 2 } + a ^ { 2 } \\cos ^ { 2 } \\theta The horizon of the black hole is located at r_+ r_+ , the largest root of the equation \u2206 = 0 \u2206 = 0 , r _ { + } = M + \\left( M ^ { 2 } - a ^ { 2 } \\right) ^ { 1 / 2 } r _ { + } = M + \\left( M ^ { 2 } - a ^ { 2 } \\right) ^ { 1 / 2 } The static limit is the surface within which no static observers exist; it resides at r_0 r_0 , the largest root of g_{tt} = 0 g_{tt} = 0 : r _ { 0 } = M + \\left( M ^ { 2 } - a ^ { 2 } \\cos ^ { 2 } \\theta \\right) ^ { 1 / 2 } r _ { 0 } = M + \\left( M ^ { 2 } - a ^ { 2 } \\cos ^ { 2 } \\theta \\right) ^ { 1 / 2 } The region between the horizon and static limit is called the ergosphere; in this region all time-like observers are dragged around the hole with angular velocity \u03a9 > 0 \u03a9 > 0 .","title":"Kerr Black Holes"},{"location":"GR/Einstein Equation/#innermost-stable-circular-orbit","text":"The Innermost stable circular orbit (often called the ISCO ) is the smallest circular orbit in which a test particle can stably orbit a massive object in general relativity. The location of the ISCO, the ISCO-radius ( r_{isco} r_{isco} ), depends on the angular momentum (spin) of the central object. The ISCO plays an important role in black hole accretion disks since it marks the inner edge of the disk . For a non-spinning massive object, the ISCO is located at, r_{isco} = \\frac{6 G M}{c^2} = 3 R_S r_{isco} = \\frac{6 G M}{c^2} = 3 R_S For a rotating black holes","title":"Innermost stable circular orbit"},{"location":"GR/Einstein Equation/#global-theorems","text":"In an isolated system, the sum of the surface areas of all black holes can never decrease.","title":"Global Theorems"},{"location":"GR/Einstein Equation/#schwarzschild-black-hole","text":"The fact that the event horizon area cannot decrease motivates the definition of the irreducible mass M_{irr} = (\\frac{\\mathcal{A}}{16 \\pi})^{\\frac{1}{2}} M_{irr} = (\\frac{\\mathcal{A}}{16 \\pi})^{\\frac{1}{2}} The definition then implies that the irreducible mass of the black hole cannot decrease, which motivates its name. The area theorem can be used to place a strict upper limit on the amount of energy that is emitted in gravitational radiation in black hole collisions. Example Consider two widely separated, non-rotating black holes of masses M_1 M_1 and M_2 M_2 , initially at rest with respect to some distant observer. Use the area theorem to find an upper limit on the energy emitted in gravitational radiation that arises from the head-on collision of the two black holes. Verify that for equal mass black holes at most 29% of the total initial energy can be emitted in gravitational radiation.","title":"Schwarzschild black hole"},{"location":"GR/Einstein Equation/#kerr-black-holes_1","text":"Given the irreducible mass M_{irr} M_{irr} and the angular momentum J of an isolated, stationary black hole, we can compute the Kerr mass M ( = M_{ADM} = M_{ADM} ) from M^2 = M^2_{irr} + \\frac{1}{4} \\frac{J^2}{M^2_{irr}} M^2 = M^2_{irr} + \\frac{1}{4} \\frac{J^2}{M^2_{irr}} According to the area theorem, only the rotational energy contribution can be tapped as a source of energy by an external system interacting with the hole, since the irreducible mass can never decrease.","title":"Kerr black holes"},{"location":"GR/Einstein Equation/#alternative-theories-of-gravity","text":"The simplest scenario that one could consider in this context is the addition of an extra scalar \ufb01eld, but one might also choose to consider extra vectors, tensors, or even higher rank fields. Of course, the effect of such additional \ufb01eld needs to be suppressed at scales where General Relativity has been well tested, such as in the lab or solar system .","title":"Alternative Theories of Gravity"},{"location":"GR/Einstein Equation/#scalar-tensor-theories","text":"A general form of the scalar-tensor theory can be derived from the Lagrangian density \\mathcal{L}=\\frac{1}{16 \\pi } \\sqrt{-g} \\left[ f\\left( \\phi \\right) R-g\\left( \\phi \\right) \\nabla _{\\mu }\\phi \\nabla ^{\\mu }\\phi -2\\Lambda \\left( \\phi \\right) \\right] +\\mathcal{L}_{m}\\left( \\psi ,h\\left( \\phi \\right) g_{\\mu \\nu}\\right) \\mathcal{L}=\\frac{1}{16 \\pi } \\sqrt{-g} \\left[ f\\left( \\phi \\right) R-g\\left( \\phi \\right) \\nabla _{\\mu }\\phi \\nabla ^{\\mu }\\phi -2\\Lambda \\left( \\phi \\right) \\right] +\\mathcal{L}_{m}\\left( \\psi ,h\\left( \\phi \\right) g_{\\mu \\nu}\\right) \\mathcal{L}_m \\mathcal{L}_m is the Lagrangian density of the matter fields \\psi \\psi .","title":"Scalar-Tensor Theories"},{"location":"GR/Solutions/","text":"The gravitational equilibrium of masses of neutrons 1 We study the gravitational equilibrium of masses of neutrons, using the equation of state for a cold Fermi gas, and general relativity . Whether there is an upper limit to the possible size of such a neutron core? Landau showed that for a model consisting of a cold degenerate Fermi gas there exist no stable equilibrium configurations for masses greater than a certain critical mass, all larger masses tending to collapse. Relativistic Treatment Of Equilibrium The most general static line element exhibiting spherical symmetry may be expressed in the form ds^2 = - e^{\\lambda} dr^2 - r^2 d \\theta^2 - r^2 sin^2 \\theta d \\phi^2 + e^{\\nu} dt^2 \\\\ \\lambda = \\lambda (r), \\nu = \\nu (r). ds^2 = - e^{\\lambda} dr^2 - r^2 d \\theta^2 - r^2 sin^2 \\theta d \\phi^2 + e^{\\nu} dt^2 \\\\ \\lambda = \\lambda (r), \\nu = \\nu (r). If the matter supports no transverse stresses and has no mass motion, then its energy momentum tensor is given by T^{\\space 1}_{1} = T^{\\space 2}_{2} = T^{\\space 3}_{3} = - P, \\space T^{\\space 4}_{4} = \\rho T^{\\space 1}_{1} = T^{\\space 2}_{2} = T^{\\space 3}_{3} = - P, \\space T^{\\space 4}_{4} = \\rho where p and \\rho \\rho are respectively the pressure and the macroscopic energy density measured in proper coordinates. The cosmological constant \\Lambda \\Lambda taken equal to zero, Einstein's field equations reduce to: 8 \\pi P = e^{-\\lambda} (\\frac{\\nu'}{r} + \\frac{1}{r^2}) - \\frac{1}{r^2} \\\\ 8 \\pi \\rho = e^{-\\lambda} (\\frac{\\lambda'}{r} - \\frac{1}{r^2}) + \\frac{1}{r^2} \\\\ \\frac{dP}{dr} = - \\frac{(P + \\rho)}{2} \\nu' 8 \\pi P = e^{-\\lambda} (\\frac{\\nu'}{r} + \\frac{1}{r^2}) - \\frac{1}{r^2} \\\\ 8 \\pi \\rho = e^{-\\lambda} (\\frac{\\lambda'}{r} - \\frac{1}{r^2}) + \\frac{1}{r^2} \\\\ \\frac{dP}{dr} = - \\frac{(P + \\rho)}{2} \\nu' where primes denote differentiation with respect to r. These three equations together with the equation of state of the material \\rho = \\rho (P) \\rho = \\rho (P) determine the mechanical equilibrium of the matter distribution. The boundary of the matter distribution is the value of r = r_b r = r_b for which P = 0 P = 0 , and such that for value r < r_b r < r_b where P > O P > O . In empty space surrounding the spherically symmetric distribution of matter P = \\rho = 0 P = \\rho = 0 , and Schwarzschild's exterior solution is obtained: e^{-\\lambda} = 1 + \\frac{A}{r} \\\\ e^{\\nu} = B (1 + \\frac{A}{r}) e^{-\\lambda} = 1 + \\frac{A}{r} \\\\ e^{\\nu} = B (1 + \\frac{A}{r}) The constants A and 8 are fixed by the requirement that at great distances away from the matter distribution the g_{\\mu \\nu} g_{\\mu \\nu} must go over into their weak-field form, i.e., B = 1 B = 1 , A = - 2m A = - 2m where m is the total Newtonian mass of the matter as calculated by a distant observer. Further introduce a new variable u(r) = \\frac{1}{2} r (1 - e^{-\\lambda}) u(r) = \\frac{1}{2} r (1 - e^{-\\lambda}) Then above equations becomes: e^{\\nu(r)} = (1 - \\frac{2m}{r_b}) e^{- \\int_0^{P(r)} \\frac{2dP}{P + \\rho(P)}} \\\\ \\frac{du}{dr} = 4 \\pi \\rho(P) r^2 \\\\ \\frac{dP}{dr} = - \\frac{P + \\rho(P)}{r(r - 2 u)}(4 \\pi P r^3 + u) e^{\\nu(r)} = (1 - \\frac{2m}{r_b}) e^{- \\int_0^{P(r)} \\frac{2dP}{P + \\rho(P)}} \\\\ \\frac{du}{dr} = 4 \\pi \\rho(P) r^2 \\\\ \\frac{dP}{dr} = - \\frac{P + \\rho(P)}{r(r - 2 u)}(4 \\pi P r^3 + u) From this equation we can see that u is very similar to m. Starting with some initial values u = u_0 u = u_0 , P = P_0 P = P_0 at r = 0 r = 0 , the two equations are integrated simultaneously to the value r = r_b r = r_b where P = O P = O , until the boundary of the matter distribution is reached. The value of u = u_b u = u_b at r = r_b r = r_b determines the value of e^{\\lambda(r_b)} e^{\\lambda(r_b)} at the boundary, and this is joined continuously across the boundary to the exterior solution, making u_b = m u_b = m Thus the mass of this spherical distribution of matter as measured by a distant observer is given by the value u_b u_b of u at r = r_b r = r_b . The following restrictions must be made on the choice of P_0 P_0 and u_0 u_0 , the initial values of P and u at r = 0 r = 0 . Particular Equations Of State The above arguments show that \\frac{du}{dr} \\frac{du}{dr} and \\frac{dP}{dr} \\frac{dP}{dr} together with a given equation of state completely determine the distribution of matter. If the matter is taken to consist of particles of rest mass \\mu_0 \\mu_0 obeying Fermi statistics, and their thermal energy and all forces between them are neglected, then it may be shown that a parametric form for the equation of state is: \\rho = K (sinht - t) \\\\ P = \\frac{1}{3} K (sinht - 8 sinh(\\frac{1}{2}t) + 3 t) \\rho = K (sinht - t) \\\\ P = \\frac{1}{3} K (sinht - 8 sinh(\\frac{1}{2}t) + 3 t) where K = \\frac{\\pi \\mu_0^4 c^5}{4 h^3} \\\\ t = 4 log(\\frac{\\widehat{P}}{\\mu_0 c} + [1 + (\\frac{\\widehat{P}}{\\mu_0 c})^2]^{\\frac{1}{2}}) K = \\frac{\\pi \\mu_0^4 c^5}{4 h^3} \\\\ t = 4 log(\\frac{\\widehat{P}}{\\mu_0 c} + [1 + (\\frac{\\widehat{P}}{\\mu_0 c})^2]^{\\frac{1}{2}}) where \\widehat{P} \\widehat{P} is the maximum momentum in the Fermi distribution and is related to the proper particle density \\frac{N}{V} \\frac{N}{V} by \\frac{N}{V} = \\frac{8 \\pi}{3 h^3} \\widehat{P}^3 \\frac{N}{V} = \\frac{8 \\pi}{3 h^3} \\widehat{P}^3 the uncertainty of a particle in space is \\frac{V}{N} \\frac{V}{N} , and the uncertainty in momentum space is 2\\frac{4 \\pi}{3} \\widehat{P}^3 2\\frac{4 \\pi}{3} \\widehat{P}^3 . so \\frac{V}{N} \\times 2\\frac{4 \\pi}{3} \\widehat{P}^3 = h^3 \\frac{V}{N} \\times 2\\frac{4 \\pi}{3} \\widehat{P}^3 = h^3 . The above equations become: \\frac{du}{dr} = 4 \\pi r^2 K (sinht - t) \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} \\frac{sinht - 2 sinh(\\frac{1}{2}t)}{cosht - 4 cosh(\\frac{1}{2}t) + 3}[\\frac{4}{3} \\pi K r^3 (sinht - 8 sinh(\\frac{1}{2}t) + 3t) + u] \\frac{du}{dr} = 4 \\pi r^2 K (sinht - t) \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} \\frac{sinht - 2 sinh(\\frac{1}{2}t)}{cosht - 4 cosh(\\frac{1}{2}t) + 3}[\\frac{4}{3} \\pi K r^3 (sinht - 8 sinh(\\frac{1}{2}t) + 3t) + u] These equations are to be integrated from the values u = 0 u = 0 , t = t_0 t = t_0 at r = 0 r = 0 to r = r_b r = r_b where t_b = 0 t_b = 0 (which makes P = 0 P = 0 ), and u = u_0 u = u_0 . No way was found to carry out the integration analytically, so equations were integrated numerically for several finite values of t_0 t_0 . For all these cases u_0 u_0 was taken to be equal to zero, since the equation of state near the origin for finite t_0 t_0 behaves like \\rho(P) = K P^s \\rho(P) = K P^s , s < 1 s < 1 . For very small values of t the equation of state reduces to P = K \\rho^{\\frac{5}{3}} P = K \\rho^{\\frac{5}{3}} and \\widehat{P} \\propto t \\widehat{P} \\propto t . Using this equation of state and Newtonian gravitational theory (which is expected to give a good result for small masses and densities), one finds that m \\propto t^{\\frac{3}{2}} m \\propto t^{\\frac{3}{2}} . Foe t_0 \\to \\infty t_0 \\to \\infty , Equation may be replaced by their expressions: \\frac{du}{dr} = \\frac{1}{2} r^2 e^t \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} (\\frac{r^3}{6}e^t + u) \\frac{du}{dr} = \\frac{1}{2} r^2 e^t \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} (\\frac{r^3}{6}e^t + u) An exact solution of these equations is: e^t = \\frac{3}{7r^2} \\\\ u = \\frac{3r}{14} e^t = \\frac{3}{7r^2} \\\\ u = \\frac{3r}{14} Then the mass carried out to r = r_b r = r_b where t = 0 t = 0 . The striking feature of the curve is that the mass increases with increasing t_0 t_0 until a maximum is reached at about t_0 =3 t_0 =3 , after which the curve drops until a value roughly \\frac{1}{3} \\odot \\frac{1}{3} \\odot is reached for t_0 = \\infty t_0 = \\infty . In other words no static solutions at all exist for m > \\frac{3}{4} \\odot m > \\frac{3}{4} \\odot , two solutions exist for all m in \\frac{3}{4} \\odot > m > \\frac{1}{3} \\odot \\frac{3}{4} \\odot > m > \\frac{1}{3} \\odot , and one solution exists for all m < \\frac{1}{3} \\odot m < \\frac{1}{3} \\odot . Free Energy In the non-relativistic polytrope solutions of Emden the equation of state was assumed to be P = K \\rho^{\\gamma} P = K \\rho^{\\gamma} . But Landau pointed out that although these solutions in \\gamma > \\frac{6}{5} \\gamma > \\frac{6}{5} give an equilibrium configuration, they do not in every case give stable equilibrium. Thus, unless \\gamma >frac{4}{3} \\gamma >frac{4}{3} the equilibrium configuration is unstable. The part of the free energy caused by compression is F = - a \\rho^{\\frac{1}{3}} + b \\rho^{\\gamma - 1} F = - a \\rho^{\\frac{1}{3}} + b \\rho^{\\gamma - 1} Polytrope solutions exist for \\gamma = \\frac{5}{3} (> \\frac{4}{3}) \\gamma = \\frac{5}{3} (> \\frac{4}{3}) corresponds to stable equilibrium, for \\gamma = \\frac{5}{4} (< \\frac{4}{3}) \\gamma = \\frac{5}{4} (< \\frac{4}{3}) to unstable equilibrium. Since the free energy must be a continuous function of t_0 t_0 , and since we know from non-relativistic calculations that for small masses (and low densities) we have a position of stable equilibrium (a minimum in the free energy curve) we can conclude that the second equilibrium position corresponds either to a maximum or to an inflection point in the free energy curve (and certainly not to a minimum). Fig. 3 gives a schematic plot of free energy against t_0 t_0 for different values of M_0 M_0 which would explain the existence of one equilibrium position for small masses, two for intermediate masses, and none for large masses. The masses marked on the curves are the actual gravitational masses corresponding to the equilibrium points of the critical free energy curves. Application To Stellar Matter Since neutron cores can hardly be stable (with respect to formation of electrons and nuclei) for masses less than \\sim 0.1 M_{\\odot} \\sim 0.1 M_{\\odot} . Since, even after thermonuclear sources of energy are exhausted, they will** not tend to form by collapse of ordinary matter for masses under 1.5 M_{\\odot} 1.5 M_{\\odot} (Landau's limit) . It seems **unlikely that static neutron cores can play any great part in stellar evolution , and the question of what happens, after energy sources are exhausted, to stars of mass greater than 1.5 M_{\\odot} 1.5 M_{\\odot} still remains unanswered . There would then seem to be only two answers possible to the question of the \"final\" behavior of very massive stars: The equation of state we have used so far fails to describe the behavior of highly condensed matter that the conclusions reached above are qualitatively misleading The star will continue to contract indefinitely, never reaching equilibrium. Non-static Solutions From this discussion it appears probable that for an understanding of the long time behavior of actual heavy stars a consideration of non-static solutions must be essential. Among all (spherical) non-static solutions one would hope to find some for which the rate of contraction, and in general the time variation, become slower and slower, so that these solutions might be regarded, not as equilibrium solutions, but as quasi-static. Some reason for this we may see in the following argument: for large enough mass the core will collapse; near the center the density and pressure will grow, and g_{tt} = e^{\\nu} g_{tt} = e^{\\nu} will be small; and as e^{\\nu} e^{\\nu} grows smaller, all processes will, as seen by an outside observer, slow down in the central region. Oppenheimer(1939) On Massive Neutron Cores \u21a9","title":"Solutions"},{"location":"GR/Solutions/#the-gravitational-equilibrium-of-masses-of-neutrons1","text":"We study the gravitational equilibrium of masses of neutrons, using the equation of state for a cold Fermi gas, and general relativity . Whether there is an upper limit to the possible size of such a neutron core? Landau showed that for a model consisting of a cold degenerate Fermi gas there exist no stable equilibrium configurations for masses greater than a certain critical mass, all larger masses tending to collapse.","title":"The gravitational equilibrium of masses of neutrons1"},{"location":"GR/Solutions/#relativistic-treatment-of-equilibrium","text":"The most general static line element exhibiting spherical symmetry may be expressed in the form ds^2 = - e^{\\lambda} dr^2 - r^2 d \\theta^2 - r^2 sin^2 \\theta d \\phi^2 + e^{\\nu} dt^2 \\\\ \\lambda = \\lambda (r), \\nu = \\nu (r). ds^2 = - e^{\\lambda} dr^2 - r^2 d \\theta^2 - r^2 sin^2 \\theta d \\phi^2 + e^{\\nu} dt^2 \\\\ \\lambda = \\lambda (r), \\nu = \\nu (r). If the matter supports no transverse stresses and has no mass motion, then its energy momentum tensor is given by T^{\\space 1}_{1} = T^{\\space 2}_{2} = T^{\\space 3}_{3} = - P, \\space T^{\\space 4}_{4} = \\rho T^{\\space 1}_{1} = T^{\\space 2}_{2} = T^{\\space 3}_{3} = - P, \\space T^{\\space 4}_{4} = \\rho where p and \\rho \\rho are respectively the pressure and the macroscopic energy density measured in proper coordinates. The cosmological constant \\Lambda \\Lambda taken equal to zero, Einstein's field equations reduce to: 8 \\pi P = e^{-\\lambda} (\\frac{\\nu'}{r} + \\frac{1}{r^2}) - \\frac{1}{r^2} \\\\ 8 \\pi \\rho = e^{-\\lambda} (\\frac{\\lambda'}{r} - \\frac{1}{r^2}) + \\frac{1}{r^2} \\\\ \\frac{dP}{dr} = - \\frac{(P + \\rho)}{2} \\nu' 8 \\pi P = e^{-\\lambda} (\\frac{\\nu'}{r} + \\frac{1}{r^2}) - \\frac{1}{r^2} \\\\ 8 \\pi \\rho = e^{-\\lambda} (\\frac{\\lambda'}{r} - \\frac{1}{r^2}) + \\frac{1}{r^2} \\\\ \\frac{dP}{dr} = - \\frac{(P + \\rho)}{2} \\nu' where primes denote differentiation with respect to r. These three equations together with the equation of state of the material \\rho = \\rho (P) \\rho = \\rho (P) determine the mechanical equilibrium of the matter distribution. The boundary of the matter distribution is the value of r = r_b r = r_b for which P = 0 P = 0 , and such that for value r < r_b r < r_b where P > O P > O . In empty space surrounding the spherically symmetric distribution of matter P = \\rho = 0 P = \\rho = 0 , and Schwarzschild's exterior solution is obtained: e^{-\\lambda} = 1 + \\frac{A}{r} \\\\ e^{\\nu} = B (1 + \\frac{A}{r}) e^{-\\lambda} = 1 + \\frac{A}{r} \\\\ e^{\\nu} = B (1 + \\frac{A}{r}) The constants A and 8 are fixed by the requirement that at great distances away from the matter distribution the g_{\\mu \\nu} g_{\\mu \\nu} must go over into their weak-field form, i.e., B = 1 B = 1 , A = - 2m A = - 2m where m is the total Newtonian mass of the matter as calculated by a distant observer. Further introduce a new variable u(r) = \\frac{1}{2} r (1 - e^{-\\lambda}) u(r) = \\frac{1}{2} r (1 - e^{-\\lambda}) Then above equations becomes: e^{\\nu(r)} = (1 - \\frac{2m}{r_b}) e^{- \\int_0^{P(r)} \\frac{2dP}{P + \\rho(P)}} \\\\ \\frac{du}{dr} = 4 \\pi \\rho(P) r^2 \\\\ \\frac{dP}{dr} = - \\frac{P + \\rho(P)}{r(r - 2 u)}(4 \\pi P r^3 + u) e^{\\nu(r)} = (1 - \\frac{2m}{r_b}) e^{- \\int_0^{P(r)} \\frac{2dP}{P + \\rho(P)}} \\\\ \\frac{du}{dr} = 4 \\pi \\rho(P) r^2 \\\\ \\frac{dP}{dr} = - \\frac{P + \\rho(P)}{r(r - 2 u)}(4 \\pi P r^3 + u) From this equation we can see that u is very similar to m. Starting with some initial values u = u_0 u = u_0 , P = P_0 P = P_0 at r = 0 r = 0 , the two equations are integrated simultaneously to the value r = r_b r = r_b where P = O P = O , until the boundary of the matter distribution is reached. The value of u = u_b u = u_b at r = r_b r = r_b determines the value of e^{\\lambda(r_b)} e^{\\lambda(r_b)} at the boundary, and this is joined continuously across the boundary to the exterior solution, making u_b = m u_b = m Thus the mass of this spherical distribution of matter as measured by a distant observer is given by the value u_b u_b of u at r = r_b r = r_b . The following restrictions must be made on the choice of P_0 P_0 and u_0 u_0 , the initial values of P and u at r = 0 r = 0 .","title":"Relativistic Treatment Of Equilibrium"},{"location":"GR/Solutions/#particular-equations-of-state","text":"The above arguments show that \\frac{du}{dr} \\frac{du}{dr} and \\frac{dP}{dr} \\frac{dP}{dr} together with a given equation of state completely determine the distribution of matter. If the matter is taken to consist of particles of rest mass \\mu_0 \\mu_0 obeying Fermi statistics, and their thermal energy and all forces between them are neglected, then it may be shown that a parametric form for the equation of state is: \\rho = K (sinht - t) \\\\ P = \\frac{1}{3} K (sinht - 8 sinh(\\frac{1}{2}t) + 3 t) \\rho = K (sinht - t) \\\\ P = \\frac{1}{3} K (sinht - 8 sinh(\\frac{1}{2}t) + 3 t) where K = \\frac{\\pi \\mu_0^4 c^5}{4 h^3} \\\\ t = 4 log(\\frac{\\widehat{P}}{\\mu_0 c} + [1 + (\\frac{\\widehat{P}}{\\mu_0 c})^2]^{\\frac{1}{2}}) K = \\frac{\\pi \\mu_0^4 c^5}{4 h^3} \\\\ t = 4 log(\\frac{\\widehat{P}}{\\mu_0 c} + [1 + (\\frac{\\widehat{P}}{\\mu_0 c})^2]^{\\frac{1}{2}}) where \\widehat{P} \\widehat{P} is the maximum momentum in the Fermi distribution and is related to the proper particle density \\frac{N}{V} \\frac{N}{V} by \\frac{N}{V} = \\frac{8 \\pi}{3 h^3} \\widehat{P}^3 \\frac{N}{V} = \\frac{8 \\pi}{3 h^3} \\widehat{P}^3 the uncertainty of a particle in space is \\frac{V}{N} \\frac{V}{N} , and the uncertainty in momentum space is 2\\frac{4 \\pi}{3} \\widehat{P}^3 2\\frac{4 \\pi}{3} \\widehat{P}^3 . so \\frac{V}{N} \\times 2\\frac{4 \\pi}{3} \\widehat{P}^3 = h^3 \\frac{V}{N} \\times 2\\frac{4 \\pi}{3} \\widehat{P}^3 = h^3 . The above equations become: \\frac{du}{dr} = 4 \\pi r^2 K (sinht - t) \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} \\frac{sinht - 2 sinh(\\frac{1}{2}t)}{cosht - 4 cosh(\\frac{1}{2}t) + 3}[\\frac{4}{3} \\pi K r^3 (sinht - 8 sinh(\\frac{1}{2}t) + 3t) + u] \\frac{du}{dr} = 4 \\pi r^2 K (sinht - t) \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} \\frac{sinht - 2 sinh(\\frac{1}{2}t)}{cosht - 4 cosh(\\frac{1}{2}t) + 3}[\\frac{4}{3} \\pi K r^3 (sinht - 8 sinh(\\frac{1}{2}t) + 3t) + u] These equations are to be integrated from the values u = 0 u = 0 , t = t_0 t = t_0 at r = 0 r = 0 to r = r_b r = r_b where t_b = 0 t_b = 0 (which makes P = 0 P = 0 ), and u = u_0 u = u_0 . No way was found to carry out the integration analytically, so equations were integrated numerically for several finite values of t_0 t_0 . For all these cases u_0 u_0 was taken to be equal to zero, since the equation of state near the origin for finite t_0 t_0 behaves like \\rho(P) = K P^s \\rho(P) = K P^s , s < 1 s < 1 . For very small values of t the equation of state reduces to P = K \\rho^{\\frac{5}{3}} P = K \\rho^{\\frac{5}{3}} and \\widehat{P} \\propto t \\widehat{P} \\propto t . Using this equation of state and Newtonian gravitational theory (which is expected to give a good result for small masses and densities), one finds that m \\propto t^{\\frac{3}{2}} m \\propto t^{\\frac{3}{2}} . Foe t_0 \\to \\infty t_0 \\to \\infty , Equation may be replaced by their expressions: \\frac{du}{dr} = \\frac{1}{2} r^2 e^t \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} (\\frac{r^3}{6}e^t + u) \\frac{du}{dr} = \\frac{1}{2} r^2 e^t \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} (\\frac{r^3}{6}e^t + u) An exact solution of these equations is: e^t = \\frac{3}{7r^2} \\\\ u = \\frac{3r}{14} e^t = \\frac{3}{7r^2} \\\\ u = \\frac{3r}{14} Then the mass carried out to r = r_b r = r_b where t = 0 t = 0 . The striking feature of the curve is that the mass increases with increasing t_0 t_0 until a maximum is reached at about t_0 =3 t_0 =3 , after which the curve drops until a value roughly \\frac{1}{3} \\odot \\frac{1}{3} \\odot is reached for t_0 = \\infty t_0 = \\infty . In other words no static solutions at all exist for m > \\frac{3}{4} \\odot m > \\frac{3}{4} \\odot , two solutions exist for all m in \\frac{3}{4} \\odot > m > \\frac{1}{3} \\odot \\frac{3}{4} \\odot > m > \\frac{1}{3} \\odot , and one solution exists for all m < \\frac{1}{3} \\odot m < \\frac{1}{3} \\odot .","title":"Particular Equations Of State"},{"location":"GR/Solutions/#free-energy","text":"In the non-relativistic polytrope solutions of Emden the equation of state was assumed to be P = K \\rho^{\\gamma} P = K \\rho^{\\gamma} . But Landau pointed out that although these solutions in \\gamma > \\frac{6}{5} \\gamma > \\frac{6}{5} give an equilibrium configuration, they do not in every case give stable equilibrium. Thus, unless \\gamma >frac{4}{3} \\gamma >frac{4}{3} the equilibrium configuration is unstable. The part of the free energy caused by compression is F = - a \\rho^{\\frac{1}{3}} + b \\rho^{\\gamma - 1} F = - a \\rho^{\\frac{1}{3}} + b \\rho^{\\gamma - 1} Polytrope solutions exist for \\gamma = \\frac{5}{3} (> \\frac{4}{3}) \\gamma = \\frac{5}{3} (> \\frac{4}{3}) corresponds to stable equilibrium, for \\gamma = \\frac{5}{4} (< \\frac{4}{3}) \\gamma = \\frac{5}{4} (< \\frac{4}{3}) to unstable equilibrium. Since the free energy must be a continuous function of t_0 t_0 , and since we know from non-relativistic calculations that for small masses (and low densities) we have a position of stable equilibrium (a minimum in the free energy curve) we can conclude that the second equilibrium position corresponds either to a maximum or to an inflection point in the free energy curve (and certainly not to a minimum). Fig. 3 gives a schematic plot of free energy against t_0 t_0 for different values of M_0 M_0 which would explain the existence of one equilibrium position for small masses, two for intermediate masses, and none for large masses. The masses marked on the curves are the actual gravitational masses corresponding to the equilibrium points of the critical free energy curves.","title":"Free Energy"},{"location":"GR/Solutions/#application-to-stellar-matter","text":"Since neutron cores can hardly be stable (with respect to formation of electrons and nuclei) for masses less than \\sim 0.1 M_{\\odot} \\sim 0.1 M_{\\odot} . Since, even after thermonuclear sources of energy are exhausted, they will** not tend to form by collapse of ordinary matter for masses under 1.5 M_{\\odot} 1.5 M_{\\odot} (Landau's limit) . It seems **unlikely that static neutron cores can play any great part in stellar evolution , and the question of what happens, after energy sources are exhausted, to stars of mass greater than 1.5 M_{\\odot} 1.5 M_{\\odot} still remains unanswered . There would then seem to be only two answers possible to the question of the \"final\" behavior of very massive stars: The equation of state we have used so far fails to describe the behavior of highly condensed matter that the conclusions reached above are qualitatively misleading The star will continue to contract indefinitely, never reaching equilibrium.","title":"Application To Stellar Matter"},{"location":"GR/Solutions/#non-static-solutions","text":"From this discussion it appears probable that for an understanding of the long time behavior of actual heavy stars a consideration of non-static solutions must be essential. Among all (spherical) non-static solutions one would hope to find some for which the rate of contraction, and in general the time variation, become slower and slower, so that these solutions might be regarded, not as equilibrium solutions, but as quasi-static. Some reason for this we may see in the following argument: for large enough mass the core will collapse; near the center the density and pressure will grow, and g_{tt} = e^{\\nu} g_{tt} = e^{\\nu} will be small; and as e^{\\nu} e^{\\nu} grows smaller, all processes will, as seen by an outside observer, slow down in the central region. Oppenheimer(1939) On Massive Neutron Cores \u21a9","title":"Non-static Solutions"},{"location":"GW/Extracting Gravitational Waveforms/","text":"Numerical relativity simulations focus on the strong-field regime of the sources, and compute a 3 + 1 spacetime metric decomposed in terms of a lapse function, shift vector and spatial three-metric. The functional form of this spacetime metric is strongly dependent on the chosen coordinate system. The Gauge-Invariant Moncrief Formalism","title":"Extracting Gravitational Waveforms"},{"location":"GW/Introduction/","text":"One of the major motivations for performing numerical relativity simulations is the accurate calculation of gravitational waveforms from promising sources in order that these theoretically computed signals can be compared with observational data from gravitational wave detectors. Gravitational wave detection In many ways, gravitational wave detection is more like hearing than seeing. In most other astronomical observations we detect photons, which behave very differently from their gravitational analogs. Photons typically have wavelengths that are much shorter than the emitting object, so that we can create images. Gravitational waves, on the other hand, have wavelengths that are larger than or at least comparable to the size of the emitting object. That means that we cannot use gravitational waves to create an image of the emitting object. In analogy to hearing we cannot even locate a gravitational wave source in the sky with just one detector. This makes it so important to operate a number of different gravitational wave detectors, spread far apart over the Earth or in space. Gravitational wave detectors measure gravitational amplitudes directly, as a function of time, and this measurement can be compared with theoretical models. In addition, \u201cmatched-filtering\u201d techniques \u2013 in which the noisy output of the detector is compared with a catalog of theoretical gravitational waveform templates \u2013 dramatically increase the likelihood of identifying a particular signal. Using this technique, the distance out to which an object can be observed increases approximately with the square root of the number of wave cycles . Ground-based gravitational wave interferometers The high frequency band includes frequencies in the approximate range 1 \\mathrm { Hz } \\lesssim f \\lesssim 10 ^ { 4 } \\mathrm { Hz } 1 \\mathrm { Hz } \\lesssim f \\lesssim 10 ^ { 4 } \\mathrm { Hz } . This frequency band is observable with the new generation of ground-based gravitational wave interferometers. A passing gravitational wave will distort the relative length of the two arms, and will therefore modify the interference pattern of the two returning light beams. gravitational wave strain The effect of a passing gravitational wave on two nearby, freely-falling test particles at a spatial separation \\xi ^ { i } \\xi ^ { i } is to change their separation according to \\ddot { \\xi } _ { i } = \\frac { 1 } { 2 } \\ddot { h } _ { i j } ^ { T T } \\xi ^ { j } \\ddot { \\xi } _ { i } = \\frac { 1 } { 2 } \\ddot { h } _ { i j } ^ { T T } \\xi ^ { j } The relative strain \\frac{\\delta \\xi}{\\xi} \\frac{\\delta \\xi}{\\xi} between these two particles is therefore proportional to the gravitational wave amplitude, which explains why h _ { i j } ^ { T T } h _ { i j } ^ { T T } is sometimes called the gravitational wave strain. Space-based detectors The low frequency band between 10 ^ { - 5 } \\mathrm { Hz } \\lesssim f \\lesssim 1 \\mathrm { Hz } 10 ^ { - 5 } \\mathrm { Hz } \\lesssim f \\lesssim 1 \\mathrm { Hz } cannot be observed with ground-based detectors. This leaves space-based observatories as the best means of detecting such radiation.","title":"Introduction"},{"location":"GW/Introduction/#gravitational-wave-detection","text":"In many ways, gravitational wave detection is more like hearing than seeing. In most other astronomical observations we detect photons, which behave very differently from their gravitational analogs. Photons typically have wavelengths that are much shorter than the emitting object, so that we can create images. Gravitational waves, on the other hand, have wavelengths that are larger than or at least comparable to the size of the emitting object. That means that we cannot use gravitational waves to create an image of the emitting object. In analogy to hearing we cannot even locate a gravitational wave source in the sky with just one detector. This makes it so important to operate a number of different gravitational wave detectors, spread far apart over the Earth or in space. Gravitational wave detectors measure gravitational amplitudes directly, as a function of time, and this measurement can be compared with theoretical models. In addition, \u201cmatched-filtering\u201d techniques \u2013 in which the noisy output of the detector is compared with a catalog of theoretical gravitational waveform templates \u2013 dramatically increase the likelihood of identifying a particular signal. Using this technique, the distance out to which an object can be observed increases approximately with the square root of the number of wave cycles . Ground-based gravitational wave interferometers The high frequency band includes frequencies in the approximate range 1 \\mathrm { Hz } \\lesssim f \\lesssim 10 ^ { 4 } \\mathrm { Hz } 1 \\mathrm { Hz } \\lesssim f \\lesssim 10 ^ { 4 } \\mathrm { Hz } . This frequency band is observable with the new generation of ground-based gravitational wave interferometers. A passing gravitational wave will distort the relative length of the two arms, and will therefore modify the interference pattern of the two returning light beams. gravitational wave strain The effect of a passing gravitational wave on two nearby, freely-falling test particles at a spatial separation \\xi ^ { i } \\xi ^ { i } is to change their separation according to \\ddot { \\xi } _ { i } = \\frac { 1 } { 2 } \\ddot { h } _ { i j } ^ { T T } \\xi ^ { j } \\ddot { \\xi } _ { i } = \\frac { 1 } { 2 } \\ddot { h } _ { i j } ^ { T T } \\xi ^ { j } The relative strain \\frac{\\delta \\xi}{\\xi} \\frac{\\delta \\xi}{\\xi} between these two particles is therefore proportional to the gravitational wave amplitude, which explains why h _ { i j } ^ { T T } h _ { i j } ^ { T T } is sometimes called the gravitational wave strain. Space-based detectors The low frequency band between 10 ^ { - 5 } \\mathrm { Hz } \\lesssim f \\lesssim 1 \\mathrm { Hz } 10 ^ { - 5 } \\mathrm { Hz } \\lesssim f \\lesssim 1 \\mathrm { Hz } cannot be observed with ground-based detectors. This leaves space-based observatories as the best means of detecting such radiation.","title":"Gravitational wave detection"},{"location":"GW/Linearized Waves/","text":"In the near-field region about sources, the gravitational fields consist of a combination of longitudinal and transverse components that cannot be disentangled unambigiously. As the transverse fields propagate away from their sources, however, they will reach an asymptotic region in which they can be modeled as a linear perturbation of a nearly Minkowski spacetime. These linearized gravitational waves carry information about the nature of the nonlinear sources that generated them. It is these linearized waves that are measured by gravitational wave detectors. Perturbation Theory Consider a small perturbation h _ { a b } h _ { a b } of a known \u201cbackground\u201d solution to Einstein\u2019s equations. In principle the background could be any solution, but here we are interested in waves propagating in a nearly Minkowski spacetime, for which the metric becomes g _ { a b } = \\eta _ { a b } + h _ { a b } , \\quad \\left| h _ { a b } \\right| \\ll 1 g _ { a b } = \\eta _ { a b } + h _ { a b } , \\quad \\left| h _ { a b } \\right| \\ll 1 It is convenient to introduce the \u201ctrace-reversed\u201d perturbation \\bar { h } _ { a b } \\equiv h _ { a b } - \\frac { 1 } { 2 } \\eta _ { a b } h _ { c } ^ { c } \\bar { h } _ { a b } \\equiv h _ { a b } - \\frac { 1 } { 2 } \\eta _ { a b } h _ { c } ^ { c } We can now exploit our coordinate-freedom to impose the \u201cLorentz gauge\u201d condition, \\nabla _ { a } \\bar { h } ^ { a b } = 0 \\nabla _ { a } \\bar { h } ^ { a b } = 0 Vacuum Solutions Einstein\u2019s equations in vacuum reduce to the wave equation \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = 0 \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = 0 the Lorentz-gauge condition does not determine \\bar { h } _ { a b } \\bar { h } _ { a b } uniquely, since we can introduce further infinitesimal gauge transformations that leave this condition unchanged. Particularly useful is the transverse-traceless or \u201cTT\u201d gauge, in which \\bar { h } _ { a 0 } ^ { T T } = 0 , \\quad \\bar { h } ^ { T T a } _ { a } = 0 \\bar { h } _ { a 0 } ^ { T T } = 0 , \\quad \\bar { h } ^ { T T a } _ { a } = 0 The first condition implies that the only nonzero components of \\bar { h } _ { a b } ^ { T T } \\bar { h } _ { a b } ^ { T T } are purely spatial. The second condition implies that h _ { c } ^ { c } = 0 h _ { c } ^ { c } = 0 , so that, the trace-reversed metric perturbations \\bar { h } _ { a b } \\bar { h } _ { a b } are identical to the original perturbations h _ { a b } h _ { a b } , and we are entitled to drop the bars whenever we write down results in the TT gauge. Together, the \u201cLorentz gauge\u201d condition and \u201cTT\u201d gauge provide eight constraints on the originally ten independent components of h _ { a b } h _ { a b } . The remaining two degrees of freedom correspond to the two possible polarization states of gravitational radiation. A general gravitational wave is then specified by two dimensionless amplitudes h _ { + } h _ { + } and h _ { \\times } h _ { \\times } as h _ { j k } ^ { T T } = h _ { + } e _ { i j } ^ { + } + h _ { \\times } e _ { i j } ^ { \\times } h _ { j k } ^ { T T } = h _ { + } e _ { i j } ^ { + } + h _ { \\times } e _ { i j } ^ { \\times } a linear plane wave For a linear plane wave propagating in vacuum in the z-direction, we have e _ { x x } ^ { + } = - e _ { y y } ^ { + } = 1 , e _ { x y } ^ { \\times } = e _ { y x } ^ { \\times } = 1 e _ { x x } ^ { + } = - e _ { y y } ^ { + } = 1 , e _ { x y } ^ { \\times } = e _ { y x } ^ { \\times } = 1 , all other components zero. Just as in electrodynamics, this type of equation admits simple plane wave solutions of the form \\bar { h } _ { a b } = \\Re \\left( A _ { a b } e ^ { i k _ { c } x ^ { c } } \\right) \\bar { h } _ { a b } = \\Re \\left( A _ { a b } e ^ { i k _ { c } x ^ { c } } \\right) Einstein\u2019s equations then demand that k ^ { a } k ^ { a } be a null vector, k _ { a } k ^ { a } = 0 k _ { a } k ^ { a } = 0 The Lorentz condition requires k ^ { a } A _ { a b } = 0 k ^ { a } A _ { a b } = 0 implying that gravitational waves are transverse. From a numerical point of view the plane wave solutions found above are not the most useful. Most numerical simulations treat spacetimes with finite, bounded sources, for which the waves propagate radially outward at large distance. Moreover such spacetimes approach asymptotic flatness at least as fast as r ^ { - 1 } r ^ { - 1 } . Clearly spacetimes containing with plane waves do not share these properties. More useful for simulation purposes are in terms of tensor spherical harmonics. Gravitational radiation carries energy, momentum, and angular momentum. We can express the radiated energy in terms of the wave amplitudes h _ { + } h _ { + } and h _ { \\times } h _ { \\times } L _ { \\mathrm { GW } } = - \\frac { d E } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega L _ { \\mathrm { GW } } = - \\frac { d E } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega Similarly, we can find the loss of angular momentum due to radiation, \\frac { d J _ { z } } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\partial _ { t } h _ { + } \\partial _ { \\phi } h _ { + } + \\partial _ { t } h _ { \\times } \\partial _ { \\phi } h _ { \\times } \\right\\rangle d \\Omega \\frac { d J _ { z } } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\partial _ { t } h _ { + } \\partial _ { \\phi } h _ { + } + \\partial _ { t } h _ { \\times } \\partial _ { \\phi } h _ { \\times } \\right\\rangle d \\Omega Finally, the loss of linear momentum due to radiation is \\frac { d P ^ { i } } { d t } = \\lim _ { r \\rightarrow \\infty } - \\frac { r ^ { 2 } } { 16 \\pi } \\int \\frac { x ^ { i } } { r } \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega \\frac { d P ^ { i } } { d t } = \\lim _ { r \\rightarrow \\infty } - \\frac { r ^ { 2 } } { 16 \\pi } \\int \\frac { x ^ { i } } { r } \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega In all the above expressions the quantities E, J and P^i P^i refer to the source, and their changes are equal and opposite to the corresponding quantities carried off by the waves. Sources Consider now the generation of gravitational radiation from a weak-field, slow-velocity source. For such a source, Einstein\u2019s equations reduce to \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = - 16 \\pi T _ { a b } \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = - 16 \\pi T _ { a b } Imposing an outgoing-wave boundary condition, we can solve equation with the help of a Green\u2019s function to obtain the integral equation, \\bar { h } _ { a b } \\left( t , x ^ { i } \\right) = 4 \\int d ^ { 3 } x ^ { \\prime } \\frac { T _ { a b } \\left( t - \\left| x ^ { i } - x ^ { i } \\right| , x ^ { i } \\right) } { \\left| x ^ { i } - x ^ { \\prime } \\right| } \\bar { h } _ { a b } \\left( t , x ^ { i } \\right) = 4 \\int d ^ { 3 } x ^ { \\prime } \\frac { T _ { a b } \\left( t - \\left| x ^ { i } - x ^ { i } \\right| , x ^ { i } \\right) } { \\left| x ^ { i } - x ^ { \\prime } \\right| } For a binary, we can estimate the typical gravitational wave strain h. For equal-mass binaries we have \\mu = M / 4 \\mu = M / 4 , so h \\simeq \\frac { 4 } { r } \\frac { \\mu M } { R } \\simeq 5 \\times 10 ^ { - 20 } \\left( \\frac { 1 \\mathrm { Mpc } } { r } \\right) \\left( \\frac { M } { M _ { \\odot } } \\right) \\left( \\frac { M } { R } \\right) h \\simeq \\frac { 4 } { r } \\frac { \\mu M } { R } \\simeq 5 \\times 10 ^ { - 20 } \\left( \\frac { 1 \\mathrm { Mpc } } { r } \\right) \\left( \\frac { M } { M _ { \\odot } } \\right) \\left( \\frac { M } { R } \\right) The characteristic gravitational wave frequency from a stellar object of mass M, radius R and compaction M/R M/R by f \\simeq \\frac { 1 } { M } \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } \\simeq 2 \\times 10 ^ { 5 } \\mathrm { Hz } \\left( \\frac { M _ { \\odot } } { M } \\right) \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } f \\simeq \\frac { 1 } { M } \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } \\simeq 2 \\times 10 ^ { 5 } \\mathrm { Hz } \\left( \\frac { M _ { \\odot } } { M } \\right) \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } The highest frequency sources are compact objects with large compactions (black holes or neutron stars) and small masses; stellar-mass compact objects fall into this category. These sources fall into the high frequency band.","title":"Linearized Waves"},{"location":"GW/Linearized Waves/#perturbation-theory","text":"Consider a small perturbation h _ { a b } h _ { a b } of a known \u201cbackground\u201d solution to Einstein\u2019s equations. In principle the background could be any solution, but here we are interested in waves propagating in a nearly Minkowski spacetime, for which the metric becomes g _ { a b } = \\eta _ { a b } + h _ { a b } , \\quad \\left| h _ { a b } \\right| \\ll 1 g _ { a b } = \\eta _ { a b } + h _ { a b } , \\quad \\left| h _ { a b } \\right| \\ll 1 It is convenient to introduce the \u201ctrace-reversed\u201d perturbation \\bar { h } _ { a b } \\equiv h _ { a b } - \\frac { 1 } { 2 } \\eta _ { a b } h _ { c } ^ { c } \\bar { h } _ { a b } \\equiv h _ { a b } - \\frac { 1 } { 2 } \\eta _ { a b } h _ { c } ^ { c } We can now exploit our coordinate-freedom to impose the \u201cLorentz gauge\u201d condition, \\nabla _ { a } \\bar { h } ^ { a b } = 0 \\nabla _ { a } \\bar { h } ^ { a b } = 0 Vacuum Solutions Einstein\u2019s equations in vacuum reduce to the wave equation \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = 0 \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = 0 the Lorentz-gauge condition does not determine \\bar { h } _ { a b } \\bar { h } _ { a b } uniquely, since we can introduce further infinitesimal gauge transformations that leave this condition unchanged. Particularly useful is the transverse-traceless or \u201cTT\u201d gauge, in which \\bar { h } _ { a 0 } ^ { T T } = 0 , \\quad \\bar { h } ^ { T T a } _ { a } = 0 \\bar { h } _ { a 0 } ^ { T T } = 0 , \\quad \\bar { h } ^ { T T a } _ { a } = 0 The first condition implies that the only nonzero components of \\bar { h } _ { a b } ^ { T T } \\bar { h } _ { a b } ^ { T T } are purely spatial. The second condition implies that h _ { c } ^ { c } = 0 h _ { c } ^ { c } = 0 , so that, the trace-reversed metric perturbations \\bar { h } _ { a b } \\bar { h } _ { a b } are identical to the original perturbations h _ { a b } h _ { a b } , and we are entitled to drop the bars whenever we write down results in the TT gauge. Together, the \u201cLorentz gauge\u201d condition and \u201cTT\u201d gauge provide eight constraints on the originally ten independent components of h _ { a b } h _ { a b } . The remaining two degrees of freedom correspond to the two possible polarization states of gravitational radiation. A general gravitational wave is then specified by two dimensionless amplitudes h _ { + } h _ { + } and h _ { \\times } h _ { \\times } as h _ { j k } ^ { T T } = h _ { + } e _ { i j } ^ { + } + h _ { \\times } e _ { i j } ^ { \\times } h _ { j k } ^ { T T } = h _ { + } e _ { i j } ^ { + } + h _ { \\times } e _ { i j } ^ { \\times } a linear plane wave For a linear plane wave propagating in vacuum in the z-direction, we have e _ { x x } ^ { + } = - e _ { y y } ^ { + } = 1 , e _ { x y } ^ { \\times } = e _ { y x } ^ { \\times } = 1 e _ { x x } ^ { + } = - e _ { y y } ^ { + } = 1 , e _ { x y } ^ { \\times } = e _ { y x } ^ { \\times } = 1 , all other components zero. Just as in electrodynamics, this type of equation admits simple plane wave solutions of the form \\bar { h } _ { a b } = \\Re \\left( A _ { a b } e ^ { i k _ { c } x ^ { c } } \\right) \\bar { h } _ { a b } = \\Re \\left( A _ { a b } e ^ { i k _ { c } x ^ { c } } \\right) Einstein\u2019s equations then demand that k ^ { a } k ^ { a } be a null vector, k _ { a } k ^ { a } = 0 k _ { a } k ^ { a } = 0 The Lorentz condition requires k ^ { a } A _ { a b } = 0 k ^ { a } A _ { a b } = 0 implying that gravitational waves are transverse. From a numerical point of view the plane wave solutions found above are not the most useful. Most numerical simulations treat spacetimes with finite, bounded sources, for which the waves propagate radially outward at large distance. Moreover such spacetimes approach asymptotic flatness at least as fast as r ^ { - 1 } r ^ { - 1 } . Clearly spacetimes containing with plane waves do not share these properties. More useful for simulation purposes are in terms of tensor spherical harmonics. Gravitational radiation carries energy, momentum, and angular momentum. We can express the radiated energy in terms of the wave amplitudes h _ { + } h _ { + } and h _ { \\times } h _ { \\times } L _ { \\mathrm { GW } } = - \\frac { d E } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega L _ { \\mathrm { GW } } = - \\frac { d E } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega Similarly, we can find the loss of angular momentum due to radiation, \\frac { d J _ { z } } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\partial _ { t } h _ { + } \\partial _ { \\phi } h _ { + } + \\partial _ { t } h _ { \\times } \\partial _ { \\phi } h _ { \\times } \\right\\rangle d \\Omega \\frac { d J _ { z } } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\partial _ { t } h _ { + } \\partial _ { \\phi } h _ { + } + \\partial _ { t } h _ { \\times } \\partial _ { \\phi } h _ { \\times } \\right\\rangle d \\Omega Finally, the loss of linear momentum due to radiation is \\frac { d P ^ { i } } { d t } = \\lim _ { r \\rightarrow \\infty } - \\frac { r ^ { 2 } } { 16 \\pi } \\int \\frac { x ^ { i } } { r } \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega \\frac { d P ^ { i } } { d t } = \\lim _ { r \\rightarrow \\infty } - \\frac { r ^ { 2 } } { 16 \\pi } \\int \\frac { x ^ { i } } { r } \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega In all the above expressions the quantities E, J and P^i P^i refer to the source, and their changes are equal and opposite to the corresponding quantities carried off by the waves. Sources Consider now the generation of gravitational radiation from a weak-field, slow-velocity source. For such a source, Einstein\u2019s equations reduce to \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = - 16 \\pi T _ { a b } \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = - 16 \\pi T _ { a b } Imposing an outgoing-wave boundary condition, we can solve equation with the help of a Green\u2019s function to obtain the integral equation, \\bar { h } _ { a b } \\left( t , x ^ { i } \\right) = 4 \\int d ^ { 3 } x ^ { \\prime } \\frac { T _ { a b } \\left( t - \\left| x ^ { i } - x ^ { i } \\right| , x ^ { i } \\right) } { \\left| x ^ { i } - x ^ { \\prime } \\right| } \\bar { h } _ { a b } \\left( t , x ^ { i } \\right) = 4 \\int d ^ { 3 } x ^ { \\prime } \\frac { T _ { a b } \\left( t - \\left| x ^ { i } - x ^ { i } \\right| , x ^ { i } \\right) } { \\left| x ^ { i } - x ^ { \\prime } \\right| } For a binary, we can estimate the typical gravitational wave strain h. For equal-mass binaries we have \\mu = M / 4 \\mu = M / 4 , so h \\simeq \\frac { 4 } { r } \\frac { \\mu M } { R } \\simeq 5 \\times 10 ^ { - 20 } \\left( \\frac { 1 \\mathrm { Mpc } } { r } \\right) \\left( \\frac { M } { M _ { \\odot } } \\right) \\left( \\frac { M } { R } \\right) h \\simeq \\frac { 4 } { r } \\frac { \\mu M } { R } \\simeq 5 \\times 10 ^ { - 20 } \\left( \\frac { 1 \\mathrm { Mpc } } { r } \\right) \\left( \\frac { M } { M _ { \\odot } } \\right) \\left( \\frac { M } { R } \\right) The characteristic gravitational wave frequency from a stellar object of mass M, radius R and compaction M/R M/R by f \\simeq \\frac { 1 } { M } \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } \\simeq 2 \\times 10 ^ { 5 } \\mathrm { Hz } \\left( \\frac { M _ { \\odot } } { M } \\right) \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } f \\simeq \\frac { 1 } { M } \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } \\simeq 2 \\times 10 ^ { 5 } \\mathrm { Hz } \\left( \\frac { M _ { \\odot } } { M } \\right) \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } The highest frequency sources are compact objects with large compactions (black holes or neutron stars) and small masses; stellar-mass compact objects fall into this category. These sources fall into the high frequency band.","title":"Perturbation Theory"},{"location":"NR/3+1 Decomposition/","text":"The 3+1 equations are entirely equivalent to the usual \ufb01eld equations but they focus on the evolution of 12 purely spatial quantities closely related to g_{ij} g_{ij} and \\partial_t g_{ij} \\partial_t g_{ij} and the constraints that they must satisfy on spatial hypersurfaces. Once these spatial field quantities are specified on some initial \u201ctime slice\u201d (i.e. spatial hypersurface) consistent with the 3 + 1 constraint equations, the 3 + 1 evolution equations can then be integrated, together with evolution equations for the matter sources, to determine these field quantities at all later times. Foliations of Spacetime We assume that the spacetime (M, g_{ab}) (M, g_{ab}) can be foliated into a family of non-intersecting spacelike three-surfaces \u03a3. The spacetime is split into spatial hypersurfaces labeled by a coordinate t. Cauchy surface Cauchy surface is a plane in space-time which is like an instant of time; its significance is that giving the initial conditions on this plane determines the future (and the past) uniquely. From t we can define the 1-form \\Omega _ { a } = \\nabla _ { a } t \\Omega _ { a } = \\nabla _ { a } t which is closed by construction, \\nabla _ { [ a } \\Omega _ { b ] } = \\nabla _ { [ a } \\nabla _ { b ] } t = 0 \\nabla _ { [ a } \\Omega _ { b ] } = \\nabla _ { [ a } \\nabla _ { b ] } t = 0 The 4-metric g_{ab} g_{ab} allows us to compute the norm of \\tilde{\u03a9} \\tilde{\u03a9} \udbff\udc1e, which we call - \\alpha ^ { - 2 } - \\alpha ^ { - 2 } \\| \\Omega \\| ^ { 2 } = g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t \\equiv - \\frac { 1 } { \\alpha ^ { 2 } } \\| \\Omega \\| ^ { 2 } = g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t \\equiv - \\frac { 1 } { \\alpha ^ { 2 } } \u03b1 \u03b1 measures how much proper time elapses between neighboring time slices along the normal vector \u03a9^a \u03a9^a to the slice, and is therefore called the lapse function . We assume that \u03b1 > 0 \u03b1 > 0 , so that \u03a9^a \u03a9^a is timelike and the hypersurface \u03a3 is spacelike everywhere. We can now define the unit normal to the slices as n ^ { a } \\equiv - g ^ { a b } \\alpha \\Omega _ { b } n ^ { a } \\equiv - g ^ { a b } \\alpha \\Omega _ { b } Here the negative sign has been chosen so that n^a n^a points in the direction of increasing t, and may therefore be thought of as the four-velocity of a \u201cnormal\u201d observer whose worldline is always normal to the spatial slices \u03a3. On each spatial slice, coordinates x^{i} x^{i} are specified (we use the convention that Latin indices take on the values 1, 2, or 3 of the spacelike dimensions). A point labeled x_{0}^{i} x_{0}^{i} on one spatial slice and another with the same label on a different slice may be skewed with respect to the unit normal direction n^a n^a (which must be timelike). Here, the two points are shifted with respect to each other by a spatial vector \\beta^{i} \\beta^{i} . The shift vector \u03b2^a \u03b2^a will measure the amount by which the spatial coordinates are shifted within a slice with respect to the normal vector. The lapse function \u03b1 \u03b1 measures how much proper time elapses between neighboring time slices along the normal vector. The lapse and the shift therefore determine how the coordinates evolve in time. The choice of \u03b1 \u03b1 and \u03b2^a \u03b2^a is quite arbitrary. The freedom to choose these four gauge functions \u03b1 \u03b1 and \u03b2^a \u03b2^a completely arbitrarily embodies the four-fold coordinate degrees of freedom inherent in general relativity . The lapse and the shift determine how the coordinates evolve from one time slice \u03a3 to the next, whereas the constraint equations represent integrability conditions which have to be satisfied within each slice. Therefore, the constraints have to be independent of how the coordinates evolve, and the lapse and the shift can enter only the evolution equations . The spatial metric \\gamma_{ab} \\gamma_{ab} With the normal vector we can construct the spatial metric \\gamma_{ab} \\gamma_{ab} that is induced by g_{ab} g_{ab} on the three-dimensional hypersurfaces \u03a3 \\gamma_{ab} = g_{ab} + n_a n_b \\gamma_{ab} = g_{ab} + n_a n_b Thus \\gamma_{ab} \\gamma_{ab} is a projection tensor that projects out all geometric objects lying along n^a n^a . This metric allows us to compute distances within a slice \u03a3. To see that \u03b3_{ab} \u03b3_{ab} is purely spatial, i.e., resides entirely in \u03a3 with no piece along n^a n^a , we contract it with the normal n^a n^a , n ^ { a } \\gamma _ { a b } = n ^ { a } g _ { a b } + n ^ { a } n _ { a } n _ { b } = n _ { b } - n _ { b } = 0 n ^ { a } \\gamma _ { a b } = n ^ { a } g _ { a b } + n ^ { a } n _ { a } n _ { b } = n _ { b } - n _ { b } = 0 Note We break up 4-dimensional tensors by decomposing them into a purely spatial part, which lies in the hypersurfaces \\Sigma \\Sigma , and a timelike part, which is normal to the spatial surface. To do so, we need two projection operators. The first one, which projects a 4-dimensional tensor into a spatial slice \\gamma^a_{\\space b} = g^a_{\\space b} + n^a n_b \\gamma^a_{\\space b} = g^a_{\\space b} + n^a n_b Similarly, we may define the normal projection operator as N^a_{\\space b} = - n^a n_b N^a_{\\space b} = - n^a n_b We can now use these two projection operators to decompose any tensor into its spatial and timelike parts. The induced metric is simply the spatial components of the spacetime metric g_{ab} g_{ab} . The three-dimensional metric only contains information about the curvature intrinsic to a slice \u03a3 , but it gives no information about what shape this slice takes in the spacetime M in which it is embedded. This information is contained in a tensor called extrinsic curvature . Note The three-dimensional covariant derivative can be expressed in terms of three-dimensional connection coefficients, which, in a coordinate basis, are given by \\Gamma _ { b c } ^ { a } = \\frac { 1 } { 2 } \\gamma ^ { a d } \\left( \\partial _ { c } \\gamma _ { d b } + \\partial _ { b } \\gamma _ { d c } - \\partial _ { d } \\gamma _ { b c } \\right) \\Gamma _ { b c } ^ { a } = \\frac { 1 } { 2 } \\gamma ^ { a d } \\left( \\partial _ { c } \\gamma _ { d b } + \\partial _ { b } \\gamma _ { d c } - \\partial _ { d } \\gamma _ { b c } \\right) The three-dimensional Riemann tensor can be computed from R _ { a b c } ^ { d } = \\partial _ { b } \\Gamma _ { a c } ^ { d } - \\partial _ { a } \\Gamma _ { b c } ^ { d } + \\Gamma _ { a c } ^ { e } \\Gamma _ { e b } ^ { d } - \\Gamma _ { b c } ^ { e } \\Gamma _ { e a } ^ { d } R _ { a b c } ^ { d } = \\partial _ { b } \\Gamma _ { a c } ^ { d } - \\partial _ { a } \\Gamma _ { b c } ^ { d } + \\Gamma _ { a c } ^ { e } \\Gamma _ { e b } ^ { d } - \\Gamma _ { b c } ^ { e } \\Gamma _ { e a } ^ { d } The three-dimensional curvature R _ { b c d } ^ { a } R _ { b c d } ^ { a } only contains information about the curvature intrinsic to a slice \u03a3, but it gives no information about what shape this slice takes in the spacetime M in which it is embedded. The Extrinsic Curvature K_{ab} K_{ab} The extrinsic curvature K_{ab} K_{ab} can be found by projecting gradients of the normal vector into the slice \u03a3 . The metric and the extrinsic curvature (\\gamma_{ab}, K_{ab}) (\\gamma_{ab}, K_{ab}) can therefore be considered as the equivalent of positions and velocities in classical mechanics \u2013 they measure the \u201cinstantaneous\u201d state of the gravitational \ufb01eld, and form the fundamental variables in our initial value formulation. We now define the extrinsic curvature, K_{ab} K_{ab} , as the negative expansion K_{ab} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_{(c} n_{d)} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d K_{ab} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_{(c} n_{d)} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d By definition, the extrinsic curvature is symmetric and purely spatial. they can only differ in the direction in which they are pointing, and the extrinsic curvature therefore provides information on how much this direction changes from point to point across a spatial hypersurface. As a consequence, the extrinsic curvature measures the rate at which the hypersurface deforms as it is carried forward along a normal. Finally, we can write the extrinsic curvature as K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} where L_n L_n denotes the Lie derivative along n^a n^a . Proof: \\gamma_{ab} \\gamma_{ab} changes proportionally to K_{ab} K_{ab} \\begin{align} K_{ab} &= - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d = - (\\delta_a^{\\space c} + n_a n^c) (\\delta_b^{\\space d} + n_b n^d) \\nabla_c n_d \\\\ &= -(\\delta_a^{\\space c} + n_a n^c) \\delta_b^{\\space d} \\nabla_c n_d = - \\nabla_a n_b - n_a a_b \\\\ \\mathcal{L}_n \\gamma_{ab} &= \\mathcal{L}_n (g_{ab} + n_a n_b) = 2 \\nabla_{(a} n_{b)} + n_a \\mathcal{L}_n n_b + n_b \\mathcal{L}_n n_a \\\\ &= 2 (\\nabla_{(a} n_{b)} - n_{(a} a_{b)}) \\\\ \\mathcal{L}_n \\gamma_{ab} &= - 2 K_{ab} \\end{align} \\begin{align} K_{ab} &= - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d = - (\\delta_a^{\\space c} + n_a n^c) (\\delta_b^{\\space d} + n_b n^d) \\nabla_c n_d \\\\ &= -(\\delta_a^{\\space c} + n_a n^c) \\delta_b^{\\space d} \\nabla_c n_d = - \\nabla_a n_b - n_a a_b \\\\ \\mathcal{L}_n \\gamma_{ab} &= \\mathcal{L}_n (g_{ab} + n_a n_b) = 2 \\nabla_{(a} n_{b)} + n_a \\mathcal{L}_n n_b + n_b \\mathcal{L}_n n_a \\\\ &= 2 (\\nabla_{(a} n_{b)} - n_{(a} a_{b)}) \\\\ \\mathcal{L}_n \\gamma_{ab} &= - 2 K_{ab} \\end{align} Since n^a n^a is a timelike vector, equation illustrates the intuitive interpretation of the extrinsic curvature as a geometric generalization of the \u201ctime derivative\u201d of the spatial metric \\gamma_{ab} \\gamma_{ab} .","title":"3+1 Decomposition"},{"location":"NR/3+1 Decomposition/#foliations-of-spacetime","text":"We assume that the spacetime (M, g_{ab}) (M, g_{ab}) can be foliated into a family of non-intersecting spacelike three-surfaces \u03a3. The spacetime is split into spatial hypersurfaces labeled by a coordinate t. Cauchy surface Cauchy surface is a plane in space-time which is like an instant of time; its significance is that giving the initial conditions on this plane determines the future (and the past) uniquely. From t we can define the 1-form \\Omega _ { a } = \\nabla _ { a } t \\Omega _ { a } = \\nabla _ { a } t which is closed by construction, \\nabla _ { [ a } \\Omega _ { b ] } = \\nabla _ { [ a } \\nabla _ { b ] } t = 0 \\nabla _ { [ a } \\Omega _ { b ] } = \\nabla _ { [ a } \\nabla _ { b ] } t = 0 The 4-metric g_{ab} g_{ab} allows us to compute the norm of \\tilde{\u03a9} \\tilde{\u03a9} \udbff\udc1e, which we call - \\alpha ^ { - 2 } - \\alpha ^ { - 2 } \\| \\Omega \\| ^ { 2 } = g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t \\equiv - \\frac { 1 } { \\alpha ^ { 2 } } \\| \\Omega \\| ^ { 2 } = g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t \\equiv - \\frac { 1 } { \\alpha ^ { 2 } } \u03b1 \u03b1 measures how much proper time elapses between neighboring time slices along the normal vector \u03a9^a \u03a9^a to the slice, and is therefore called the lapse function . We assume that \u03b1 > 0 \u03b1 > 0 , so that \u03a9^a \u03a9^a is timelike and the hypersurface \u03a3 is spacelike everywhere. We can now define the unit normal to the slices as n ^ { a } \\equiv - g ^ { a b } \\alpha \\Omega _ { b } n ^ { a } \\equiv - g ^ { a b } \\alpha \\Omega _ { b } Here the negative sign has been chosen so that n^a n^a points in the direction of increasing t, and may therefore be thought of as the four-velocity of a \u201cnormal\u201d observer whose worldline is always normal to the spatial slices \u03a3. On each spatial slice, coordinates x^{i} x^{i} are specified (we use the convention that Latin indices take on the values 1, 2, or 3 of the spacelike dimensions). A point labeled x_{0}^{i} x_{0}^{i} on one spatial slice and another with the same label on a different slice may be skewed with respect to the unit normal direction n^a n^a (which must be timelike). Here, the two points are shifted with respect to each other by a spatial vector \\beta^{i} \\beta^{i} . The shift vector \u03b2^a \u03b2^a will measure the amount by which the spatial coordinates are shifted within a slice with respect to the normal vector. The lapse function \u03b1 \u03b1 measures how much proper time elapses between neighboring time slices along the normal vector. The lapse and the shift therefore determine how the coordinates evolve in time. The choice of \u03b1 \u03b1 and \u03b2^a \u03b2^a is quite arbitrary. The freedom to choose these four gauge functions \u03b1 \u03b1 and \u03b2^a \u03b2^a completely arbitrarily embodies the four-fold coordinate degrees of freedom inherent in general relativity . The lapse and the shift determine how the coordinates evolve from one time slice \u03a3 to the next, whereas the constraint equations represent integrability conditions which have to be satisfied within each slice. Therefore, the constraints have to be independent of how the coordinates evolve, and the lapse and the shift can enter only the evolution equations .","title":"Foliations of Spacetime"},{"location":"NR/3+1 Decomposition/#the-spatial-metric-gamma_abgamma_ab","text":"With the normal vector we can construct the spatial metric \\gamma_{ab} \\gamma_{ab} that is induced by g_{ab} g_{ab} on the three-dimensional hypersurfaces \u03a3 \\gamma_{ab} = g_{ab} + n_a n_b \\gamma_{ab} = g_{ab} + n_a n_b Thus \\gamma_{ab} \\gamma_{ab} is a projection tensor that projects out all geometric objects lying along n^a n^a . This metric allows us to compute distances within a slice \u03a3. To see that \u03b3_{ab} \u03b3_{ab} is purely spatial, i.e., resides entirely in \u03a3 with no piece along n^a n^a , we contract it with the normal n^a n^a , n ^ { a } \\gamma _ { a b } = n ^ { a } g _ { a b } + n ^ { a } n _ { a } n _ { b } = n _ { b } - n _ { b } = 0 n ^ { a } \\gamma _ { a b } = n ^ { a } g _ { a b } + n ^ { a } n _ { a } n _ { b } = n _ { b } - n _ { b } = 0 Note We break up 4-dimensional tensors by decomposing them into a purely spatial part, which lies in the hypersurfaces \\Sigma \\Sigma , and a timelike part, which is normal to the spatial surface. To do so, we need two projection operators. The first one, which projects a 4-dimensional tensor into a spatial slice \\gamma^a_{\\space b} = g^a_{\\space b} + n^a n_b \\gamma^a_{\\space b} = g^a_{\\space b} + n^a n_b Similarly, we may define the normal projection operator as N^a_{\\space b} = - n^a n_b N^a_{\\space b} = - n^a n_b We can now use these two projection operators to decompose any tensor into its spatial and timelike parts. The induced metric is simply the spatial components of the spacetime metric g_{ab} g_{ab} . The three-dimensional metric only contains information about the curvature intrinsic to a slice \u03a3 , but it gives no information about what shape this slice takes in the spacetime M in which it is embedded. This information is contained in a tensor called extrinsic curvature . Note The three-dimensional covariant derivative can be expressed in terms of three-dimensional connection coefficients, which, in a coordinate basis, are given by \\Gamma _ { b c } ^ { a } = \\frac { 1 } { 2 } \\gamma ^ { a d } \\left( \\partial _ { c } \\gamma _ { d b } + \\partial _ { b } \\gamma _ { d c } - \\partial _ { d } \\gamma _ { b c } \\right) \\Gamma _ { b c } ^ { a } = \\frac { 1 } { 2 } \\gamma ^ { a d } \\left( \\partial _ { c } \\gamma _ { d b } + \\partial _ { b } \\gamma _ { d c } - \\partial _ { d } \\gamma _ { b c } \\right) The three-dimensional Riemann tensor can be computed from R _ { a b c } ^ { d } = \\partial _ { b } \\Gamma _ { a c } ^ { d } - \\partial _ { a } \\Gamma _ { b c } ^ { d } + \\Gamma _ { a c } ^ { e } \\Gamma _ { e b } ^ { d } - \\Gamma _ { b c } ^ { e } \\Gamma _ { e a } ^ { d } R _ { a b c } ^ { d } = \\partial _ { b } \\Gamma _ { a c } ^ { d } - \\partial _ { a } \\Gamma _ { b c } ^ { d } + \\Gamma _ { a c } ^ { e } \\Gamma _ { e b } ^ { d } - \\Gamma _ { b c } ^ { e } \\Gamma _ { e a } ^ { d } The three-dimensional curvature R _ { b c d } ^ { a } R _ { b c d } ^ { a } only contains information about the curvature intrinsic to a slice \u03a3, but it gives no information about what shape this slice takes in the spacetime M in which it is embedded.","title":"The spatial metric \\gamma_{ab}\\gamma_{ab}"},{"location":"NR/3+1 Decomposition/#the-extrinsic-curvature-k_abk_ab","text":"The extrinsic curvature K_{ab} K_{ab} can be found by projecting gradients of the normal vector into the slice \u03a3 . The metric and the extrinsic curvature (\\gamma_{ab}, K_{ab}) (\\gamma_{ab}, K_{ab}) can therefore be considered as the equivalent of positions and velocities in classical mechanics \u2013 they measure the \u201cinstantaneous\u201d state of the gravitational \ufb01eld, and form the fundamental variables in our initial value formulation. We now define the extrinsic curvature, K_{ab} K_{ab} , as the negative expansion K_{ab} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_{(c} n_{d)} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d K_{ab} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_{(c} n_{d)} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d By definition, the extrinsic curvature is symmetric and purely spatial. they can only differ in the direction in which they are pointing, and the extrinsic curvature therefore provides information on how much this direction changes from point to point across a spatial hypersurface. As a consequence, the extrinsic curvature measures the rate at which the hypersurface deforms as it is carried forward along a normal. Finally, we can write the extrinsic curvature as K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} where L_n L_n denotes the Lie derivative along n^a n^a . Proof: \\gamma_{ab} \\gamma_{ab} changes proportionally to K_{ab} K_{ab} \\begin{align} K_{ab} &= - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d = - (\\delta_a^{\\space c} + n_a n^c) (\\delta_b^{\\space d} + n_b n^d) \\nabla_c n_d \\\\ &= -(\\delta_a^{\\space c} + n_a n^c) \\delta_b^{\\space d} \\nabla_c n_d = - \\nabla_a n_b - n_a a_b \\\\ \\mathcal{L}_n \\gamma_{ab} &= \\mathcal{L}_n (g_{ab} + n_a n_b) = 2 \\nabla_{(a} n_{b)} + n_a \\mathcal{L}_n n_b + n_b \\mathcal{L}_n n_a \\\\ &= 2 (\\nabla_{(a} n_{b)} - n_{(a} a_{b)}) \\\\ \\mathcal{L}_n \\gamma_{ab} &= - 2 K_{ab} \\end{align} \\begin{align} K_{ab} &= - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d = - (\\delta_a^{\\space c} + n_a n^c) (\\delta_b^{\\space d} + n_b n^d) \\nabla_c n_d \\\\ &= -(\\delta_a^{\\space c} + n_a n^c) \\delta_b^{\\space d} \\nabla_c n_d = - \\nabla_a n_b - n_a a_b \\\\ \\mathcal{L}_n \\gamma_{ab} &= \\mathcal{L}_n (g_{ab} + n_a n_b) = 2 \\nabla_{(a} n_{b)} + n_a \\mathcal{L}_n n_b + n_b \\mathcal{L}_n n_a \\\\ &= 2 (\\nabla_{(a} n_{b)} - n_{(a} a_{b)}) \\\\ \\mathcal{L}_n \\gamma_{ab} &= - 2 K_{ab} \\end{align} Since n^a n^a is a timelike vector, equation illustrates the intuitive interpretation of the extrinsic curvature as a geometric generalization of the \u201ctime derivative\u201d of the spatial metric \\gamma_{ab} \\gamma_{ab} .","title":"The Extrinsic Curvature K_{ab}K_{ab}"},{"location":"NR/ADM/","text":"The metric \\gamma_{ab} \\gamma_{ab} and the extrinsic curvature K_{ab} K_{ab} cannot be chosen arbitrarily. Instead, they have to satisfy certain constraints . The projections of the Riemann tensor In order to find these relations, we have to relate the three-dimensional Riemann tensor R^a_{\\space bcd} R^a_{\\space bcd} of the the hypersurfaces \u03a3 to the four-dimensional Riemann tensor ^{(4)} R^a_{\\space bcd} ^{(4)} R^a_{\\space bcd} of M. relate the three-dimensional Riemann tensor to the four-dimensional Riemann tensor Let us consider the Ricci identity defining the (three-dimensional) Riemann tensor Riem as measuring the lack of commutation of two successive covariant derivatives with respect to the connection D associated with \\Sigma \\Sigma 's metric \\gamma \\gamma . The four-dimensional version of this identity is D_{\\alpha} D_{\\beta} v^{\\gamma}-D_{\\beta} D_{\\alpha} v^{\\gamma}=R_{\\mu \\alpha \\beta}^{\\gamma} v^{\\mu} D_{\\alpha} D_{\\beta} v^{\\gamma}-D_{\\beta} D_{\\alpha} v^{\\gamma}=R_{\\mu \\alpha \\beta}^{\\gamma} v^{\\mu} where v v is a generic vector field tangent to \\Sigma \\Sigma . The relation between the D-derivative and the \\nabla \\nabla -derivative D_{\\rho} T_{\\beta_{1} \\ldots \\beta_{q}}^{\\alpha_{1} \\ldots \\alpha_{p}}=\\gamma_{\\mu_{1}}^{\\alpha_{1}} \\cdots \\gamma^{\\alpha_{p}}_{\\mu_{p}} \\gamma^{\\nu_{1}}_{\\beta_{1}} \\cdots \\gamma^{\\nu_{q}}_{\\beta_{q}} \\gamma^{\\sigma}_{\\rho} \\nabla_{\\sigma} T_{\\nu_{1} \\ldots \\nu_{q}}^{\\mu_{1} \\ldots \\mu_{p}} D_{\\rho} T_{\\beta_{1} \\ldots \\beta_{q}}^{\\alpha_{1} \\ldots \\alpha_{p}}=\\gamma_{\\mu_{1}}^{\\alpha_{1}} \\cdots \\gamma^{\\alpha_{p}}_{\\mu_{p}} \\gamma^{\\nu_{1}}_{\\beta_{1}} \\cdots \\gamma^{\\nu_{q}}_{\\beta_{q}} \\gamma^{\\sigma}_{\\rho} \\nabla_{\\sigma} T_{\\nu_{1} \\ldots \\nu_{q}}^{\\mu_{1} \\ldots \\mu_{p}} To do so, we first take a completely spatial projection of ^{(4)} R^a_{\\space bcd} ^{(4)} R^a_{\\space bcd} , then a projection with one index projected in the normal direction, and finally a projection with two indices projected in the normal direction. All other projections vanish identically because of the symmetries of the Riemann tensor. A decomposition of ^{(4)} R^a_{\\space bcd} ^{(4)} R^a_{\\space bcd} into spatial and normal pieces therefore involves these three different types of projections . The above projections give rise to the equations of Gauss, Codazzi and Ricci 1 . Gauss\u2019 equation: a completely spatial projection. R_{abcd} + K_{ac} K_{bd} -K_{ad} K_{cb} = \\gamma^p_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} \\gamma^s_{\\space d} {}^{(4)} R_{pqrs} R_{abcd} + K_{ac} K_{bd} -K_{ad} K_{cb} = \\gamma^p_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} \\gamma^s_{\\space d} {}^{(4)} R_{pqrs} Codazzi equation: the part projected three times onto \\Sigma_{t} \\Sigma_{t} and once along the normal n D_b K_{ac} - D_a K_{bc} = \\gamma^p_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} n^s_{\\space d} {}^{(4)} R_{pqrs} D_b K_{ac} - D_a K_{bc} = \\gamma^p_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} n^s_{\\space d} {}^{(4)} R_{pqrs} Ricci equation: the projection of the spacetime Riemann tensor twice onto \\Sigma_{t} \\Sigma_{t} and twice along n. \\gamma_{\\alpha \\mu} n^{\\rho} \\gamma_{\\beta}^{\\nu} n^{\\sigma} {}^{4} R_{\\rho \\nu \\sigma}^{\\mu}=\\frac{1}{N} \\mathcal{L}_{m} K_{\\alpha \\beta}+\\frac{1}{N} D_{\\alpha} D_{\\beta} N+K_{\\alpha \\mu} K_{\\beta}^{\\mu} \\gamma_{\\alpha \\mu} n^{\\rho} \\gamma_{\\beta}^{\\nu} n^{\\sigma} {}^{4} R_{\\rho \\nu \\sigma}^{\\mu}=\\frac{1}{N} \\mathcal{L}_{m} K_{\\alpha \\beta}+\\frac{1}{N} D_{\\alpha} D_{\\beta} N+K_{\\alpha \\mu} K_{\\beta}^{\\mu} We can rewrite Einstein\u2019s \ufb01eld equations in a 3+1 form. Basically, we just need to take the equations of Gauss, Codazzi and Ricci and eliminate the four-dimensional Rieman tensor using Einstein\u2019s equations. G_{ab} = {}^{(4)} R_{ab} - \\frac{1}{2} {}^{(4)} R g_{ab} = 8 \\pi T_{ab} G_{ab} = {}^{(4)} R_{ab} - \\frac{1}{2} {}^{(4)} R g_{ab} = 8 \\pi T_{ab} Constraint equations We will first derive the constraint equations from Gauss\u2019 equation and the Codazzi equation. Contracting Gauss\u2019 equation: R + K^2 - K_{ab}K^{ab} = 16 \\pi \\rho R + K^2 - K_{ab}K^{ab} = 16 \\pi \\rho Note We now define the energy density \u03c1 to be the total energy density as measured by a normal observer n^a n^a , \\rho = n_a n_b T^{ab} \\\\ 2 n^p n^r G_{pr} = R + K^2 - K_{ab} K^{ab} \\rho = n_a n_b T^{ab} \\\\ 2 n^p n^r G_{pr} = R + K^2 - K_{ab} K^{ab} Contracting the Codazzi equation: D_b K^b_{\\space a} - D_a K = 8 \\pi S_a D_b K^b_{\\space a} - D_a K = 8 \\pi S_a Note We now define S_a S_a to be the momentum density as measured by a normal observer n^a n^a , S_a = - \\gamma^b_{\\space a} n^c T_{bc} \\\\ D_b K^b_{\\space a} - D_a K = - \\gamma^q_{\\space a} n^s G_{qs} S_a = - \\gamma^b_{\\space a} n^c T_{bc} \\\\ D_b K^b_{\\space a} - D_a K = - \\gamma^q_{\\space a} n^s G_{qs} They are the conditions that allow a three-dimensional slice \u03a3 with data (\\gamma_{ab}, K_{ab}) (\\gamma_{ab}, K_{ab}) to be embedded in a four-dimensional manifold M with data g_{ab} g_{ab} . We will discuss strategies for solving the constraint equations and finding initial data that represent a snapshot of the gravitational fields at a certain instant of time. Constraint equations constrain the fields in space at one instant of time, independently of their past history. Freedom The four constraint equations cannot determine all of the gravitational fields (\\gamma_{ij}, K_{ij}) (\\gamma_{ij}, K_{ij}) . Both \\gamma_{ij} \\gamma_{ij} and K_{ij} K_{ij} are symmetric, three-dimensional tensors, they together have twelve independent components . The four constraint equations can only determine four of these Four undetermined functions are related to coordinate choices Two independent sets of values for the conjugate pair (\\gamma_{ij}, K_{ij}) (\\gamma_{ij}, K_{ij}) . Two dynamical degrees of freedom correspond to the two polarization modes of a gravitational wave It is quite intuitive that the state of a dynamical field, like a gravitational wave, cannot be determined from constraint equations . Waves satisfy hyperbolic equations, and their state at any time depends on their past history. It is therefore natural that the constraint equations serve to constrain only the \u201clongitudinal\u201d parts of the fields, while the \u201ctransverse\u201d parts, related to the dynamical degrees of freedom, remain freely specifiable. Ideally one would like to separate unambiguously the longitudinal from the transverse parts of the fields at some initial time, freely specifying the latter and then solving the constraints for the former. Given the nonlinear nature of general relativity such a rigorous separation is not possible ; instead, all these fields are entangled in the spatial metric and the extrinsic curvature. Evolution Equations The evolution equations evolve the data (\u03b3_{ab},K_{ab}) (\u03b3_{ab},K_{ab}) forward in time. However, the Lie derivative along n^a n^a , \\mathcal { L } _ { \\mathbf { n } } \\mathcal { L } _ { \\mathbf { n } } , is not a natural time derivative since n^a n^a is not dual to the surface 1-form \u03a9_a \u03a9_a , i.e. their dot product is not unity n ^ { a } \\Omega _ { a } = - \\alpha g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t = \\alpha ^ { - 1 } n ^ { a } \\Omega _ { a } = - \\alpha g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t = \\alpha ^ { - 1 } Instead, consider the vector t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } which is dual to \u03a9_a \u03a9_a for any spatial shift vector \u03b2^a \u03b2^a , t ^ { a } \\Omega _ { a } = \\alpha n ^ { a } \\Omega _ { a } + \\beta ^ { a } \\Omega _ { a } = 1 t ^ { a } \\Omega _ { a } = \\alpha n ^ { a } \\Omega _ { a } + \\beta ^ { a } \\Omega _ { a } = 1 It will prove useful to choose t^a t^a to be the congruence along which we propagate the spatial coordinate grid from one time slice to the next slice. In other words, t^a t^a will connect points with the same spatial coordinates on neighboring time slices. Note Observers who are \u201cat rest\u201d relative to the slices follow the normal congruence n^a n^a and are called either normal or Eulerian observers. while observers following the congruence t^a t^a are called coordinate observers. If matter is present it moves entirely independently of the coordinates with four-velocity u^a u^a . Ricci\u2019s equation: The evolution equation for the extrinsic curvature: \\begin{align} \\mathcal{L}_{t} K_{ab} = &- D_{a} D_{b} \\alpha + \\alpha (R_{ab} - 2 K_{ac} K^{c}_{\\space b} + K K_{ab}) \\\\ &- 8 \\pi \\alpha \\left( S_{ab} - \\frac{1}{2} \\gamma_{ab} \\left( S-\\rho \\right) \\right) + \\mathcal{L}_{\\beta}K_{ab} \\end{align} \\begin{align} \\mathcal{L}_{t} K_{ab} = &- D_{a} D_{b} \\alpha + \\alpha (R_{ab} - 2 K_{ac} K^{c}_{\\space b} + K K_{ab}) \\\\ &- 8 \\pi \\alpha \\left( S_{ab} - \\frac{1}{2} \\gamma_{ab} \\left( S-\\rho \\right) \\right) + \\mathcal{L}_{\\beta}K_{ab} \\end{align} Note a projection with two indices projected in the normal direction. \\mathcal{L}_n K_{ab} = n^d n^c \\gamma^q_{\\space a} \\gamma^r_{\\space b} {}^{(4)} R_{drcq} - \\frac{1}{\\alpha} D_a D_b \\alpha - K^c_{\\space b} K_{ac} \\\\ S_{ab} = \\gamma^c_{\\space a} \\gamma^d_{\\space b} T_{cd} \\\\ S = S^a_{\\space a} \\mathcal{L}_n K_{ab} = n^d n^c \\gamma^q_{\\space a} \\gamma^r_{\\space b} {}^{(4)} R_{drcq} - \\frac{1}{\\alpha} D_a D_b \\alpha - K^c_{\\space b} K_{ac} \\\\ S_{ab} = \\gamma^c_{\\space a} \\gamma^d_{\\space b} T_{cd} \\\\ S = S^a_{\\space a} The evolution equation for the spatial metric \\gamma_{ab} \\gamma_{ab} : \\mathcal{L}_t \\gamma_{ab} = - 2 \\alpha K_{ab} + \\mathcal{L}_{\\beta} \\gamma_{ab} \\mathcal{L}_t \\gamma_{ab} = - 2 \\alpha K_{ab} + \\mathcal{L}_{\\beta} \\gamma_{ab} Note K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} It is quite intuitive, though, that things will simplify if we adopt a coordinate system that reflects our 3 + 1 split of spacetime in a natural way. We will see that the Lie derivative in the evolution equations then reduces to a partial derivative with respect to coordinate time and, as an additional bene\ufb01t, we will be able to ignore all timelike components of spatial tensors. The coupled evolution equations the extrinsic curvature and the spatial metric determine the evolution of the gravitational \ufb01eld data (\\gamma_{ab}, K_{ab}) (\\gamma_{ab}, K_{ab}) . Together with the constraint equations they are completely equivalent to Einstein\u2019s equations. Note we have succeeded in recasting Einstein\u2019s equations, which are second order in time in their original form, as a coupled set of partial differential equations that are now first order in time . So far, we have expressed our equations in a covariant, coordinate independent manner, i.e. the basis vectors e_a e_a have been completely arbitrary and have no particular relationship to the 1-form \u03a9_a \u03a9_a or to the congruence defined by t^a t^a . ADM Equations It is quite intuitive, though, that things will simplify if we adopt a coordinate system that effects our 3 + 1 split of spacetime in a natural way. To do so, we first introduce a basis of three spatial vectors e^a_{(i)} e^a_{(i)} , reside in a particular time slice \u03a3: \\Omega_a e^a_{(i)} = 0 \\Omega_a e^a_{(i)} = 0 We extend our spatial vectors to other slices \u03a3 by Lie dragging along t^a t^a \\mathcal{L}_t e^a_{(i)} = 0 \\mathcal{L}_t e^a_{(i)} = 0 As the fourth basis vector we pick e^a_0 = t^a e^a_0 = t^a . The duality condition then implies that e^a_{(0)} e^a_{(0)} has the components t ^ { a } = e _ { ( 0 ) } ^ { a } = ( 1,0,0,0 ) t ^ { a } = e _ { ( 0 ) } ^ { a } = ( 1,0,0,0 ) This means that the Lie derivative along t^a t^a reduces to a partial derivative with respect to t: \\mathcal{L}_t = \\partial_t \\mathcal{L}_t = \\partial_t . Since spatial tensors vanish when contracted with the normal vector, this also means that all components of spatial tensors with a contravariant index equal to zero must vanish. For the shift vector, \\beta ^ { a } = \\left( 0 , \\beta ^ { i } \\right) \\beta ^ { a } = \\left( 0 , \\beta ^ { i } \\right) Solving equation t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } for n^a n^a then yields the contravariant components n ^ { a } = \\left( \\alpha ^ { - 1 } , - \\alpha ^ { - 1 } \\beta ^ { i } \\right) n ^ { a } = \\left( \\alpha ^ { - 1 } , - \\alpha ^ { - 1 } \\beta ^ { i } \\right) and from the normalization condition n_a n^a = \u22121 n_a n^a = \u22121 we find n _ { a } = ( - \\alpha , 0,0,0 ) n _ { a } = ( - \\alpha , 0,0,0 ) From the definition of the spatial metric we have \\gamma_{ij} = g_{ij} \\gamma_{ij} = g_{ij} meaning that the metric on \u03a3 is just the spatial part of the four-metric. Since zeroth components of spatial contravariant tensors have to vanish, we also have \\gamma^{a0} = 0 \\gamma^{a0} = 0 . The inverse metric can therefore be expressed as: g^{ab} = \\gamma^{ab} - n^{a} n^{b} = \\begin{pmatrix} \\alpha^{-2} & \\alpha^{-2} \\beta^{i} \\\\ \\alpha^{-2} \\beta^{j} & \\gamma^{ij} - \\alpha^{2} \\beta^{i} \\beta^{j} \\end{pmatrix} g^{ab} = \\gamma^{ab} - n^{a} n^{b} = \\begin{pmatrix} \\alpha^{-2} & \\alpha^{-2} \\beta^{i} \\\\ \\alpha^{-2} \\beta^{j} & \\gamma^{ij} - \\alpha^{2} \\beta^{i} \\beta^{j} \\end{pmatrix} We can now invert it and find the components of the four-dimensional metric g_{ab} = \\begin{pmatrix} \\alpha^{-2} + \\beta_l \\beta^l & \\beta_{i} \\\\ \\beta_{j} & \\gamma_{ij} \\end{pmatrix} g_{ab} = \\begin{pmatrix} \\alpha^{-2} + \\beta_l \\beta^l & \\beta_{i} \\\\ \\beta_{j} & \\gamma_{ij} \\end{pmatrix} Equivalently, the line element may be decomposed as: ds^{2} = - \\alpha^{2} dt^{2} + \\gamma_{ij} \\left( dx^{i} + \\beta^{i} dt \\right) \\left( dx^{j} + \\beta^{j}dt \\right) ds^{2} = - \\alpha^{2} dt^{2} + \\gamma_{ij} \\left( dx^{i} + \\beta^{i} dt \\right) \\left( dx^{j} + \\beta^{j}dt \\right) which is often refered to as the metric in 3 + 1 form. We may interpret this line element as the Pythagorean Theorem for a 4-dimensional spacetime, ds^2 = - (properTime)^2 + (properDistance)^2 ds^2 = - (properTime)^2 + (properDistance)^2 This equation thus determines the invariant interval between neighboring points A and B. Ill-posedness The ADM equations by themselves proved to be unstable for many strong-field problems, including black-hole mergers. Well-Posedness Mathematical models of physical phenomena should have the properties that: Existence: a solution exists, Uniqueness: the solution is unique, Stability: the solution's behavior changes continuously with the initial conditions. If one of these conditions is not satisfied, the PDE problem is said to be ill-posed . A system of equations would be stable if the norm of the solution is bounded by the norm of the initial data in terms of constants independent of the initial data. \\|u(\\cdot, t)\\| \\leq a e^{b t}\\|u(\\cdot, 0)\\| \\|u(\\cdot, t)\\| \\leq a e^{b t}\\|u(\\cdot, 0)\\| where a,b are the same constants for all initial data. The system is first-order in time and second-order in space, being generically represented in the form \\dot{u}=A^{i j}\\left(x^{k}, t, u\\right) u_{, i j}+B^{i}\\left(x^{k}, t, u, u_{, k}\\right) u_{, i}+C\\left(x^{k}, t, u\\right) \\equiv P\\left(x^{k}, t, u, u_{, k}, \\partial / \\partial x^{j}\\right) u \\dot{u}=A^{i j}\\left(x^{k}, t, u\\right) u_{, i j}+B^{i}\\left(x^{k}, t, u, u_{, k}\\right) u_{, i}+C\\left(x^{k}, t, u\\right) \\equiv P\\left(x^{k}, t, u, u_{, k}, \\partial / \\partial x^{j}\\right) u Any time that an evolution system can be represented in this form, we interpret the right-hand side as an evolution operator acting on a solution. In this case, the evolution operator is P, and contains all the terms in the right-hand side of equation. It is essential to point out that the properties of stability of a system are encoded in the principal terms of the operator P, namely, in A^{i j}\\left(x^{k}, t, u\\right) A^{i j}\\left(x^{k}, t, u\\right) . This means that we can restrict our attention to a system of the \\dot{u}=A^{i j}\\left(x^{k}, t, u\\right) u_{, i j} \\dot{u}=A^{i j}\\left(x^{k}, t, u\\right) u_{, i j} The principal terms of the evolution operator of the standard ADM form are \\begin{aligned} \\dot{\\gamma}_{i j} &=0 \\\\ \\dot{K}_{i j} &=\\frac{\\alpha}{2}\\left(2 \\gamma^{k l} \\gamma_{l(i, j) k}-\\gamma^{k l} \\gamma_{i j, k l}-\\gamma^{k l} \\gamma_{k l, i j}\\right) \\end{aligned} \\begin{aligned} \\dot{\\gamma}_{i j} &=0 \\\\ \\dot{K}_{i j} &=\\frac{\\alpha}{2}\\left(2 \\gamma^{k l} \\gamma_{l(i, j) k}-\\gamma^{k l} \\gamma_{i j, k l}-\\gamma^{k l} \\gamma_{k l, i j}\\right) \\end{aligned} Consider the following periodic solution to with \\alpha=1 \\alpha=1 (geodesic slicing): \\begin{aligned} \\gamma_{i j} &=\\left(1+\\frac{1}{2} \\cos (k \\cdot x)\\right) \\delta_{i j} \\\\ K_{i j} &=t \\frac{\\cos (k \\cdot x)}{\\left(1+\\frac{1}{2} \\cos (k \\cdot x)\\right)}\\left(k_{i} k_{j}+\\delta_{i j} k \\cdot k\\right) \\end{aligned} \\begin{aligned} \\gamma_{i j} &=\\left(1+\\frac{1}{2} \\cos (k \\cdot x)\\right) \\delta_{i j} \\\\ K_{i j} &=t \\frac{\\cos (k \\cdot x)}{\\left(1+\\frac{1}{2} \\cos (k \\cdot x)\\right)}\\left(k_{i} k_{j}+\\delta_{i j} k \\cdot k\\right) \\end{aligned} With the norm \\|u(\\cdot, t)\\| \\equiv \\frac{1}{L^{3}} \\int_{c u b e} d^{3} x\\left(\\sum_{i j}\\left(\\gamma_{i j}\\right)^{2}+\\sum_{i j}\\left(K_{i j}\\right)^{2}\\right) \\|u(\\cdot, t)\\| \\equiv \\frac{1}{L^{3}} \\int_{c u b e} d^{3} x\\left(\\sum_{i j}\\left(\\gamma_{i j}\\right)^{2}+\\sum_{i j}\\left(K_{i j}\\right)^{2}\\right) we have \\|u(\\cdot, t)\\|=\\left(\\frac{3}{2}\\right)^{3}+6(k \\cdot k)^{2} t^{2} \\frac{1}{L^{3}} \\int_{c u b e} d^{3} x \\frac{\\cos ^{2}(k \\cdot x)}{\\left(1+\\frac{1}{2} \\cos (k \\cdot x)\\right)^{2}} \\|u(\\cdot, t)\\|=\\left(\\frac{3}{2}\\right)^{3}+6(k \\cdot k)^{2} t^{2} \\frac{1}{L^{3}} \\int_{c u b e} d^{3} x \\frac{\\cos ^{2}(k \\cdot x)}{\\left(1+\\frac{1}{2} \\cos (k \\cdot x)\\right)^{2}} It is very simple to see that the following inequality holds: \\|u(\\cdot, t)\\| \\geq\\|u(\\cdot, 0)\\|\\left(1+\\frac{2^{5}}{3^{4}}(k \\cdot k)^{2} t^{2}\\right) \\|u(\\cdot, t)\\| \\geq\\|u(\\cdot, 0)\\|\\left(1+\\frac{2^{5}}{3^{4}}(k \\cdot k)^{2} t^{2}\\right) It is impossible to bound the terms in parenthesis in the right-hand-side by a factor of the form a e^{b t} a e^{b t} with a and b independent of \\omega \\equiv \\sqrt{k \\cdot k} \\omega \\equiv \\sqrt{k \\cdot k} . Because of the presence of \\omega \\omega , we conclude that the norm is not bounded in terms of the initial data and the standard ADM equations are ill-posed for \\alpha=1 \\alpha=1 . Although this may create a difficulty in the stability analysis of these systems, we do not think that this necessarily implies an obstruction to numerical integration of any of them, in general. For particular applications, it is possible that the bad behavior at high frequencies may be disregarded . One of the key improvements in numerical simulations prior to the breakthroughs of 2005 was the introduction of the so-called NOKBSSN formulation of the Einstein equations in 3+1. This system modifies the standard ADM equations in several crucial ways. initial-value problem We first decide which field variables we want to determine by solving constraint equations. We then have to make choices for the remaining, freely specifiable variables. Lastly, we must solve these equations for the constrained field variables. Analogy Electric Field Maxwell\u2019s equations also split into constraint and evolution equations. The constraint equations have to be satis\ufb01ed by any electric and magnetic \ufb01eld at each instant of time, but they are not sufficient to completely determine these fields. Consider the equation for the electric field \\vec{E} \\vec{E} , \\nabla \\cdot \\vec{E} = 4 \\pi \\rho \\nabla \\cdot \\vec{E} = 4 \\pi \\rho Given an electrical charge density \u03c1, we can solve this equation for one of the components of E^i E^i , but not all three of them. For example, we could make certain choices for E^x E^x and E^y E^y , and then solve for E^z E^z , even though we might be troubled by the asymmetry in singling out one particular component in this approach. Alternatively, we may prefer to write E^i E^i as some \u201cbackground\u201d field \\bar { E } ^ { i } \\bar { E } ^ { i } times some overall scaling factor, say \u03c8^4 \u03c8^4 E ^ { i } = \\psi ^ { 4 } \\bar { E } ^ { i } E ^ { i } = \\psi ^ { 4 } \\bar { E } ^ { i } make certain choices for all three components of the background field \\bar { E } ^ { i } \\bar { E } ^ { i } , and then solve for the scaling factor \u03c8^4 \u03c8^4 . Though it might not be so useful for treating Maxwell\u2019s equations, such an approach leads to a very convenient and tractable system for Einstein\u2019s equations. Conformal Transformation We begin by writing the spatial metric \\gamma_{ij} \\gamma_{ij} as a product of some power of a positive scaling factor \u03c8 and a background metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} , \\gamma_{ij} = \u03c8^4 \\bar{\\gamma}_{ij} \\gamma_{ij} = \u03c8^4 \\bar{\\gamma}_{ij} This identification is a conformal transformation of the spatial metric. We call \u03c8 the conformal factor , and \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} the conformally related metric . Taking \u03c8 to the fourth power turns out to be convenient, but is otherwise arbitrary. Loosely speaking, the conformal factor absorbs the overall scale of the metric, which leaves five degrees of freedom in the conformally related metric . Superficially, the conformal transformation is just a mathematical trick , namely, rewriting one unknown as a product of two unknowns in order to make solving some equations easier. Note From now on we will denote all objects associated with the conformal metric \\bar{\\gamma}_{i j} \\bar{\\gamma}_{i j} with a bar. In the above equations \\psi \\psi must be treated as a scalar function in covariant derivatives. The inverse of \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} : \\gamma ^ { i j } = \\psi ^ { - 4 } \\bar { \\gamma } ^ { i j } \\gamma ^ { i j } = \\psi ^ { - 4 } \\bar { \\gamma } ^ { i j } In three dimensions, the connection coefficients must transform according to \\Gamma _ { j k } ^ { i } = \\bar { \\Gamma } _ { j k } ^ { i } + 2 \\left( \\delta _ { j } ^ { i } \\bar { D } _ { k } \\ln \\psi + \\delta _ { k } ^ { i } \\bar { D } _ { j } \\ln \\psi - \\bar { \\gamma } _ { j k } \\bar { \\gamma } ^ { i l } \\bar { D } _ { l } \\ln \\psi \\right) \\Gamma _ { j k } ^ { i } = \\bar { \\Gamma } _ { j k } ^ { i } + 2 \\left( \\delta _ { j } ^ { i } \\bar { D } _ { k } \\ln \\psi + \\delta _ { k } ^ { i } \\bar { D } _ { j } \\ln \\psi - \\bar { \\gamma } _ { j k } \\bar { \\gamma } ^ { i l } \\bar { D } _ { l } \\ln \\psi \\right) For the Ricci tensor we similarly find \\begin{aligned} R_{i j}=& \\bar{R}_{i j}-2\\left(\\bar{D}_{i} \\bar{D}_{j} \\ln \\psi+\\bar{\\gamma}_{i j} \\bar{\\gamma}^{l m} \\bar{D}_{l} \\bar{D}_{m} \\ln \\psi\\right) \\\\ &+4\\left(\\left(\\bar{D}_{i} \\ln \\psi\\right)\\left(\\bar{D}_{j} \\ln \\psi\\right)-\\bar{\\gamma}_{i j} \\bar{\\gamma}^{l m}\\left(\\bar{D}_{l} \\ln \\psi\\right)\\left(\\bar{D}_{m} \\ln \\psi\\right)\\right) \\end{aligned} \\begin{aligned} R_{i j}=& \\bar{R}_{i j}-2\\left(\\bar{D}_{i} \\bar{D}_{j} \\ln \\psi+\\bar{\\gamma}_{i j} \\bar{\\gamma}^{l m} \\bar{D}_{l} \\bar{D}_{m} \\ln \\psi\\right) \\\\ &+4\\left(\\left(\\bar{D}_{i} \\ln \\psi\\right)\\left(\\bar{D}_{j} \\ln \\psi\\right)-\\bar{\\gamma}_{i j} \\bar{\\gamma}^{l m}\\left(\\bar{D}_{l} \\ln \\psi\\right)\\left(\\bar{D}_{m} \\ln \\psi\\right)\\right) \\end{aligned} For the scalar curvature R = \\psi ^ { - 4 } \\bar { R } - 8 \\psi ^ { - 5 } \\bar { D } ^ { 2 } \\psi R = \\psi ^ { - 4 } \\bar { R } - 8 \\psi ^ { - 5 } \\bar { D } ^ { 2 } \\psi Inserting the scalar curvature into the Hamiltonian constraint yields 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { 5 } K _ { i j } K ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { 5 } K _ { i j } K ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho which, for a given choice of the conformally related metric \\bar { \\gamma } ^ { i j } \\bar { \\gamma } ^ { i j } , we may interpret as an equation for the conformal factor \u03c8. The extrinsic curvature K_{ij} K_{ij} has to satisfy the momentum constraint, and it will be useful to rescale K_{ij} K_{ij} conformally as well. It is convenient to split K_{ij} K_{ij} into its trace K K and a traceless part A_{i j} A_{i j} according to K_{i j}=A_{i j}+\\frac{1}{3} \\gamma_{i j} K K_{i j}=A_{i j}+\\frac{1}{3} \\gamma_{i j} K and to conformally transform K K and A_{i j} A_{i j} separately. A priori it is not clear how to transform K K and A_{i j} A_{i j} , and our only guidance for inventing rules is that the transformation should bring the constraint equations into a simple and solvable form. Consider the transformations \\begin{aligned} A^{i j} &=\\psi^{\\alpha} \\bar{A}^{i j} \\\\ K &=\\psi^{\\beta} \\bar{K} \\end{aligned} \\begin{aligned} A^{i j} &=\\psi^{\\alpha} \\bar{A}^{i j} \\\\ K &=\\psi^{\\beta} \\bar{K} \\end{aligned} With the choices of \\alpha=-10 \\alpha=-10 and \\beta=0 \\beta=0 , the momentum constraint is \\bar{D}_{j} \\bar{A}^{i j}-\\frac{2}{3} \\psi^{6} \\bar{\\gamma}^{i j} \\bar{D}_{j} K=8 \\pi \\psi^{10} S^{i} \\bar{D}_{j} \\bar{A}^{i j}-\\frac{2}{3} \\psi^{6} \\bar{\\gamma}^{i j} \\bar{D}_{j} K=8 \\pi \\psi^{10} S^{i} In addition to the spatial metric and extrinsic curvature, it may also be necessary to transform the matter sources \\rho \\rho and S^{i} S^{i} to insure uniqueness of solutions . Gourgoulhon, E. 3+1 Formalism and Bases of Numerical Relativity. arXiv:gr-qc/0703035 (2007). \u21a9 Frittelli, S. & Gomez, R. Ill-posedness in the Einstein equations. Journal of Mathematical Physics 41, 5535\u20135549 (2000). \u21a9","title":"ADM"},{"location":"NR/ADM/#the-projections-of-the-riemann-tensor","text":"In order to find these relations, we have to relate the three-dimensional Riemann tensor R^a_{\\space bcd} R^a_{\\space bcd} of the the hypersurfaces \u03a3 to the four-dimensional Riemann tensor ^{(4)} R^a_{\\space bcd} ^{(4)} R^a_{\\space bcd} of M. relate the three-dimensional Riemann tensor to the four-dimensional Riemann tensor Let us consider the Ricci identity defining the (three-dimensional) Riemann tensor Riem as measuring the lack of commutation of two successive covariant derivatives with respect to the connection D associated with \\Sigma \\Sigma 's metric \\gamma \\gamma . The four-dimensional version of this identity is D_{\\alpha} D_{\\beta} v^{\\gamma}-D_{\\beta} D_{\\alpha} v^{\\gamma}=R_{\\mu \\alpha \\beta}^{\\gamma} v^{\\mu} D_{\\alpha} D_{\\beta} v^{\\gamma}-D_{\\beta} D_{\\alpha} v^{\\gamma}=R_{\\mu \\alpha \\beta}^{\\gamma} v^{\\mu} where v v is a generic vector field tangent to \\Sigma \\Sigma . The relation between the D-derivative and the \\nabla \\nabla -derivative D_{\\rho} T_{\\beta_{1} \\ldots \\beta_{q}}^{\\alpha_{1} \\ldots \\alpha_{p}}=\\gamma_{\\mu_{1}}^{\\alpha_{1}} \\cdots \\gamma^{\\alpha_{p}}_{\\mu_{p}} \\gamma^{\\nu_{1}}_{\\beta_{1}} \\cdots \\gamma^{\\nu_{q}}_{\\beta_{q}} \\gamma^{\\sigma}_{\\rho} \\nabla_{\\sigma} T_{\\nu_{1} \\ldots \\nu_{q}}^{\\mu_{1} \\ldots \\mu_{p}} D_{\\rho} T_{\\beta_{1} \\ldots \\beta_{q}}^{\\alpha_{1} \\ldots \\alpha_{p}}=\\gamma_{\\mu_{1}}^{\\alpha_{1}} \\cdots \\gamma^{\\alpha_{p}}_{\\mu_{p}} \\gamma^{\\nu_{1}}_{\\beta_{1}} \\cdots \\gamma^{\\nu_{q}}_{\\beta_{q}} \\gamma^{\\sigma}_{\\rho} \\nabla_{\\sigma} T_{\\nu_{1} \\ldots \\nu_{q}}^{\\mu_{1} \\ldots \\mu_{p}} To do so, we first take a completely spatial projection of ^{(4)} R^a_{\\space bcd} ^{(4)} R^a_{\\space bcd} , then a projection with one index projected in the normal direction, and finally a projection with two indices projected in the normal direction. All other projections vanish identically because of the symmetries of the Riemann tensor. A decomposition of ^{(4)} R^a_{\\space bcd} ^{(4)} R^a_{\\space bcd} into spatial and normal pieces therefore involves these three different types of projections . The above projections give rise to the equations of Gauss, Codazzi and Ricci 1 . Gauss\u2019 equation: a completely spatial projection. R_{abcd} + K_{ac} K_{bd} -K_{ad} K_{cb} = \\gamma^p_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} \\gamma^s_{\\space d} {}^{(4)} R_{pqrs} R_{abcd} + K_{ac} K_{bd} -K_{ad} K_{cb} = \\gamma^p_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} \\gamma^s_{\\space d} {}^{(4)} R_{pqrs} Codazzi equation: the part projected three times onto \\Sigma_{t} \\Sigma_{t} and once along the normal n D_b K_{ac} - D_a K_{bc} = \\gamma^p_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} n^s_{\\space d} {}^{(4)} R_{pqrs} D_b K_{ac} - D_a K_{bc} = \\gamma^p_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} n^s_{\\space d} {}^{(4)} R_{pqrs} Ricci equation: the projection of the spacetime Riemann tensor twice onto \\Sigma_{t} \\Sigma_{t} and twice along n. \\gamma_{\\alpha \\mu} n^{\\rho} \\gamma_{\\beta}^{\\nu} n^{\\sigma} {}^{4} R_{\\rho \\nu \\sigma}^{\\mu}=\\frac{1}{N} \\mathcal{L}_{m} K_{\\alpha \\beta}+\\frac{1}{N} D_{\\alpha} D_{\\beta} N+K_{\\alpha \\mu} K_{\\beta}^{\\mu} \\gamma_{\\alpha \\mu} n^{\\rho} \\gamma_{\\beta}^{\\nu} n^{\\sigma} {}^{4} R_{\\rho \\nu \\sigma}^{\\mu}=\\frac{1}{N} \\mathcal{L}_{m} K_{\\alpha \\beta}+\\frac{1}{N} D_{\\alpha} D_{\\beta} N+K_{\\alpha \\mu} K_{\\beta}^{\\mu} We can rewrite Einstein\u2019s \ufb01eld equations in a 3+1 form. Basically, we just need to take the equations of Gauss, Codazzi and Ricci and eliminate the four-dimensional Rieman tensor using Einstein\u2019s equations. G_{ab} = {}^{(4)} R_{ab} - \\frac{1}{2} {}^{(4)} R g_{ab} = 8 \\pi T_{ab} G_{ab} = {}^{(4)} R_{ab} - \\frac{1}{2} {}^{(4)} R g_{ab} = 8 \\pi T_{ab}","title":"The projections of the Riemann tensor"},{"location":"NR/ADM/#constraint-equations","text":"We will first derive the constraint equations from Gauss\u2019 equation and the Codazzi equation. Contracting Gauss\u2019 equation: R + K^2 - K_{ab}K^{ab} = 16 \\pi \\rho R + K^2 - K_{ab}K^{ab} = 16 \\pi \\rho Note We now define the energy density \u03c1 to be the total energy density as measured by a normal observer n^a n^a , \\rho = n_a n_b T^{ab} \\\\ 2 n^p n^r G_{pr} = R + K^2 - K_{ab} K^{ab} \\rho = n_a n_b T^{ab} \\\\ 2 n^p n^r G_{pr} = R + K^2 - K_{ab} K^{ab} Contracting the Codazzi equation: D_b K^b_{\\space a} - D_a K = 8 \\pi S_a D_b K^b_{\\space a} - D_a K = 8 \\pi S_a Note We now define S_a S_a to be the momentum density as measured by a normal observer n^a n^a , S_a = - \\gamma^b_{\\space a} n^c T_{bc} \\\\ D_b K^b_{\\space a} - D_a K = - \\gamma^q_{\\space a} n^s G_{qs} S_a = - \\gamma^b_{\\space a} n^c T_{bc} \\\\ D_b K^b_{\\space a} - D_a K = - \\gamma^q_{\\space a} n^s G_{qs} They are the conditions that allow a three-dimensional slice \u03a3 with data (\\gamma_{ab}, K_{ab}) (\\gamma_{ab}, K_{ab}) to be embedded in a four-dimensional manifold M with data g_{ab} g_{ab} . We will discuss strategies for solving the constraint equations and finding initial data that represent a snapshot of the gravitational fields at a certain instant of time. Constraint equations constrain the fields in space at one instant of time, independently of their past history. Freedom The four constraint equations cannot determine all of the gravitational fields (\\gamma_{ij}, K_{ij}) (\\gamma_{ij}, K_{ij}) . Both \\gamma_{ij} \\gamma_{ij} and K_{ij} K_{ij} are symmetric, three-dimensional tensors, they together have twelve independent components . The four constraint equations can only determine four of these Four undetermined functions are related to coordinate choices Two independent sets of values for the conjugate pair (\\gamma_{ij}, K_{ij}) (\\gamma_{ij}, K_{ij}) . Two dynamical degrees of freedom correspond to the two polarization modes of a gravitational wave It is quite intuitive that the state of a dynamical field, like a gravitational wave, cannot be determined from constraint equations . Waves satisfy hyperbolic equations, and their state at any time depends on their past history. It is therefore natural that the constraint equations serve to constrain only the \u201clongitudinal\u201d parts of the fields, while the \u201ctransverse\u201d parts, related to the dynamical degrees of freedom, remain freely specifiable. Ideally one would like to separate unambiguously the longitudinal from the transverse parts of the fields at some initial time, freely specifying the latter and then solving the constraints for the former. Given the nonlinear nature of general relativity such a rigorous separation is not possible ; instead, all these fields are entangled in the spatial metric and the extrinsic curvature.","title":"Constraint equations"},{"location":"NR/ADM/#evolution-equations","text":"The evolution equations evolve the data (\u03b3_{ab},K_{ab}) (\u03b3_{ab},K_{ab}) forward in time. However, the Lie derivative along n^a n^a , \\mathcal { L } _ { \\mathbf { n } } \\mathcal { L } _ { \\mathbf { n } } , is not a natural time derivative since n^a n^a is not dual to the surface 1-form \u03a9_a \u03a9_a , i.e. their dot product is not unity n ^ { a } \\Omega _ { a } = - \\alpha g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t = \\alpha ^ { - 1 } n ^ { a } \\Omega _ { a } = - \\alpha g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t = \\alpha ^ { - 1 } Instead, consider the vector t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } which is dual to \u03a9_a \u03a9_a for any spatial shift vector \u03b2^a \u03b2^a , t ^ { a } \\Omega _ { a } = \\alpha n ^ { a } \\Omega _ { a } + \\beta ^ { a } \\Omega _ { a } = 1 t ^ { a } \\Omega _ { a } = \\alpha n ^ { a } \\Omega _ { a } + \\beta ^ { a } \\Omega _ { a } = 1 It will prove useful to choose t^a t^a to be the congruence along which we propagate the spatial coordinate grid from one time slice to the next slice. In other words, t^a t^a will connect points with the same spatial coordinates on neighboring time slices. Note Observers who are \u201cat rest\u201d relative to the slices follow the normal congruence n^a n^a and are called either normal or Eulerian observers. while observers following the congruence t^a t^a are called coordinate observers. If matter is present it moves entirely independently of the coordinates with four-velocity u^a u^a . Ricci\u2019s equation: The evolution equation for the extrinsic curvature: \\begin{align} \\mathcal{L}_{t} K_{ab} = &- D_{a} D_{b} \\alpha + \\alpha (R_{ab} - 2 K_{ac} K^{c}_{\\space b} + K K_{ab}) \\\\ &- 8 \\pi \\alpha \\left( S_{ab} - \\frac{1}{2} \\gamma_{ab} \\left( S-\\rho \\right) \\right) + \\mathcal{L}_{\\beta}K_{ab} \\end{align} \\begin{align} \\mathcal{L}_{t} K_{ab} = &- D_{a} D_{b} \\alpha + \\alpha (R_{ab} - 2 K_{ac} K^{c}_{\\space b} + K K_{ab}) \\\\ &- 8 \\pi \\alpha \\left( S_{ab} - \\frac{1}{2} \\gamma_{ab} \\left( S-\\rho \\right) \\right) + \\mathcal{L}_{\\beta}K_{ab} \\end{align} Note a projection with two indices projected in the normal direction. \\mathcal{L}_n K_{ab} = n^d n^c \\gamma^q_{\\space a} \\gamma^r_{\\space b} {}^{(4)} R_{drcq} - \\frac{1}{\\alpha} D_a D_b \\alpha - K^c_{\\space b} K_{ac} \\\\ S_{ab} = \\gamma^c_{\\space a} \\gamma^d_{\\space b} T_{cd} \\\\ S = S^a_{\\space a} \\mathcal{L}_n K_{ab} = n^d n^c \\gamma^q_{\\space a} \\gamma^r_{\\space b} {}^{(4)} R_{drcq} - \\frac{1}{\\alpha} D_a D_b \\alpha - K^c_{\\space b} K_{ac} \\\\ S_{ab} = \\gamma^c_{\\space a} \\gamma^d_{\\space b} T_{cd} \\\\ S = S^a_{\\space a} The evolution equation for the spatial metric \\gamma_{ab} \\gamma_{ab} : \\mathcal{L}_t \\gamma_{ab} = - 2 \\alpha K_{ab} + \\mathcal{L}_{\\beta} \\gamma_{ab} \\mathcal{L}_t \\gamma_{ab} = - 2 \\alpha K_{ab} + \\mathcal{L}_{\\beta} \\gamma_{ab} Note K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} It is quite intuitive, though, that things will simplify if we adopt a coordinate system that reflects our 3 + 1 split of spacetime in a natural way. We will see that the Lie derivative in the evolution equations then reduces to a partial derivative with respect to coordinate time and, as an additional bene\ufb01t, we will be able to ignore all timelike components of spatial tensors. The coupled evolution equations the extrinsic curvature and the spatial metric determine the evolution of the gravitational \ufb01eld data (\\gamma_{ab}, K_{ab}) (\\gamma_{ab}, K_{ab}) . Together with the constraint equations they are completely equivalent to Einstein\u2019s equations. Note we have succeeded in recasting Einstein\u2019s equations, which are second order in time in their original form, as a coupled set of partial differential equations that are now first order in time . So far, we have expressed our equations in a covariant, coordinate independent manner, i.e. the basis vectors e_a e_a have been completely arbitrary and have no particular relationship to the 1-form \u03a9_a \u03a9_a or to the congruence defined by t^a t^a .","title":"Evolution Equations"},{"location":"NR/ADM/#adm-equations","text":"It is quite intuitive, though, that things will simplify if we adopt a coordinate system that effects our 3 + 1 split of spacetime in a natural way. To do so, we first introduce a basis of three spatial vectors e^a_{(i)} e^a_{(i)} , reside in a particular time slice \u03a3: \\Omega_a e^a_{(i)} = 0 \\Omega_a e^a_{(i)} = 0 We extend our spatial vectors to other slices \u03a3 by Lie dragging along t^a t^a \\mathcal{L}_t e^a_{(i)} = 0 \\mathcal{L}_t e^a_{(i)} = 0 As the fourth basis vector we pick e^a_0 = t^a e^a_0 = t^a . The duality condition then implies that e^a_{(0)} e^a_{(0)} has the components t ^ { a } = e _ { ( 0 ) } ^ { a } = ( 1,0,0,0 ) t ^ { a } = e _ { ( 0 ) } ^ { a } = ( 1,0,0,0 ) This means that the Lie derivative along t^a t^a reduces to a partial derivative with respect to t: \\mathcal{L}_t = \\partial_t \\mathcal{L}_t = \\partial_t . Since spatial tensors vanish when contracted with the normal vector, this also means that all components of spatial tensors with a contravariant index equal to zero must vanish. For the shift vector, \\beta ^ { a } = \\left( 0 , \\beta ^ { i } \\right) \\beta ^ { a } = \\left( 0 , \\beta ^ { i } \\right) Solving equation t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } for n^a n^a then yields the contravariant components n ^ { a } = \\left( \\alpha ^ { - 1 } , - \\alpha ^ { - 1 } \\beta ^ { i } \\right) n ^ { a } = \\left( \\alpha ^ { - 1 } , - \\alpha ^ { - 1 } \\beta ^ { i } \\right) and from the normalization condition n_a n^a = \u22121 n_a n^a = \u22121 we find n _ { a } = ( - \\alpha , 0,0,0 ) n _ { a } = ( - \\alpha , 0,0,0 ) From the definition of the spatial metric we have \\gamma_{ij} = g_{ij} \\gamma_{ij} = g_{ij} meaning that the metric on \u03a3 is just the spatial part of the four-metric. Since zeroth components of spatial contravariant tensors have to vanish, we also have \\gamma^{a0} = 0 \\gamma^{a0} = 0 . The inverse metric can therefore be expressed as: g^{ab} = \\gamma^{ab} - n^{a} n^{b} = \\begin{pmatrix} \\alpha^{-2} & \\alpha^{-2} \\beta^{i} \\\\ \\alpha^{-2} \\beta^{j} & \\gamma^{ij} - \\alpha^{2} \\beta^{i} \\beta^{j} \\end{pmatrix} g^{ab} = \\gamma^{ab} - n^{a} n^{b} = \\begin{pmatrix} \\alpha^{-2} & \\alpha^{-2} \\beta^{i} \\\\ \\alpha^{-2} \\beta^{j} & \\gamma^{ij} - \\alpha^{2} \\beta^{i} \\beta^{j} \\end{pmatrix} We can now invert it and find the components of the four-dimensional metric g_{ab} = \\begin{pmatrix} \\alpha^{-2} + \\beta_l \\beta^l & \\beta_{i} \\\\ \\beta_{j} & \\gamma_{ij} \\end{pmatrix} g_{ab} = \\begin{pmatrix} \\alpha^{-2} + \\beta_l \\beta^l & \\beta_{i} \\\\ \\beta_{j} & \\gamma_{ij} \\end{pmatrix} Equivalently, the line element may be decomposed as: ds^{2} = - \\alpha^{2} dt^{2} + \\gamma_{ij} \\left( dx^{i} + \\beta^{i} dt \\right) \\left( dx^{j} + \\beta^{j}dt \\right) ds^{2} = - \\alpha^{2} dt^{2} + \\gamma_{ij} \\left( dx^{i} + \\beta^{i} dt \\right) \\left( dx^{j} + \\beta^{j}dt \\right) which is often refered to as the metric in 3 + 1 form. We may interpret this line element as the Pythagorean Theorem for a 4-dimensional spacetime, ds^2 = - (properTime)^2 + (properDistance)^2 ds^2 = - (properTime)^2 + (properDistance)^2 This equation thus determines the invariant interval between neighboring points A and B.","title":"ADM Equations"},{"location":"NR/ADM/#ill-posedness","text":"The ADM equations by themselves proved to be unstable for many strong-field problems, including black-hole mergers. Well-Posedness Mathematical models of physical phenomena should have the properties that: Existence: a solution exists, Uniqueness: the solution is unique, Stability: the solution's behavior changes continuously with the initial conditions. If one of these conditions is not satisfied, the PDE problem is said to be ill-posed . A system of equations would be stable if the norm of the solution is bounded by the norm of the initial data in terms of constants independent of the initial data. \\|u(\\cdot, t)\\| \\leq a e^{b t}\\|u(\\cdot, 0)\\| \\|u(\\cdot, t)\\| \\leq a e^{b t}\\|u(\\cdot, 0)\\| where a,b are the same constants for all initial data. The system is first-order in time and second-order in space, being generically represented in the form \\dot{u}=A^{i j}\\left(x^{k}, t, u\\right) u_{, i j}+B^{i}\\left(x^{k}, t, u, u_{, k}\\right) u_{, i}+C\\left(x^{k}, t, u\\right) \\equiv P\\left(x^{k}, t, u, u_{, k}, \\partial / \\partial x^{j}\\right) u \\dot{u}=A^{i j}\\left(x^{k}, t, u\\right) u_{, i j}+B^{i}\\left(x^{k}, t, u, u_{, k}\\right) u_{, i}+C\\left(x^{k}, t, u\\right) \\equiv P\\left(x^{k}, t, u, u_{, k}, \\partial / \\partial x^{j}\\right) u Any time that an evolution system can be represented in this form, we interpret the right-hand side as an evolution operator acting on a solution. In this case, the evolution operator is P, and contains all the terms in the right-hand side of equation. It is essential to point out that the properties of stability of a system are encoded in the principal terms of the operator P, namely, in A^{i j}\\left(x^{k}, t, u\\right) A^{i j}\\left(x^{k}, t, u\\right) . This means that we can restrict our attention to a system of the \\dot{u}=A^{i j}\\left(x^{k}, t, u\\right) u_{, i j} \\dot{u}=A^{i j}\\left(x^{k}, t, u\\right) u_{, i j} The principal terms of the evolution operator of the standard ADM form are \\begin{aligned} \\dot{\\gamma}_{i j} &=0 \\\\ \\dot{K}_{i j} &=\\frac{\\alpha}{2}\\left(2 \\gamma^{k l} \\gamma_{l(i, j) k}-\\gamma^{k l} \\gamma_{i j, k l}-\\gamma^{k l} \\gamma_{k l, i j}\\right) \\end{aligned} \\begin{aligned} \\dot{\\gamma}_{i j} &=0 \\\\ \\dot{K}_{i j} &=\\frac{\\alpha}{2}\\left(2 \\gamma^{k l} \\gamma_{l(i, j) k}-\\gamma^{k l} \\gamma_{i j, k l}-\\gamma^{k l} \\gamma_{k l, i j}\\right) \\end{aligned} Consider the following periodic solution to with \\alpha=1 \\alpha=1 (geodesic slicing): \\begin{aligned} \\gamma_{i j} &=\\left(1+\\frac{1}{2} \\cos (k \\cdot x)\\right) \\delta_{i j} \\\\ K_{i j} &=t \\frac{\\cos (k \\cdot x)}{\\left(1+\\frac{1}{2} \\cos (k \\cdot x)\\right)}\\left(k_{i} k_{j}+\\delta_{i j} k \\cdot k\\right) \\end{aligned} \\begin{aligned} \\gamma_{i j} &=\\left(1+\\frac{1}{2} \\cos (k \\cdot x)\\right) \\delta_{i j} \\\\ K_{i j} &=t \\frac{\\cos (k \\cdot x)}{\\left(1+\\frac{1}{2} \\cos (k \\cdot x)\\right)}\\left(k_{i} k_{j}+\\delta_{i j} k \\cdot k\\right) \\end{aligned} With the norm \\|u(\\cdot, t)\\| \\equiv \\frac{1}{L^{3}} \\int_{c u b e} d^{3} x\\left(\\sum_{i j}\\left(\\gamma_{i j}\\right)^{2}+\\sum_{i j}\\left(K_{i j}\\right)^{2}\\right) \\|u(\\cdot, t)\\| \\equiv \\frac{1}{L^{3}} \\int_{c u b e} d^{3} x\\left(\\sum_{i j}\\left(\\gamma_{i j}\\right)^{2}+\\sum_{i j}\\left(K_{i j}\\right)^{2}\\right) we have \\|u(\\cdot, t)\\|=\\left(\\frac{3}{2}\\right)^{3}+6(k \\cdot k)^{2} t^{2} \\frac{1}{L^{3}} \\int_{c u b e} d^{3} x \\frac{\\cos ^{2}(k \\cdot x)}{\\left(1+\\frac{1}{2} \\cos (k \\cdot x)\\right)^{2}} \\|u(\\cdot, t)\\|=\\left(\\frac{3}{2}\\right)^{3}+6(k \\cdot k)^{2} t^{2} \\frac{1}{L^{3}} \\int_{c u b e} d^{3} x \\frac{\\cos ^{2}(k \\cdot x)}{\\left(1+\\frac{1}{2} \\cos (k \\cdot x)\\right)^{2}} It is very simple to see that the following inequality holds: \\|u(\\cdot, t)\\| \\geq\\|u(\\cdot, 0)\\|\\left(1+\\frac{2^{5}}{3^{4}}(k \\cdot k)^{2} t^{2}\\right) \\|u(\\cdot, t)\\| \\geq\\|u(\\cdot, 0)\\|\\left(1+\\frac{2^{5}}{3^{4}}(k \\cdot k)^{2} t^{2}\\right) It is impossible to bound the terms in parenthesis in the right-hand-side by a factor of the form a e^{b t} a e^{b t} with a and b independent of \\omega \\equiv \\sqrt{k \\cdot k} \\omega \\equiv \\sqrt{k \\cdot k} . Because of the presence of \\omega \\omega , we conclude that the norm is not bounded in terms of the initial data and the standard ADM equations are ill-posed for \\alpha=1 \\alpha=1 . Although this may create a difficulty in the stability analysis of these systems, we do not think that this necessarily implies an obstruction to numerical integration of any of them, in general. For particular applications, it is possible that the bad behavior at high frequencies may be disregarded . One of the key improvements in numerical simulations prior to the breakthroughs of 2005 was the introduction of the so-called NOKBSSN formulation of the Einstein equations in 3+1. This system modifies the standard ADM equations in several crucial ways.","title":"Ill-posedness"},{"location":"NR/ADM/#initial-value-problem","text":"We first decide which field variables we want to determine by solving constraint equations. We then have to make choices for the remaining, freely specifiable variables. Lastly, we must solve these equations for the constrained field variables. Analogy Electric Field Maxwell\u2019s equations also split into constraint and evolution equations. The constraint equations have to be satis\ufb01ed by any electric and magnetic \ufb01eld at each instant of time, but they are not sufficient to completely determine these fields. Consider the equation for the electric field \\vec{E} \\vec{E} , \\nabla \\cdot \\vec{E} = 4 \\pi \\rho \\nabla \\cdot \\vec{E} = 4 \\pi \\rho Given an electrical charge density \u03c1, we can solve this equation for one of the components of E^i E^i , but not all three of them. For example, we could make certain choices for E^x E^x and E^y E^y , and then solve for E^z E^z , even though we might be troubled by the asymmetry in singling out one particular component in this approach. Alternatively, we may prefer to write E^i E^i as some \u201cbackground\u201d field \\bar { E } ^ { i } \\bar { E } ^ { i } times some overall scaling factor, say \u03c8^4 \u03c8^4 E ^ { i } = \\psi ^ { 4 } \\bar { E } ^ { i } E ^ { i } = \\psi ^ { 4 } \\bar { E } ^ { i } make certain choices for all three components of the background field \\bar { E } ^ { i } \\bar { E } ^ { i } , and then solve for the scaling factor \u03c8^4 \u03c8^4 . Though it might not be so useful for treating Maxwell\u2019s equations, such an approach leads to a very convenient and tractable system for Einstein\u2019s equations.","title":"initial-value problem"},{"location":"NR/ADM/#conformal-transformation","text":"We begin by writing the spatial metric \\gamma_{ij} \\gamma_{ij} as a product of some power of a positive scaling factor \u03c8 and a background metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} , \\gamma_{ij} = \u03c8^4 \\bar{\\gamma}_{ij} \\gamma_{ij} = \u03c8^4 \\bar{\\gamma}_{ij} This identification is a conformal transformation of the spatial metric. We call \u03c8 the conformal factor , and \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} the conformally related metric . Taking \u03c8 to the fourth power turns out to be convenient, but is otherwise arbitrary. Loosely speaking, the conformal factor absorbs the overall scale of the metric, which leaves five degrees of freedom in the conformally related metric . Superficially, the conformal transformation is just a mathematical trick , namely, rewriting one unknown as a product of two unknowns in order to make solving some equations easier. Note From now on we will denote all objects associated with the conformal metric \\bar{\\gamma}_{i j} \\bar{\\gamma}_{i j} with a bar. In the above equations \\psi \\psi must be treated as a scalar function in covariant derivatives. The inverse of \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} : \\gamma ^ { i j } = \\psi ^ { - 4 } \\bar { \\gamma } ^ { i j } \\gamma ^ { i j } = \\psi ^ { - 4 } \\bar { \\gamma } ^ { i j } In three dimensions, the connection coefficients must transform according to \\Gamma _ { j k } ^ { i } = \\bar { \\Gamma } _ { j k } ^ { i } + 2 \\left( \\delta _ { j } ^ { i } \\bar { D } _ { k } \\ln \\psi + \\delta _ { k } ^ { i } \\bar { D } _ { j } \\ln \\psi - \\bar { \\gamma } _ { j k } \\bar { \\gamma } ^ { i l } \\bar { D } _ { l } \\ln \\psi \\right) \\Gamma _ { j k } ^ { i } = \\bar { \\Gamma } _ { j k } ^ { i } + 2 \\left( \\delta _ { j } ^ { i } \\bar { D } _ { k } \\ln \\psi + \\delta _ { k } ^ { i } \\bar { D } _ { j } \\ln \\psi - \\bar { \\gamma } _ { j k } \\bar { \\gamma } ^ { i l } \\bar { D } _ { l } \\ln \\psi \\right) For the Ricci tensor we similarly find \\begin{aligned} R_{i j}=& \\bar{R}_{i j}-2\\left(\\bar{D}_{i} \\bar{D}_{j} \\ln \\psi+\\bar{\\gamma}_{i j} \\bar{\\gamma}^{l m} \\bar{D}_{l} \\bar{D}_{m} \\ln \\psi\\right) \\\\ &+4\\left(\\left(\\bar{D}_{i} \\ln \\psi\\right)\\left(\\bar{D}_{j} \\ln \\psi\\right)-\\bar{\\gamma}_{i j} \\bar{\\gamma}^{l m}\\left(\\bar{D}_{l} \\ln \\psi\\right)\\left(\\bar{D}_{m} \\ln \\psi\\right)\\right) \\end{aligned} \\begin{aligned} R_{i j}=& \\bar{R}_{i j}-2\\left(\\bar{D}_{i} \\bar{D}_{j} \\ln \\psi+\\bar{\\gamma}_{i j} \\bar{\\gamma}^{l m} \\bar{D}_{l} \\bar{D}_{m} \\ln \\psi\\right) \\\\ &+4\\left(\\left(\\bar{D}_{i} \\ln \\psi\\right)\\left(\\bar{D}_{j} \\ln \\psi\\right)-\\bar{\\gamma}_{i j} \\bar{\\gamma}^{l m}\\left(\\bar{D}_{l} \\ln \\psi\\right)\\left(\\bar{D}_{m} \\ln \\psi\\right)\\right) \\end{aligned} For the scalar curvature R = \\psi ^ { - 4 } \\bar { R } - 8 \\psi ^ { - 5 } \\bar { D } ^ { 2 } \\psi R = \\psi ^ { - 4 } \\bar { R } - 8 \\psi ^ { - 5 } \\bar { D } ^ { 2 } \\psi Inserting the scalar curvature into the Hamiltonian constraint yields 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { 5 } K _ { i j } K ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { 5 } K _ { i j } K ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho which, for a given choice of the conformally related metric \\bar { \\gamma } ^ { i j } \\bar { \\gamma } ^ { i j } , we may interpret as an equation for the conformal factor \u03c8. The extrinsic curvature K_{ij} K_{ij} has to satisfy the momentum constraint, and it will be useful to rescale K_{ij} K_{ij} conformally as well. It is convenient to split K_{ij} K_{ij} into its trace K K and a traceless part A_{i j} A_{i j} according to K_{i j}=A_{i j}+\\frac{1}{3} \\gamma_{i j} K K_{i j}=A_{i j}+\\frac{1}{3} \\gamma_{i j} K and to conformally transform K K and A_{i j} A_{i j} separately. A priori it is not clear how to transform K K and A_{i j} A_{i j} , and our only guidance for inventing rules is that the transformation should bring the constraint equations into a simple and solvable form. Consider the transformations \\begin{aligned} A^{i j} &=\\psi^{\\alpha} \\bar{A}^{i j} \\\\ K &=\\psi^{\\beta} \\bar{K} \\end{aligned} \\begin{aligned} A^{i j} &=\\psi^{\\alpha} \\bar{A}^{i j} \\\\ K &=\\psi^{\\beta} \\bar{K} \\end{aligned} With the choices of \\alpha=-10 \\alpha=-10 and \\beta=0 \\beta=0 , the momentum constraint is \\bar{D}_{j} \\bar{A}^{i j}-\\frac{2}{3} \\psi^{6} \\bar{\\gamma}^{i j} \\bar{D}_{j} K=8 \\pi \\psi^{10} S^{i} \\bar{D}_{j} \\bar{A}^{i j}-\\frac{2}{3} \\psi^{6} \\bar{\\gamma}^{i j} \\bar{D}_{j} K=8 \\pi \\psi^{10} S^{i} In addition to the spatial metric and extrinsic curvature, it may also be necessary to transform the matter sources \\rho \\rho and S^{i} S^{i} to insure uniqueness of solutions . Gourgoulhon, E. 3+1 Formalism and Bases of Numerical Relativity. arXiv:gr-qc/0703035 (2007). \u21a9 Frittelli, S. & Gomez, R. Ill-posedness in the Einstein equations. Journal of Mathematical Physics 41, 5535\u20135549 (2000). \u21a9","title":"Conformal Transformation"},{"location":"NR/BSSN/","text":"Decomposing the three metric and the extrinsic curvature according to \\begin{aligned} \\gamma_{i j} &=e^{4 \\phi} \\tilde{\\gamma}_{i j} \\\\ K_{i j} &=e^{4 \\phi}\\left(\\tilde{A}_{i j}+\\frac{1}{3} \\tilde{\\gamma}_{i j} K\\right) \\end{aligned} \\begin{aligned} \\gamma_{i j} &=e^{4 \\phi} \\tilde{\\gamma}_{i j} \\\\ K_{i j} &=e^{4 \\phi}\\left(\\tilde{A}_{i j}+\\frac{1}{3} \\tilde{\\gamma}_{i j} K\\right) \\end{aligned} where \\tilde{\\gamma}_{i j} \\tilde{\\gamma}_{i j} has unit determinant and K=\\gamma^{i j} K_{i j} K=\\gamma^{i j} K_{i j} is the mean curvature, the evolution equations are obtained from The freedom to choose the coordinate gauge allows one to complete the evolution system in many different ways, and this can also lead to many different systems of equations, each one with 1ts own structure. The BSSN variables are \\phi \\phi , g_{a b} g_{a b} , A_{a b} A_{a b} , K K , and \\Gamma^{a} \\Gamma^{a} . Firstly, the spatial metric \\gamma_{i j} \\gamma_{i j} is split into an overall conformal factor e^{\\phi} e^{\\phi} and a conformal metric \\tilde{\\gamma}_{i j} \\tilde{\\gamma}_{i j} , where e^{4 \\phi} \\tilde{\\gamma}_{i j}=\\gamma_{i j} e^{4 \\phi} \\tilde{\\gamma}_{i j}=\\gamma_{i j} . and the determinant of \\tilde{\\gamma}_{i j} \\tilde{\\gamma}_{i j} is unity. This conformal metric has its corresponding Christoffel symbols ^{(3)} \\widetilde{\\Gamma}^{k}_{i j} ^{(3)} \\widetilde{\\Gamma}^{k}_{i j} and Ricci tensor ^{(3)} \\tilde{R}_{i j} ^{(3)} \\tilde{R}_{i j} . Second, the three combinations \\tilde{\\gamma}^{i j} {}^{(3)} \\tilde{\\gamma}^k_{i j}={}^{(3)} \\tilde{\\Gamma}^{k}(k=1,2,3) \\tilde{\\gamma}^{i j} {}^{(3)} \\tilde{\\gamma}^k_{i j}={}^{(3)} \\tilde{\\Gamma}^{k}(k=1,2,3) , as well as the K=\\gamma^{i j} K_{i j} K=\\gamma^{i j} K_{i j} are promoted to evolved variables. Third, the remaining evolved extrinsic curvature variables are trace-free conformal extrinsic curvature variables \\tilde{A}_{i j}=e^{-4 \\phi}\\left[K_{i j}-(1 / 3) K \\gamma_{i j}\\right] \\tilde{A}_{i j}=e^{-4 \\phi}\\left[K_{i j}-(1 / 3) K \\gamma_{i j}\\right] . Finally, the momentum constraint equations are used to modify the evolution equations for {}^{(3)} \\tilde{\\Gamma}^{k} {}^{(3)} \\tilde{\\Gamma}^{k} , which introduces a constraint damping quality to the system. These changes, in conjunction with a particular choice of gauge conditions, namely the use of certain Bona-Masso type lapse conditions (known as 1+log slicing) and \u0393- driver shift conditions led to the first genuinely stable, fully nonlinear implementations of the Einstein equations for systems without symmetries, at least for non-black-hole spacetimes. The factoring out of the conformal factor \\phi \\phi proved to be particularly advantageous for collisions of black holes.","title":"BSSN"},{"location":"NR/Conformal Transformation/","text":"Analogy Electric Field Maxwell\u2019s equations also split into constraint and evolution equations. The constraint equations have to be satis\ufb01ed by any electric and magnetic \ufb01eld at each instant of time, but they are not sufficient to completely determine these fields. Consider the equation for the electric field \\vec{E} \\vec{E} , \\nabla \\cdot \\vec{E} = 4 \\pi \\rho \\nabla \\cdot \\vec{E} = 4 \\pi \\rho Given an electrical charge density \u03c1, we can solve this equation for one of the components of E^i E^i , but not all three of them. For example, we could make certain choices for E^x E^x and E^y E^y , and then solve for E^z E^z , even though we might be troubled by the asymmetry in singling out one particular component in this approach. Alternatively, we may prefer to write E^i E^i as some \u201cbackground\u201d field \\bar { E } ^ { i } \\bar { E } ^ { i } times some overall scaling factor, say \u03c8^4 \u03c8^4 E ^ { i } = \\psi ^ { 4 } \\bar { E } ^ { i } E ^ { i } = \\psi ^ { 4 } \\bar { E } ^ { i } make certain choices for all three components of the background field \\bar { E } ^ { i } \\bar { E } ^ { i } , and then solve for the scaling factor \u03c8^4 \u03c8^4 . Though it might not be so useful for treating Maxwell\u2019s equations, such an approach leads to a very convenient and tractable system for Einstein\u2019s equations. Conformal Transformation of the Spatial Metric We begin by writing the spatial metric \\gamma_{ij} \\gamma_{ij} as a product of some power of a positive scaling factor \u03c8 and a background metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} , \\gamma_{ij} = \u03c8^4 \\bar{\\gamma}_{ij} \\gamma_{ij} = \u03c8^4 \\bar{\\gamma}_{ij} This identification is a conformal transformation of the spatial metric. We call \u03c8 the conformal factor , and \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} the conformally related metric . Taking \u03c8 to the fourth power turns out to be convenient, but is otherwise arbitrary. Loosely speaking, the conformal factor absorbs the overall scale of the metric, which leaves five degrees of freedom in the conformally related metric . Superficially, the conformal transformation is just a mathematical trick , namely, rewriting one unknown as a product of two unknowns in order to make solving some equations easier. The inverse of \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} : \\gamma ^ { i j } = \\psi ^ { - 4 } \\bar { \\gamma } ^ { i j } \\gamma ^ { i j } = \\psi ^ { - 4 } \\bar { \\gamma } ^ { i j } In three dimensions, the connection coefficients must transform according to \\Gamma _ { j k } ^ { i } = \\bar { \\Gamma } _ { j k } ^ { i } + 2 \\left( \\delta _ { j } ^ { i } \\bar { D } _ { k } \\ln \\psi + \\delta _ { k } ^ { i } \\bar { D } _ { j } \\ln \\psi - \\bar { \\gamma } _ { j k } \\bar { \\gamma } ^ { i l } \\bar { D } _ { l } \\ln \\psi \\right) \\Gamma _ { j k } ^ { i } = \\bar { \\Gamma } _ { j k } ^ { i } + 2 \\left( \\delta _ { j } ^ { i } \\bar { D } _ { k } \\ln \\psi + \\delta _ { k } ^ { i } \\bar { D } _ { j } \\ln \\psi - \\bar { \\gamma } _ { j k } \\bar { \\gamma } ^ { i l } \\bar { D } _ { l } \\ln \\psi \\right) For the scalar curvature R = \\psi ^ { - 4 } \\bar { R } - 8 \\psi ^ { - 5 } \\bar { D } ^ { 2 } \\psi R = \\psi ^ { - 4 } \\bar { R } - 8 \\psi ^ { - 5 } \\bar { D } ^ { 2 } \\psi Inserting the scalar curvature into the Hamiltonian constraint yields 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { 5 } K _ { i j } K ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { 5 } K _ { i j } K ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho which, for a given choice of the conformally related metric \\bar { \\gamma } ^ { i j } \\bar { \\gamma } ^ { i j } , we may interpret as an equation for the conformal factor \u03c8. The extrinsic curvature K_{ij} K_{ij} has to satisfy the momentum constraint, and it will be useful to rescale K_{ij} K_{ij} conformally as well. Conformal transformation of the extrinsic curvature We have conformally transformed the spatial metric, but before we proceed we also have to decompose the extrinsic curvature. It is convenient to split K_{ij} K_{ij} into its trace K and a traceless part A_{ij} A_{ij} according to K_{ij} = A_{ij} + \\frac{1}{3} \\gamma_{ij} K K_{ij} = A_{ij} + \\frac{1}{3} \\gamma_{ij} K and to conformally transform K and A_{ij} A_{ij} separately. A priori it is not clear how to transform K and A_{ij} A_{ij} , and our only guidance for inventing rules is that the transformation should bring the constraint equations into a simple and solvable form. Consider the transformations \\begin{aligned} A ^ { i j } & = \\psi ^ { \\alpha } \\bar { A } ^ { i j } \\\\ K & = \\psi ^ { \\beta } \\bar { K } \\end{aligned} \\begin{aligned} A ^ { i j } & = \\psi ^ { \\alpha } \\bar { A } ^ { i j } \\\\ K & = \\psi ^ { \\beta } \\bar { K } \\end{aligned} where \u03b1 and \u03b2 are two so far undetermined exponents. Inserting the above expressions into the momentum constraint (the choice \u03b1 = \u221210 \u03b1 = \u221210 ) yields \\psi ^ { - 10 } \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { \\beta - 4 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\bar { K } - \\frac { 2 } { 3 } \\beta \\psi ^ { \\beta - 5 } \\bar { K } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\psi = 8 \\pi S ^ { i } \\psi ^ { - 10 } \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { \\beta - 4 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\bar { K } - \\frac { 2 } { 3 } \\beta \\psi ^ { \\beta - 5 } \\bar { K } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\psi = 8 \\pi S ^ { i } Our desire to simplify equations motivates the choice \u03b2 = 0 \u03b2 = 0 , so that we treat K as a conformal invariant, K = \\bar{K} K = \\bar{K} . With these choices, the Hamiltonian constraint now becomes 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\frac { 2 } { 3 } \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { - 7 } \\bar { A } _ { i j } \\bar { A } ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\frac { 2 } { 3 } \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { - 7 } \\bar { A } _ { i j } \\bar { A } ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho and the momentum constraint is \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { 6 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } K = 8 \\pi \\psi ^ { 10 } S ^ { i } \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { 6 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } K = 8 \\pi \\psi ^ { 10 } S ^ { i } In addition to the spatial metric and extrinsic curvature, it may also be necessary to transform the matter sources \u03c1 and S^i S^i to insure uniqueness of solutions. We start by considering the linear equation \\nabla ^ { 2 } u = f u \\nabla ^ { 2 } u = f u on some domain \u03a9. Here f is some given function, and we will assume u = 0 u = 0 on the boundary \u2202\u03a9 \u2202\u03a9 . If f is non-negative everywhere, we can apply the maximum principle to show that u = 0 everywhere. The point is that if u were non-zero somewhere in \u03a9, say positive, then it must have a maximum somewhere. At the maximum the left hand side of (3.40) must be negative, but the right hand side is non-negative if f \u2265 0 f \u2265 0 , which is a contradiction. Clearly, the argument works the same way if u is negative somewhere, implying that u = 0 u = 0 everywhere if f \u2265 0 f \u2265 0 . Now consider the non-linear equation \\nabla ^ { 2 } u = f u ^ { n } \\nabla ^ { 2 } u = f u ^ { n } and assume there exist two positive solutions u_1 u_1 and u_2 \u2265 u_1 u_2 \u2265 u_1 that are identical, u_1 = u_2 u_1 = u_2 , on the boundary \u2202\u03a9 \u2202\u03a9 . The difference \u2206u = u_2 \u2212 u_1 \u2206u = u_2 \u2212 u_1 must then satisfy an equation \\nabla ^ { 2 } \\Delta u = n f \\tilde { u } ^ { n - 1 } \\Delta u \\nabla ^ { 2 } \\Delta u = n f \\tilde { u } ^ { n - 1 } \\Delta u where \\tilde { u } \\tilde { u } is some positive function satisfying u_1 \u2264 \\tilde{u} \u2264 u_2 u_1 \u2264 \\tilde{u} \u2264 u_2 . Applying the above argument to \u2206u \u2206u , we see that the maximum principle implies \u2206u = 0 \u2206u = 0 and hence uniqueness of solutions if and only if nf \u2265 0 nf \u2265 0 , i.e. if the coefficient and exponent in the source term have the same sign. Inspecting the Hamiltonian constraint we see that the matter term \u221216 \u03c0 \u03c8^5 \u03c1 \u221216 \u03c0 \u03c8^5 \u03c1 features the \u201cwrong signs\u201d: it has a negative coefficient (assuming a positive matter density \u03c1), but a positive exponent for \u03c8. Therefore the maximum principle cannot be applied, and the uniqueness of solutions cannot be established. Uniqueness of solutions can be restored, however, by introducing a conformal rescaling of the density. With \\rho = \\psi ^ { \\delta } \\bar { \\rho } \\rho = \\psi ^ { \\delta } \\bar { \\rho } , where \u03b4 \u2264 \u22125 \u03b4 \u2264 \u22125 and where \\bar{\u03c1} \\bar{\u03c1} is now considered a given function, the matter term carries the \u201cright signs\u201d, and the maximum principle can be applied to establish the uniqueness of solutions. Conformal Transverse-Traceless Decomposition Any symmetric, traceless tensor can be split into a transverse-traceless part that is divergenceless and a longitudinal part that can be written as a symmetric, traceless gradient of a vector. We can therefore decompose \\bar{A}^{ij} \\bar{A}^{ij} as \\bar { A } ^ { i j } = \\bar { A } _ { T T } ^ { i j } + \\bar { A } _ { L } ^ { i j } \\bar { A } ^ { i j } = \\bar { A } _ { T T } ^ { i j } + \\bar { A } _ { L } ^ { i j } where the transverse part is divergenceless \\bar { D } _ { j } \\bar { A } _ { T T } ^ { i j } = 0 \\bar { D } _ { j } \\bar { A } _ { T T } ^ { i j } = 0 and where the longitudinal part satisfies \\bar { A } _ { L } ^ { i j } = \\bar { D } ^ { i } W ^ { j } + \\bar { D } ^ { j } W ^ { i } - \\frac { 2 } { 3 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { k } W ^ { k } \\equiv ( \\bar { L } W ) ^ { i j } \\bar { A } _ { L } ^ { i j } = \\bar { D } ^ { i } W ^ { j } + \\bar { D } ^ { j } W ^ { i } - \\frac { 2 } { 3 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { k } W ^ { k } \\equiv ( \\bar { L } W ) ^ { i j } Here W^i W^i is a vector potential, and it is easy to see that the longitudinal operator or vector gradient \\bar{L} \\bar{L} produces a symmetric, traceless tensor. We can now write the divergence of \\bar{A}^{ij} \\bar{A}^{ij} as \\bar { D } _ { j } A ^ { i j } = \\bar { D } _ { j } A _ { L } ^ { i j } = \\bar { D } _ { j } ( \\bar { L } W ) ^ { i j } = \\bar { D } ^ { 2 } W ^ { i } + \\frac { 1 } { 3 } \\bar { D } ^ { i } \\left( \\bar { D } _ { j } W ^ { j } \\right) + \\bar { R } _ { j } ^ { i } W ^ { j } \\equiv \\left( \\bar { \\Delta } _ { L } W \\right) ^ { i } \\bar { D } _ { j } A ^ { i j } = \\bar { D } _ { j } A _ { L } ^ { i j } = \\bar { D } _ { j } ( \\bar { L } W ) ^ { i j } = \\bar { D } ^ { 2 } W ^ { i } + \\frac { 1 } { 3 } \\bar { D } ^ { i } \\left( \\bar { D } _ { j } W ^ { j } \\right) + \\bar { R } _ { j } ^ { i } W ^ { j } \\equiv \\left( \\bar { \\Delta } _ { L } W \\right) ^ { i } where \\bar{\u2206}_L \\bar{\u2206}_L is the vector Laplacian. Note that \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} and \\bar{A}^{ij}_{L} \\bar{A}^{ij}_{L} are transverse and longitudinal with respect to the conformal metric \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} , which is why this decomposition is called the conformal transverse-traceless decomposition. Alternatively one can also adopt a physical transverse-traceless decomposition, where the corresponding tensors are transverse and longitudinal with respect to the physical metric \u03b3_{ij} \u03b3_{ij} . We started out with six independent variables in both the spatial metric \\gamma_{ij} \\gamma_{ij} and the extrinsic curvature K_{ij} K_{ij} . Splitting o\ufb00 the conformal factor \u03c8 left five degrees of freedom in the conformally related metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} (once we have specified its determinant \\bar{\\gamma} \\bar{\\gamma} ). Of the six independent variables in K_{ij} K_{ij} we moved one into its trace K, two into \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} (which is symmetric, traceless, and divergenceless), and three into \\bar{A}^{ij}_L \\bar{A}^{ij}_L (which is reflected in its representation by a vector). Of the twelve original degrees of freedom, the constraint equations determine only four, namely the conformal factor \u03c8 (Hamiltonian constraint) and the longitudinal part of the traceless extrinsic curvature \\bar{A}^{ij}_L \\bar{A}^{ij}_L (momentum constraint). Four of the remaining eight degrees of freedom are associated with the coordinate freedom - three spatial coordinates hidden in the spatial metric and a time coordinate that is associated with K. This leaves four physical degrees of freedom undetermined - two in the conformally related metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} , and two in the transverse part of traceless extrinsic curvature \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} . These two freely specifiable degrees of freedom carry the dynamical degrees of freedom of the gravitational fields. All others are either fixed by the constraint equations or represent coordinate freedom. We have reduced the Hamiltonian and momentum constraint to equations for the conformal factor \u03c8 and the vector potential W^i W^i , from which the longitudinal part of the extrinsic curvature is constructed. These quantities can be solved for only after choices have been made for the remaining quantities in the equations, namely the conformally related metric \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} , the transverse-traceless part of the extrinsic curvature \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} , the trace of the extrinsic curvature K, and, if present, any matter sources. The choice of these background data has to be made in accordance with the physical or astrophysical situation that one wants to represent. Physically, the choice affects the gravitational wave content present in the initial data, in the sense that a dynamical evolution of data constructed with different background data leads to different amounts of emitted gravitational radiation. It is often not clear how a suitable background can be constructed precisely, and we will return to this issue on several occasions. Given its loose association with the transverse parts of the gravitational fields, one often sets \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} equal to zero in an attempt to minimize the gravitational wave content in the initial data. Conformal Transformations of Black Hole Solutions It is instructive to consider some simple, but physically interesting, solutions to the constraint equation. Consider vacuum solutions for which the matter source terms vanish (\u03c1 = 0 = S^i) (\u03c1 = 0 = S^i) and focus on a \u201cmoment of time symmetry\u201d. At a moment of time symmetry, all time derivatives of \u03b3_{ij} \u03b3_{ij} are zero and the 4\u2212dimensional line interval has to be invariant under time reversal, t \u2192 \u2212t t \u2192 \u2212t . The latter condition implies that the shift must satisfy \u03b2^i = 0 \u03b2^i = 0 and, hence, the extrinsic curvature also has to vanish everywhere on the slice, K_{ij} = 0 = K K_{ij} = 0 = K . On such a time slice the momentum constraints are satisfied trivially. The Hamiltonian constraint reduces to \\bar { D } ^ { 2 } \\psi = \\frac { 1 } { 8 } \\psi \\bar { R } \\bar { D } ^ { 2 } \\psi = \\frac { 1 } { 8 } \\psi \\bar { R } Let us further choose the conformally related metric to be flat, \\bar { \\gamma } _ { i j } = \\eta _ { i j } \\bar { \\gamma } _ { i j } = \\eta _ { i j } Whenever this is the case, we call the physical spatial metric \u03b3_{ij} \u03b3_{ij} conformally flat. \u201cconformal flatness\u201d refers, for our purposes, to the spatial metric and not the spacetime metric. In four or any higher dimensions, we can evaluate the Weyl tensor to examine whether any given metric is conformally flat. This is a consequence of the fact that the Weyl tensor is invariant under conformal transformations of the spacetime metric \u2013 this explains why it is often called the conformal tensor. Any spherically symmetric spatial metric is always conformally flat, meaning that we can always write such a metric as \\gamma _ { i j } = \\psi ^ { 4 } \\eta _ { i j } \\gamma _ { i j } = \\psi ^ { 4 } \\eta _ { i j } . For any spherically symmetric space, we may hence assume conformal flatness without loss of generality. Assuming conformal flatness dramatically simplifies all calculations, since \\bar{D}_i \\bar{D}_i reduces to the flat covariant derivative (and in particular to partial derivatives in cartesian coordinates). Moreover, the Ricci tensor and scalar curvature associated with the conformally related metric must now vanish, \\bar{R}_{ij} = \\bar{R} = 0 \\bar{R}_{ij} = \\bar{R} = 0 . Under this assumption, the Hamiltonian constraint becomes the remarkably simple Laplace equation \\bar { D } ^ { 2 } \\psi = 0 \\bar { D } ^ { 2 } \\psi = 0 Spherically symmetric solutions are \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } in this particular case, the constant M is in fact the black hole mass M. It shouldn\u2019t come as a great surprise that this is just the Schwarzschild solution in isotropic coordinates. d l ^ { 2 } = \\gamma _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\eta _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\left( d r ^ { 2 } + r ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) d l ^ { 2 } = \\gamma _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\eta _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\left( d r ^ { 2 } + r ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) This solution forms the basis of the so-called puncture methods for black holes. The solution is singular at r = 0 r = 0 . However, we can show that this singularity is only a coordinate singularity by considering the coordinate transformation r = \\left( \\frac { \\mathcal { M } } { 2 } \\right) ^ { 2 } \\frac { 1 } { \\hat { r } } r = \\left( \\frac { \\mathcal { M } } { 2 } \\right) ^ { 2 } \\frac { 1 } { \\hat { r } } under which the isotropic Schwarzschild metric becomes d l ^ { 2 } = \\left( 1 + \\frac { \\mathcal { M } } { 2 \\hat { r } } \\right) ^ { 4 } \\left( d \\hat { r } ^ { 2 } + \\hat { r } ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) d l ^ { 2 } = \\left( 1 + \\frac { \\mathcal { M } } { 2 \\hat { r } } \\right) ^ { 4 } \\left( d \\hat { r } ^ { 2 } + \\hat { r } ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) The geometry described by metric evaluated at a radius \\hat{r} = a \\hat{r} = a is identical to that of the above metric evaluated at r = a r = a . The mapping therefore maps the metric into itself, and is hence an isometry. In particular, this demonstrates that the origin r = 0 r = 0 is isomorphic to spatial infinity, which is perfectly regular. This demonstrates that the isotropic radius r covers only the black hole exterior, and that each Schwarzschild R corresponds to two values of the isotropic radius r. The isotropic radius r corresponding to the smallest areal (or circumferential) radius R is r = M/2 r = M/2 , which we refer to as the black hole throat. For a single Schwarzschild black hole, the throat coincides with both the apparent and event horizons. It is almost trivial to generalize our one black hole solution \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } to an arbitrary number of black holes at a moment of time symmetry. Since \\bar { D } ^ { 2 } \\psi = 0 \\bar { D } ^ { 2 } \\psi = 0 is linear, we obtain the solution simply by adding the individual contribution of each black hole according to \\psi = 1 + \\sum_{\\alpha} \\frac { \\mathcal { M } _ { \\alpha } } { 2 r _ { \\alpha } } \\psi = 1 + \\sum_{\\alpha} \\frac { \\mathcal { M } _ { \\alpha } } { 2 r _ { \\alpha } } Here r_\u03b1 = |x^i \u2212 C_\u03b1^i | r_\u03b1 = |x^i \u2212 C_\u03b1^i | is the (coordinate) separation from the center C_\u03b1^i C_\u03b1^i of the \u03b1th black hole. The total mass of the spacetime is the sum of the coefficients M_\u03b1 M_\u03b1 . However, since the total mass will also include contributions from the black hole interactions, M_\u03b1 M_\u03b1 can be identified with the mass of the \u03b1-th black hole only in the limit of large separations. Particularly interesting astrophysically and for the generation of gravitational waves is the case of binary black holes \\psi = 1 + \\frac { \\mathcal { M } _ { 1 } } { 2 r _ { 1 } } + \\frac { \\mathcal { M } _ { 2 } } { 2 r _ { 2 } } \\psi = 1 + \\frac { \\mathcal { M } _ { 1 } } { 2 r _ { 1 } } + \\frac { \\mathcal { M } _ { 2 } } { 2 r _ { 2 } } This simple solution to the constraint equations for two black holes instantaneously at rest at a moment of time symmetry can be used as initial data for head-on collisions of black holes. In general, the existence of other black holes destroys the symmetry that we found for a single black hole. Drawing an embedding diagram for such a geometry yields several different \u201csheets\u201d, where each sheet corresponds to one universe. A geometry containing N black holes may contain up to N + 1 different asymptotically flat universes. For each throat we can add terms inside that throat that correspond to images of the other black holes. Doing so, the solution becomes \u201csymmetrized\u201d so that the reflection through each throat is again an isometry. In other words, each Einstein-Rosen bridge connects to the same asymptotically flat universe, and the geometry consists of only two asymptotically flat universes, which are connected by several Einstein-Rosen bridges. For two equal-mass black holes we may also interpret this solution as a wormhole black hole solution. Cut off the bottom universe at the two throats, which leaves two \u201copen-ended\u201d throats hanging down from the top universe. We can now identify these two open ends with each other, effectively gluing them together. The two throats now form a \u201cwormhole\u201d that connects to a single, asymptotically flat (but multiply connected) universe. Given the original isometry conditions across the throats, and given that they have the same mass, the resulting metric is smooth across the throat and a valid solution to the Hamiltonian constraint. In cylindrical coordinates the metric becomes d l ^ { 2 } = \\psi ^ { 4 } \\left( d \\rho ^ { 2 } + d z ^ { 2 } + \\rho ^ { 2 } d \\phi ^ { 2 } \\right) d l ^ { 2 } = \\psi ^ { 4 } \\left( d \\rho ^ { 2 } + d z ^ { 2 } + \\rho ^ { 2 } d \\phi ^ { 2 } \\right) where the corresponding conformal factor is given by \\psi = 1 + \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } \\left( \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z + z _ { n } \\right) ^ { 2 } } } + \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z - z _ { n } \\right) ^ { 2 } } } \\right) \\psi = 1 + \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } \\left( \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z + z _ { n } \\right) ^ { 2 } } } + \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z - z _ { n } \\right) ^ { 2 } } } \\right) Here z _ { n } = \\operatorname { coth } ( n \\mu ) z _ { n } = \\operatorname { coth } ( n \\mu ) , and \u03bc is a free parameter. the total mass of this system, which we will identify with the \u201cADM mass\u201d is M _ { \\mathrm { ADM } } = 4 \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } M _ { \\mathrm { ADM } } = 4 \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } The proper distance L along the spacelike geodesic connecting the throats, or equivalently the proper length of a geodesic loop through the wormhole, is L = 2 \\left( 1 + 2 \\mu \\sum _ { n = 1 } ^ { \\infty } \\frac { n } { \\sinh ( n \\mu ) } \\right) L = 2 \\left( 1 + 2 \\mu \\sum _ { n = 1 } ^ { \\infty } \\frac { n } { \\sinh ( n \\mu ) } \\right) The parameter \u03bc is seen to parameterize both the mass and separation of the two holes. Since the solution can be rescaled to arbitrary physical mass, \u03bc effectively determines the dimensionless ratio L/M_{ADM} L/M_{ADM} , the parameter that, apart from mass, distinguishes one binary from another in this class of initial data.","title":"Conformal Transformation"},{"location":"NR/Conformal Transformation/#conformal-transformation-of-the-spatial-metric","text":"We begin by writing the spatial metric \\gamma_{ij} \\gamma_{ij} as a product of some power of a positive scaling factor \u03c8 and a background metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} , \\gamma_{ij} = \u03c8^4 \\bar{\\gamma}_{ij} \\gamma_{ij} = \u03c8^4 \\bar{\\gamma}_{ij} This identification is a conformal transformation of the spatial metric. We call \u03c8 the conformal factor , and \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} the conformally related metric . Taking \u03c8 to the fourth power turns out to be convenient, but is otherwise arbitrary. Loosely speaking, the conformal factor absorbs the overall scale of the metric, which leaves five degrees of freedom in the conformally related metric . Superficially, the conformal transformation is just a mathematical trick , namely, rewriting one unknown as a product of two unknowns in order to make solving some equations easier. The inverse of \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} : \\gamma ^ { i j } = \\psi ^ { - 4 } \\bar { \\gamma } ^ { i j } \\gamma ^ { i j } = \\psi ^ { - 4 } \\bar { \\gamma } ^ { i j } In three dimensions, the connection coefficients must transform according to \\Gamma _ { j k } ^ { i } = \\bar { \\Gamma } _ { j k } ^ { i } + 2 \\left( \\delta _ { j } ^ { i } \\bar { D } _ { k } \\ln \\psi + \\delta _ { k } ^ { i } \\bar { D } _ { j } \\ln \\psi - \\bar { \\gamma } _ { j k } \\bar { \\gamma } ^ { i l } \\bar { D } _ { l } \\ln \\psi \\right) \\Gamma _ { j k } ^ { i } = \\bar { \\Gamma } _ { j k } ^ { i } + 2 \\left( \\delta _ { j } ^ { i } \\bar { D } _ { k } \\ln \\psi + \\delta _ { k } ^ { i } \\bar { D } _ { j } \\ln \\psi - \\bar { \\gamma } _ { j k } \\bar { \\gamma } ^ { i l } \\bar { D } _ { l } \\ln \\psi \\right) For the scalar curvature R = \\psi ^ { - 4 } \\bar { R } - 8 \\psi ^ { - 5 } \\bar { D } ^ { 2 } \\psi R = \\psi ^ { - 4 } \\bar { R } - 8 \\psi ^ { - 5 } \\bar { D } ^ { 2 } \\psi Inserting the scalar curvature into the Hamiltonian constraint yields 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { 5 } K _ { i j } K ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { 5 } K _ { i j } K ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho which, for a given choice of the conformally related metric \\bar { \\gamma } ^ { i j } \\bar { \\gamma } ^ { i j } , we may interpret as an equation for the conformal factor \u03c8. The extrinsic curvature K_{ij} K_{ij} has to satisfy the momentum constraint, and it will be useful to rescale K_{ij} K_{ij} conformally as well.","title":"Conformal Transformation of the Spatial Metric"},{"location":"NR/Conformal Transformation/#conformal-transformation-of-the-extrinsic-curvature","text":"We have conformally transformed the spatial metric, but before we proceed we also have to decompose the extrinsic curvature. It is convenient to split K_{ij} K_{ij} into its trace K and a traceless part A_{ij} A_{ij} according to K_{ij} = A_{ij} + \\frac{1}{3} \\gamma_{ij} K K_{ij} = A_{ij} + \\frac{1}{3} \\gamma_{ij} K and to conformally transform K and A_{ij} A_{ij} separately. A priori it is not clear how to transform K and A_{ij} A_{ij} , and our only guidance for inventing rules is that the transformation should bring the constraint equations into a simple and solvable form. Consider the transformations \\begin{aligned} A ^ { i j } & = \\psi ^ { \\alpha } \\bar { A } ^ { i j } \\\\ K & = \\psi ^ { \\beta } \\bar { K } \\end{aligned} \\begin{aligned} A ^ { i j } & = \\psi ^ { \\alpha } \\bar { A } ^ { i j } \\\\ K & = \\psi ^ { \\beta } \\bar { K } \\end{aligned} where \u03b1 and \u03b2 are two so far undetermined exponents. Inserting the above expressions into the momentum constraint (the choice \u03b1 = \u221210 \u03b1 = \u221210 ) yields \\psi ^ { - 10 } \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { \\beta - 4 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\bar { K } - \\frac { 2 } { 3 } \\beta \\psi ^ { \\beta - 5 } \\bar { K } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\psi = 8 \\pi S ^ { i } \\psi ^ { - 10 } \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { \\beta - 4 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\bar { K } - \\frac { 2 } { 3 } \\beta \\psi ^ { \\beta - 5 } \\bar { K } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\psi = 8 \\pi S ^ { i } Our desire to simplify equations motivates the choice \u03b2 = 0 \u03b2 = 0 , so that we treat K as a conformal invariant, K = \\bar{K} K = \\bar{K} . With these choices, the Hamiltonian constraint now becomes 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\frac { 2 } { 3 } \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { - 7 } \\bar { A } _ { i j } \\bar { A } ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\frac { 2 } { 3 } \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { - 7 } \\bar { A } _ { i j } \\bar { A } ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho and the momentum constraint is \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { 6 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } K = 8 \\pi \\psi ^ { 10 } S ^ { i } \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { 6 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } K = 8 \\pi \\psi ^ { 10 } S ^ { i } In addition to the spatial metric and extrinsic curvature, it may also be necessary to transform the matter sources \u03c1 and S^i S^i to insure uniqueness of solutions. We start by considering the linear equation \\nabla ^ { 2 } u = f u \\nabla ^ { 2 } u = f u on some domain \u03a9. Here f is some given function, and we will assume u = 0 u = 0 on the boundary \u2202\u03a9 \u2202\u03a9 . If f is non-negative everywhere, we can apply the maximum principle to show that u = 0 everywhere. The point is that if u were non-zero somewhere in \u03a9, say positive, then it must have a maximum somewhere. At the maximum the left hand side of (3.40) must be negative, but the right hand side is non-negative if f \u2265 0 f \u2265 0 , which is a contradiction. Clearly, the argument works the same way if u is negative somewhere, implying that u = 0 u = 0 everywhere if f \u2265 0 f \u2265 0 . Now consider the non-linear equation \\nabla ^ { 2 } u = f u ^ { n } \\nabla ^ { 2 } u = f u ^ { n } and assume there exist two positive solutions u_1 u_1 and u_2 \u2265 u_1 u_2 \u2265 u_1 that are identical, u_1 = u_2 u_1 = u_2 , on the boundary \u2202\u03a9 \u2202\u03a9 . The difference \u2206u = u_2 \u2212 u_1 \u2206u = u_2 \u2212 u_1 must then satisfy an equation \\nabla ^ { 2 } \\Delta u = n f \\tilde { u } ^ { n - 1 } \\Delta u \\nabla ^ { 2 } \\Delta u = n f \\tilde { u } ^ { n - 1 } \\Delta u where \\tilde { u } \\tilde { u } is some positive function satisfying u_1 \u2264 \\tilde{u} \u2264 u_2 u_1 \u2264 \\tilde{u} \u2264 u_2 . Applying the above argument to \u2206u \u2206u , we see that the maximum principle implies \u2206u = 0 \u2206u = 0 and hence uniqueness of solutions if and only if nf \u2265 0 nf \u2265 0 , i.e. if the coefficient and exponent in the source term have the same sign. Inspecting the Hamiltonian constraint we see that the matter term \u221216 \u03c0 \u03c8^5 \u03c1 \u221216 \u03c0 \u03c8^5 \u03c1 features the \u201cwrong signs\u201d: it has a negative coefficient (assuming a positive matter density \u03c1), but a positive exponent for \u03c8. Therefore the maximum principle cannot be applied, and the uniqueness of solutions cannot be established. Uniqueness of solutions can be restored, however, by introducing a conformal rescaling of the density. With \\rho = \\psi ^ { \\delta } \\bar { \\rho } \\rho = \\psi ^ { \\delta } \\bar { \\rho } , where \u03b4 \u2264 \u22125 \u03b4 \u2264 \u22125 and where \\bar{\u03c1} \\bar{\u03c1} is now considered a given function, the matter term carries the \u201cright signs\u201d, and the maximum principle can be applied to establish the uniqueness of solutions.","title":"Conformal transformation of the extrinsic curvature"},{"location":"NR/Conformal Transformation/#conformal-transverse-traceless-decomposition","text":"Any symmetric, traceless tensor can be split into a transverse-traceless part that is divergenceless and a longitudinal part that can be written as a symmetric, traceless gradient of a vector. We can therefore decompose \\bar{A}^{ij} \\bar{A}^{ij} as \\bar { A } ^ { i j } = \\bar { A } _ { T T } ^ { i j } + \\bar { A } _ { L } ^ { i j } \\bar { A } ^ { i j } = \\bar { A } _ { T T } ^ { i j } + \\bar { A } _ { L } ^ { i j } where the transverse part is divergenceless \\bar { D } _ { j } \\bar { A } _ { T T } ^ { i j } = 0 \\bar { D } _ { j } \\bar { A } _ { T T } ^ { i j } = 0 and where the longitudinal part satisfies \\bar { A } _ { L } ^ { i j } = \\bar { D } ^ { i } W ^ { j } + \\bar { D } ^ { j } W ^ { i } - \\frac { 2 } { 3 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { k } W ^ { k } \\equiv ( \\bar { L } W ) ^ { i j } \\bar { A } _ { L } ^ { i j } = \\bar { D } ^ { i } W ^ { j } + \\bar { D } ^ { j } W ^ { i } - \\frac { 2 } { 3 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { k } W ^ { k } \\equiv ( \\bar { L } W ) ^ { i j } Here W^i W^i is a vector potential, and it is easy to see that the longitudinal operator or vector gradient \\bar{L} \\bar{L} produces a symmetric, traceless tensor. We can now write the divergence of \\bar{A}^{ij} \\bar{A}^{ij} as \\bar { D } _ { j } A ^ { i j } = \\bar { D } _ { j } A _ { L } ^ { i j } = \\bar { D } _ { j } ( \\bar { L } W ) ^ { i j } = \\bar { D } ^ { 2 } W ^ { i } + \\frac { 1 } { 3 } \\bar { D } ^ { i } \\left( \\bar { D } _ { j } W ^ { j } \\right) + \\bar { R } _ { j } ^ { i } W ^ { j } \\equiv \\left( \\bar { \\Delta } _ { L } W \\right) ^ { i } \\bar { D } _ { j } A ^ { i j } = \\bar { D } _ { j } A _ { L } ^ { i j } = \\bar { D } _ { j } ( \\bar { L } W ) ^ { i j } = \\bar { D } ^ { 2 } W ^ { i } + \\frac { 1 } { 3 } \\bar { D } ^ { i } \\left( \\bar { D } _ { j } W ^ { j } \\right) + \\bar { R } _ { j } ^ { i } W ^ { j } \\equiv \\left( \\bar { \\Delta } _ { L } W \\right) ^ { i } where \\bar{\u2206}_L \\bar{\u2206}_L is the vector Laplacian. Note that \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} and \\bar{A}^{ij}_{L} \\bar{A}^{ij}_{L} are transverse and longitudinal with respect to the conformal metric \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} , which is why this decomposition is called the conformal transverse-traceless decomposition. Alternatively one can also adopt a physical transverse-traceless decomposition, where the corresponding tensors are transverse and longitudinal with respect to the physical metric \u03b3_{ij} \u03b3_{ij} . We started out with six independent variables in both the spatial metric \\gamma_{ij} \\gamma_{ij} and the extrinsic curvature K_{ij} K_{ij} . Splitting o\ufb00 the conformal factor \u03c8 left five degrees of freedom in the conformally related metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} (once we have specified its determinant \\bar{\\gamma} \\bar{\\gamma} ). Of the six independent variables in K_{ij} K_{ij} we moved one into its trace K, two into \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} (which is symmetric, traceless, and divergenceless), and three into \\bar{A}^{ij}_L \\bar{A}^{ij}_L (which is reflected in its representation by a vector). Of the twelve original degrees of freedom, the constraint equations determine only four, namely the conformal factor \u03c8 (Hamiltonian constraint) and the longitudinal part of the traceless extrinsic curvature \\bar{A}^{ij}_L \\bar{A}^{ij}_L (momentum constraint). Four of the remaining eight degrees of freedom are associated with the coordinate freedom - three spatial coordinates hidden in the spatial metric and a time coordinate that is associated with K. This leaves four physical degrees of freedom undetermined - two in the conformally related metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} , and two in the transverse part of traceless extrinsic curvature \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} . These two freely specifiable degrees of freedom carry the dynamical degrees of freedom of the gravitational fields. All others are either fixed by the constraint equations or represent coordinate freedom. We have reduced the Hamiltonian and momentum constraint to equations for the conformal factor \u03c8 and the vector potential W^i W^i , from which the longitudinal part of the extrinsic curvature is constructed. These quantities can be solved for only after choices have been made for the remaining quantities in the equations, namely the conformally related metric \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} , the transverse-traceless part of the extrinsic curvature \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} , the trace of the extrinsic curvature K, and, if present, any matter sources. The choice of these background data has to be made in accordance with the physical or astrophysical situation that one wants to represent. Physically, the choice affects the gravitational wave content present in the initial data, in the sense that a dynamical evolution of data constructed with different background data leads to different amounts of emitted gravitational radiation. It is often not clear how a suitable background can be constructed precisely, and we will return to this issue on several occasions. Given its loose association with the transverse parts of the gravitational fields, one often sets \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} equal to zero in an attempt to minimize the gravitational wave content in the initial data.","title":"Conformal Transverse-Traceless Decomposition"},{"location":"NR/Conformal Transformation/#conformal-transformations-of-black-hole-solutions","text":"It is instructive to consider some simple, but physically interesting, solutions to the constraint equation. Consider vacuum solutions for which the matter source terms vanish (\u03c1 = 0 = S^i) (\u03c1 = 0 = S^i) and focus on a \u201cmoment of time symmetry\u201d. At a moment of time symmetry, all time derivatives of \u03b3_{ij} \u03b3_{ij} are zero and the 4\u2212dimensional line interval has to be invariant under time reversal, t \u2192 \u2212t t \u2192 \u2212t . The latter condition implies that the shift must satisfy \u03b2^i = 0 \u03b2^i = 0 and, hence, the extrinsic curvature also has to vanish everywhere on the slice, K_{ij} = 0 = K K_{ij} = 0 = K . On such a time slice the momentum constraints are satisfied trivially. The Hamiltonian constraint reduces to \\bar { D } ^ { 2 } \\psi = \\frac { 1 } { 8 } \\psi \\bar { R } \\bar { D } ^ { 2 } \\psi = \\frac { 1 } { 8 } \\psi \\bar { R } Let us further choose the conformally related metric to be flat, \\bar { \\gamma } _ { i j } = \\eta _ { i j } \\bar { \\gamma } _ { i j } = \\eta _ { i j } Whenever this is the case, we call the physical spatial metric \u03b3_{ij} \u03b3_{ij} conformally flat. \u201cconformal flatness\u201d refers, for our purposes, to the spatial metric and not the spacetime metric. In four or any higher dimensions, we can evaluate the Weyl tensor to examine whether any given metric is conformally flat. This is a consequence of the fact that the Weyl tensor is invariant under conformal transformations of the spacetime metric \u2013 this explains why it is often called the conformal tensor. Any spherically symmetric spatial metric is always conformally flat, meaning that we can always write such a metric as \\gamma _ { i j } = \\psi ^ { 4 } \\eta _ { i j } \\gamma _ { i j } = \\psi ^ { 4 } \\eta _ { i j } . For any spherically symmetric space, we may hence assume conformal flatness without loss of generality. Assuming conformal flatness dramatically simplifies all calculations, since \\bar{D}_i \\bar{D}_i reduces to the flat covariant derivative (and in particular to partial derivatives in cartesian coordinates). Moreover, the Ricci tensor and scalar curvature associated with the conformally related metric must now vanish, \\bar{R}_{ij} = \\bar{R} = 0 \\bar{R}_{ij} = \\bar{R} = 0 . Under this assumption, the Hamiltonian constraint becomes the remarkably simple Laplace equation \\bar { D } ^ { 2 } \\psi = 0 \\bar { D } ^ { 2 } \\psi = 0 Spherically symmetric solutions are \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } in this particular case, the constant M is in fact the black hole mass M. It shouldn\u2019t come as a great surprise that this is just the Schwarzschild solution in isotropic coordinates. d l ^ { 2 } = \\gamma _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\eta _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\left( d r ^ { 2 } + r ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) d l ^ { 2 } = \\gamma _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\eta _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\left( d r ^ { 2 } + r ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) This solution forms the basis of the so-called puncture methods for black holes. The solution is singular at r = 0 r = 0 . However, we can show that this singularity is only a coordinate singularity by considering the coordinate transformation r = \\left( \\frac { \\mathcal { M } } { 2 } \\right) ^ { 2 } \\frac { 1 } { \\hat { r } } r = \\left( \\frac { \\mathcal { M } } { 2 } \\right) ^ { 2 } \\frac { 1 } { \\hat { r } } under which the isotropic Schwarzschild metric becomes d l ^ { 2 } = \\left( 1 + \\frac { \\mathcal { M } } { 2 \\hat { r } } \\right) ^ { 4 } \\left( d \\hat { r } ^ { 2 } + \\hat { r } ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) d l ^ { 2 } = \\left( 1 + \\frac { \\mathcal { M } } { 2 \\hat { r } } \\right) ^ { 4 } \\left( d \\hat { r } ^ { 2 } + \\hat { r } ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) The geometry described by metric evaluated at a radius \\hat{r} = a \\hat{r} = a is identical to that of the above metric evaluated at r = a r = a . The mapping therefore maps the metric into itself, and is hence an isometry. In particular, this demonstrates that the origin r = 0 r = 0 is isomorphic to spatial infinity, which is perfectly regular. This demonstrates that the isotropic radius r covers only the black hole exterior, and that each Schwarzschild R corresponds to two values of the isotropic radius r. The isotropic radius r corresponding to the smallest areal (or circumferential) radius R is r = M/2 r = M/2 , which we refer to as the black hole throat. For a single Schwarzschild black hole, the throat coincides with both the apparent and event horizons. It is almost trivial to generalize our one black hole solution \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } to an arbitrary number of black holes at a moment of time symmetry. Since \\bar { D } ^ { 2 } \\psi = 0 \\bar { D } ^ { 2 } \\psi = 0 is linear, we obtain the solution simply by adding the individual contribution of each black hole according to \\psi = 1 + \\sum_{\\alpha} \\frac { \\mathcal { M } _ { \\alpha } } { 2 r _ { \\alpha } } \\psi = 1 + \\sum_{\\alpha} \\frac { \\mathcal { M } _ { \\alpha } } { 2 r _ { \\alpha } } Here r_\u03b1 = |x^i \u2212 C_\u03b1^i | r_\u03b1 = |x^i \u2212 C_\u03b1^i | is the (coordinate) separation from the center C_\u03b1^i C_\u03b1^i of the \u03b1th black hole. The total mass of the spacetime is the sum of the coefficients M_\u03b1 M_\u03b1 . However, since the total mass will also include contributions from the black hole interactions, M_\u03b1 M_\u03b1 can be identified with the mass of the \u03b1-th black hole only in the limit of large separations. Particularly interesting astrophysically and for the generation of gravitational waves is the case of binary black holes \\psi = 1 + \\frac { \\mathcal { M } _ { 1 } } { 2 r _ { 1 } } + \\frac { \\mathcal { M } _ { 2 } } { 2 r _ { 2 } } \\psi = 1 + \\frac { \\mathcal { M } _ { 1 } } { 2 r _ { 1 } } + \\frac { \\mathcal { M } _ { 2 } } { 2 r _ { 2 } } This simple solution to the constraint equations for two black holes instantaneously at rest at a moment of time symmetry can be used as initial data for head-on collisions of black holes. In general, the existence of other black holes destroys the symmetry that we found for a single black hole. Drawing an embedding diagram for such a geometry yields several different \u201csheets\u201d, where each sheet corresponds to one universe. A geometry containing N black holes may contain up to N + 1 different asymptotically flat universes. For each throat we can add terms inside that throat that correspond to images of the other black holes. Doing so, the solution becomes \u201csymmetrized\u201d so that the reflection through each throat is again an isometry. In other words, each Einstein-Rosen bridge connects to the same asymptotically flat universe, and the geometry consists of only two asymptotically flat universes, which are connected by several Einstein-Rosen bridges. For two equal-mass black holes we may also interpret this solution as a wormhole black hole solution. Cut off the bottom universe at the two throats, which leaves two \u201copen-ended\u201d throats hanging down from the top universe. We can now identify these two open ends with each other, effectively gluing them together. The two throats now form a \u201cwormhole\u201d that connects to a single, asymptotically flat (but multiply connected) universe. Given the original isometry conditions across the throats, and given that they have the same mass, the resulting metric is smooth across the throat and a valid solution to the Hamiltonian constraint. In cylindrical coordinates the metric becomes d l ^ { 2 } = \\psi ^ { 4 } \\left( d \\rho ^ { 2 } + d z ^ { 2 } + \\rho ^ { 2 } d \\phi ^ { 2 } \\right) d l ^ { 2 } = \\psi ^ { 4 } \\left( d \\rho ^ { 2 } + d z ^ { 2 } + \\rho ^ { 2 } d \\phi ^ { 2 } \\right) where the corresponding conformal factor is given by \\psi = 1 + \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } \\left( \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z + z _ { n } \\right) ^ { 2 } } } + \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z - z _ { n } \\right) ^ { 2 } } } \\right) \\psi = 1 + \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } \\left( \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z + z _ { n } \\right) ^ { 2 } } } + \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z - z _ { n } \\right) ^ { 2 } } } \\right) Here z _ { n } = \\operatorname { coth } ( n \\mu ) z _ { n } = \\operatorname { coth } ( n \\mu ) , and \u03bc is a free parameter. the total mass of this system, which we will identify with the \u201cADM mass\u201d is M _ { \\mathrm { ADM } } = 4 \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } M _ { \\mathrm { ADM } } = 4 \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } The proper distance L along the spacelike geodesic connecting the throats, or equivalently the proper length of a geodesic loop through the wormhole, is L = 2 \\left( 1 + 2 \\mu \\sum _ { n = 1 } ^ { \\infty } \\frac { n } { \\sinh ( n \\mu ) } \\right) L = 2 \\left( 1 + 2 \\mu \\sum _ { n = 1 } ^ { \\infty } \\frac { n } { \\sinh ( n \\mu ) } \\right) The parameter \u03bc is seen to parameterize both the mass and separation of the two holes. Since the solution can be rescaled to arbitrary physical mass, \u03bc effectively determines the dimensionless ratio L/M_{ADM} L/M_{ADM} , the parameter that, apart from mass, distinguishes one binary from another in this class of initial data.","title":"Conformal Transformations of Black Hole Solutions"},{"location":"NR/Coordinates/","text":"The 3+1 evolution equations for \\gamma_{ij} \\gamma_{ij} and for K_{ij} K_{ij} are not quite ready for numerical integration. For one thing, we have yet to impose coordinate conditions by specifying the lapse function \u03b1 \u03b1 and the shift vector \u03b2^i \u03b2^i that appear in these equations. The lapse and shift are freely specifiable gauge variables that need to be chosen in order to advance the field data from one time slice to the next. What constitutes a \u201cgood\u201d coordinate system? Clearly, the adopted coordinates must not allow the appearance of any singularities, which could have dire consequences for a numerical simulation. Such a singularity, which is often associated with a black hole, could be either a coordinate singularity or a physical singularity. To avoid coordinate singularities associated with horizons, like the one at r_s = 2M r_s = 2M , black hole simulations have sometimes been carried out using \u201chorizon penetrating\u201d coordinates in which light cones do not pinch-off at the horizon. The lapse \u03b1 determines how the shape of the slices \u03a3 changes in time, since it relates the advance of proper time to coordinate time along the normal vector na connecting one spatial slice to the next. The shift \u03b2^i \u03b2^i , on the other hand, determines how spatial points at rest with respect to a normal observer n^a n^a are relabeled on neighboring slices. The spatial gauge or spatial coordinates is therefore imposed by a choice for the shift vector. Geodesic Slicing Since the lapse \u03b1 \u03b1 and the shift \u03b2^i \u03b2^i can be chosen freely, let us first consider the simplest possible choice, \\alpha = 1 , \\quad \\beta ^ { i } = 0 \\alpha = 1 , \\quad \\beta ^ { i } = 0 In the context of numerical relativity this gauge choice is often called geodesic slicing; the resulting coordinates are also known as Gaussian-normal coordinates. Recall that coordinate observers move with 4\u2212velocities u ^ { a } = t ^ { a } = e _ { ( 0 ) } ^ { a } u ^ { a } = t ^ { a } = e _ { ( 0 ) } ^ { a } (i.e. spatial velocities u^i = 0 u^i = 0 ). Thus with \u03b2^i = 0 \u03b2^i = 0 , coordinate observers coincide with normal observers ( u^a = n^a u^a = n^a ). With \u03b1 = 1 \u03b1 = 1 , the proper time intervals that they measure agree with coordinate time intervals. Their acceleration is given by equation a _ { b } = D _ { b } \\ln \\alpha = 0 a _ { b } = D _ { b } \\ln \\alpha = 0 Evidently, since their acceleration vanishes, normal observers are freely-falling and therefore follow geodesics, hence the name of this slicing condition. Despite its simplicity, geodesic slicing tends to form coordinate singularities very quickly during an evolution. This result is not surprising, since geodesics tend to focus in the presence of gravitating sources. Coordinate observers therefore approach each other, collide, and thereby form a coordinate singularity . As an example, consider a weak gravitational wave that is initially centered on the origin of an otherwise flat vacuum spacetime. After a brief interaction the wave disperses and leaves behind flat space. Also consider a set of coordinate observers that are at rest with respect to each other initially. The gravitational wave packet carries energy and hence attracts the observers gravitationally, who, initially, start moving toward the origin of the spacetime . Once the gravitational wave has dispersed, the observers are no longer attracted gravitationally to the center, but they continue to coast toward each other until they form a coordinate singularity . As the following exercise demonstrates, we can even estimate the time scale after which this singularity will form. Maximal Slicing A common choice is the maximal slicing condition K = 0 K = 0 If we assume maximal slicing not only on one slice, but at all times, then the time derivative of K must vanish as well, K = 0 = \\partial _ { t } K K = 0 = \\partial _ { t } K D ^ { 2 } \\alpha = \\alpha \\left( K _ { i j } K ^ { i j } + 4 \\pi ( \\rho + S ) \\right) D ^ { 2 } \\alpha = \\alpha \\left( K _ { i j } K ^ { i j } + 4 \\pi ( \\rho + S ) \\right) which we can solve for the lapse \u03b1 \u03b1 independently of the shift \u03b2^i \u03b2^i . By construction, maximal slicing prevents the focussing of normal observers that we have found for geodesic slicing. This means that maximal slices are \u201cvolume preserving\u201d along the normal congruence n^a n^a . Normal observers in maximal slicing move like irrotational and incompressible fluid elements. The incompressible property prevents the focussing of normal observers that occurs in geodesic slicing. Harmonic Coordinates Consider a contraction of the four dimensional connection coefficients ^ { ( 4 ) } \\Gamma ^ { a } \\equiv g ^ { b c ( 4 ) } \\Gamma _ { b c } ^ { a } = - \\frac { 1 } { | g | ^ { 1 / 2 } } \\partial _ { b } \\left( | g | ^ { 1 / 2 } g ^ { a b } \\right) ^ { ( 4 ) } \\Gamma ^ { a } \\equiv g ^ { b c ( 4 ) } \\Gamma _ { b c } ^ { a } = - \\frac { 1 } { | g | ^ { 1 / 2 } } \\partial _ { b } \\left( | g | ^ { 1 / 2 } g ^ { a b } \\right) One way to impose a gauge condition is to set these quantities equal to some pre-determined gauge source functions H^a H^a , ^ { ( 4 ) } \\Gamma ^ { a } = H ^ { a } ^ { ( 4 ) } \\Gamma ^ { a } = H ^ { a } In particular, we may choose these gauge source functions to vanish, which defines harmonic coordinates ^ { ( 4 ) } \\Gamma ^ { a } = 0 ^ { ( 4 ) } \\Gamma ^ { a } = 0 More common in 3+1 calculations is harmonic slicing, in which only the time-component ^ { ( 4 ) } \\Gamma ^ { 0 } ^ { ( 4 ) } \\Gamma ^ { 0 } is set to zero. The singularity avoidance properties of harmonic slicing are weaker than those, for example, of maximal slicing. Quasi-isotropic and Radial Gauge We now turn to gauge conditions for the spatial coordinates, i.e., conditions that specify the shift vector \u03b2^i \u03b2^i . As is the case when picking a lapse, an important goal when choosing a shift is to provide for a stable, long-term dynamical evolution. In addition, it is often desirable to bring the spatial metric into a simple form . Loosely speaking, two different strategies can be employed when constructing a spatial gauge condition. One strategy is to define a geometric condition on the spatial metric from which a gauge condition can be derived. Alternatively, we can impose an algebraic condition on the spatial metric directly. For example, we can set some of its components to zero in order to simplify the Einstein equations. In general the spatial metric \u03b3_{ij} \u03b3_{ij} has six independent components. Using our three degrees of spatial coordinate freedom we can impose three conditions on the metric, and thereby reduce the number of its independent variables to three. Note In spherical polar coordinates, quasi-isotropic gauge is defined by the three conditions \\gamma _ { r \\theta } = \\gamma _ { r \\phi } = 0 \\\\ \\gamma _ { \\theta \\theta } \\gamma _ { \\phi \\phi } - \\left( \\gamma _ { \\theta \\phi } \\right) ^ { 2 } = \\gamma _ { r r } \\gamma _ { \\phi \\phi } r ^ { 2 } \\gamma _ { r \\theta } = \\gamma _ { r \\phi } = 0 \\\\ \\gamma _ { \\theta \\theta } \\gamma _ { \\phi \\phi } - \\left( \\gamma _ { \\theta \\phi } \\right) ^ { 2 } = \\gamma _ { r r } \\gamma _ { \\phi \\phi } r ^ { 2 } which reduces the metric to the form d l ^ { 2 } = A ^ { 2 } \\left( d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } \\right) + B ^ { 2 } r ^ { 2 } ( \\sin \\theta d \\phi + \\xi d \\theta ) ^ { 2 } d l ^ { 2 } = A ^ { 2 } \\left( d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } \\right) + B ^ { 2 } r ^ { 2 } ( \\sin \\theta d \\phi + \\xi d \\theta ) ^ { 2 } Minimal Distortion The conformally related metric \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} has five independent functions, two of which correspond to true dynamical degrees of freedom and three to coordinate freedom. For a stable and accurate numerical evolution it is desirable to eliminate purely coordinate-related fluctuations in \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} . To accomplish this, one may want to construct a gauge condition that minimizes the time rate of change of the conformally related metric. This gauge condition is called minimal distortion . An \u201capproximate minimal distortion\u201d condition may lead to a coordinate system with similar geometric properties. In the fixed puncture approach, there are singularities of this type associated with each black hole and the gauge conditions are chosen so that these singularities do not move. Each of these singularities is called a \u201cpuncture\u201d. Keeping the puncture fixed has several advantages. First, the singularity in the conformal factor can be handled analytically. Second, by keeping the black holes fixed in coordinate space, one can use the much simpler fixed excision techniques.","title":"Coordinates"},{"location":"NR/Coordinates/#geodesic-slicing","text":"Since the lapse \u03b1 \u03b1 and the shift \u03b2^i \u03b2^i can be chosen freely, let us first consider the simplest possible choice, \\alpha = 1 , \\quad \\beta ^ { i } = 0 \\alpha = 1 , \\quad \\beta ^ { i } = 0 In the context of numerical relativity this gauge choice is often called geodesic slicing; the resulting coordinates are also known as Gaussian-normal coordinates. Recall that coordinate observers move with 4\u2212velocities u ^ { a } = t ^ { a } = e _ { ( 0 ) } ^ { a } u ^ { a } = t ^ { a } = e _ { ( 0 ) } ^ { a } (i.e. spatial velocities u^i = 0 u^i = 0 ). Thus with \u03b2^i = 0 \u03b2^i = 0 , coordinate observers coincide with normal observers ( u^a = n^a u^a = n^a ). With \u03b1 = 1 \u03b1 = 1 , the proper time intervals that they measure agree with coordinate time intervals. Their acceleration is given by equation a _ { b } = D _ { b } \\ln \\alpha = 0 a _ { b } = D _ { b } \\ln \\alpha = 0 Evidently, since their acceleration vanishes, normal observers are freely-falling and therefore follow geodesics, hence the name of this slicing condition. Despite its simplicity, geodesic slicing tends to form coordinate singularities very quickly during an evolution. This result is not surprising, since geodesics tend to focus in the presence of gravitating sources. Coordinate observers therefore approach each other, collide, and thereby form a coordinate singularity . As an example, consider a weak gravitational wave that is initially centered on the origin of an otherwise flat vacuum spacetime. After a brief interaction the wave disperses and leaves behind flat space. Also consider a set of coordinate observers that are at rest with respect to each other initially. The gravitational wave packet carries energy and hence attracts the observers gravitationally, who, initially, start moving toward the origin of the spacetime . Once the gravitational wave has dispersed, the observers are no longer attracted gravitationally to the center, but they continue to coast toward each other until they form a coordinate singularity . As the following exercise demonstrates, we can even estimate the time scale after which this singularity will form.","title":"Geodesic Slicing"},{"location":"NR/Coordinates/#maximal-slicing","text":"A common choice is the maximal slicing condition K = 0 K = 0 If we assume maximal slicing not only on one slice, but at all times, then the time derivative of K must vanish as well, K = 0 = \\partial _ { t } K K = 0 = \\partial _ { t } K D ^ { 2 } \\alpha = \\alpha \\left( K _ { i j } K ^ { i j } + 4 \\pi ( \\rho + S ) \\right) D ^ { 2 } \\alpha = \\alpha \\left( K _ { i j } K ^ { i j } + 4 \\pi ( \\rho + S ) \\right) which we can solve for the lapse \u03b1 \u03b1 independently of the shift \u03b2^i \u03b2^i . By construction, maximal slicing prevents the focussing of normal observers that we have found for geodesic slicing. This means that maximal slices are \u201cvolume preserving\u201d along the normal congruence n^a n^a . Normal observers in maximal slicing move like irrotational and incompressible fluid elements. The incompressible property prevents the focussing of normal observers that occurs in geodesic slicing.","title":"Maximal Slicing"},{"location":"NR/Coordinates/#harmonic-coordinates","text":"Consider a contraction of the four dimensional connection coefficients ^ { ( 4 ) } \\Gamma ^ { a } \\equiv g ^ { b c ( 4 ) } \\Gamma _ { b c } ^ { a } = - \\frac { 1 } { | g | ^ { 1 / 2 } } \\partial _ { b } \\left( | g | ^ { 1 / 2 } g ^ { a b } \\right) ^ { ( 4 ) } \\Gamma ^ { a } \\equiv g ^ { b c ( 4 ) } \\Gamma _ { b c } ^ { a } = - \\frac { 1 } { | g | ^ { 1 / 2 } } \\partial _ { b } \\left( | g | ^ { 1 / 2 } g ^ { a b } \\right) One way to impose a gauge condition is to set these quantities equal to some pre-determined gauge source functions H^a H^a , ^ { ( 4 ) } \\Gamma ^ { a } = H ^ { a } ^ { ( 4 ) } \\Gamma ^ { a } = H ^ { a } In particular, we may choose these gauge source functions to vanish, which defines harmonic coordinates ^ { ( 4 ) } \\Gamma ^ { a } = 0 ^ { ( 4 ) } \\Gamma ^ { a } = 0 More common in 3+1 calculations is harmonic slicing, in which only the time-component ^ { ( 4 ) } \\Gamma ^ { 0 } ^ { ( 4 ) } \\Gamma ^ { 0 } is set to zero. The singularity avoidance properties of harmonic slicing are weaker than those, for example, of maximal slicing.","title":"Harmonic Coordinates"},{"location":"NR/Coordinates/#quasi-isotropic-and-radial-gauge","text":"We now turn to gauge conditions for the spatial coordinates, i.e., conditions that specify the shift vector \u03b2^i \u03b2^i . As is the case when picking a lapse, an important goal when choosing a shift is to provide for a stable, long-term dynamical evolution. In addition, it is often desirable to bring the spatial metric into a simple form . Loosely speaking, two different strategies can be employed when constructing a spatial gauge condition. One strategy is to define a geometric condition on the spatial metric from which a gauge condition can be derived. Alternatively, we can impose an algebraic condition on the spatial metric directly. For example, we can set some of its components to zero in order to simplify the Einstein equations. In general the spatial metric \u03b3_{ij} \u03b3_{ij} has six independent components. Using our three degrees of spatial coordinate freedom we can impose three conditions on the metric, and thereby reduce the number of its independent variables to three. Note In spherical polar coordinates, quasi-isotropic gauge is defined by the three conditions \\gamma _ { r \\theta } = \\gamma _ { r \\phi } = 0 \\\\ \\gamma _ { \\theta \\theta } \\gamma _ { \\phi \\phi } - \\left( \\gamma _ { \\theta \\phi } \\right) ^ { 2 } = \\gamma _ { r r } \\gamma _ { \\phi \\phi } r ^ { 2 } \\gamma _ { r \\theta } = \\gamma _ { r \\phi } = 0 \\\\ \\gamma _ { \\theta \\theta } \\gamma _ { \\phi \\phi } - \\left( \\gamma _ { \\theta \\phi } \\right) ^ { 2 } = \\gamma _ { r r } \\gamma _ { \\phi \\phi } r ^ { 2 } which reduces the metric to the form d l ^ { 2 } = A ^ { 2 } \\left( d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } \\right) + B ^ { 2 } r ^ { 2 } ( \\sin \\theta d \\phi + \\xi d \\theta ) ^ { 2 } d l ^ { 2 } = A ^ { 2 } \\left( d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } \\right) + B ^ { 2 } r ^ { 2 } ( \\sin \\theta d \\phi + \\xi d \\theta ) ^ { 2 }","title":"Quasi-isotropic and Radial Gauge"},{"location":"NR/Coordinates/#minimal-distortion","text":"The conformally related metric \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} has five independent functions, two of which correspond to true dynamical degrees of freedom and three to coordinate freedom. For a stable and accurate numerical evolution it is desirable to eliminate purely coordinate-related fluctuations in \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} . To accomplish this, one may want to construct a gauge condition that minimizes the time rate of change of the conformally related metric. This gauge condition is called minimal distortion . An \u201capproximate minimal distortion\u201d condition may lead to a coordinate system with similar geometric properties. In the fixed puncture approach, there are singularities of this type associated with each black hole and the gauge conditions are chosen so that these singularities do not move. Each of these singularities is called a \u201cpuncture\u201d. Keeping the puncture fixed has several advantages. First, the singularity in the conformal factor can be handled analytically. Second, by keeping the black holes fixed in coordinate space, one can use the much simpler fixed excision techniques.","title":"Minimal Distortion"},{"location":"NR/Introduction/","text":"For all but the simplest systems, analytic solutions for the evolution of such systems do not exist . Hence the task of solving Einstein's equations must be performed numerically on a computer . The dimensionless compaction Only rather exotic phenomena involve sufficiently strong spacetime curvature to require numerical relativity. Newtonian gravity clearly works quite well for main sequence stars, planets, and the like. As is well-known, relativity becomes important when speeds approach the speed of light c, so a reasonable guess would be to expect important general relativistic effects as the escape velocity approaches c. Then an object of mass M and radius R will require relativistic treatment if R is close to the gravitational radius r_{G} \\equiv 2 G M / c^{2} r_{G} \\equiv 2 G M / c^{2} , the radius of a nonspinning black hole of mass M. The same condition can be stated in terms of the dimensionless compaction \\mathcal{C} \\equiv \\frac{G M}{R c^{2}} \\mathcal{C} \\equiv \\frac{G M}{R c^{2}} \u3002Strong-gravity objects have high compaction (order unity being the standard of \u201chigh\u201d). Black holes (\\mathcal{C} \\sim 1) (\\mathcal{C} \\sim 1) and neutron stars (\\mathcal{C} \\sim 0.1) (\\mathcal{C} \\sim 0.1) are compact objects by this definition. White dwarfs \\left(\\mathcal{C} \\sim 10^{-4}\\right) \\left(\\mathcal{C} \\sim 10^{-4}\\right) are a marginal case\u2013relativity plays a large role in their stability condition but not their equilibrium structure\u2013and are usually also classified as compact. In classical dynamics, the evolution of a system is uniquely determined by the initial positions and velocities of its constituents. By analogy, the evolution of general relativistic gravitational field is determined by specifying the metric quantities g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} at a given (initial) instant of time t . Now these metric quantities can be integrated forward in time provided we can obtain from the Einstein field equations expressions for \\partial^2_t g_{ab} \\partial^2_t g_{ab} at all points on the hypersurface . That way we can integrate these expressions to compute g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} on a new spacelike hypersurface at some new time t + \\delta t t + \\delta t , and then, by repeating the process, obtain g_{ab} g_{ab} for all other points x^0 x^0 and x^i x^i in the (future) spacetime. Cauchy problem This is a fundamental problem arising in the mathematical theory of partial differential equations. The Bianchi identities \\nabla_b G^{ab} = 0 \\nabla_b G^{ab} = 0 give \\partial_t G^{a0} = - \\partial_i G^{ai} - G^{bc} \\Gamma^a_{bc} - G^{ab} \\Gamma^c_{bc} \\partial_t G^{a0} = - \\partial_i G^{ai} - G^{bc} \\Gamma^a_{bc} - G^{ab} \\Gamma^c_{bc} Since no term on the right hand side of equation contains third time derivatives or higher, the four quantities G^{a0} G^{a0} cannot contain second time derivatives. Hence the four equations G^{a0} = 8 \\pi T^{a0} G^{a0} = 8 \\pi T^{a0} do not furnish any of the information required for the dynamical evolution of the fields. Rather, they supply four constraints on the initial data , i.e. four relations between g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} on the initial hypersurface at x^0 = t x^0 = t . The only truly dynamical equations must be provided by the six remaining relations G^{ij} = 8 \\pi T^{ij} G^{ij} = 8 \\pi T^{ij} Analogy Maxwell\u2019s equations \\begin{array} { l } { D _ { i } E ^ { i } - 4 \\pi \\rho = 0 } \\\\ D _ { i } B ^ { i } = 0 \\end{array} \\begin{array} { l } { D _ { i } E ^ { i } - 4 \\pi \\rho = 0 } \\\\ D _ { i } B ^ { i } = 0 \\end{array} The above equations involve only spatial derivatives of the electric and magnetic fields and hold at each instant of time independently of the prior or subsequent evolution of the fields. They therefore constrain any possible configurations of the fields, and are correspondingly called the constraint equations . \\begin{aligned} \\partial _ { t } E _ { i } & = \\epsilon _ { i j k } D ^ { j } B ^ { k } - 4 \\pi j _ { i } \\\\ \\partial _ { t } B _ { i } & = - \\epsilon _ { i j k } D ^ { j } E ^ { k } \\end{aligned} \\begin{aligned} \\partial _ { t } E _ { i } & = \\epsilon _ { i j k } D ^ { j } B ^ { k } - 4 \\pi j _ { i } \\\\ \\partial _ { t } B _ { i } & = - \\epsilon _ { i j k } D ^ { j } E ^ { k } \\end{aligned} These equations describe how the fields evolve forward in time, and are therefore called the evolution equations . To completely determine the time evolution of the electromagnetic fields we also have to specify how the sources \u03c1 and j^i j^i evolve according to the net force acting on them. It is not surprising that there is a mismatch between the required number (10) of second time 2 derivatives \\partial_t^2 g_{ab} \\partial_t^2 g_{ab} and the available number (6) of dynamical \ufb01eld equations. After all, there is always a fourfold ambiguity associated with the freedom to choose four different coordinates to label points in spacetime. So, for example, we could always choose Gaussian normal coordinates and set g_{00} = \u22121 g_{00} = \u22121 and g_{0i} = 0 g_{0i} = 0 . In general relativity, the gauge freedom comes in the form of the freedom to choose coordinates arbitrarily . In order to get a unique solution, we need to impose gauge conditions. (the gauge variables \\alpha, \\beta^{i} \\alpha, \\beta^{i} ) Analogy Maxwell\u2019s equations 1 It is possible to bring Maxwell\u2019s equations into a form that is closer to the 3+1 form of Einstein\u2019s equations. To do so, we introduce the vector potential A ^ { a } = \\left( \\Phi , A ^ { i } \\right) A ^ { a } = \\left( \\Phi , A ^ { i } \\right) and write B^i B^i as B _ { i } = \\epsilon _ { i j k } D ^ { j } A ^ { k } B _ { i } = \\epsilon _ { i j k } D ^ { j } A ^ { k } By construction, B_i B_i automatically satisfies the constraint D _ { i } B ^ { i } = 0 D _ { i } B ^ { i } = 0 . The two evolution equations can be rewritten in terms of E_i E_i and A_i A_i \\begin{aligned} \\partial _ { t } A _ { i } & = - E _ { i } - D _ { i } \\Phi \\\\ \\partial _ { t } E _ { i } & = D _ { i } D ^ { j } A _ { j } - D ^ { j } D _ { j } A _ { i } - 4 \\pi j _ { i } \\end{aligned} \\begin{aligned} \\partial _ { t } A _ { i } & = - E _ { i } - D _ { i } \\Phi \\\\ \\partial _ { t } E _ { i } & = D _ { i } D ^ { j } A _ { j } - D ^ { j } D _ { j } A _ { i } - 4 \\pi j _ { i } \\end{aligned} With the vector potential A_i A_i we have introduced a gauge freedom into electrodynamics which is expressed in the freely specifiable gauge variable \u03a6 \u03a6 . These are supplemented by the matter evolution equations, \\nabla^{\\mu} J_{\\mu}=\\partial_{t} \\rho+D^{i} j_{i}=0 \\nabla^{\\mu} J_{\\mu}=\\partial_{t} \\rho+D^{i} j_{i}=0 Note that j_i j_i does not possess an independent evolution equation. (Their motion depends on what forces are acting on them.) The initial value problem in electrodynamics can now be solved in two steps. In the first step, initial data ( A_i A_i , E_i E_i ), together with the sources (\u03c1, j_i j_i ), are specified that satisfy the constraint equations. In the second step, these fields are evolved according to the evolution equations. Before the evolution equations can be solved, a suitable gauge condition has to be chosen . Returning to the Einstein equations themselves, similar to how the 4-vector A ^ { a } A ^ { a } in electromagnetism is not unique due to gauge freedom, the metric that satisfies general relativity equation (and any relevant boundary conditions) is not unique. The Cauchy problem in general relativity logically involves a decomposition of four-dimensional spacetime into three dimensional space and one-dimensional time . Complications The equations that arise in numerical relativity are typically multidimensional, nonlinear, coupled partial differential equations in space and time . They have in common with other areas of computational physics, like magnetohydrodynamics. However, solving Einstein\u2019s equations poses some additional complications that are unique to general relativity. In general relativity, coordinates are merely labels that distinguish points in spacetime; by themselves coordinate intervals have no physical significance. To use coordinate intervals to determine physically measurable proper distances and proper times requires the spacetime metric, but the metric is known only after Einstein\u2019s equations have been solved . Moreover, as the numerical integrations that determine the metric proceed, it often turns out that the original, arbitrary choice of coordinates turns out to be bad, because, for example, singularities appear in the equations. Encountering such singularities , be they physical or coordinate, results in some of the terms in Einstein\u2019s equations becoming infinite, potentially causing overflows in the computer output and premature termination of the numerical integration . Treating black holes is one of the main goals of numerical relativity, but this poses another complication. The reason is that black holes contain physical spacetime singularities \u2013 regions where the gravitational tidal field, the matter density and the spacetime curvature all become infinite. Thus, when dealing with black holes, it is crucial to choose a computational technique that avoids encountering their interior spacetime singularities in the course of the simulation . Another complication arises in the context of one of the most pressing goals of numerical relativity \u2013 the calculation of waveforms from promising astrophysical sources of gravitational radiation. These theoretical templates are essential for the identification and physical interpretation of gravitational wave sources. However, the gravitational wave components of the spacetime metric usually constitute small fractions of the smooth background metric. Moreover, to extract the waves from the background in a simulation requires that one probe the numerical spacetime in the far-field, or radiation, zone, which is typically at large distance from the strong-field central source. Yet it is the strong-field region which usually consumes most the computational resources (e.g. spatial resolution) to guarantee accuracy. Furthermore, waiting for the wave to propagate to the far-field region usually takes nonnegligible integration time. Smarr, L. & York, J. W. Radiation gauge in general relativity. Phys. Rev. D 17, 1945\u20131956 (1978). \u21a9","title":"Introduction"},{"location":"NR/Introduction/#cauchy-problem","text":"This is a fundamental problem arising in the mathematical theory of partial differential equations. The Bianchi identities \\nabla_b G^{ab} = 0 \\nabla_b G^{ab} = 0 give \\partial_t G^{a0} = - \\partial_i G^{ai} - G^{bc} \\Gamma^a_{bc} - G^{ab} \\Gamma^c_{bc} \\partial_t G^{a0} = - \\partial_i G^{ai} - G^{bc} \\Gamma^a_{bc} - G^{ab} \\Gamma^c_{bc} Since no term on the right hand side of equation contains third time derivatives or higher, the four quantities G^{a0} G^{a0} cannot contain second time derivatives. Hence the four equations G^{a0} = 8 \\pi T^{a0} G^{a0} = 8 \\pi T^{a0} do not furnish any of the information required for the dynamical evolution of the fields. Rather, they supply four constraints on the initial data , i.e. four relations between g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} on the initial hypersurface at x^0 = t x^0 = t . The only truly dynamical equations must be provided by the six remaining relations G^{ij} = 8 \\pi T^{ij} G^{ij} = 8 \\pi T^{ij} Analogy Maxwell\u2019s equations \\begin{array} { l } { D _ { i } E ^ { i } - 4 \\pi \\rho = 0 } \\\\ D _ { i } B ^ { i } = 0 \\end{array} \\begin{array} { l } { D _ { i } E ^ { i } - 4 \\pi \\rho = 0 } \\\\ D _ { i } B ^ { i } = 0 \\end{array} The above equations involve only spatial derivatives of the electric and magnetic fields and hold at each instant of time independently of the prior or subsequent evolution of the fields. They therefore constrain any possible configurations of the fields, and are correspondingly called the constraint equations . \\begin{aligned} \\partial _ { t } E _ { i } & = \\epsilon _ { i j k } D ^ { j } B ^ { k } - 4 \\pi j _ { i } \\\\ \\partial _ { t } B _ { i } & = - \\epsilon _ { i j k } D ^ { j } E ^ { k } \\end{aligned} \\begin{aligned} \\partial _ { t } E _ { i } & = \\epsilon _ { i j k } D ^ { j } B ^ { k } - 4 \\pi j _ { i } \\\\ \\partial _ { t } B _ { i } & = - \\epsilon _ { i j k } D ^ { j } E ^ { k } \\end{aligned} These equations describe how the fields evolve forward in time, and are therefore called the evolution equations . To completely determine the time evolution of the electromagnetic fields we also have to specify how the sources \u03c1 and j^i j^i evolve according to the net force acting on them. It is not surprising that there is a mismatch between the required number (10) of second time 2 derivatives \\partial_t^2 g_{ab} \\partial_t^2 g_{ab} and the available number (6) of dynamical \ufb01eld equations. After all, there is always a fourfold ambiguity associated with the freedom to choose four different coordinates to label points in spacetime. So, for example, we could always choose Gaussian normal coordinates and set g_{00} = \u22121 g_{00} = \u22121 and g_{0i} = 0 g_{0i} = 0 . In general relativity, the gauge freedom comes in the form of the freedom to choose coordinates arbitrarily . In order to get a unique solution, we need to impose gauge conditions. (the gauge variables \\alpha, \\beta^{i} \\alpha, \\beta^{i} ) Analogy Maxwell\u2019s equations 1 It is possible to bring Maxwell\u2019s equations into a form that is closer to the 3+1 form of Einstein\u2019s equations. To do so, we introduce the vector potential A ^ { a } = \\left( \\Phi , A ^ { i } \\right) A ^ { a } = \\left( \\Phi , A ^ { i } \\right) and write B^i B^i as B _ { i } = \\epsilon _ { i j k } D ^ { j } A ^ { k } B _ { i } = \\epsilon _ { i j k } D ^ { j } A ^ { k } By construction, B_i B_i automatically satisfies the constraint D _ { i } B ^ { i } = 0 D _ { i } B ^ { i } = 0 . The two evolution equations can be rewritten in terms of E_i E_i and A_i A_i \\begin{aligned} \\partial _ { t } A _ { i } & = - E _ { i } - D _ { i } \\Phi \\\\ \\partial _ { t } E _ { i } & = D _ { i } D ^ { j } A _ { j } - D ^ { j } D _ { j } A _ { i } - 4 \\pi j _ { i } \\end{aligned} \\begin{aligned} \\partial _ { t } A _ { i } & = - E _ { i } - D _ { i } \\Phi \\\\ \\partial _ { t } E _ { i } & = D _ { i } D ^ { j } A _ { j } - D ^ { j } D _ { j } A _ { i } - 4 \\pi j _ { i } \\end{aligned} With the vector potential A_i A_i we have introduced a gauge freedom into electrodynamics which is expressed in the freely specifiable gauge variable \u03a6 \u03a6 . These are supplemented by the matter evolution equations, \\nabla^{\\mu} J_{\\mu}=\\partial_{t} \\rho+D^{i} j_{i}=0 \\nabla^{\\mu} J_{\\mu}=\\partial_{t} \\rho+D^{i} j_{i}=0 Note that j_i j_i does not possess an independent evolution equation. (Their motion depends on what forces are acting on them.) The initial value problem in electrodynamics can now be solved in two steps. In the first step, initial data ( A_i A_i , E_i E_i ), together with the sources (\u03c1, j_i j_i ), are specified that satisfy the constraint equations. In the second step, these fields are evolved according to the evolution equations. Before the evolution equations can be solved, a suitable gauge condition has to be chosen . Returning to the Einstein equations themselves, similar to how the 4-vector A ^ { a } A ^ { a } in electromagnetism is not unique due to gauge freedom, the metric that satisfies general relativity equation (and any relevant boundary conditions) is not unique. The Cauchy problem in general relativity logically involves a decomposition of four-dimensional spacetime into three dimensional space and one-dimensional time .","title":"Cauchy problem"},{"location":"NR/Introduction/#complications","text":"The equations that arise in numerical relativity are typically multidimensional, nonlinear, coupled partial differential equations in space and time . They have in common with other areas of computational physics, like magnetohydrodynamics. However, solving Einstein\u2019s equations poses some additional complications that are unique to general relativity. In general relativity, coordinates are merely labels that distinguish points in spacetime; by themselves coordinate intervals have no physical significance. To use coordinate intervals to determine physically measurable proper distances and proper times requires the spacetime metric, but the metric is known only after Einstein\u2019s equations have been solved . Moreover, as the numerical integrations that determine the metric proceed, it often turns out that the original, arbitrary choice of coordinates turns out to be bad, because, for example, singularities appear in the equations. Encountering such singularities , be they physical or coordinate, results in some of the terms in Einstein\u2019s equations becoming infinite, potentially causing overflows in the computer output and premature termination of the numerical integration . Treating black holes is one of the main goals of numerical relativity, but this poses another complication. The reason is that black holes contain physical spacetime singularities \u2013 regions where the gravitational tidal field, the matter density and the spacetime curvature all become infinite. Thus, when dealing with black holes, it is crucial to choose a computational technique that avoids encountering their interior spacetime singularities in the course of the simulation . Another complication arises in the context of one of the most pressing goals of numerical relativity \u2013 the calculation of waveforms from promising astrophysical sources of gravitational radiation. These theoretical templates are essential for the identification and physical interpretation of gravitational wave sources. However, the gravitational wave components of the spacetime metric usually constitute small fractions of the smooth background metric. Moreover, to extract the waves from the background in a simulation requires that one probe the numerical spacetime in the far-field, or radiation, zone, which is typically at large distance from the strong-field central source. Yet it is the strong-field region which usually consumes most the computational resources (e.g. spatial resolution) to guarantee accuracy. Furthermore, waiting for the wave to propagate to the far-field region usually takes nonnegligible integration time. Smarr, L. & York, J. W. Radiation gauge in general relativity. Phys. Rev. D 17, 1945\u20131956 (1978). \u21a9","title":"Complications"},{"location":"NR/MHD/","text":"The GRHydro scheme is written in a first-order hyperbolic flux-conservative evolution system for the conserved variables D, S^{i} S^{i} , \\tau \\tau , and \\mathcal{B}^{i} \\mathcal{B}^{i} , defined in terms of the primitive variables \\rho \\rho , \\epsilon \\epsilon , v^{i} v^{i} , and B^{i} B^{i} such that \\begin{aligned} D &=\\sqrt{\\gamma} \\rho W \\\\ S_{j} &=\\sqrt{\\gamma}\\left(\\rho h^{*} W^{2} v_{j}-\\alpha b^{0} b_{j}\\right) \\\\ \\tau &=\\sqrt{\\gamma}\\left(\\rho h^{*} W^{2}-P^{*}-\\left(\\alpha b^{0}\\right)^{2}\\right)-D \\\\ \\mathcal{B}^{k} &=\\sqrt{\\gamma} B^{k} \\end{aligned} \\begin{aligned} D &=\\sqrt{\\gamma} \\rho W \\\\ S_{j} &=\\sqrt{\\gamma}\\left(\\rho h^{*} W^{2} v_{j}-\\alpha b^{0} b_{j}\\right) \\\\ \\tau &=\\sqrt{\\gamma}\\left(\\rho h^{*} W^{2}-P^{*}-\\left(\\alpha b^{0}\\right)^{2}\\right)-D \\\\ \\mathcal{B}^{k} &=\\sqrt{\\gamma} B^{k} \\end{aligned} where \\gamma \\gamma is the determinant of \\gamma_{i j} \\gamma_{i j} . We choose a definition of the 3-velocity v^{i} v^{i} that corresponds to the velocity seen by an Eulerian observer at rest in the current spatial 3-hypersurface v^{i}=\\frac{u^{i}}{W}+\\frac{\\beta^{i}}{\\alpha} v^{i}=\\frac{u^{i}}{W}+\\frac{\\beta^{i}}{\\alpha} and W \\equiv\\left(1-v^{i} v_{i}\\right)^{-1 / 2} W \\equiv\\left(1-v^{i} v_{i}\\right)^{-1 / 2} is the Lorentz factor. Note that v^{i} v^{i} , B^{i} B^{i} , S^{i} S^{i} , and \\beta^{i} \\beta^{i} are 3-vectors, and their indices are raised and lowered with the 3-metric, e.g., v_{i} \\equiv \\gamma_{i j} v^{j} v_{i} \\equiv \\gamma_{i j} v^{j} . The evolution system for the conserved variables, \\frac{\\partial \\mathbf{U}}{\\partial t}+\\frac{\\partial \\mathbf{F}^{i}}{\\partial x^{i}}=\\mathbf{S} \\frac{\\partial \\mathbf{U}}{\\partial t}+\\frac{\\partial \\mathbf{F}^{i}}{\\partial x^{i}}=\\mathbf{S} with \\mathbf{U}=\\left[D, S_{j}, \\tau, \\mathcal{B}^{k}\\right] \\\\ \\mathbf{F}^{i}=\\alpha \\times \\left[ \\begin{array}{c}{D \\tilde{v}^{i}} \\\\ {S_{j} \\tilde{v}^{i}+\\sqrt{\\gamma} P^{*} \\delta_{j}^{i}-b_{j} \\mathcal{B}^{i} / W} \\\\ {\\tau \\tilde{v}^{i}+\\sqrt{\\gamma} P^{*} v^{i}-\\alpha b^{0} \\mathcal{B}^{i} / W} \\\\ {\\mathcal{B}^{k} \\tilde{v}^{i}-\\mathcal{B}^{i} \\tilde{v}^{k}}\\end{array}\\right] \\\\ \\mathbf{S}=\\alpha \\sqrt{\\gamma} \\times \\left[ \\begin{array}{c}{0} \\\\ {T^{\\mu \\nu}\\left(\\frac{\\partial g_{i}-\\Gamma_{\\mu}^{\\lambda} g_{\\lambda j} )}{\\partial x^{\\mu}}-\\Gamma_{\\mu}^{\\lambda} g_{\\lambda j}\\right)} \\\\ {\\alpha\\left(T^{\\mu 0 \\ln \\alpha}-T^{\\mu \\nu} \\Gamma_{\\mu \\nu}^{0}\\right)} \\\\ {\\overline{0}}\\end{array}\\right] \\mathbf{U}=\\left[D, S_{j}, \\tau, \\mathcal{B}^{k}\\right] \\\\ \\mathbf{F}^{i}=\\alpha \\times \\left[ \\begin{array}{c}{D \\tilde{v}^{i}} \\\\ {S_{j} \\tilde{v}^{i}+\\sqrt{\\gamma} P^{*} \\delta_{j}^{i}-b_{j} \\mathcal{B}^{i} / W} \\\\ {\\tau \\tilde{v}^{i}+\\sqrt{\\gamma} P^{*} v^{i}-\\alpha b^{0} \\mathcal{B}^{i} / W} \\\\ {\\mathcal{B}^{k} \\tilde{v}^{i}-\\mathcal{B}^{i} \\tilde{v}^{k}}\\end{array}\\right] \\\\ \\mathbf{S}=\\alpha \\sqrt{\\gamma} \\times \\left[ \\begin{array}{c}{0} \\\\ {T^{\\mu \\nu}\\left(\\frac{\\partial g_{i}-\\Gamma_{\\mu}^{\\lambda} g_{\\lambda j} )}{\\partial x^{\\mu}}-\\Gamma_{\\mu}^{\\lambda} g_{\\lambda j}\\right)} \\\\ {\\alpha\\left(T^{\\mu 0 \\ln \\alpha}-T^{\\mu \\nu} \\Gamma_{\\mu \\nu}^{0}\\right)} \\\\ {\\overline{0}}\\end{array}\\right] Here, \\tilde{v}^{i}=v^{i}-\\beta^{i} / \\alpha \\tilde{v}^{i}=v^{i}-\\beta^{i} / \\alpha and \\Gamma_{\\mu \\nu}^{\\lambda} \\Gamma_{\\mu \\nu}^{\\lambda} are the 4-Christoffel symbols. The magnetic field is divergence-free, the \u201cno-monopoles\u201d constraint: \\nabla \\cdot B \\equiv \\frac{1}{\\sqrt{\\gamma}} \\partial_{i}\\left(\\sqrt{\\gamma} B^{i}\\right)=0 \\nabla \\cdot B \\equiv \\frac{1}{\\sqrt{\\gamma}} \\partial_{i}\\left(\\sqrt{\\gamma} B^{i}\\right)=0 which also implies \\partial_{i} \\mathcal{B}^{i}=0 \\partial_{i} \\mathcal{B}^{i}=0 In practice, we implement two different methods to actively enforce this constraint. In the \u201cdivergence cleaning\u201d technique we include the ability to modify the magnetic field evolution by introducing a new field variable that dissipates away numerical divergences. An alternative method, commonly called \u201cconstrained transport\u201d, instead carefully constructs a numerical method so that the constraint is satisfied to round-off error at the discrete level.","title":"MHD"},{"location":"NR/Matter Sources/","text":"The stress-energy tensor accounts for all sources of energy-momentum in spacetime, excluding gravity. It thus arises from all forms of matter, electromagnetic fields, neutrinos, scalar fields, etc, in the universe. For brevity, we shall sometimes refer to these sources collectively as the \u201cmatter sources\u201d and the terms that they contribute in the 3 + 1 equations as the \u201cmatter source terms\u201d. \u201cMatter\u201d source terms appear in the Hamiltonian constraint equation, the momentum constraint equation, and the 3 + 1 evolution equation. The evolution equations for the \u201cmatter\u201d sources are given by \\nabla _ { b } T ^ { a b } = 0 \\nabla _ { b } T ^ { a b } = 0 , which express the conservation of the total 4-momentum in spacetime. These conservation equations must be solved simultaneously with the 3 + 1 evolution equations for the gravitational field to determine the entire foliation of spacetime. Some of the quantities appearing in the stress-energy tensor require auxiliary equations. These auxiliary equations include, for example, the continuity equation and an equation of state in the case of hydrodynamic matter, and Maxwell\u2019s equations in the case of an electromagnetic field , and so on. The \u201cmatter\u201d source terms \u03c1, S_i S_i and S_{ij} S_{ij} appearing in the 3+1 equations for the gravitational field are projections of the stress-energy tensor into n^a n^a and \u03a3 and are given by \\rho = n_a n_b T^{ab} \\\\ S_i = - \\gamma_{ia} n_b T^{ab} \\\\ S_{ij} = \\gamma_{ia} \\gamma_{jb} T^{ab} \\rho = n_a n_b T^{ab} \\\\ S_i = - \\gamma_{ia} n_b T^{ab} \\\\ S_{ij} = \\gamma_{ia} \\gamma_{jb} T^{ab} The quantity \\rho \\rho is the total mass-energy density as measured by a normal observer, S_i S_i is the momentum density and S_{ij} S_{ij} is the stress. Finally, S is de\ufb01ned as the trace of S_{ij} S_{ij} , S = \\gamma^{ij} S_{ij} S = \\gamma^{ij} S_{ij} In the following sections, we discuss some of the most important \u201cmatter\u201d sources that arise in astrophysical applications. These sources include hydrodynamic fluids, magnetohydrodynamic plasmas threaded by magnetic fields, radiation gases (e.g., photon and neutrino), collisionless matter, and scalar fields. Vacuum Vacuum spacetimes are characterized by the vacuum stress energy tensor T^{ab} = 0 T^{ab} = 0 Spacetimes containing black holes and (or) gravitational waves, and nothing else, are characterized by such a stress-energy tensor in Einstein\u2019s \ufb01eld equations. Vacuum spacetimes are simpler to deal with numerically since they require no additional energy-momentum conservation equations or auxiliary \ufb01eld equations to solve. Hydrodynamics Relativistic hydrodynamic matter is an important source of stress-energy in many astrophysical applications. Loosely speaking, a hydrodynamic description of matter is appropriate whenever the mean free path of a particle due to collisions with neighboring particles is much shorter than the characteristic size or local scale length of the system. Perfect Gases The stress-energy tensor of a perfect gas is given by T^{ab} = \\rho_0 h u^a u^b + P g^{ab} T^{ab} = \\rho_0 h u^a u^b + P g^{ab} h is the specific enthalpy h = 1 + \\epsilon + P / \\rho _ { 0 } h = 1 + \\epsilon + P / \\rho _ { 0 } where \\epsilon \\epsilon is the specific internal energy density. The total mass-energy density as measured by an observer comoving with the fluid is then given by \\rho ^ { * } = \\rho _ { 0 } ( 1 + \\epsilon ) \\rho ^ { * } = \\rho _ { 0 } ( 1 + \\epsilon ) . The local conservation of energy-momentum \\nabla_b T^{ab} = 0 \\nabla_b T^{ab} = 0 The conservation of rest mass \\nabla_a (\\rho_0 u^a) = 0 \\nabla_a (\\rho_0 u^a) = 0 Imperfect Gases There are many important astrophysical applications that involve imperfect gases characterized by viscosity, conductivity and (or) radiation. For example, viscosity can drive non-axisymmetric instabilities in rotating stars, while radiation can lead to the cooling and contraction of stars. Viscosity The contribution of viscosity to the stress-energy tensor is T _ { \\mathrm { visc } } ^ { a b } = - 2 \\eta \\sigma ^ { a b } - \\zeta \\theta P ^ { a b } T _ { \\mathrm { visc } } ^ { a b } = - 2 \\eta \\sigma ^ { a b } - \\zeta \\theta P ^ { a b } where \u03b7 \u2265 0 \u03b7 \u2265 0 is the coefficient of dynamic, or shear, viscosity, \u03b6 \u2265 0 \u03b6 \u2265 0 is the coefficient of bulk viscosity. Heat and Radiation Diffusion The contribution of heat flux (i.e. conduction) to the stress-energy tensor is T _ { \\text { heat } } ^ { a b } = u ^ { a } q ^ { b } + u ^ { b } q ^ { a } T _ { \\text { heat } } ^ { a b } = u ^ { a } q ^ { b } + u ^ { b } q ^ { a } where the heat-flux 4-vector q^a q^a is given by q ^ { a } = - \\lambda _ { \\mathrm { th } } P ^ { a b } \\left( \\nabla _ { b } T + T a _ { b } \\right) q ^ { a } = - \\lambda _ { \\mathrm { th } } P ^ { a b } \\left( \\nabla _ { b } T + T a _ { b } \\right) T is the temperature, a ^ { a } = u ^ { b } \\nabla _ { b } u ^ { a } a ^ { a } = u ^ { b } \\nabla _ { b } u ^ { a } is the fluid 4-acceleration, and \u03bb_{th} \u03bb_{th} is the coefficient of thermal conduction. A useful application of the thermal conduction formalism is heat transport via thermal radiation. Radiation Hydrodynamics In general, a gas is neither optically thick nor optically thin (i.e. transparent) everywhere, nor is the radiation always in thermal equilibrium with the matter. In such cases we cannot treat radiation transport in the diffusion approximation as discussed above. To handle the more general case, the radiation field can be described by a radiation stress-energy tensor, T _ { \\mathrm { rad } } ^ { a b } = \\iint d \\nu d \\Omega I _ { \\nu } N ^ { a } N ^ { b } T _ { \\mathrm { rad } } ^ { a b } = \\iint d \\nu d \\Omega I _ { \\nu } N ^ { a } N ^ { b } The radiation hydrodynamics problem is very difficult to solve in general, since the intensity is a function of six-dimensional phase space plus time, and the radiation transport equation with complicated radiation-fluid interaction terms (including scattering) has a nontrivial integrodifferential character. Magnetohydrodynamics Magnetic fields play a crucial role in determining the evolution of many relativistic objects. In any highly conducting astrophysical plasma, a frozen-in magnetic field can be amplified appreciably by gas compression or shear. Even when an initial seed field is weak, the field can grow in the course of time to significantly influence the gas dynamical behavior of the system. Electromagnetic Field Equations Along with the electromagnetic field, we shall assume the presence of a perfect fluid, so that the total stress-energy tensor is given by T ^ { a b } = \\rho _ { 0 } h u ^ { a } u ^ { b } + P g ^ { a b } + T _ { \\mathrm { em } } ^ { a b } T ^ { a b } = \\rho _ { 0 } h u ^ { a } u ^ { b } + P g ^ { a b } + T _ { \\mathrm { em } } ^ { a b } The electromagnetic stress-energy tensor 4 \\pi T _ { \\mathrm { em } } ^ { a b } = F ^ { a c } F _ { c } ^ { b } - \\frac { 1 } { 4 } g ^ { a b } F _ { c d } F ^ { c d } 4 \\pi T _ { \\mathrm { em } } ^ { a b } = F ^ { a c } F _ { c } ^ { b } - \\frac { 1 } { 4 } g ^ { a b } F _ { c d } F ^ { c d } Equation of state For many purposes it is useful to employ a simple \u201c\u0393-law\u201d equation of state (EOS) of the form P = (\\Gamma - 1) \\rho_0 \\varepsilon P = (\\Gamma - 1) \\rho_0 \\varepsilon Realistic applications involving relativistic objects are rarely described by EOSs obeying this simple form . However, a \u0393-law EOS provides a computationally practical, albeit crude, approximation that can be adapted to mimick the gross behavior of different states of matter in many applications. For example, to model a stiff nuclear EOS in a neutron star , one can adopt a moderately high value of \u0393 in a \u0393-law EOS, e.g. \u0393 \u2248 2. By contrast, to model a moderately soft, thermal radiation-dominated EOS governing a very massive or supermassive star, one can set \u0393 = 4/3. For isentropic flow, a \u0393-law EOS is equivalent to the equation of state of a polytrope, P = K \\rho _ { 0 } ^ { \\Gamma } , \\quad \\Gamma = 1 + 1 / n P = K \\rho _ { 0 } ^ { \\Gamma } , \\quad \\Gamma = 1 + 1 / n where n is the polytropic index and K is the gas constant. However, for non-isentropic flow, which is always the case when encountering a shock, K is no longer constant throughout the fluid . Collisionless Matter Several important astrophysical systems are made up of particles of collisionless matter. In such systems, the mean-free-path for particle-particle interactions is much longer than the scale of the system. One example of a collisionless system is a star cluster, a large, self-gravitating, N-body system in which the individual particles \u2013 the stars \u2013 interact exclusively via gravitation. Scalar Fields Scalar fields give rise to particles of spin 0, while vector fields (like the electromagnetic field) give rise to particles of spin 1 (like the photon, in the case of electromagnetism), and tensor fields of rank two or higher give rise to higher-spin particles. A complex scalar field has two degrees of freedom instead of just one, and it can be interpreted as a particle and an antiparticle. Real fields are their own antiparticles. A neutral \u03c0 meson is an example of a real scalar field, while the charged \u03c0^+ \u03c0^+ - and \u03c0_\u2212 \u03c0_\u2212 -mesons are described by complex scalar fields.","title":"Matter Sources"},{"location":"NR/Matter Sources/#vacuum","text":"Vacuum spacetimes are characterized by the vacuum stress energy tensor T^{ab} = 0 T^{ab} = 0 Spacetimes containing black holes and (or) gravitational waves, and nothing else, are characterized by such a stress-energy tensor in Einstein\u2019s \ufb01eld equations. Vacuum spacetimes are simpler to deal with numerically since they require no additional energy-momentum conservation equations or auxiliary \ufb01eld equations to solve.","title":"Vacuum"},{"location":"NR/Matter Sources/#hydrodynamics","text":"Relativistic hydrodynamic matter is an important source of stress-energy in many astrophysical applications. Loosely speaking, a hydrodynamic description of matter is appropriate whenever the mean free path of a particle due to collisions with neighboring particles is much shorter than the characteristic size or local scale length of the system.","title":"Hydrodynamics"},{"location":"NR/Matter Sources/#perfect-gases","text":"The stress-energy tensor of a perfect gas is given by T^{ab} = \\rho_0 h u^a u^b + P g^{ab} T^{ab} = \\rho_0 h u^a u^b + P g^{ab} h is the specific enthalpy h = 1 + \\epsilon + P / \\rho _ { 0 } h = 1 + \\epsilon + P / \\rho _ { 0 } where \\epsilon \\epsilon is the specific internal energy density. The total mass-energy density as measured by an observer comoving with the fluid is then given by \\rho ^ { * } = \\rho _ { 0 } ( 1 + \\epsilon ) \\rho ^ { * } = \\rho _ { 0 } ( 1 + \\epsilon ) . The local conservation of energy-momentum \\nabla_b T^{ab} = 0 \\nabla_b T^{ab} = 0 The conservation of rest mass \\nabla_a (\\rho_0 u^a) = 0 \\nabla_a (\\rho_0 u^a) = 0","title":"Perfect Gases"},{"location":"NR/Matter Sources/#imperfect-gases","text":"There are many important astrophysical applications that involve imperfect gases characterized by viscosity, conductivity and (or) radiation. For example, viscosity can drive non-axisymmetric instabilities in rotating stars, while radiation can lead to the cooling and contraction of stars. Viscosity The contribution of viscosity to the stress-energy tensor is T _ { \\mathrm { visc } } ^ { a b } = - 2 \\eta \\sigma ^ { a b } - \\zeta \\theta P ^ { a b } T _ { \\mathrm { visc } } ^ { a b } = - 2 \\eta \\sigma ^ { a b } - \\zeta \\theta P ^ { a b } where \u03b7 \u2265 0 \u03b7 \u2265 0 is the coefficient of dynamic, or shear, viscosity, \u03b6 \u2265 0 \u03b6 \u2265 0 is the coefficient of bulk viscosity. Heat and Radiation Diffusion The contribution of heat flux (i.e. conduction) to the stress-energy tensor is T _ { \\text { heat } } ^ { a b } = u ^ { a } q ^ { b } + u ^ { b } q ^ { a } T _ { \\text { heat } } ^ { a b } = u ^ { a } q ^ { b } + u ^ { b } q ^ { a } where the heat-flux 4-vector q^a q^a is given by q ^ { a } = - \\lambda _ { \\mathrm { th } } P ^ { a b } \\left( \\nabla _ { b } T + T a _ { b } \\right) q ^ { a } = - \\lambda _ { \\mathrm { th } } P ^ { a b } \\left( \\nabla _ { b } T + T a _ { b } \\right) T is the temperature, a ^ { a } = u ^ { b } \\nabla _ { b } u ^ { a } a ^ { a } = u ^ { b } \\nabla _ { b } u ^ { a } is the fluid 4-acceleration, and \u03bb_{th} \u03bb_{th} is the coefficient of thermal conduction. A useful application of the thermal conduction formalism is heat transport via thermal radiation. Radiation Hydrodynamics In general, a gas is neither optically thick nor optically thin (i.e. transparent) everywhere, nor is the radiation always in thermal equilibrium with the matter. In such cases we cannot treat radiation transport in the diffusion approximation as discussed above. To handle the more general case, the radiation field can be described by a radiation stress-energy tensor, T _ { \\mathrm { rad } } ^ { a b } = \\iint d \\nu d \\Omega I _ { \\nu } N ^ { a } N ^ { b } T _ { \\mathrm { rad } } ^ { a b } = \\iint d \\nu d \\Omega I _ { \\nu } N ^ { a } N ^ { b } The radiation hydrodynamics problem is very difficult to solve in general, since the intensity is a function of six-dimensional phase space plus time, and the radiation transport equation with complicated radiation-fluid interaction terms (including scattering) has a nontrivial integrodifferential character.","title":"Imperfect Gases"},{"location":"NR/Matter Sources/#magnetohydrodynamics","text":"Magnetic fields play a crucial role in determining the evolution of many relativistic objects. In any highly conducting astrophysical plasma, a frozen-in magnetic field can be amplified appreciably by gas compression or shear. Even when an initial seed field is weak, the field can grow in the course of time to significantly influence the gas dynamical behavior of the system.","title":"Magnetohydrodynamics"},{"location":"NR/Matter Sources/#electromagnetic-field-equations","text":"Along with the electromagnetic field, we shall assume the presence of a perfect fluid, so that the total stress-energy tensor is given by T ^ { a b } = \\rho _ { 0 } h u ^ { a } u ^ { b } + P g ^ { a b } + T _ { \\mathrm { em } } ^ { a b } T ^ { a b } = \\rho _ { 0 } h u ^ { a } u ^ { b } + P g ^ { a b } + T _ { \\mathrm { em } } ^ { a b } The electromagnetic stress-energy tensor 4 \\pi T _ { \\mathrm { em } } ^ { a b } = F ^ { a c } F _ { c } ^ { b } - \\frac { 1 } { 4 } g ^ { a b } F _ { c d } F ^ { c d } 4 \\pi T _ { \\mathrm { em } } ^ { a b } = F ^ { a c } F _ { c } ^ { b } - \\frac { 1 } { 4 } g ^ { a b } F _ { c d } F ^ { c d }","title":"Electromagnetic Field Equations"},{"location":"NR/Matter Sources/#equation-of-state","text":"For many purposes it is useful to employ a simple \u201c\u0393-law\u201d equation of state (EOS) of the form P = (\\Gamma - 1) \\rho_0 \\varepsilon P = (\\Gamma - 1) \\rho_0 \\varepsilon Realistic applications involving relativistic objects are rarely described by EOSs obeying this simple form . However, a \u0393-law EOS provides a computationally practical, albeit crude, approximation that can be adapted to mimick the gross behavior of different states of matter in many applications. For example, to model a stiff nuclear EOS in a neutron star , one can adopt a moderately high value of \u0393 in a \u0393-law EOS, e.g. \u0393 \u2248 2. By contrast, to model a moderately soft, thermal radiation-dominated EOS governing a very massive or supermassive star, one can set \u0393 = 4/3. For isentropic flow, a \u0393-law EOS is equivalent to the equation of state of a polytrope, P = K \\rho _ { 0 } ^ { \\Gamma } , \\quad \\Gamma = 1 + 1 / n P = K \\rho _ { 0 } ^ { \\Gamma } , \\quad \\Gamma = 1 + 1 / n where n is the polytropic index and K is the gas constant. However, for non-isentropic flow, which is always the case when encountering a shock, K is no longer constant throughout the fluid .","title":"Equation of state"},{"location":"NR/Matter Sources/#collisionless-matter","text":"Several important astrophysical systems are made up of particles of collisionless matter. In such systems, the mean-free-path for particle-particle interactions is much longer than the scale of the system. One example of a collisionless system is a star cluster, a large, self-gravitating, N-body system in which the individual particles \u2013 the stars \u2013 interact exclusively via gravitation.","title":"Collisionless Matter"},{"location":"NR/Matter Sources/#scalar-fields","text":"Scalar fields give rise to particles of spin 0, while vector fields (like the electromagnetic field) give rise to particles of spin 1 (like the photon, in the case of electromagnetism), and tensor fields of rank two or higher give rise to higher-spin particles. A complex scalar field has two degrees of freedom instead of just one, and it can be interpreted as a particle and an antiparticle. Real fields are their own antiparticles. A neutral \u03c0 meson is an example of a real scalar field, while the charged \u03c0^+ \u03c0^+ - and \u03c0_\u2212 \u03c0_\u2212 -mesons are described by complex scalar fields.","title":"Scalar Fields"},{"location":"NR/Numerical Methods/","text":"There are two major classes of techniques used for numerical simulations of the Einstein equations. These are finite-difference methods , typically coupled to adaptive mesh refinement techniques, and pseudo-spectral methods . Note Most of the finite difference codes are based on modifications to the ADM system. These equations are in a form with mixed second and first derivatives. Basically, the system is such that only first time derivatives occur, but first and second spatial derivatives occur. (Of course, auxiliary evolution variables can be introduced so that the system only has first spatial derivatives, but at the cost of introducing additional constraints.) A black hole interior presents a major challenge to any numerical technique because of the curvature singularity it harbors. Fortunately, the singularity is concealed behind an event horizon. The region inside the horizon cannot affect the exterior solution, so numerical simulations need not evolve it accurately. One way to do this is to simply not evolve a region inside the horizon, i.e., to excise this region. The other method, the puncture method involves allowing singularities in the computational domain. In the appropriate gauge, these singularities are sufficiently benign that finite difference methods can handle them. Finite Difference Methods In a finite difference approximation a function f(t,x) f(t,x) is represented by values at a discrete set of points. At the core of finite difference approximation is therefore a discretization of the spacetime, or a numerical grid. Instead of evaluating f at all values of x, for example, we only consider discrete values x_i x_i . The distance between the gridpoints x_i x_i is called the gridspacing \u2206x \u2206x . For uniform grids, for which \u2206x \u2206x is constant, we have x _ { i } = x _ { 0 } + i \\Delta x x _ { i } = x _ { 0 } + i \\Delta x If the solution depends on time we also discretize the time coordinate, for example as t ^ { n } = t ^ { 0 } + n \\Delta t t ^ { n } = t ^ { 0 } + n \\Delta t The finite difference representation of the function f(t,x) f(t,x) , for example, is f _ { i } ^ { n } = f \\left( t ^ { n } , x _ { i } \\right) + \\text { truncation error. } f _ { i } ^ { n } = f \\left( t ^ { n } , x _ { i } \\right) + \\text { truncation error. } Differential equations involve derivatives, so we must next discuss how to represent derivatives in a finite difference representation. Assuming that f(x) f(x) can be differentiated to sufficiently high order and that it can be represented as a Taylor series, we have f _ { i + 1 } = f \\left( x _ { i } + \\Delta x \\right) = f \\left( x _ { i } \\right) + \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) f _ { i + 1 } = f \\left( x _ { i } + \\Delta x \\right) = f \\left( x _ { i } \\right) + \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) Solving for \\left( \\partial _ { x } f \\right) _ { x _ { i } } = \\left( \\partial _ { x } f \\right) _ { i } \\left( \\partial _ { x } f \\right) _ { x _ { i } } = \\left( \\partial _ { x } f \\right) _ { i } we find \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i } } { \\Delta x } + \\mathcal { O } ( \\Delta x ) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i } } { \\Delta x } + \\mathcal { O } ( \\Delta x ) The truncation error of this expression is linear in \u2206x \u2206x , and it turns out that we can do better. We call equation a one-sided derivative , since it uses only neighbors on one side of x_i x_i . Consider the Taylor expansion to the point x_{ i \u2212 1 } x_{ i \u2212 1 } , f _ { i - 1 } = f \\left( x _ { i } - \\Delta x \\right) = f \\left( x _ { i } \\right) - \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) f _ { i - 1 } = f \\left( x _ { i } - \\Delta x \\right) = f \\left( x _ { i } \\right) - \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) we now find \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i - 1 } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i - 1 } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) which is second order in \u2206x \u2206x . In general, centered derivatives lead to higher order schemes than one-sided derivatives for the same number of gridpoints. The key point is that we are able to combine the two Taylor expansions in such a way that the leading order error term cancels out, leaving us with a higher order representation of the derivative . This cancellation only works out for uniform grids , when \u2206x \u2206x is independent of x. This is one of the reasons why many current numerical relativity applications of finite difference schemes work with uniform grids. Higher order derivatives can be constructed in a similar fashion. Adding the two Taylor expansions all terms odd in \u2206x \u2206x drop out and we find for the second derivative \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } } { ( \\Delta x ) ^ { 2 } } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } } { ( \\Delta x ) ^ { 2 } } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) Fourth-order finite-difference Fourth-order finite-difference representations of the first and second derivatives of a function f are given by \\left( \\partial _ { x } f \\right) _ { i } = \\frac { 1 } { 12 \\Delta x } \\left( f _ { i - 2 } - 8 f _ { i - 1 } + 8 f _ { i + 1 } - f _ { i + 2 } \\right) \\\\ \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { 1 } { 12 ( \\Delta x ) ^ { 2 } } \\left( - f _ { i - 2 } + 16 f _ { i - 1 } - 30 f _ { i } + 16 f _ { i + 1 } - f _ { i + 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { 1 } { 12 \\Delta x } \\left( f _ { i - 2 } - 8 f _ { i - 1 } + 8 f _ { i + 1 } - f _ { i + 2 } \\right) \\\\ \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { 1 } { 12 ( \\Delta x ) ^ { 2 } } \\left( - f _ { i - 2 } + 16 f _ { i - 1 } - 30 f _ { i } + 16 f _ { i + 1 } - f _ { i + 2 } \\right) where we have omitted the truncation error, \\mathcal { O } \\left( \\Delta x ^ { 4 } \\right) \\mathcal { O } \\left( \\Delta x ^ { 4 } \\right) Elliptic Equations As an example of a simple, one-dimensional elliptic equation consider \\partial_{x}^{2} f=s \\partial_{x}^{2} f=s We first have to construct a numerical grid that covers an interval between x_{min} x_{min} and x_{max} x_{max} . We then divide the interval \\left[x_{\\min }, x_{\\max }\\right] \\left[x_{\\min }, x_{\\max }\\right] into N gridcells, leading to a gridspacing of \\Delta x=\\frac{x_{\\max }-x_{\\min }}{N} \\Delta x=\\frac{x_{\\max }-x_{\\min }}{N} We can choose our grid points to be located either at the center of these cells, which would be referred to as a cell-centered grid, or on the vertices, which would be referred to as a vertex-centered grid. For a cell-centered grid we have N grid points located at x_{i}=x_{\\min }+(i-1 / 2) \\Delta x, \\quad i=1, \\ldots, N x_{i}=x_{\\min }+(i-1 / 2) \\Delta x, \\quad i=1, \\ldots, N whereas for a vertex centered grid we have N + 1 gridpoints located a x_{i}=x_{\\min }+(i-1) \\Delta x, \\quad i=1, \\ldots, N+1 x_{i}=x_{\\min }+(i-1) \\Delta x, \\quad i=1, \\ldots, N+1 The difference between cell-centered and vertex-centered grids only affects the implementation of boundary conditions, but not the finite difference representation of the differential equation itself. We are now ready to finite difference the differential equation. We define two arrays, f_i f_i and s_i s_i , which represent the functions f and s at the gridpoints x_i x_i for i = 1, . . . , N i = 1, . . . , N . In the interior of our domain we can represent the differential equation as f_{i+1}-2 f_{i}+f_{i-1}=(\\Delta x)^{2} s_{i} \\quad i=2, \\ldots, N-1 f_{i+1}-2 f_{i}+f_{i-1}=(\\Delta x)^{2} s_{i} \\quad i=2, \\ldots, N-1 At the lower boundary point i = 1 i = 1 the neighbor i \u2212 1 i \u2212 1 does not exist in our domain, and, similarly, at the upper boundary point i = N i = N the point i + 1 i + 1 does not exist. At these points we have to implement the boundary conditions, which can be done in many different ways. Let us assume that the solution f is a symmetric function about x = 0 x = 0 , in which case we can restrict the analysis to positive x and impose a Neuman condition at the origin, \\partial_{x} f=0 \\quad \\text { at } x=0 \\partial_{x} f=0 \\quad \\text { at } x=0 The two grid points x_0 x_0 and x_1 x_1 then bracket the boundary point x_{min} = 0 x_{min} = 0 symmetrically. We can then write the boundary condition as f_{1}=f_{0} f_{1}=f_{0} For i = 1 we yields f_{i+1}-f_{i}=(\\Delta x)^{2} s_{i} \\quad i=1 f_{i+1}-f_{i}=(\\Delta x)^{2} s_{i} \\quad i=1 We can use a similar strategy at the upper boundary. Let us also assume that f falls off with 1/x 1/x for large x, which results in the Robin boundary condition \\partial_{x}(x f)=0 \\quad \\text { as } x \\rightarrow \\infty \\partial_{x}(x f)=0 \\quad \\text { as } x \\rightarrow \\infty With the help of a virtual grid point x_{N + 1} x_{N + 1} we can write the boundary condition in \\Delta x \\Delta x as f_{N+1}=\\frac{x_{N}}{x_{N+1}} f_{N}=\\frac{x_{N}}{x_{N}+\\Delta x} f_{N} f_{N+1}=\\frac{x_{N}}{x_{N+1}} f_{N}=\\frac{x_{N}}{x_{N}+\\Delta x} f_{N} We can again insert this into for i = N and find \\left(\\frac{x_{i}}{x_{i}+\\Delta x}-2\\right) f_{i}+f_{i-1}=(\\Delta x)^{2} s_{i} \\quad i=N \\left(\\frac{x_{i}}{x_{i}+\\Delta x}-2\\right) f_{i}+f_{i-1}=(\\Delta x)^{2} s_{i} \\quad i=N Elliptic Equations now form a coupled set of N linear equations for the N elements f_i f_i that we can write as \\left( \\begin{array}{ccccccc}{-1} & {1} & {0} & {0} & {0} & {0} & {0} \\\\ {1} & {-2} & {1} & {0} & {0} & {0} & {0} \\\\ {0} & {\\ddots} & {\\ddots} & {\\ddots} & {0} & {0} & {0} \\\\ {0} & {0} & {1} & {-2} & {1} & {0} & {0} \\\\ {0} & {0} & {0} & {\\ddots} & {\\ddots} & {\\ddots} & {0} \\\\ {0} & {0} & {0} & {0} & {1} & {-2} & {1} \\\\ {0} & {0} & {0} & {0} & {0} & {1} & {x_{N} /\\left(x_{N}+\\Delta x\\right)-2}\\end{array}\\right) \\cdot \\left( \\begin{array}{c}{f_{1}} \\\\ {f_{2}} \\\\ {\\vdots} \\\\ {f_{i}} \\\\ {\\vdots} \\\\ {f_{N-1}} \\\\ {f_{N}}\\end{array}\\right)=(\\Delta x)^{2} \\left( \\begin{array}{c}{s_{1}} \\\\ {s_{2}} \\\\ {\\vdots} \\\\ {s_{i}} \\\\ {\\vdots} \\\\ {s_{N-1}} \\\\ {s_{N}}\\end{array}\\right) \\left( \\begin{array}{ccccccc}{-1} & {1} & {0} & {0} & {0} & {0} & {0} \\\\ {1} & {-2} & {1} & {0} & {0} & {0} & {0} \\\\ {0} & {\\ddots} & {\\ddots} & {\\ddots} & {0} & {0} & {0} \\\\ {0} & {0} & {1} & {-2} & {1} & {0} & {0} \\\\ {0} & {0} & {0} & {\\ddots} & {\\ddots} & {\\ddots} & {0} \\\\ {0} & {0} & {0} & {0} & {1} & {-2} & {1} \\\\ {0} & {0} & {0} & {0} & {0} & {1} & {x_{N} /\\left(x_{N}+\\Delta x\\right)-2}\\end{array}\\right) \\cdot \\left( \\begin{array}{c}{f_{1}} \\\\ {f_{2}} \\\\ {\\vdots} \\\\ {f_{i}} \\\\ {\\vdots} \\\\ {f_{N-1}} \\\\ {f_{N}}\\end{array}\\right)=(\\Delta x)^{2} \\left( \\begin{array}{c}{s_{1}} \\\\ {s_{2}} \\\\ {\\vdots} \\\\ {s_{i}} \\\\ {\\vdots} \\\\ {s_{N-1}} \\\\ {s_{N}}\\end{array}\\right) or, in a more compact form, \\mathbf{A} \\cdot \\mathbf{f}=(\\Delta x)^{2} \\mathbf{S} \\mathbf{A} \\cdot \\mathbf{f}=(\\Delta x)^{2} \\mathbf{S} The solution is given by \\mathbf{f}=(\\Delta x)^{2} \\mathbf{A}^{-1} \\cdot \\mathbf{S} \\mathbf{f}=(\\Delta x)^{2} \\mathbf{A}^{-1} \\cdot \\mathbf{S} so that we have reduced the problem to inverting an N \u00d7 N matrix. Hyperbolic Equations For simplicity it does not contain any source terms, and the the wave speed v is constant. \\partial _ { t } u + v \\partial _ { x } u = 0 \\partial _ { t } u + v \\partial _ { x } u = 0 The equation is satisfied exactly by any function of the form u ( t , x ) = u ( x - v t ) u ( t , x ) = u ( x - v t ) . The equation has a time derivative in addition to the space derivative, and thus requires initial data . Inserting both finite-difference representations \\left( \\partial _ { x } u \\right) _ { j } ^ { n } = \\frac { u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\\\ \\left( \\partial _ { t } u \\right) _ { j } ^ { n } = \\frac { u _ { j } ^ { n + 1 } - u _ { j } ^ { n } } { \\Delta t } + \\mathcal { O } ( \\Delta t ) \\left( \\partial _ { x } u \\right) _ { j } ^ { n } = \\frac { u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\\\ \\left( \\partial _ { t } u \\right) _ { j } ^ { n } = \\frac { u _ { j } ^ { n + 1 } - u _ { j } ^ { n } } { \\Delta t } + \\mathcal { O } ( \\Delta t ) we can solve for u^{n+1}_j u^{n+1}_j and find u _ { j } ^ { n + 1 } = u _ { j } ^ { n } - \\frac { v } { 2 } \\frac { \\Delta t } { \\Delta x } \\left( u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } \\right) u _ { j } ^ { n + 1 } = u _ { j } ^ { n } - \\frac { v } { 2 } \\frac { \\Delta t } { \\Delta x } \\left( u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } \\right) or reasons that are quite obivous this differencing scheme is called forward-time centered-space, or FTCS. It is an example of an explicit scheme, meaning that we can solve for the grid function u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } at the new time level n + 1 directly in terms of function values on the old time level n. Courant-Friedrichs-Lewy condition Unfortunately, however, FTCS is fairly useless. The equation is satisfied exactly by any function of the form u ( t , x ) = u ( x - v t ) u ( t , x ) = u ( x - v t ) . we can write the solution u ( t , x ) u ( t , x ) to our continuum hyperbolic differential equation as a superposition of eigenmodes e^{i(\\omega t+k x)} e^{i(\\omega t+k x)} . Here k is a spatial wave number. A real \\omega \\omega , for which e^{i \\omega t} e^{i \\omega t} has a magnitude of unity, yields sinusoidally oscillating modes, while the existence of a complex piece in \\omega \\omega leads to exponentially growing or damping modes. In the case of exponential growth, the magnitude of e^{i \\omega t} e^{i \\omega t} will exceed unity. We can perform a similar spectral analysis of the finite difference equation. Write the eigenmode for u_{j}^{n} u_{j}^{n} as u_{j}^{n}=\\xi^{n} e^{i k(j \\Delta x)} u_{j}^{n}=\\xi^{n} e^{i k(j \\Delta x)} Here the quantity \\xi \\xi plays the role of e^{i \\omega \\Delta t} e^{i \\omega \\Delta t} and is called the amplification factor: u_{j}^{n}=\\xi u_{j}^{n-1} = \\xi^{2} u_{j}^{n-2} \\ldots=\\xi^{n} u_{j}^{0} u_{j}^{n}=\\xi u_{j}^{n-1} = \\xi^{2} u_{j}^{n-2} \\ldots=\\xi^{n} u_{j}^{0} For the scheme to be stable, the magnitude \\xi \\xi must be smaller or equal to unity for all k, |\\xi(k)| \\leq 1 |\\xi(k)| \\leq 1 To perform a von Neumann stability anaylsis of the FTCS scheme \\xi(k)=1-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x \\xi(k)=1-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x the magnitude of \\xi \\xi is greater than unity for all k, indicating that this scheme is unstable. In fact, we have |\\xi|>1 |\\xi|>1 independently of our choice for \\Delta x \\Delta x and \\Delta t \\Delta t , which makes this scheme unconditionally unstable. That is bad. The good news is that there are several ways of fixing this problem. For example, we could replace the term u_{j}^{n} u_{j}^{n} by the spatial average \\left(u_{j+1}^{n}+u_{j-1}^{n}\\right) / 2 \\left(u_{j+1}^{n}+u_{j-1}^{n}\\right) / 2 . u_{j}^{n+1}=\\frac{1}{2}\\left(u_{j+1}^{n}+u_{j-1}^{n}\\right)-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n}-u_{j-1}^{n}\\right) u_{j}^{n+1}=\\frac{1}{2}\\left(u_{j+1}^{n}+u_{j-1}^{n}\\right)-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n}-u_{j-1}^{n}\\right) a von Neumann analysis results in the amplification factor \\xi=\\cos k \\Delta x-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x \\xi=\\cos k \\Delta x-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x The von Neumann stability criterion then implies that we must have \\frac { | v | \\Delta t } { \\Delta x } \\leq 1 \\frac { | v | \\Delta t } { \\Delta x } \\leq 1 The Courant condition states that the the grid point u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } at the new time level n+1 has to reside inside the domain of determinacy of the interval spanned by the finite difference stencil at the time level n. This makes intuitive sense: if u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } were outside this domain, its physical specification would require more information about the past than we are providing numerically, which may trigger an instability. Recalling that v represents the speed of a characteristic, we may interpret the Courant condition in terms of the domain of determinacy. It seems somewhat like a miracle that simply replacing a grid function by a local average manages to change the numerical scheme from unconditionally unstable to conditionally stable. This change can be interpreted in very physical terms u_{j}^{n+1}=u_{j}^{n}+\\frac{1}{2}\\left(u_{j+1}^{n}-2 u_{j}^{n}+u_{j-1}^{n}\\right)-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n}-u_{j-1}^{n}\\right) u_{j}^{n+1}=u_{j}^{n}+\\frac{1}{2}\\left(u_{j+1}^{n}-2 u_{j}^{n}+u_{j-1}^{n}\\right)-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n}-u_{j-1}^{n}\\right) or \\frac{u_{j}^{n+1}-u_{j}^{n}}{\\Delta t}=-v \\frac{u_{j+1}^{n}-u_{j-1}^{n}}{2 \\Delta x}+\\frac{(\\Delta x)^{2}}{2 \\Delta t} \\frac{u_{j+1}^{n}-2 u_{j}^{n}+u_{j-1}^{n}}{(\\Delta x)^{2}} \\frac{u_{j}^{n+1}-u_{j}^{n}}{\\Delta t}=-v \\frac{u_{j+1}^{n}-u_{j-1}^{n}}{2 \\Delta x}+\\frac{(\\Delta x)^{2}}{2 \\Delta t} \\frac{u_{j+1}^{n}-2 u_{j}^{n}+u_{j-1}^{n}}{(\\Delta x)^{2}} But equation is a finite-difference representation of the differential equation \\partial_{t} u+v \\partial_{x} u=D \\partial_{x}^{2} u \\partial_{t} u+v \\partial_{x} u=D \\partial_{x}^{2} u where the term on the right-hand side is essentially a diffusion term, with parameter D=(\\Delta x)^{2} /(2 \\Delta t) D=(\\Delta x)^{2} /(2 \\Delta t) serving as a constant coefficient of diffusion. This feature implies the amplitude of any wave will decrease spuriously with time as it propagates. A related effect is anomalous dispersion, an additional price we pay for stablity in the Lax scheme and many other finite-difference schemes for hyperbolic systems. implicit scheme Yet another way of constructing a stable two-level scheme is to use backward time differencing instead of forward differencing. This approach then yields the \u201cbackward-time, centered-space\u201d scheme, u_{j}^{n+1}=u_{j}^{n}-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n+1}-u_{j-1}^{n+1}\\right) u_{j}^{n+1}=u_{j}^{n}-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n+1}-u_{j-1}^{n+1}\\right) Performing a von Neumann stability analysis we find the amplification factor |\\xi(k)| \\leq 1 |\\xi(k)| \\leq 1 for all values of \\Delta t \\Delta t . This finding means that this scheme is unconditionally stable. The size of the stepsize \u2206t is no longer restricted by stability, and instead is limited only by accuracy requirements. this property is even more important for parabolic equations. The disadvantage of the backward differencing scheme is that we can no longer solve for the new grid function u_{j}^{n+1} u_{j}^{n+1} at the new time t^{n+1} t^{n+1} explicitly in terms of old grid functions at t^{n} t^{n} alone. Instead, now couples u_{j}^{n+1} u_{j}^{n+1} with the its closest neighbors u_{j+1}^{n+1} u_{j+1}^{n+1} and u_{j-1}^{n+1} u_{j-1}^{n+1} . This coupling provides an implicit linear relation between the new grid functions, and is therefore an example of an implicit finite-differencing scheme. We can no longer sweep through the grid and update one point at a time; instead we now have to solve for all grid points simultaneously . Writing equation at all interior grid points, and then taking into account the boundary conditions, leads to a system of equations quite similar to elliptic equations. Method of Lines A popular alternative to these complete finite difference schemes is therefore the method of lines (or MOL for short). The basic idea of the method of lines is to finite difference the space derivatives only. Now we introduce a spatial grid only, at least for now, so that the function values at these gridpoint, u_{j}(t)=u\\left(t, x_{j}\\right) u_{j}(t)=u\\left(t, x_{j}\\right) , remain functions of time. As a result, our partial differential equation for u(t, x) u(t, x) becomes a set of ordinary differential equations for the grid values u_{j}(t) u_{j}(t) . The next question is how to integrate the ordinary differential equations. The appealing feature of the method of lines, however, is that we can use any method for the integration of the ordinary differential equations that we like. In fact, many such methods, including very efficient, high-order methods, are precoded and readily available. One such algorithm is the ever-popular Runge-Kutta method. To implement, say, a fourth-order scheme for our model \\partial_{t} u+v \\partial_{x} u=0 \\partial_{t} u+v \\partial_{x} u=0 we could adopt the fourth-order differencing stencil to replace the spatial derivative, yielding \\frac{d u_{j}}{d t}=-\\frac{v}{12 \\Delta x}\\left(u_{i-2}-8 u_{j-1}+8 u_{j+1}-u_{i+2}\\right) \\frac{d u_{j}}{d t}=-\\frac{v}{12 \\Delta x}\\left(u_{i-2}-8 u_{j-1}+8 u_{j+1}-u_{i+2}\\right) and then integrate this set of ordinary differential equations with a fourth-order Runge-Kutta method. Runge-Kutta (RK) method The explicit form of the algorithms is Prediction step (common for both RK2 and RK3): \\boldsymbol{U}^{(1)}=\\boldsymbol{U}^{(n)}+\\Delta t L\\left(\\boldsymbol{U}^{(n)}\\right) \\boldsymbol{U}^{(1)}=\\boldsymbol{U}^{(n)}+\\Delta t L\\left(\\boldsymbol{U}^{(n)}\\right) Depending on the order do: RK2: \\boldsymbol{U}^{n+1}=\\frac{1}{\\alpha}\\left[\\beta \\boldsymbol{U}^{n}+\\boldsymbol{U}^{(1)}+\\Delta t L\\left(\\boldsymbol{U}^{(1)}\\right)\\right] \\boldsymbol{U}^{n+1}=\\frac{1}{\\alpha}\\left[\\beta \\boldsymbol{U}^{n}+\\boldsymbol{U}^{(1)}+\\Delta t L\\left(\\boldsymbol{U}^{(1)}\\right)\\right] RK3: \\begin{aligned} \\boldsymbol{U}^{(2)} &=\\frac{1}{\\alpha}\\left[\\beta \\boldsymbol{U}^{(2 n)}+\\boldsymbol{U}^{(1)}+\\Delta t L\\left(\\boldsymbol{U}^{(1)}\\right)\\right] \\\\ \\boldsymbol{U}^{n+1} &=\\frac{1}{\\beta}\\left[\\beta \\boldsymbol{U}^{(2 n)}+2 \\boldsymbol{U}^{(2)}+2 \\Delta t L\\left(\\boldsymbol{U}^{(2)}\\right)\\right] \\end{aligned} \\begin{aligned} \\boldsymbol{U}^{(2)} &=\\frac{1}{\\alpha}\\left[\\beta \\boldsymbol{U}^{(2 n)}+\\boldsymbol{U}^{(1)}+\\Delta t L\\left(\\boldsymbol{U}^{(1)}\\right)\\right] \\\\ \\boldsymbol{U}^{n+1} &=\\frac{1}{\\beta}\\left[\\beta \\boldsymbol{U}^{(2 n)}+2 \\boldsymbol{U}^{(2)}+2 \\Delta t L\\left(\\boldsymbol{U}^{(2)}\\right)\\right] \\end{aligned} Ghost Zones Cactus is based upon a distributed computing paradigm. That is, the problem domain is split into blocks, each of which is assigned to a processor. Consider the 1-D wave equation \\frac{\\partial^{2} \\phi}{\\partial t^{2}}=\\frac{\\partial^{2} \\phi}{\\partial x^{2}} \\frac{\\partial^{2} \\phi}{\\partial t^{2}}=\\frac{\\partial^{2} \\phi}{\\partial x^{2}} To solve this by partial differences, one discretises the derivatives to get an equation relating the solution at different times. \\phi(t+\\Delta t, x)-2 \\phi(t, x)+\\phi(t-\\Delta t, x)=\\frac{\\Delta t^{2}}{\\Delta x^{2}}\\{\\phi(t, x+\\Delta x)-2 \\phi(t, x)+\\phi(t, x-\\Delta x)\\} \\phi(t+\\Delta t, x)-2 \\phi(t, x)+\\phi(t-\\Delta t, x)=\\frac{\\Delta t^{2}}{\\Delta x^{2}}\\{\\phi(t, x+\\Delta x)-2 \\phi(t, x)+\\phi(t, x-\\Delta x)\\} On examination, you can see that to generate the data at the point (t+\\Delta t, x) (t+\\Delta t, x) we need data from the four points (t, x) (t, x) , (t -\\Delta t, x) (t -\\Delta t, x) , (t, x + \\Delta x) (t, x + \\Delta x) and (t, x- \\Delta x) (t, x- \\Delta x) only. Now, if you evolve the above scheme, it becomes apparent that at each iteration the number of grid points you can evolve decreases by one at each edge. At the outer boundary of the physical domain, the data for the boundary point can be generated by the boundary conditions, however, at internal boundaries, the data has to be copied from the adjacent processor. It would be inefficient to copy each point individually, so instead, a number of ghostzones are created at the internal boundaries. A ghostzone consists of a copy of the whole plane (in 3D, line in 2D, point in 1D) of the data from the adjacent processor. Once the data has been evolved one step, the data in the ghostzones can be exchanged (or synchronised) between processors in one fell swoop before the next evolution step. Mesh Refinement It is often the case in simulations of physical systems that the most interesting phenomena may occur in only a subset of the computational domain. In the other regions of the domain it may be possible to use a less accurate approximation, thereby reducing the computational resources required, and still obtain results which are essentially similar to those obtained if no such reduction is made. Note Imagine, for concreteness, a simulation of a strong-field gravitational wave source, like a compact binary containing neutron stars or black holes. On the one hand we have to resolve these sources well, so as to minimize truncation error in the strong-field region. On the other hand, the grid must extend into the weak-field region at large distances from the sources, so as to minimize error from the outer boundaries and to enable us to extract the emitted gravitational radiation accurately. In particular, we may consider using a computational mesh which is non-uniform in space and time, using a finer mesh resolution in the \u201cinteresting\u201d regions where we expect it to be necessary, and using a coarser resolution in other areas . This is what we mean by mesh refinement (MR). The mesh refinement driver that we use is called Carpet and is available together with the application framework Cactus. It uses the Berger\u2013Oliger approach, where the computational domain as well as all refined subdomains consist of a set of rectangular grids. Furthermore, there is a constant refinement ratio between refinement levels. The basic idea underlying mesh refinement techniques is to perform the simulation not on one numerical grid, but on several, as in the multigrid methods. notation The grids are grouped into refinement levels (or simply \u201clevels\u201d) L^K L^K , each containing an arbitrary number of grids G^{k}_{j} G^{k}_{j} . Each grid on refinement level k has the grid spacing (in one dimension) \\Delta x^{k} \\Delta x^{k} . The grid spacings are related by the relation \\Delta x^{k}=\\Delta x^{k-1} / N_{\\text { refine }} \\Delta x^{k}=\\Delta x^{k-1} / N_{\\text { refine }} with the integer refinement factor N_{\\text { refine }} N_{\\text { refine }} . The base level L^0 L^0 covers the entire domain (typically with a single grid) using a coarse grid spacing. The refined grids have to be properly nested. That is, any grid G^{k}_{j} G^{k}_{j} must be completely contained within the set of grids L^{k-1} L^{k-1} of the next coarser level, except possibly at the outer boundaries. The times and places where refined grids are created and removed are decided by some refinement criterion. The simplest criterion, which is also indispensable for testing, is manually specifying the locations of the refined grids at fixed locations in space at all times. This is called fixed mesh refinement. A bit more involved is keeping the same refinement hierarchy, but moving the finer grids according to some knowledge about the simulated system , tracking some feature such as a black hole or a neutron star. This might be called \u201cmoving fixed mesh refinement\u201d. Clearly the most desirable strategy is an automatic criterion that estimates the truncation error, and places the refined grids only when and where necessary. This is what is commonly understood by adaptive mesh refinement. Carpet supports all of the above in principle. Note The situation is more complicated for objects that are moving, as is the case for a coalescing binary star system. In this case we do not know a priori the trajectories of the companion stars, hence do not know which regions need refining. Moreover, these regions will be changing as the system evolves and the stars move. Clearly, we would like to move the refined grids with the stars. Such an approach, whereby the grid is relocated during the simulation to give optimal resolution at each time step, is called adaptive mesh refinement or AMR. Time evolution scheme In multigrid methods, the numerical solution is computed on a hierarchy of computational grids with increasing grid resolution. The finer grids may or may not cover all the physical space that is covered by the coarser grids. The numerical solution is then computed by completing sweeps through the grid hierarchy. Prolongation The coarse grid is sufficiently small so that we can compute a solution with a direct solver. This provides the \u201cglobal\u201d features of the solution, albeit on a coarse grid and hence with a large local truncation error. We then interpolate this approximate solution to the next finer grid. This interpolation from a coarser grid to a finer grid is called a \u201cprolongation\u201d. In the mathematical field of numerical analysis, interpolation is a method of constructing new data points within the range of a discrete set of known data points. AMR scheme evolves coarse grid data forward in time before evolving any data on the finer grids. These evolved coarse grid data can then be used to provide boundary conditions for the evolution of data on the finer grids via prolongation , i.e. interpolation in time and space. A refinement by a factor of N_{\\text { refine }} N_{\\text { refine }} requires time step sizes that are smaller by a factor N_{\\text { refine }} N_{\\text { refine }} , and hence N_{\\text { refine }} N_{\\text { refine }} time steps on level k+1 k+1 are necessary for each time step on level k. Restriction At time steps in which the coarse and fine grids are both defined, the fine grid data are restricted onto the coarse grid (via a simple copy operation) after it has been evolved forward in time. The coarser grids now \u201clearn\u201d from the finer grids by comparing their last solution with the one that comes back from a finer grid. This comparison provides an estimate for the local truncation error. These sweeps through the grid hierarchy can be repeated until the solution has converged to a pre-determined accuracy. If there are more than two grid levels, then one proceeds recursively from coarsest to finest, evolving data on the coarsest grid first, interpolating this data in time and space along boundaries of finer grids, evolving the finer grid data, and restricting evolved data from finer to coarser grids whenever possible. Note For time evolution schemes that consist only of a single iteration (or step), the fine grid boundary condition needs to be applied only once. Most higher-order time integrations schemes, such as Runge-Kutta or iterative Crank-Nicholson, are actually multi-step schemes and correspondingly require the fine grid boundary condition to be applied multiple times . If this is not done in a consistent manner at each iteration, then the coarse and the fine grid time evolution will not couple correctly, and this can introduce a significant error. There are several ways to guarantee consistent boundary conditions on fine grids. Our method use a larger fine grid boundary. That is, each of the integration substeps is formally applied to a progressively smaller domain, and the prolongation operation re-enlarges the domain back to its original size. Note that this \u201cbuffering\u201d is done only for prolongation boundaries; outer boundaries are handled in the conventional way. Note also that the use of buffer zones is potentially more computationally efficient. We emphasise that the use of these buffer zones is not always necessary. To our knowledge the buffer zones are necessary only when the system of equations contains second spatial derivatives, and a multi-step numerical method is used for time integration. Inter-grid transport operators As described above, the interaction between the individual refinement levels happens via prolongation and restriction. For prolongation, Carpet currently supports polynomial interpolation, up to quadratic interpolation in time, which requires keeping at least two previous time levels of data. It also supports up to quintic interpolation in space, which requires using at least three ghost zones. We usually use cubic interpolation in space, which requires only two ghost zones. For restricting, Carpet currently uses sampling (i.e., a simple copy operation). These transport operators are not conservative. Since our formulation of Einstein\u2019s equation is not in a conservative form, any use of conservative inter-grid operations offers no benefit. However, the transport operators can easily be changed. Initial data generation Initial data generation and time evolution are controlled by the driver Carpet. Initial data are created recursively, starting on the coarsest level L^{0} L^{0} . In many cases, the initial data specification is only valid for a single time t=0 t=0 . However, for the time interpolation necessary during prolongation, it may be necessary to have data on several time levels. One solution is to use only lower order interpolation during the first few time steps. We decided instead, we offer the option to evolve coarse grid data backwards in time in order to provide sufficient time levels for higher order interpolation in time at fine grid boundaries. This initial data generation proceeds in two stages. First the data are evolved both forwards and backwards in time one step, leading to the \u201chourglass\u201d structure. This evolution proceeds recursively from coarsest to finest, so that all data necessary for time interpolation are present. Note that this would not be the case if we evolved two steps backwards in time, as there would not be enough data for the time interpolation for the restriction operation between these two steps. Pseudo-spectral methods In spectral methods the evolved fields are expressed in terms of a finite sum of basis functions. An example of this would be to describe a field on a sphere in terms of an expansion in spherical harmonics. These methods have the advantage that if the fields are smooth then the error in truncating the expansion converges to zero exponentially with the number of basis functions used in the expansion.","title":"Numerical Methods"},{"location":"NR/Numerical Methods/#finite-difference-methods","text":"In a finite difference approximation a function f(t,x) f(t,x) is represented by values at a discrete set of points. At the core of finite difference approximation is therefore a discretization of the spacetime, or a numerical grid. Instead of evaluating f at all values of x, for example, we only consider discrete values x_i x_i . The distance between the gridpoints x_i x_i is called the gridspacing \u2206x \u2206x . For uniform grids, for which \u2206x \u2206x is constant, we have x _ { i } = x _ { 0 } + i \\Delta x x _ { i } = x _ { 0 } + i \\Delta x If the solution depends on time we also discretize the time coordinate, for example as t ^ { n } = t ^ { 0 } + n \\Delta t t ^ { n } = t ^ { 0 } + n \\Delta t The finite difference representation of the function f(t,x) f(t,x) , for example, is f _ { i } ^ { n } = f \\left( t ^ { n } , x _ { i } \\right) + \\text { truncation error. } f _ { i } ^ { n } = f \\left( t ^ { n } , x _ { i } \\right) + \\text { truncation error. } Differential equations involve derivatives, so we must next discuss how to represent derivatives in a finite difference representation. Assuming that f(x) f(x) can be differentiated to sufficiently high order and that it can be represented as a Taylor series, we have f _ { i + 1 } = f \\left( x _ { i } + \\Delta x \\right) = f \\left( x _ { i } \\right) + \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) f _ { i + 1 } = f \\left( x _ { i } + \\Delta x \\right) = f \\left( x _ { i } \\right) + \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) Solving for \\left( \\partial _ { x } f \\right) _ { x _ { i } } = \\left( \\partial _ { x } f \\right) _ { i } \\left( \\partial _ { x } f \\right) _ { x _ { i } } = \\left( \\partial _ { x } f \\right) _ { i } we find \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i } } { \\Delta x } + \\mathcal { O } ( \\Delta x ) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i } } { \\Delta x } + \\mathcal { O } ( \\Delta x ) The truncation error of this expression is linear in \u2206x \u2206x , and it turns out that we can do better. We call equation a one-sided derivative , since it uses only neighbors on one side of x_i x_i . Consider the Taylor expansion to the point x_{ i \u2212 1 } x_{ i \u2212 1 } , f _ { i - 1 } = f \\left( x _ { i } - \\Delta x \\right) = f \\left( x _ { i } \\right) - \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) f _ { i - 1 } = f \\left( x _ { i } - \\Delta x \\right) = f \\left( x _ { i } \\right) - \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) we now find \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i - 1 } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i - 1 } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) which is second order in \u2206x \u2206x . In general, centered derivatives lead to higher order schemes than one-sided derivatives for the same number of gridpoints. The key point is that we are able to combine the two Taylor expansions in such a way that the leading order error term cancels out, leaving us with a higher order representation of the derivative . This cancellation only works out for uniform grids , when \u2206x \u2206x is independent of x. This is one of the reasons why many current numerical relativity applications of finite difference schemes work with uniform grids. Higher order derivatives can be constructed in a similar fashion. Adding the two Taylor expansions all terms odd in \u2206x \u2206x drop out and we find for the second derivative \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } } { ( \\Delta x ) ^ { 2 } } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } } { ( \\Delta x ) ^ { 2 } } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) Fourth-order finite-difference Fourth-order finite-difference representations of the first and second derivatives of a function f are given by \\left( \\partial _ { x } f \\right) _ { i } = \\frac { 1 } { 12 \\Delta x } \\left( f _ { i - 2 } - 8 f _ { i - 1 } + 8 f _ { i + 1 } - f _ { i + 2 } \\right) \\\\ \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { 1 } { 12 ( \\Delta x ) ^ { 2 } } \\left( - f _ { i - 2 } + 16 f _ { i - 1 } - 30 f _ { i } + 16 f _ { i + 1 } - f _ { i + 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { 1 } { 12 \\Delta x } \\left( f _ { i - 2 } - 8 f _ { i - 1 } + 8 f _ { i + 1 } - f _ { i + 2 } \\right) \\\\ \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { 1 } { 12 ( \\Delta x ) ^ { 2 } } \\left( - f _ { i - 2 } + 16 f _ { i - 1 } - 30 f _ { i } + 16 f _ { i + 1 } - f _ { i + 2 } \\right) where we have omitted the truncation error, \\mathcal { O } \\left( \\Delta x ^ { 4 } \\right) \\mathcal { O } \\left( \\Delta x ^ { 4 } \\right)","title":"Finite Difference Methods"},{"location":"NR/Numerical Methods/#elliptic-equations","text":"As an example of a simple, one-dimensional elliptic equation consider \\partial_{x}^{2} f=s \\partial_{x}^{2} f=s We first have to construct a numerical grid that covers an interval between x_{min} x_{min} and x_{max} x_{max} . We then divide the interval \\left[x_{\\min }, x_{\\max }\\right] \\left[x_{\\min }, x_{\\max }\\right] into N gridcells, leading to a gridspacing of \\Delta x=\\frac{x_{\\max }-x_{\\min }}{N} \\Delta x=\\frac{x_{\\max }-x_{\\min }}{N} We can choose our grid points to be located either at the center of these cells, which would be referred to as a cell-centered grid, or on the vertices, which would be referred to as a vertex-centered grid. For a cell-centered grid we have N grid points located at x_{i}=x_{\\min }+(i-1 / 2) \\Delta x, \\quad i=1, \\ldots, N x_{i}=x_{\\min }+(i-1 / 2) \\Delta x, \\quad i=1, \\ldots, N whereas for a vertex centered grid we have N + 1 gridpoints located a x_{i}=x_{\\min }+(i-1) \\Delta x, \\quad i=1, \\ldots, N+1 x_{i}=x_{\\min }+(i-1) \\Delta x, \\quad i=1, \\ldots, N+1 The difference between cell-centered and vertex-centered grids only affects the implementation of boundary conditions, but not the finite difference representation of the differential equation itself. We are now ready to finite difference the differential equation. We define two arrays, f_i f_i and s_i s_i , which represent the functions f and s at the gridpoints x_i x_i for i = 1, . . . , N i = 1, . . . , N . In the interior of our domain we can represent the differential equation as f_{i+1}-2 f_{i}+f_{i-1}=(\\Delta x)^{2} s_{i} \\quad i=2, \\ldots, N-1 f_{i+1}-2 f_{i}+f_{i-1}=(\\Delta x)^{2} s_{i} \\quad i=2, \\ldots, N-1 At the lower boundary point i = 1 i = 1 the neighbor i \u2212 1 i \u2212 1 does not exist in our domain, and, similarly, at the upper boundary point i = N i = N the point i + 1 i + 1 does not exist. At these points we have to implement the boundary conditions, which can be done in many different ways. Let us assume that the solution f is a symmetric function about x = 0 x = 0 , in which case we can restrict the analysis to positive x and impose a Neuman condition at the origin, \\partial_{x} f=0 \\quad \\text { at } x=0 \\partial_{x} f=0 \\quad \\text { at } x=0 The two grid points x_0 x_0 and x_1 x_1 then bracket the boundary point x_{min} = 0 x_{min} = 0 symmetrically. We can then write the boundary condition as f_{1}=f_{0} f_{1}=f_{0} For i = 1 we yields f_{i+1}-f_{i}=(\\Delta x)^{2} s_{i} \\quad i=1 f_{i+1}-f_{i}=(\\Delta x)^{2} s_{i} \\quad i=1 We can use a similar strategy at the upper boundary. Let us also assume that f falls off with 1/x 1/x for large x, which results in the Robin boundary condition \\partial_{x}(x f)=0 \\quad \\text { as } x \\rightarrow \\infty \\partial_{x}(x f)=0 \\quad \\text { as } x \\rightarrow \\infty With the help of a virtual grid point x_{N + 1} x_{N + 1} we can write the boundary condition in \\Delta x \\Delta x as f_{N+1}=\\frac{x_{N}}{x_{N+1}} f_{N}=\\frac{x_{N}}{x_{N}+\\Delta x} f_{N} f_{N+1}=\\frac{x_{N}}{x_{N+1}} f_{N}=\\frac{x_{N}}{x_{N}+\\Delta x} f_{N} We can again insert this into for i = N and find \\left(\\frac{x_{i}}{x_{i}+\\Delta x}-2\\right) f_{i}+f_{i-1}=(\\Delta x)^{2} s_{i} \\quad i=N \\left(\\frac{x_{i}}{x_{i}+\\Delta x}-2\\right) f_{i}+f_{i-1}=(\\Delta x)^{2} s_{i} \\quad i=N Elliptic Equations now form a coupled set of N linear equations for the N elements f_i f_i that we can write as \\left( \\begin{array}{ccccccc}{-1} & {1} & {0} & {0} & {0} & {0} & {0} \\\\ {1} & {-2} & {1} & {0} & {0} & {0} & {0} \\\\ {0} & {\\ddots} & {\\ddots} & {\\ddots} & {0} & {0} & {0} \\\\ {0} & {0} & {1} & {-2} & {1} & {0} & {0} \\\\ {0} & {0} & {0} & {\\ddots} & {\\ddots} & {\\ddots} & {0} \\\\ {0} & {0} & {0} & {0} & {1} & {-2} & {1} \\\\ {0} & {0} & {0} & {0} & {0} & {1} & {x_{N} /\\left(x_{N}+\\Delta x\\right)-2}\\end{array}\\right) \\cdot \\left( \\begin{array}{c}{f_{1}} \\\\ {f_{2}} \\\\ {\\vdots} \\\\ {f_{i}} \\\\ {\\vdots} \\\\ {f_{N-1}} \\\\ {f_{N}}\\end{array}\\right)=(\\Delta x)^{2} \\left( \\begin{array}{c}{s_{1}} \\\\ {s_{2}} \\\\ {\\vdots} \\\\ {s_{i}} \\\\ {\\vdots} \\\\ {s_{N-1}} \\\\ {s_{N}}\\end{array}\\right) \\left( \\begin{array}{ccccccc}{-1} & {1} & {0} & {0} & {0} & {0} & {0} \\\\ {1} & {-2} & {1} & {0} & {0} & {0} & {0} \\\\ {0} & {\\ddots} & {\\ddots} & {\\ddots} & {0} & {0} & {0} \\\\ {0} & {0} & {1} & {-2} & {1} & {0} & {0} \\\\ {0} & {0} & {0} & {\\ddots} & {\\ddots} & {\\ddots} & {0} \\\\ {0} & {0} & {0} & {0} & {1} & {-2} & {1} \\\\ {0} & {0} & {0} & {0} & {0} & {1} & {x_{N} /\\left(x_{N}+\\Delta x\\right)-2}\\end{array}\\right) \\cdot \\left( \\begin{array}{c}{f_{1}} \\\\ {f_{2}} \\\\ {\\vdots} \\\\ {f_{i}} \\\\ {\\vdots} \\\\ {f_{N-1}} \\\\ {f_{N}}\\end{array}\\right)=(\\Delta x)^{2} \\left( \\begin{array}{c}{s_{1}} \\\\ {s_{2}} \\\\ {\\vdots} \\\\ {s_{i}} \\\\ {\\vdots} \\\\ {s_{N-1}} \\\\ {s_{N}}\\end{array}\\right) or, in a more compact form, \\mathbf{A} \\cdot \\mathbf{f}=(\\Delta x)^{2} \\mathbf{S} \\mathbf{A} \\cdot \\mathbf{f}=(\\Delta x)^{2} \\mathbf{S} The solution is given by \\mathbf{f}=(\\Delta x)^{2} \\mathbf{A}^{-1} \\cdot \\mathbf{S} \\mathbf{f}=(\\Delta x)^{2} \\mathbf{A}^{-1} \\cdot \\mathbf{S} so that we have reduced the problem to inverting an N \u00d7 N matrix.","title":"Elliptic Equations"},{"location":"NR/Numerical Methods/#hyperbolic-equations","text":"For simplicity it does not contain any source terms, and the the wave speed v is constant. \\partial _ { t } u + v \\partial _ { x } u = 0 \\partial _ { t } u + v \\partial _ { x } u = 0 The equation is satisfied exactly by any function of the form u ( t , x ) = u ( x - v t ) u ( t , x ) = u ( x - v t ) . The equation has a time derivative in addition to the space derivative, and thus requires initial data . Inserting both finite-difference representations \\left( \\partial _ { x } u \\right) _ { j } ^ { n } = \\frac { u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\\\ \\left( \\partial _ { t } u \\right) _ { j } ^ { n } = \\frac { u _ { j } ^ { n + 1 } - u _ { j } ^ { n } } { \\Delta t } + \\mathcal { O } ( \\Delta t ) \\left( \\partial _ { x } u \\right) _ { j } ^ { n } = \\frac { u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\\\ \\left( \\partial _ { t } u \\right) _ { j } ^ { n } = \\frac { u _ { j } ^ { n + 1 } - u _ { j } ^ { n } } { \\Delta t } + \\mathcal { O } ( \\Delta t ) we can solve for u^{n+1}_j u^{n+1}_j and find u _ { j } ^ { n + 1 } = u _ { j } ^ { n } - \\frac { v } { 2 } \\frac { \\Delta t } { \\Delta x } \\left( u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } \\right) u _ { j } ^ { n + 1 } = u _ { j } ^ { n } - \\frac { v } { 2 } \\frac { \\Delta t } { \\Delta x } \\left( u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } \\right) or reasons that are quite obivous this differencing scheme is called forward-time centered-space, or FTCS. It is an example of an explicit scheme, meaning that we can solve for the grid function u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } at the new time level n + 1 directly in terms of function values on the old time level n.","title":"Hyperbolic Equations"},{"location":"NR/Numerical Methods/#courant-friedrichs-lewy-condition","text":"Unfortunately, however, FTCS is fairly useless. The equation is satisfied exactly by any function of the form u ( t , x ) = u ( x - v t ) u ( t , x ) = u ( x - v t ) . we can write the solution u ( t , x ) u ( t , x ) to our continuum hyperbolic differential equation as a superposition of eigenmodes e^{i(\\omega t+k x)} e^{i(\\omega t+k x)} . Here k is a spatial wave number. A real \\omega \\omega , for which e^{i \\omega t} e^{i \\omega t} has a magnitude of unity, yields sinusoidally oscillating modes, while the existence of a complex piece in \\omega \\omega leads to exponentially growing or damping modes. In the case of exponential growth, the magnitude of e^{i \\omega t} e^{i \\omega t} will exceed unity. We can perform a similar spectral analysis of the finite difference equation. Write the eigenmode for u_{j}^{n} u_{j}^{n} as u_{j}^{n}=\\xi^{n} e^{i k(j \\Delta x)} u_{j}^{n}=\\xi^{n} e^{i k(j \\Delta x)} Here the quantity \\xi \\xi plays the role of e^{i \\omega \\Delta t} e^{i \\omega \\Delta t} and is called the amplification factor: u_{j}^{n}=\\xi u_{j}^{n-1} = \\xi^{2} u_{j}^{n-2} \\ldots=\\xi^{n} u_{j}^{0} u_{j}^{n}=\\xi u_{j}^{n-1} = \\xi^{2} u_{j}^{n-2} \\ldots=\\xi^{n} u_{j}^{0} For the scheme to be stable, the magnitude \\xi \\xi must be smaller or equal to unity for all k, |\\xi(k)| \\leq 1 |\\xi(k)| \\leq 1 To perform a von Neumann stability anaylsis of the FTCS scheme \\xi(k)=1-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x \\xi(k)=1-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x the magnitude of \\xi \\xi is greater than unity for all k, indicating that this scheme is unstable. In fact, we have |\\xi|>1 |\\xi|>1 independently of our choice for \\Delta x \\Delta x and \\Delta t \\Delta t , which makes this scheme unconditionally unstable. That is bad. The good news is that there are several ways of fixing this problem. For example, we could replace the term u_{j}^{n} u_{j}^{n} by the spatial average \\left(u_{j+1}^{n}+u_{j-1}^{n}\\right) / 2 \\left(u_{j+1}^{n}+u_{j-1}^{n}\\right) / 2 . u_{j}^{n+1}=\\frac{1}{2}\\left(u_{j+1}^{n}+u_{j-1}^{n}\\right)-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n}-u_{j-1}^{n}\\right) u_{j}^{n+1}=\\frac{1}{2}\\left(u_{j+1}^{n}+u_{j-1}^{n}\\right)-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n}-u_{j-1}^{n}\\right) a von Neumann analysis results in the amplification factor \\xi=\\cos k \\Delta x-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x \\xi=\\cos k \\Delta x-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x The von Neumann stability criterion then implies that we must have \\frac { | v | \\Delta t } { \\Delta x } \\leq 1 \\frac { | v | \\Delta t } { \\Delta x } \\leq 1 The Courant condition states that the the grid point u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } at the new time level n+1 has to reside inside the domain of determinacy of the interval spanned by the finite difference stencil at the time level n. This makes intuitive sense: if u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } were outside this domain, its physical specification would require more information about the past than we are providing numerically, which may trigger an instability. Recalling that v represents the speed of a characteristic, we may interpret the Courant condition in terms of the domain of determinacy. It seems somewhat like a miracle that simply replacing a grid function by a local average manages to change the numerical scheme from unconditionally unstable to conditionally stable. This change can be interpreted in very physical terms u_{j}^{n+1}=u_{j}^{n}+\\frac{1}{2}\\left(u_{j+1}^{n}-2 u_{j}^{n}+u_{j-1}^{n}\\right)-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n}-u_{j-1}^{n}\\right) u_{j}^{n+1}=u_{j}^{n}+\\frac{1}{2}\\left(u_{j+1}^{n}-2 u_{j}^{n}+u_{j-1}^{n}\\right)-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n}-u_{j-1}^{n}\\right) or \\frac{u_{j}^{n+1}-u_{j}^{n}}{\\Delta t}=-v \\frac{u_{j+1}^{n}-u_{j-1}^{n}}{2 \\Delta x}+\\frac{(\\Delta x)^{2}}{2 \\Delta t} \\frac{u_{j+1}^{n}-2 u_{j}^{n}+u_{j-1}^{n}}{(\\Delta x)^{2}} \\frac{u_{j}^{n+1}-u_{j}^{n}}{\\Delta t}=-v \\frac{u_{j+1}^{n}-u_{j-1}^{n}}{2 \\Delta x}+\\frac{(\\Delta x)^{2}}{2 \\Delta t} \\frac{u_{j+1}^{n}-2 u_{j}^{n}+u_{j-1}^{n}}{(\\Delta x)^{2}} But equation is a finite-difference representation of the differential equation \\partial_{t} u+v \\partial_{x} u=D \\partial_{x}^{2} u \\partial_{t} u+v \\partial_{x} u=D \\partial_{x}^{2} u where the term on the right-hand side is essentially a diffusion term, with parameter D=(\\Delta x)^{2} /(2 \\Delta t) D=(\\Delta x)^{2} /(2 \\Delta t) serving as a constant coefficient of diffusion. This feature implies the amplitude of any wave will decrease spuriously with time as it propagates. A related effect is anomalous dispersion, an additional price we pay for stablity in the Lax scheme and many other finite-difference schemes for hyperbolic systems.","title":"Courant-Friedrichs-Lewy condition"},{"location":"NR/Numerical Methods/#implicit-scheme","text":"Yet another way of constructing a stable two-level scheme is to use backward time differencing instead of forward differencing. This approach then yields the \u201cbackward-time, centered-space\u201d scheme, u_{j}^{n+1}=u_{j}^{n}-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n+1}-u_{j-1}^{n+1}\\right) u_{j}^{n+1}=u_{j}^{n}-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n+1}-u_{j-1}^{n+1}\\right) Performing a von Neumann stability analysis we find the amplification factor |\\xi(k)| \\leq 1 |\\xi(k)| \\leq 1 for all values of \\Delta t \\Delta t . This finding means that this scheme is unconditionally stable. The size of the stepsize \u2206t is no longer restricted by stability, and instead is limited only by accuracy requirements. this property is even more important for parabolic equations. The disadvantage of the backward differencing scheme is that we can no longer solve for the new grid function u_{j}^{n+1} u_{j}^{n+1} at the new time t^{n+1} t^{n+1} explicitly in terms of old grid functions at t^{n} t^{n} alone. Instead, now couples u_{j}^{n+1} u_{j}^{n+1} with the its closest neighbors u_{j+1}^{n+1} u_{j+1}^{n+1} and u_{j-1}^{n+1} u_{j-1}^{n+1} . This coupling provides an implicit linear relation between the new grid functions, and is therefore an example of an implicit finite-differencing scheme. We can no longer sweep through the grid and update one point at a time; instead we now have to solve for all grid points simultaneously . Writing equation at all interior grid points, and then taking into account the boundary conditions, leads to a system of equations quite similar to elliptic equations.","title":"implicit scheme"},{"location":"NR/Numerical Methods/#method-of-lines","text":"A popular alternative to these complete finite difference schemes is therefore the method of lines (or MOL for short). The basic idea of the method of lines is to finite difference the space derivatives only. Now we introduce a spatial grid only, at least for now, so that the function values at these gridpoint, u_{j}(t)=u\\left(t, x_{j}\\right) u_{j}(t)=u\\left(t, x_{j}\\right) , remain functions of time. As a result, our partial differential equation for u(t, x) u(t, x) becomes a set of ordinary differential equations for the grid values u_{j}(t) u_{j}(t) . The next question is how to integrate the ordinary differential equations. The appealing feature of the method of lines, however, is that we can use any method for the integration of the ordinary differential equations that we like. In fact, many such methods, including very efficient, high-order methods, are precoded and readily available. One such algorithm is the ever-popular Runge-Kutta method. To implement, say, a fourth-order scheme for our model \\partial_{t} u+v \\partial_{x} u=0 \\partial_{t} u+v \\partial_{x} u=0 we could adopt the fourth-order differencing stencil to replace the spatial derivative, yielding \\frac{d u_{j}}{d t}=-\\frac{v}{12 \\Delta x}\\left(u_{i-2}-8 u_{j-1}+8 u_{j+1}-u_{i+2}\\right) \\frac{d u_{j}}{d t}=-\\frac{v}{12 \\Delta x}\\left(u_{i-2}-8 u_{j-1}+8 u_{j+1}-u_{i+2}\\right) and then integrate this set of ordinary differential equations with a fourth-order Runge-Kutta method.","title":"Method of Lines"},{"location":"NR/Numerical Methods/#runge-kutta-rk-method","text":"The explicit form of the algorithms is Prediction step (common for both RK2 and RK3): \\boldsymbol{U}^{(1)}=\\boldsymbol{U}^{(n)}+\\Delta t L\\left(\\boldsymbol{U}^{(n)}\\right) \\boldsymbol{U}^{(1)}=\\boldsymbol{U}^{(n)}+\\Delta t L\\left(\\boldsymbol{U}^{(n)}\\right) Depending on the order do: RK2: \\boldsymbol{U}^{n+1}=\\frac{1}{\\alpha}\\left[\\beta \\boldsymbol{U}^{n}+\\boldsymbol{U}^{(1)}+\\Delta t L\\left(\\boldsymbol{U}^{(1)}\\right)\\right] \\boldsymbol{U}^{n+1}=\\frac{1}{\\alpha}\\left[\\beta \\boldsymbol{U}^{n}+\\boldsymbol{U}^{(1)}+\\Delta t L\\left(\\boldsymbol{U}^{(1)}\\right)\\right] RK3: \\begin{aligned} \\boldsymbol{U}^{(2)} &=\\frac{1}{\\alpha}\\left[\\beta \\boldsymbol{U}^{(2 n)}+\\boldsymbol{U}^{(1)}+\\Delta t L\\left(\\boldsymbol{U}^{(1)}\\right)\\right] \\\\ \\boldsymbol{U}^{n+1} &=\\frac{1}{\\beta}\\left[\\beta \\boldsymbol{U}^{(2 n)}+2 \\boldsymbol{U}^{(2)}+2 \\Delta t L\\left(\\boldsymbol{U}^{(2)}\\right)\\right] \\end{aligned} \\begin{aligned} \\boldsymbol{U}^{(2)} &=\\frac{1}{\\alpha}\\left[\\beta \\boldsymbol{U}^{(2 n)}+\\boldsymbol{U}^{(1)}+\\Delta t L\\left(\\boldsymbol{U}^{(1)}\\right)\\right] \\\\ \\boldsymbol{U}^{n+1} &=\\frac{1}{\\beta}\\left[\\beta \\boldsymbol{U}^{(2 n)}+2 \\boldsymbol{U}^{(2)}+2 \\Delta t L\\left(\\boldsymbol{U}^{(2)}\\right)\\right] \\end{aligned}","title":"Runge-Kutta (RK) method"},{"location":"NR/Numerical Methods/#ghost-zones","text":"Cactus is based upon a distributed computing paradigm. That is, the problem domain is split into blocks, each of which is assigned to a processor. Consider the 1-D wave equation \\frac{\\partial^{2} \\phi}{\\partial t^{2}}=\\frac{\\partial^{2} \\phi}{\\partial x^{2}} \\frac{\\partial^{2} \\phi}{\\partial t^{2}}=\\frac{\\partial^{2} \\phi}{\\partial x^{2}} To solve this by partial differences, one discretises the derivatives to get an equation relating the solution at different times. \\phi(t+\\Delta t, x)-2 \\phi(t, x)+\\phi(t-\\Delta t, x)=\\frac{\\Delta t^{2}}{\\Delta x^{2}}\\{\\phi(t, x+\\Delta x)-2 \\phi(t, x)+\\phi(t, x-\\Delta x)\\} \\phi(t+\\Delta t, x)-2 \\phi(t, x)+\\phi(t-\\Delta t, x)=\\frac{\\Delta t^{2}}{\\Delta x^{2}}\\{\\phi(t, x+\\Delta x)-2 \\phi(t, x)+\\phi(t, x-\\Delta x)\\} On examination, you can see that to generate the data at the point (t+\\Delta t, x) (t+\\Delta t, x) we need data from the four points (t, x) (t, x) , (t -\\Delta t, x) (t -\\Delta t, x) , (t, x + \\Delta x) (t, x + \\Delta x) and (t, x- \\Delta x) (t, x- \\Delta x) only. Now, if you evolve the above scheme, it becomes apparent that at each iteration the number of grid points you can evolve decreases by one at each edge. At the outer boundary of the physical domain, the data for the boundary point can be generated by the boundary conditions, however, at internal boundaries, the data has to be copied from the adjacent processor. It would be inefficient to copy each point individually, so instead, a number of ghostzones are created at the internal boundaries. A ghostzone consists of a copy of the whole plane (in 3D, line in 2D, point in 1D) of the data from the adjacent processor. Once the data has been evolved one step, the data in the ghostzones can be exchanged (or synchronised) between processors in one fell swoop before the next evolution step.","title":"Ghost Zones"},{"location":"NR/Numerical Methods/#mesh-refinement","text":"It is often the case in simulations of physical systems that the most interesting phenomena may occur in only a subset of the computational domain. In the other regions of the domain it may be possible to use a less accurate approximation, thereby reducing the computational resources required, and still obtain results which are essentially similar to those obtained if no such reduction is made. Note Imagine, for concreteness, a simulation of a strong-field gravitational wave source, like a compact binary containing neutron stars or black holes. On the one hand we have to resolve these sources well, so as to minimize truncation error in the strong-field region. On the other hand, the grid must extend into the weak-field region at large distances from the sources, so as to minimize error from the outer boundaries and to enable us to extract the emitted gravitational radiation accurately. In particular, we may consider using a computational mesh which is non-uniform in space and time, using a finer mesh resolution in the \u201cinteresting\u201d regions where we expect it to be necessary, and using a coarser resolution in other areas . This is what we mean by mesh refinement (MR). The mesh refinement driver that we use is called Carpet and is available together with the application framework Cactus. It uses the Berger\u2013Oliger approach, where the computational domain as well as all refined subdomains consist of a set of rectangular grids. Furthermore, there is a constant refinement ratio between refinement levels. The basic idea underlying mesh refinement techniques is to perform the simulation not on one numerical grid, but on several, as in the multigrid methods. notation The grids are grouped into refinement levels (or simply \u201clevels\u201d) L^K L^K , each containing an arbitrary number of grids G^{k}_{j} G^{k}_{j} . Each grid on refinement level k has the grid spacing (in one dimension) \\Delta x^{k} \\Delta x^{k} . The grid spacings are related by the relation \\Delta x^{k}=\\Delta x^{k-1} / N_{\\text { refine }} \\Delta x^{k}=\\Delta x^{k-1} / N_{\\text { refine }} with the integer refinement factor N_{\\text { refine }} N_{\\text { refine }} . The base level L^0 L^0 covers the entire domain (typically with a single grid) using a coarse grid spacing. The refined grids have to be properly nested. That is, any grid G^{k}_{j} G^{k}_{j} must be completely contained within the set of grids L^{k-1} L^{k-1} of the next coarser level, except possibly at the outer boundaries. The times and places where refined grids are created and removed are decided by some refinement criterion. The simplest criterion, which is also indispensable for testing, is manually specifying the locations of the refined grids at fixed locations in space at all times. This is called fixed mesh refinement. A bit more involved is keeping the same refinement hierarchy, but moving the finer grids according to some knowledge about the simulated system , tracking some feature such as a black hole or a neutron star. This might be called \u201cmoving fixed mesh refinement\u201d. Clearly the most desirable strategy is an automatic criterion that estimates the truncation error, and places the refined grids only when and where necessary. This is what is commonly understood by adaptive mesh refinement. Carpet supports all of the above in principle. Note The situation is more complicated for objects that are moving, as is the case for a coalescing binary star system. In this case we do not know a priori the trajectories of the companion stars, hence do not know which regions need refining. Moreover, these regions will be changing as the system evolves and the stars move. Clearly, we would like to move the refined grids with the stars. Such an approach, whereby the grid is relocated during the simulation to give optimal resolution at each time step, is called adaptive mesh refinement or AMR.","title":"Mesh Refinement"},{"location":"NR/Numerical Methods/#time-evolution-scheme","text":"In multigrid methods, the numerical solution is computed on a hierarchy of computational grids with increasing grid resolution. The finer grids may or may not cover all the physical space that is covered by the coarser grids. The numerical solution is then computed by completing sweeps through the grid hierarchy.","title":"Time evolution scheme"},{"location":"NR/Numerical Methods/#prolongation","text":"The coarse grid is sufficiently small so that we can compute a solution with a direct solver. This provides the \u201cglobal\u201d features of the solution, albeit on a coarse grid and hence with a large local truncation error. We then interpolate this approximate solution to the next finer grid. This interpolation from a coarser grid to a finer grid is called a \u201cprolongation\u201d. In the mathematical field of numerical analysis, interpolation is a method of constructing new data points within the range of a discrete set of known data points. AMR scheme evolves coarse grid data forward in time before evolving any data on the finer grids. These evolved coarse grid data can then be used to provide boundary conditions for the evolution of data on the finer grids via prolongation , i.e. interpolation in time and space. A refinement by a factor of N_{\\text { refine }} N_{\\text { refine }} requires time step sizes that are smaller by a factor N_{\\text { refine }} N_{\\text { refine }} , and hence N_{\\text { refine }} N_{\\text { refine }} time steps on level k+1 k+1 are necessary for each time step on level k.","title":"Prolongation"},{"location":"NR/Numerical Methods/#restriction","text":"At time steps in which the coarse and fine grids are both defined, the fine grid data are restricted onto the coarse grid (via a simple copy operation) after it has been evolved forward in time. The coarser grids now \u201clearn\u201d from the finer grids by comparing their last solution with the one that comes back from a finer grid. This comparison provides an estimate for the local truncation error. These sweeps through the grid hierarchy can be repeated until the solution has converged to a pre-determined accuracy. If there are more than two grid levels, then one proceeds recursively from coarsest to finest, evolving data on the coarsest grid first, interpolating this data in time and space along boundaries of finer grids, evolving the finer grid data, and restricting evolved data from finer to coarser grids whenever possible. Note For time evolution schemes that consist only of a single iteration (or step), the fine grid boundary condition needs to be applied only once. Most higher-order time integrations schemes, such as Runge-Kutta or iterative Crank-Nicholson, are actually multi-step schemes and correspondingly require the fine grid boundary condition to be applied multiple times . If this is not done in a consistent manner at each iteration, then the coarse and the fine grid time evolution will not couple correctly, and this can introduce a significant error. There are several ways to guarantee consistent boundary conditions on fine grids. Our method use a larger fine grid boundary. That is, each of the integration substeps is formally applied to a progressively smaller domain, and the prolongation operation re-enlarges the domain back to its original size. Note that this \u201cbuffering\u201d is done only for prolongation boundaries; outer boundaries are handled in the conventional way. Note also that the use of buffer zones is potentially more computationally efficient. We emphasise that the use of these buffer zones is not always necessary. To our knowledge the buffer zones are necessary only when the system of equations contains second spatial derivatives, and a multi-step numerical method is used for time integration.","title":"Restriction"},{"location":"NR/Numerical Methods/#inter-grid-transport-operators","text":"As described above, the interaction between the individual refinement levels happens via prolongation and restriction. For prolongation, Carpet currently supports polynomial interpolation, up to quadratic interpolation in time, which requires keeping at least two previous time levels of data. It also supports up to quintic interpolation in space, which requires using at least three ghost zones. We usually use cubic interpolation in space, which requires only two ghost zones. For restricting, Carpet currently uses sampling (i.e., a simple copy operation). These transport operators are not conservative. Since our formulation of Einstein\u2019s equation is not in a conservative form, any use of conservative inter-grid operations offers no benefit. However, the transport operators can easily be changed.","title":"Inter-grid transport operators"},{"location":"NR/Numerical Methods/#initial-data-generation","text":"Initial data generation and time evolution are controlled by the driver Carpet. Initial data are created recursively, starting on the coarsest level L^{0} L^{0} . In many cases, the initial data specification is only valid for a single time t=0 t=0 . However, for the time interpolation necessary during prolongation, it may be necessary to have data on several time levels. One solution is to use only lower order interpolation during the first few time steps. We decided instead, we offer the option to evolve coarse grid data backwards in time in order to provide sufficient time levels for higher order interpolation in time at fine grid boundaries. This initial data generation proceeds in two stages. First the data are evolved both forwards and backwards in time one step, leading to the \u201chourglass\u201d structure. This evolution proceeds recursively from coarsest to finest, so that all data necessary for time interpolation are present. Note that this would not be the case if we evolved two steps backwards in time, as there would not be enough data for the time interpolation for the restriction operation between these two steps.","title":"Initial data generation"},{"location":"NR/Numerical Methods/#pseudo-spectral-methods","text":"In spectral methods the evolved fields are expressed in terms of a finite sum of basis functions. An example of this would be to describe a field on a sphere in terms of an expansion in spherical harmonics. These methods have the advantage that if the fields are smooth then the error in truncating the expansion converges to zero exponentially with the number of basis functions used in the expansion.","title":"Pseudo-spectral methods"},{"location":"SP/Introduction/","text":"These detections required technically sophisticated analysis pipelines to reduce the strain data. This is because typical events are buried under the detector noise, and cannot be simply \u201cseen\u201d in raw data at current sensitivities. Hence, any search for signals in the data needs to properly and precisely model the detector noise.","title":"Introduction"},{"location":"SP/matched filter/","text":"Let h be the gravitational-wave signal we are looking for and let \ud835\udc5b be the detector\u2019s noise. For convenience we assume that the signal h is a continuous function of time \ud835\udc61 and that the noise \ud835\udc5b is a continuous random process. Assuming that the noise is additive the data x x can be written as x(t)=n(t)+h(t) x(t)=n(t)+h(t)","title":"Matched Filtering"}]}