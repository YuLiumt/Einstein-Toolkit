{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Content Einstein Toolkit: Introduction Install Cactus General Relativity: 'GR.md' Gravitational Wave: 'GW.md' Introduction Numerical Relativity: 'NR.md'","title":"Home"},{"location":"#content","text":"Einstein Toolkit: Introduction Install Cactus General Relativity: 'GR.md' Gravitational Wave: 'GW.md' Introduction Numerical Relativity: 'NR.md'","title":"Content"},{"location":"GR/","text":"General Relativity A well-known feature of General Relativity is that space and time are relative but events are absolute. \u201cmatter tells spacetime how to curve, and curved spacetime tells matter how to move\u201d. Manifolds Vectors We define a tangent vector \\upsilon \\upsilon at point p \\in M p \\in M to be a map \\upsilon : \\mathcal{F}_M \\rightarrow R \\upsilon : \\mathcal{F}_M \\rightarrow R Linear \\upsilon (a f + b g) = a \\upsilon (f) + b \\upsilon (g) \\upsilon (a f + b g) = a \\upsilon (f) + b \\upsilon (g) Obeys the Leibnitz rule \\upsilon (f g) = f(p) \\upsilon (g) + g(p) \\upsilon (f) \\upsilon (f g) = f(p) \\upsilon (g) + g(p) \\upsilon (f) Let M be an n-dimensional manifold. Let p \\in M p \\in M and let V_p V_p denote the tangent space at p p . Then dim \\space V_p = n dim \\space V_p = n . If $f \\in \\mathcal{F} $, For \\mu = 1, ..., n \\mu = 1, ..., n define X_{\\mu} : \\mathcal{F} \\rightarrow R X_{\\mu} : \\mathcal{F} \\rightarrow R by X_{\\mu}(f):= \\frac{\\partial f(x)}{\\partial x^{\\mu}}, \\forall f \\in \\mathcal{F}_M X_{\\mu}(f):= \\frac{\\partial f(x)}{\\partial x^{\\mu}}, \\forall f \\in \\mathcal{F}_M where (x^1, ... , x^n) (x^1, ... , x^n) are the Cartesian coordinates of R^n R^n . Then X_1, \\cdots, X_n X_1, \\cdots, X_n are tangent vectors. An arbitrary tangent vector \\upsilon \\upsilon as a sum of the X_{\\mu} X_{\\mu} , \\upsilon = \\sum^n_{\\mu = 1} \\upsilon^{\\mu} X_{\\mu} \\upsilon = \\sum^n_{\\mu = 1} \\upsilon^{\\mu} X_{\\mu} Dual Vector Let V V be any finite-dimensional vector space, linear maps \\omega : V \\rightarrow R \\omega : V \\rightarrow R are called dual vectors. df|_p(\\upsilon) := \\upsilon (f), \\space \\forall \\upsilon \\in V_p df|_p(\\upsilon) := \\upsilon (f), \\space \\forall \\upsilon \\in V_p If \\frac{\\partial}{\\partial x^{\\nu}} \\frac{\\partial}{\\partial x^{\\nu}} is a basis of V V , we can define elements dx^{\\mu} dx^{\\mu} dx^{\\mu}(\\frac{\\partial}{\\partial x^{\\nu}}) = \\frac{\\partial}{\\partial x^{\\nu}}(x^{\\mu}) = \\delta^{\\mu}_{\\nu} dx^{\\mu}(\\frac{\\partial}{\\partial x^{\\nu}}) = \\frac{\\partial}{\\partial x^{\\nu}}(x^{\\mu}) = \\delta^{\\mu}_{\\nu} {dx^{\\mu}} {dx^{\\mu}} is a basis of V^{*} V^{*} . Derivative Operators A derivative operator, \\nabla \\nabla , (sometimes called a covariant derivative) on a manifold M M is a map which takes each smooth tensor field of type (k, l) (k, l) to a smooth tensor field of type (k, l + 1) (k, l + 1) . Any tow derivative operators \\nabla_a \\nabla_a and \\tilde{\\nabla}_a \\tilde{\\nabla}_a must agree in their action on scalar fields. \\nabla_a f = \\tilde{\\nabla}_a f = (df)_a, \\forall f \\in \\cal{F}_M \\nabla_a f = \\tilde{\\nabla}_a f = (df)_a, \\forall f \\in \\cal{F}_M \\tilde{\\nabla}_a - \\nabla_a \\tilde{\\nabla}_a - \\nabla_a defines a map of dual vectors at p p to tensors of type (0, 2) (0, 2) at p p . Consequently (\\tilde{\\nabla}_a - \\nabla_a) (\\tilde{\\nabla}_a - \\nabla_a) defines a tensor of type (1, 2) (1, 2) at p p , which we will denote as C^c_{\\space ab} C^c_{\\space ab} . \\nabla_a \\omega_b = \\tilde{\\nabla}_a \\omega_b - C^{c}_{ab} \\omega_c \\nabla_a \\omega_b = \\tilde{\\nabla}_a \\omega_b - C^{c}_{ab} \\omega_c C^c_{\\space ab} C^c_{\\space ab} must also have this property C^c_{\\space ab} = C^c_{\\space ba} \\\\ \\nabla_a \\upsilon^b = C^b_{\\space ac} \\upsilon^c + \\tilde{\\nabla}_a \\upsilon^b \\\\ \\nabla_a T^b_{c} = \\tilde{\\nabla}_a T^b_c + C^b_{\\space ad} T^d_c - C^{d}_{\\space ac} T^b_d C^c_{\\space ab} = C^c_{\\space ba} \\\\ \\nabla_a \\upsilon^b = C^b_{\\space ac} \\upsilon^c + \\tilde{\\nabla}_a \\upsilon^b \\\\ \\nabla_a T^b_{c} = \\tilde{\\nabla}_a T^b_c + C^b_{\\space ad} T^d_c - C^{d}_{\\space ac} T^b_d This displays the possible disagreements of the actions of \\nabla_a \\nabla_a and \\tilde{\\nabla}_a \\tilde{\\nabla}_a on Tensor Parallel Transport Given a derivative operator \\nabla_a \\nabla_a we can define the notion of the parallel transport of a vector along a curve C C with a tangent T^a T^a . A vector \\upsilon^a \\upsilon^a given at each point on the curve is said to be parallel transported as one moves along the curve if the equation $$ T^b \\nabla_b \\upsilon^a = 0 $$ is satisfied along the curve. Given two vectors u^a u^a and \\upsilon^a \\upsilon^a , we demand that their inner product g_{ab} u^a \\upsilon^a g_{ab} u^a \\upsilon^a remain unchanged if we parallel-transport them along any curve. Thus we require $$ 0 = T^c \\nabla_c (g_{ab} u^a \\upsilon^b) = g_{ab} u^a T^c \\nabla_c (\\upsilon^b) + g_{ab} \\upsilon^b T^c \\nabla_c (u^a) + u^a \\upsilon^b T^c \\nabla_c (g_{ab}) $$ Equation will hold for all curves and parallel transported vectors if and only if $$ \\nabla_c (g_{ab}) = 0 $$ which is the additional condition we wish to impose on \\nabla_a \\nabla_a . We attempt to solve for C^c_{\\space ab} C^c_{\\space ab} so that the derivative operator determined by \\tilde{\\nabla}_a \\tilde{\\nabla}_a and C^c_{\\space ab} C^c_{\\space ab} will satisfy the required property. $$ C^c_{\\space ab} = \\frac{1}{2} g^{cd} (\\partial_a g_{bd} + \\partial_b g_{ad} - \\partial_d g_{ab}) $$ Curvature Given a derivative operator, there exists a notion of how to parallel transport a vector from p to q along a curve C. However, the vector in V_q V_q which we get by this parallel transport procedure starting from a vector in V_p V_p will, in general, depend on the choice of curve connecting them. We can use the path dependence of parallel transport to define an intrinsic notion of curvature. The failure of a vector to return to its original value when parallel transported around a small closed loop is governed by the Riemann tensor. (\\nabla_a \\nabla_b - \\nabla_b \\nabla_a) (\\nabla_a \\nabla_b - \\nabla_b \\nabla_a) defines a linear map dual vectors at p p to type (0, 3) (0, 3) tensors at p p , its action is that of a tensor of (1, 3) (1, 3) . Thus, we have shown that there exists a tensor field R_{abc}^{\\space \\space \\space d} R_{abc}^{\\space \\space \\space d} such that for all dual vector fields \\omega_c \\omega_c , we have $$ \\nabla_a \\nabla_b \\omega_c - \\nabla_b \\nabla_a \\omega_c = R_{abc}^{\\space \\space \\space d} \\omega_c $$ Properties of the Riemann tensor: 1. R_{abc}^{\\space \\space \\space d} = - R_{bac}^{\\space \\space \\space d} R_{abc}^{\\space \\space \\space d} = - R_{bac}^{\\space \\space \\space d} 2. R_{[abc]}^{\\space \\space \\space \\space \\space d} = 0 R_{[abc]}^{\\space \\space \\space \\space \\space d} = 0 3. R_{abcd} = - R_{abdc} R_{abcd} = - R_{abdc} 4. \\nabla_{[a}R_{bc]d}^{\\space \\space \\space e} = 0\u200b \\nabla_{[a}R_{bc]d}^{\\space \\space \\space e} = 0\u200b 5. R_{abcd} = R_{cdab} R_{abcd} = R_{cdab} Its trace over the second and fourth (or equivalently, the first and third) indices defines the Ricci tensor, R_{ac} R_{ac} , $$ R_{ac} = R_{abc}^{\\space \\space \\space b} $$ The scalar curvature, R, is defined as the trace of the Ricci tensor: $$ R = R_a^{\\space a} $$ We denote the symmetric and antisymmetric parts of a tensor with brackets () and [] around indices in the usual way. For example $$ T_{(ab)} = \\frac{1}{2} (T_{ab} + T_{ba}) \\ T_{[ab]} = \\frac{1}{2} (T_{ab} - T_{ba}) $$ To calculate the curvature by the coordinate component method, we begin by choosing a coordinate system. We express the derivative operator \\nabla_a \\nabla_a in terms of the ordinary derivative \\partial_a \\partial_a of this coordinate system and the Christoffel symbol \\Gamma^c_{\\space ab} \\Gamma^c_{\\space ab} . $$ R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma} = \\frac{\\partial}{\\partial x^{\\nu}} \\Gamma^{\\sigma} {\\space \\mu \\rho} - \\frac{\\partial}{\\partial x^{\\mu}} \\Gamma^{\\sigma} {\\space \\nu \\rho} + \\sum_a (\\Gamma^{a} {\\space \\mu \\rho} \\Gamma^{\\sigma} {\\space a \\nu} - \\Gamma^{a} {\\space \\nu \\rho} \\Gamma^{\\sigma} {\\space a \\mu}) $$ Thus, to calculate R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b starting from g_{ab}\u200b g_{ab}\u200b , we first obtain the components, g_{\\mu \\nu}\u200b g_{\\mu \\nu}\u200b , of the metric in our coordinate basis. We then calculate \\Gamma^{\\sigma}_{\\space \\mu \\nu}\u200b \\Gamma^{\\sigma}_{\\space \\mu \\nu}\u200b . Finally we calculate the components R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b . The Lie Derivative Consider a (non-zero) vector \ufb01eld X^{a} X^{a} in a manifold M M . We can find the integral curves x^a(\\lambda) x^a(\\lambda) (or orbits, or trajectories) of X X a by integrating the ordinary differential equations \\frac{dx^{a}}{d \\lambda} = X^a (x^a(\\lambda)) \\frac{dx^{a}}{d \\lambda} = X^a (x^a(\\lambda)) Here \\lambda\u200b \\lambda\u200b is some affine parameter. We would now like to define a derivative of a tensor \ufb01eld. This involves comparing the tensor \ufb01eld at two different points along X^a X^a , say P P and Q Q , and taking the limit as Q Q tends to P P . This is where we encounter a conceptual problem: what do we mean by comparing two tensors at two different locations in the manifold M? In order to differentiate a tensor in a tensorial manner, we therefore have to evaluate the two tensors at the same point. To do so, we have to drag one tensor to the other point before we can compare the two tensors. However, this recipe still leaves open how we drag T^a_{\\space b} T^a_{\\space b} along X^a X^a . One approach would be to parallel-transport the tensor T^a_{\\space b} T^a_{\\space b} from P P to Q Q . This idea leads to the definition of the covariant derivative. Parallel-transporting is not the only way of dragging T^a_{\\space b} T^a_{\\space b} along X^a X^a . In other words, the Lie derivative along a vector field X^a X^a measures by how much the changes in a tensor \ufb01eld along X^a X^a differ from a mere infinitesimal coordinate transformation generated by X^a X^a . Unlike the covariant derivative, the Lie derivative does not require an affine connection, and hence requires less structure. For a scalar f f , the Lie derivative naturally reduces to the partial derivative L_X f = X^b \\nabla_b f = X^b \\partial_b f L_X f = X^b \\nabla_b f = X^b \\partial_b f Note that the Lie derivative satis\ufb01es the Leibnitz rule for outer products. L_X \\upsilon^a = X^b \\nabla_b \\upsilon^a - \\upsilon^b \\nabla_b X^a = [X, \\upsilon]^a \\\\ L_X \\omega_a = X^b \\nabla_b \\omega_a + \\omega_b \\nabla_a X^b L_X \\upsilon^a = X^b \\nabla_b \\upsilon^a - \\upsilon^b \\nabla_b X^a = [X, \\upsilon]^a \\\\ L_X \\omega_a = X^b \\nabla_b \\omega_a + \\omega_b \\nabla_a X^b Killing Vectors As an important application, consider the Lie derivative along X^a X^a of a metric g_{ab} g_{ab} . L_X g_{ab} = X^c \\nabla_c g_{ab} + g_{cb} \\nabla_a X^c + g_{ca} \\nabla_b X^c L_X g_{ab} = X^c \\nabla_c g_{ab} + g_{cb} \\nabla_a X^c + g_{ca} \\nabla_b X^c If \\nabla_a \\nabla_a is compatible with the metric, the first term vanishes, and we L_X g_{ab} = \\nabla_a X_b + \\nabla_b X_a L_X g_{ab} = \\nabla_a X_b + \\nabla_b X_a A Killing vector \ufb01eld \\xi^a \\xi^a can now be de\ufb01ned by L_{\\xi} g_{ab} = 0 L_{\\xi} g_{ab} = 0 In other words, a Killing \ufb01eld \\xi_a \\xi_a generates an isometry of the spacetime, and a displacement along \\xi^a \\xi^a leaves the metric invariant. Killing's equation \\nabla^a X^b + \\nabla^b X^a = 0 \\nabla^a X^b + \\nabla^b X^a = 0 In some cases it is very easy to identify a Killing vector. If the metric components are independent of a coordinate x^i x^i , then it follows from the property that the coordinate basis vector e^a e^a is a Killing vector. Gravitational Wave LIGO The Advanced LIGO gravitational wave observatories performed their first observing run (O1) from September 12, 2015 to January 19, 2016. This provided a total of 51.5 days of coincident observations from the two detectors located in Hanford, WA and Livingston, LA. A second observing run (O2) of the Advanced LIGO detectors took place from November 30, 2016 to August 25, 2017. The Virgo gravitational wave detector also collected data for part of this period, starting from August 1, 2017. Linearized Waves In the near-\ufb01eld region about such sources, the gravitational fields consist of a combination of longitudinal and transverse components that cannot be disentangled unambiguously. As the transverse fields propagate away from their sources, they can be modeled as a linear perturbation of a nearly Minkowski spacetime. These linearized gravitational waves carry information about the nature of the nonlinear sources that generated them. It is these linearized waves that are measured by gravitational wave detectors. Consider a small perturbation h_{ab} h_{ab} of a known \u201cbackground\u201d solution to Einstein\u2019s equations. In principle the background could be any solution, but here we are interested in waves propagating in a nearly Minkowski spacetime, for which the metric becomes g_{ab} = \\eta_{ab} + h_{ab} \\space |h_{ab} \\ll 1| g_{ab} = \\eta_{ab} + h_{ab} \\space |h_{ab} \\ll 1| It is convenient to introduce the \u201ctrace-reversed\u201d perturbation \\bar{h}_{ab} = h_{ab} - \\frac{1}{2} \\eta_{ab} h_c^{\\space c} \\bar{h}_{ab} = h_{ab} - \\frac{1}{2} \\eta_{ab} h_c^{\\space c} We can now exploit our coordinate-freedom to impose the \u201cLorentz gauge\u201d condition, \\nabla_a \\bar{h}^{ab} = 0 \\nabla_a \\bar{h}^{ab} = 0 in which case Einstein\u2019s equations in vacuum reduce to the wave equation \\nabla^c \\nabla_c \\bar{h}_{ab} = 0 \\nabla^c \\nabla_c \\bar{h}_{ab} = 0 As it turns out, the Lorentz-gauge condition does not determine \\bar{h}_{ab} \\bar{h}_{ab} uniquely, since we can introduce further infinitesimal gauge transformations that leave this condition unchanged. We can therefore use this remaining gauge freedom to impose further conditions on the perturbations \\bar{h}_{ab} \\bar{h}_{ab} . Particularly useful is the transverse-traceless or \u201cTT\u201d gauge, in which \\bar{h}^{TT}_{a0} = 0 \\\\ {\\bar{h}^{TT}}^a_{\\space a} = 0 \\bar{h}^{TT}_{a0} = 0 \\\\ {\\bar{h}^{TT}}^a_{\\space a} = 0 The first condition implies that the only nonzero components of \\bar{h}^{TT}_{ab} \\bar{h}^{TT}_{ab} are purely spatial. The second condition implies that h_c^{\\space c} = 0 h_c^{\\space c} = 0 , so that, the trace-reversed metric perturbations \\bar{h}_{ab} \\bar{h}_{ab} are identical to the original perturbations h_{ab} h_{ab} , and we are entitled to drop the bars whenever we write down results in the TT gauge. The \u201cLorentz gauge\u201d condition and the \u201cTT\u201d gauge provide eight constraints on the originally ten independent components of h_{ab} h_{ab} . The remaining two degrees of freedom correspond to the two possible polarization states of gravitational radiation. It is often convenient to express these two polarization states in terms of the two polarization tensors e^+_{ab} e^+_{ab} and e^{\\times}_{ab} e^{\\times}_{ab} . For a linear plane wave propagating in vacuum in the z-direction, for example, we have e^+_{xx} = - e^+_{yy} = 1 \\\\ e^{\\times}_{xy} = e^{\\times}_{yx} = 1 \\\\ all \\space other \\space components \\space zero e^+_{xx} = - e^+_{yy} = 1 \\\\ e^{\\times}_{xy} = e^{\\times}_{yx} = 1 \\\\ all \\space other \\space components \\space zero A general gravitational wave is then specified by two dimensionless amplitudes h_+ h_+ and h_\u00d7 h_\u00d7 as h^{TT}_{jk} = h_+ e^+_{ij} + h_\u00d7 e^{\\times}_{ij} h^{TT}_{jk} = h_+ e^+_{ij} + h_\u00d7 e^{\\times}_{ij} Gravitational radiation carries energy, momentum, and angular momentum Lensed Gravitational Waves When a GW signal passes by massive objects, the incoming wave behaves similarly to light in that the signal becomes gravitationally lensed. Black Hole A black hole is de\ufb01ned as a region of spacetime from which no null geodesic can escape to infinity. The surface of a black hole, the event horizon, acts as a one-way membrane through which light and matter can enter the black hole, but once inside, can never escape. It is the boundary in spacetime separating those events that can emit light rays that can propagate to infinity and those which cannot. More precisely, the event horizon is de\ufb01ned as the boundary of the causal past of future null infinity. It is a 2 + 1 dimensional hypersurface in spacetime formed by those outward-going, future-directed null geodesics that neither escape to infinity nor fall toward the center of the black hole. The event horizon is a gauge-invariant entity, and contains important geometric information about a black hole spacetime. The most general stationary black hole solution to Einstein\u2019s equations is the analytically known Kerr-Newman metric. It is uniquely specified by just three parameters: the mass M, angular momentum J and the charge Q of the black hole . Special cases are the Kerr metric (Q = 0), the Reissner-Nordstrom metric (J = 0) and the Schwarzschild metric (J = 0, Q = 0). Schwarzschild Black Holes The Schwarzschild solution for a vacuum spherical spacetime may be written as d s ^ { 2 } = - \\left( 1 - \\frac { 2 M } { r } \\right) d t ^ { 2 } + \\left( 1 - \\frac { 2 M } { r } \\right) ^ { - 1 } d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } d s ^ { 2 } = - \\left( 1 - \\frac { 2 M } { r } \\right) d t ^ { 2 } + \\left( 1 - \\frac { 2 M } { r } \\right) ^ { - 1 } d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } The black hole event horizon is located at r = 2M r = 2M and is sometimes called the Schwarzschild radius. It is also referred to as the \u201cstatic limit\u201d, because static observers cannot exist inside r = 2M r = 2M , and the \u201csurface of infinite redshift\u201d, because photons emitted by a static source just outside r = 2M r = 2M will have infinite wavelength when measured by a static observer at infinity. Circular orbits of test particles exist down to r = 3M r = 3M . The singularity in the metric at r = 2M r = 2M is a coordinate singularity, removable by coordinate transformation , while the singularity at r = 0 r = 0 is a physical spacetime singularity. In fact, the curvature invariant I \\equiv {}^ { ( 4 ) } R _ { a b c d } {}^ { ( 4 ) } R ^ { a b c d } = 48 M ^ { 2 } / r ^ { 6 } I \\equiv {}^ { ( 4 ) } R _ { a b c d } {}^ { ( 4 ) } R ^ { a b c d } = 48 M ^ { 2 } / r ^ { 6 } clearly blows up at the origin, showing that the tidal gravitational field becomes infinite at the center of the black hole. One alternative coordinate choice that removes the coordinate singularity at r = 2M r = 2M is the Kruskal-Szekeres coordinate system. d s ^ { 2 } = \\frac { 32 M ^ { 3 } } { r } e ^ { - r / 2 M } \\left( - d v ^ { 2 } + d u ^ { 2 } \\right) + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } d s ^ { 2 } = \\frac { 32 M ^ { 3 } } { r } e ^ { - r / 2 M } \\left( - d v ^ { 2 } + d u ^ { 2 } \\right) + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } The original Schwarzschild coordinate system covers only half of the spacetime manifold, while Kruskal-Szekeres coordinates cover the entire manifold. Kerr Black Holes The solution to Einstein\u2019s equations describing a stationary, rotating, uncharged black hole of mass M and angular momentum J in vacuum may be expressed in Boyer-Lindquist coordinates in the form d s ^ { 2 } = - \\left( 1 - \\frac { 2 M r } { \\Sigma } \\right) d t ^ { 2 } - \\frac { 4 a M r \\sin ^ { 2 } \\theta } { \\Sigma } d t d \\phi + \\frac { \\Sigma } { \\Delta } d r ^ { 2 } + \\Sigma d \\theta ^ { 2 } + \\left( r ^ { 2 } + a ^ { 2 } + \\frac { 2 a ^ { 2 } M r \\sin ^ { 2 } \\theta } { \\Sigma } \\right) \\sin ^ { 2 } \\theta d \\phi ^ { 2 } d s ^ { 2 } = - \\left( 1 - \\frac { 2 M r } { \\Sigma } \\right) d t ^ { 2 } - \\frac { 4 a M r \\sin ^ { 2 } \\theta } { \\Sigma } d t d \\phi + \\frac { \\Sigma } { \\Delta } d r ^ { 2 } + \\Sigma d \\theta ^ { 2 } + \\left( r ^ { 2 } + a ^ { 2 } + \\frac { 2 a ^ { 2 } M r \\sin ^ { 2 } \\theta } { \\Sigma } \\right) \\sin ^ { 2 } \\theta d \\phi ^ { 2 } where a \\equiv J / M , \\quad \\Delta \\equiv r ^ { 2 } - 2 M r + a ^ { 2 } , \\quad \\Sigma \\equiv r ^ { 2 } + a ^ { 2 } \\cos ^ { 2 } \\theta a \\equiv J / M , \\quad \\Delta \\equiv r ^ { 2 } - 2 M r + a ^ { 2 } , \\quad \\Sigma \\equiv r ^ { 2 } + a ^ { 2 } \\cos ^ { 2 } \\theta The horizon of the black hole is located at r_+ r_+ , the largest root of the equation \u2206 = 0 \u2206 = 0 , r _ { + } = M + \\left( M ^ { 2 } - a ^ { 2 } \\right) ^ { 1 / 2 } r _ { + } = M + \\left( M ^ { 2 } - a ^ { 2 } \\right) ^ { 1 / 2 } The static limit is the surface within which no static observers exist; it resides at r_0 r_0 , the largest root of g_{tt} = 0 g_{tt} = 0 : r _ { 0 } = M + \\left( M ^ { 2 } - a ^ { 2 } \\cos ^ { 2 } \\theta \\right) ^ { 1 / 2 } r _ { 0 } = M + \\left( M ^ { 2 } - a ^ { 2 } \\cos ^ { 2 } \\theta \\right) ^ { 1 / 2 } The region between the horizon and static limit is called the ergosphere; in this region all time-like observers are dragged around the hole with angular velocity \u03a9 > 0 \u03a9 > 0 . Innermost stable circular orbit The Innermost stable circular orbit (often called the ISCO ) is the smallest circular orbit in which a test particle can stably orbit a massive object in general relativity. The location of the ISCO, the ISCO-radius ( r_{isco} r_{isco} ), depends on the angular momentum (spin) of the central object. The ISCO plays an important role in black hole accretion disks since it marks the inner edge of the disk . For a non-spinning massive object, the ISCO is located at, r_{isco} = \\frac{6 G M}{c^2} = 3 R_S r_{isco} = \\frac{6 G M}{c^2} = 3 R_S For a rotating black holes Global Theorems In an isolated system, the sum of the surface areas of all black holes can never decrease. Schwarzschild black hole The fact that the event horizon area cannot decrease motivates the definition of the irreducible mass M_{irr} = (\\frac{\\mathcal{A}}{16 \\pi})^{\\frac{1}{2}} M_{irr} = (\\frac{\\mathcal{A}}{16 \\pi})^{\\frac{1}{2}} The definition then implies that the irreducible mass of the black hole cannot decrease, which motivates its name. The area theorem can be used to place a strict upper limit on the amount of energy that is emitted in gravitational radiation in black hole collisions. Consider two widely separated, non-rotating black holes of masses M_1 M_1 and M_2 M_2 , initially at rest with respect to some distant observer. Use the area theorem to find an upper limit on the energy emitted in gravitational radiation that arises from the head-on collision of the two black holes. Verify that for equal mass black holes at most 29% of the total initial energy can be emitted in gravitational radiation. Kerr black holes Given the irreducible mass M_{irr} M_{irr} and the angular momentum J of an isolated, stationary black hole, we can compute the Kerr mass M ( = M_{ADM} = M_{ADM} ) from M^2 = M^2_{irr} + \\frac{1}{4} \\frac{J^2}{M^2_{irr}} M^2 = M^2_{irr} + \\frac{1}{4} \\frac{J^2}{M^2_{irr}} According to the area theorem, only the rotational energy contribution can be tapped as a source of energy by an external system interacting with the hole, since the irreducible mass can never decrease. Weak Equivalence Principle We imagine that a body is made up of atoms, and that the inertial mass m\\_I m\\_I of an atom consists of the sum of all the mass and energy contributions of its constituents. But we suppose that the different forms of energy may contribute differently to the gravitational mass m\\_G m\\_G than they do to m\\_I m\\_I . One way to express this is to write m\\_G = m\\_I (1 + eta) m\\_G = m\\_I (1 + eta) , where eta eta is a dimensionless parameter that measures the difference. Because different forms of energy arising from the relevant subatomic interactions (such as electromagnetic and nuclear interactions) contribute different amounts to the total, depending on atomic structure, eta eta could depend on the type of atom. Alternative Theories of Gravity The simplest scenario that one could consider in this context is the addition of an extra scalar \ufb01eld, but one might also choose to consider extra vectors, tensors, or even higher rank fields. Of course, the effect of such additional \ufb01eld needs to be suppressed at scales where General Relativity has been well tested, such as in the lab or solar system 1 . Scalar-Tensor Theories A general form of the scalar-tensor theory can be derived from the Lagrangian density $$ \\mathcal{L}=\\frac{1}{16 \\pi } \\sqrt{-g} \\left[ f\\left( \\phi \\right) R-g\\left( \\phi \\right) \\nabla {\\mu }\\phi \\nabla ^{\\mu }\\phi -2\\Lambda \\left( \\phi \\right) \\right] +\\mathcal{L} {m}\\left( \\psi ,h\\left( \\phi \\right) g_{\\mu \\nu}\\right) $$ \\mathcal{L}_m \\mathcal{L}_m is the Lagrangian density of the matter fields \\psi \\psi . Clifton, T., Ferreira, P. G., Padilla, A., & Skordis, C. (2011, June 14). Modified Gravity and Cosmology. arXiv.org. http://doi.org/10.1016/j.physrep.2012.01.001 \u21a9","title":"General Relativity"},{"location":"GR/#general-relativity","text":"A well-known feature of General Relativity is that space and time are relative but events are absolute. \u201cmatter tells spacetime how to curve, and curved spacetime tells matter how to move\u201d.","title":"General Relativity"},{"location":"GR/#manifolds","text":"","title":"Manifolds"},{"location":"GR/#vectors","text":"We define a tangent vector \\upsilon \\upsilon at point p \\in M p \\in M to be a map \\upsilon : \\mathcal{F}_M \\rightarrow R \\upsilon : \\mathcal{F}_M \\rightarrow R Linear \\upsilon (a f + b g) = a \\upsilon (f) + b \\upsilon (g) \\upsilon (a f + b g) = a \\upsilon (f) + b \\upsilon (g) Obeys the Leibnitz rule \\upsilon (f g) = f(p) \\upsilon (g) + g(p) \\upsilon (f) \\upsilon (f g) = f(p) \\upsilon (g) + g(p) \\upsilon (f) Let M be an n-dimensional manifold. Let p \\in M p \\in M and let V_p V_p denote the tangent space at p p . Then dim \\space V_p = n dim \\space V_p = n . If $f \\in \\mathcal{F} $, For \\mu = 1, ..., n \\mu = 1, ..., n define X_{\\mu} : \\mathcal{F} \\rightarrow R X_{\\mu} : \\mathcal{F} \\rightarrow R by X_{\\mu}(f):= \\frac{\\partial f(x)}{\\partial x^{\\mu}}, \\forall f \\in \\mathcal{F}_M X_{\\mu}(f):= \\frac{\\partial f(x)}{\\partial x^{\\mu}}, \\forall f \\in \\mathcal{F}_M where (x^1, ... , x^n) (x^1, ... , x^n) are the Cartesian coordinates of R^n R^n . Then X_1, \\cdots, X_n X_1, \\cdots, X_n are tangent vectors. An arbitrary tangent vector \\upsilon \\upsilon as a sum of the X_{\\mu} X_{\\mu} , \\upsilon = \\sum^n_{\\mu = 1} \\upsilon^{\\mu} X_{\\mu} \\upsilon = \\sum^n_{\\mu = 1} \\upsilon^{\\mu} X_{\\mu}","title":"Vectors"},{"location":"GR/#dual-vector","text":"Let V V be any finite-dimensional vector space, linear maps \\omega : V \\rightarrow R \\omega : V \\rightarrow R are called dual vectors. df|_p(\\upsilon) := \\upsilon (f), \\space \\forall \\upsilon \\in V_p df|_p(\\upsilon) := \\upsilon (f), \\space \\forall \\upsilon \\in V_p If \\frac{\\partial}{\\partial x^{\\nu}} \\frac{\\partial}{\\partial x^{\\nu}} is a basis of V V , we can define elements dx^{\\mu} dx^{\\mu} dx^{\\mu}(\\frac{\\partial}{\\partial x^{\\nu}}) = \\frac{\\partial}{\\partial x^{\\nu}}(x^{\\mu}) = \\delta^{\\mu}_{\\nu} dx^{\\mu}(\\frac{\\partial}{\\partial x^{\\nu}}) = \\frac{\\partial}{\\partial x^{\\nu}}(x^{\\mu}) = \\delta^{\\mu}_{\\nu} {dx^{\\mu}} {dx^{\\mu}} is a basis of V^{*} V^{*} .","title":"Dual Vector"},{"location":"GR/#derivative-operators","text":"A derivative operator, \\nabla \\nabla , (sometimes called a covariant derivative) on a manifold M M is a map which takes each smooth tensor field of type (k, l) (k, l) to a smooth tensor field of type (k, l + 1) (k, l + 1) . Any tow derivative operators \\nabla_a \\nabla_a and \\tilde{\\nabla}_a \\tilde{\\nabla}_a must agree in their action on scalar fields. \\nabla_a f = \\tilde{\\nabla}_a f = (df)_a, \\forall f \\in \\cal{F}_M \\nabla_a f = \\tilde{\\nabla}_a f = (df)_a, \\forall f \\in \\cal{F}_M \\tilde{\\nabla}_a - \\nabla_a \\tilde{\\nabla}_a - \\nabla_a defines a map of dual vectors at p p to tensors of type (0, 2) (0, 2) at p p . Consequently (\\tilde{\\nabla}_a - \\nabla_a) (\\tilde{\\nabla}_a - \\nabla_a) defines a tensor of type (1, 2) (1, 2) at p p , which we will denote as C^c_{\\space ab} C^c_{\\space ab} . \\nabla_a \\omega_b = \\tilde{\\nabla}_a \\omega_b - C^{c}_{ab} \\omega_c \\nabla_a \\omega_b = \\tilde{\\nabla}_a \\omega_b - C^{c}_{ab} \\omega_c C^c_{\\space ab} C^c_{\\space ab} must also have this property C^c_{\\space ab} = C^c_{\\space ba} \\\\ \\nabla_a \\upsilon^b = C^b_{\\space ac} \\upsilon^c + \\tilde{\\nabla}_a \\upsilon^b \\\\ \\nabla_a T^b_{c} = \\tilde{\\nabla}_a T^b_c + C^b_{\\space ad} T^d_c - C^{d}_{\\space ac} T^b_d C^c_{\\space ab} = C^c_{\\space ba} \\\\ \\nabla_a \\upsilon^b = C^b_{\\space ac} \\upsilon^c + \\tilde{\\nabla}_a \\upsilon^b \\\\ \\nabla_a T^b_{c} = \\tilde{\\nabla}_a T^b_c + C^b_{\\space ad} T^d_c - C^{d}_{\\space ac} T^b_d This displays the possible disagreements of the actions of \\nabla_a \\nabla_a and \\tilde{\\nabla}_a \\tilde{\\nabla}_a on Tensor","title":"Derivative Operators"},{"location":"GR/#parallel-transport","text":"Given a derivative operator \\nabla_a \\nabla_a we can define the notion of the parallel transport of a vector along a curve C C with a tangent T^a T^a . A vector \\upsilon^a \\upsilon^a given at each point on the curve is said to be parallel transported as one moves along the curve if the equation $$ T^b \\nabla_b \\upsilon^a = 0 $$ is satisfied along the curve. Given two vectors u^a u^a and \\upsilon^a \\upsilon^a , we demand that their inner product g_{ab} u^a \\upsilon^a g_{ab} u^a \\upsilon^a remain unchanged if we parallel-transport them along any curve. Thus we require $$ 0 = T^c \\nabla_c (g_{ab} u^a \\upsilon^b) = g_{ab} u^a T^c \\nabla_c (\\upsilon^b) + g_{ab} \\upsilon^b T^c \\nabla_c (u^a) + u^a \\upsilon^b T^c \\nabla_c (g_{ab}) $$ Equation will hold for all curves and parallel transported vectors if and only if $$ \\nabla_c (g_{ab}) = 0 $$ which is the additional condition we wish to impose on \\nabla_a \\nabla_a . We attempt to solve for C^c_{\\space ab} C^c_{\\space ab} so that the derivative operator determined by \\tilde{\\nabla}_a \\tilde{\\nabla}_a and C^c_{\\space ab} C^c_{\\space ab} will satisfy the required property. $$ C^c_{\\space ab} = \\frac{1}{2} g^{cd} (\\partial_a g_{bd} + \\partial_b g_{ad} - \\partial_d g_{ab}) $$","title":"Parallel Transport"},{"location":"GR/#curvature","text":"Given a derivative operator, there exists a notion of how to parallel transport a vector from p to q along a curve C. However, the vector in V_q V_q which we get by this parallel transport procedure starting from a vector in V_p V_p will, in general, depend on the choice of curve connecting them. We can use the path dependence of parallel transport to define an intrinsic notion of curvature. The failure of a vector to return to its original value when parallel transported around a small closed loop is governed by the Riemann tensor. (\\nabla_a \\nabla_b - \\nabla_b \\nabla_a) (\\nabla_a \\nabla_b - \\nabla_b \\nabla_a) defines a linear map dual vectors at p p to type (0, 3) (0, 3) tensors at p p , its action is that of a tensor of (1, 3) (1, 3) . Thus, we have shown that there exists a tensor field R_{abc}^{\\space \\space \\space d} R_{abc}^{\\space \\space \\space d} such that for all dual vector fields \\omega_c \\omega_c , we have $$ \\nabla_a \\nabla_b \\omega_c - \\nabla_b \\nabla_a \\omega_c = R_{abc}^{\\space \\space \\space d} \\omega_c $$ Properties of the Riemann tensor: 1. R_{abc}^{\\space \\space \\space d} = - R_{bac}^{\\space \\space \\space d} R_{abc}^{\\space \\space \\space d} = - R_{bac}^{\\space \\space \\space d} 2. R_{[abc]}^{\\space \\space \\space \\space \\space d} = 0 R_{[abc]}^{\\space \\space \\space \\space \\space d} = 0 3. R_{abcd} = - R_{abdc} R_{abcd} = - R_{abdc} 4. \\nabla_{[a}R_{bc]d}^{\\space \\space \\space e} = 0\u200b \\nabla_{[a}R_{bc]d}^{\\space \\space \\space e} = 0\u200b 5. R_{abcd} = R_{cdab} R_{abcd} = R_{cdab} Its trace over the second and fourth (or equivalently, the first and third) indices defines the Ricci tensor, R_{ac} R_{ac} , $$ R_{ac} = R_{abc}^{\\space \\space \\space b} $$ The scalar curvature, R, is defined as the trace of the Ricci tensor: $$ R = R_a^{\\space a} $$ We denote the symmetric and antisymmetric parts of a tensor with brackets () and [] around indices in the usual way. For example $$ T_{(ab)} = \\frac{1}{2} (T_{ab} + T_{ba}) \\ T_{[ab]} = \\frac{1}{2} (T_{ab} - T_{ba}) $$ To calculate the curvature by the coordinate component method, we begin by choosing a coordinate system. We express the derivative operator \\nabla_a \\nabla_a in terms of the ordinary derivative \\partial_a \\partial_a of this coordinate system and the Christoffel symbol \\Gamma^c_{\\space ab} \\Gamma^c_{\\space ab} . $$ R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma} = \\frac{\\partial}{\\partial x^{\\nu}} \\Gamma^{\\sigma} {\\space \\mu \\rho} - \\frac{\\partial}{\\partial x^{\\mu}} \\Gamma^{\\sigma} {\\space \\nu \\rho} + \\sum_a (\\Gamma^{a} {\\space \\mu \\rho} \\Gamma^{\\sigma} {\\space a \\nu} - \\Gamma^{a} {\\space \\nu \\rho} \\Gamma^{\\sigma} {\\space a \\mu}) $$ Thus, to calculate R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b starting from g_{ab}\u200b g_{ab}\u200b , we first obtain the components, g_{\\mu \\nu}\u200b g_{\\mu \\nu}\u200b , of the metric in our coordinate basis. We then calculate \\Gamma^{\\sigma}_{\\space \\mu \\nu}\u200b \\Gamma^{\\sigma}_{\\space \\mu \\nu}\u200b . Finally we calculate the components R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b R_{\\mu \\nu \\rho}^{\\space \\space \\space \\sigma}\u200b .","title":"Curvature"},{"location":"GR/#the-lie-derivative","text":"Consider a (non-zero) vector \ufb01eld X^{a} X^{a} in a manifold M M . We can find the integral curves x^a(\\lambda) x^a(\\lambda) (or orbits, or trajectories) of X X a by integrating the ordinary differential equations \\frac{dx^{a}}{d \\lambda} = X^a (x^a(\\lambda)) \\frac{dx^{a}}{d \\lambda} = X^a (x^a(\\lambda)) Here \\lambda\u200b \\lambda\u200b is some affine parameter. We would now like to define a derivative of a tensor \ufb01eld. This involves comparing the tensor \ufb01eld at two different points along X^a X^a , say P P and Q Q , and taking the limit as Q Q tends to P P . This is where we encounter a conceptual problem: what do we mean by comparing two tensors at two different locations in the manifold M? In order to differentiate a tensor in a tensorial manner, we therefore have to evaluate the two tensors at the same point. To do so, we have to drag one tensor to the other point before we can compare the two tensors. However, this recipe still leaves open how we drag T^a_{\\space b} T^a_{\\space b} along X^a X^a . One approach would be to parallel-transport the tensor T^a_{\\space b} T^a_{\\space b} from P P to Q Q . This idea leads to the definition of the covariant derivative. Parallel-transporting is not the only way of dragging T^a_{\\space b} T^a_{\\space b} along X^a X^a . In other words, the Lie derivative along a vector field X^a X^a measures by how much the changes in a tensor \ufb01eld along X^a X^a differ from a mere infinitesimal coordinate transformation generated by X^a X^a . Unlike the covariant derivative, the Lie derivative does not require an affine connection, and hence requires less structure. For a scalar f f , the Lie derivative naturally reduces to the partial derivative L_X f = X^b \\nabla_b f = X^b \\partial_b f L_X f = X^b \\nabla_b f = X^b \\partial_b f Note that the Lie derivative satis\ufb01es the Leibnitz rule for outer products. L_X \\upsilon^a = X^b \\nabla_b \\upsilon^a - \\upsilon^b \\nabla_b X^a = [X, \\upsilon]^a \\\\ L_X \\omega_a = X^b \\nabla_b \\omega_a + \\omega_b \\nabla_a X^b L_X \\upsilon^a = X^b \\nabla_b \\upsilon^a - \\upsilon^b \\nabla_b X^a = [X, \\upsilon]^a \\\\ L_X \\omega_a = X^b \\nabla_b \\omega_a + \\omega_b \\nabla_a X^b","title":"The Lie Derivative"},{"location":"GR/#killing-vectors","text":"As an important application, consider the Lie derivative along X^a X^a of a metric g_{ab} g_{ab} . L_X g_{ab} = X^c \\nabla_c g_{ab} + g_{cb} \\nabla_a X^c + g_{ca} \\nabla_b X^c L_X g_{ab} = X^c \\nabla_c g_{ab} + g_{cb} \\nabla_a X^c + g_{ca} \\nabla_b X^c If \\nabla_a \\nabla_a is compatible with the metric, the first term vanishes, and we L_X g_{ab} = \\nabla_a X_b + \\nabla_b X_a L_X g_{ab} = \\nabla_a X_b + \\nabla_b X_a A Killing vector \ufb01eld \\xi^a \\xi^a can now be de\ufb01ned by L_{\\xi} g_{ab} = 0 L_{\\xi} g_{ab} = 0 In other words, a Killing \ufb01eld \\xi_a \\xi_a generates an isometry of the spacetime, and a displacement along \\xi^a \\xi^a leaves the metric invariant. Killing's equation \\nabla^a X^b + \\nabla^b X^a = 0 \\nabla^a X^b + \\nabla^b X^a = 0 In some cases it is very easy to identify a Killing vector. If the metric components are independent of a coordinate x^i x^i , then it follows from the property that the coordinate basis vector e^a e^a is a Killing vector.","title":"Killing Vectors"},{"location":"GR/#gravitational-wave","text":"","title":"Gravitational Wave"},{"location":"GR/#ligo","text":"The Advanced LIGO gravitational wave observatories performed their first observing run (O1) from September 12, 2015 to January 19, 2016. This provided a total of 51.5 days of coincident observations from the two detectors located in Hanford, WA and Livingston, LA. A second observing run (O2) of the Advanced LIGO detectors took place from November 30, 2016 to August 25, 2017. The Virgo gravitational wave detector also collected data for part of this period, starting from August 1, 2017.","title":"LIGO"},{"location":"GR/#linearized-waves","text":"In the near-\ufb01eld region about such sources, the gravitational fields consist of a combination of longitudinal and transverse components that cannot be disentangled unambiguously. As the transverse fields propagate away from their sources, they can be modeled as a linear perturbation of a nearly Minkowski spacetime. These linearized gravitational waves carry information about the nature of the nonlinear sources that generated them. It is these linearized waves that are measured by gravitational wave detectors. Consider a small perturbation h_{ab} h_{ab} of a known \u201cbackground\u201d solution to Einstein\u2019s equations. In principle the background could be any solution, but here we are interested in waves propagating in a nearly Minkowski spacetime, for which the metric becomes g_{ab} = \\eta_{ab} + h_{ab} \\space |h_{ab} \\ll 1| g_{ab} = \\eta_{ab} + h_{ab} \\space |h_{ab} \\ll 1| It is convenient to introduce the \u201ctrace-reversed\u201d perturbation \\bar{h}_{ab} = h_{ab} - \\frac{1}{2} \\eta_{ab} h_c^{\\space c} \\bar{h}_{ab} = h_{ab} - \\frac{1}{2} \\eta_{ab} h_c^{\\space c} We can now exploit our coordinate-freedom to impose the \u201cLorentz gauge\u201d condition, \\nabla_a \\bar{h}^{ab} = 0 \\nabla_a \\bar{h}^{ab} = 0 in which case Einstein\u2019s equations in vacuum reduce to the wave equation \\nabla^c \\nabla_c \\bar{h}_{ab} = 0 \\nabla^c \\nabla_c \\bar{h}_{ab} = 0 As it turns out, the Lorentz-gauge condition does not determine \\bar{h}_{ab} \\bar{h}_{ab} uniquely, since we can introduce further infinitesimal gauge transformations that leave this condition unchanged. We can therefore use this remaining gauge freedom to impose further conditions on the perturbations \\bar{h}_{ab} \\bar{h}_{ab} . Particularly useful is the transverse-traceless or \u201cTT\u201d gauge, in which \\bar{h}^{TT}_{a0} = 0 \\\\ {\\bar{h}^{TT}}^a_{\\space a} = 0 \\bar{h}^{TT}_{a0} = 0 \\\\ {\\bar{h}^{TT}}^a_{\\space a} = 0 The first condition implies that the only nonzero components of \\bar{h}^{TT}_{ab} \\bar{h}^{TT}_{ab} are purely spatial. The second condition implies that h_c^{\\space c} = 0 h_c^{\\space c} = 0 , so that, the trace-reversed metric perturbations \\bar{h}_{ab} \\bar{h}_{ab} are identical to the original perturbations h_{ab} h_{ab} , and we are entitled to drop the bars whenever we write down results in the TT gauge. The \u201cLorentz gauge\u201d condition and the \u201cTT\u201d gauge provide eight constraints on the originally ten independent components of h_{ab} h_{ab} . The remaining two degrees of freedom correspond to the two possible polarization states of gravitational radiation. It is often convenient to express these two polarization states in terms of the two polarization tensors e^+_{ab} e^+_{ab} and e^{\\times}_{ab} e^{\\times}_{ab} . For a linear plane wave propagating in vacuum in the z-direction, for example, we have e^+_{xx} = - e^+_{yy} = 1 \\\\ e^{\\times}_{xy} = e^{\\times}_{yx} = 1 \\\\ all \\space other \\space components \\space zero e^+_{xx} = - e^+_{yy} = 1 \\\\ e^{\\times}_{xy} = e^{\\times}_{yx} = 1 \\\\ all \\space other \\space components \\space zero A general gravitational wave is then specified by two dimensionless amplitudes h_+ h_+ and h_\u00d7 h_\u00d7 as h^{TT}_{jk} = h_+ e^+_{ij} + h_\u00d7 e^{\\times}_{ij} h^{TT}_{jk} = h_+ e^+_{ij} + h_\u00d7 e^{\\times}_{ij} Gravitational radiation carries energy, momentum, and angular momentum","title":"Linearized Waves"},{"location":"GR/#lensed-gravitational-waves","text":"When a GW signal passes by massive objects, the incoming wave behaves similarly to light in that the signal becomes gravitationally lensed.","title":"Lensed Gravitational Waves"},{"location":"GR/#black-hole","text":"A black hole is de\ufb01ned as a region of spacetime from which no null geodesic can escape to infinity. The surface of a black hole, the event horizon, acts as a one-way membrane through which light and matter can enter the black hole, but once inside, can never escape. It is the boundary in spacetime separating those events that can emit light rays that can propagate to infinity and those which cannot. More precisely, the event horizon is de\ufb01ned as the boundary of the causal past of future null infinity. It is a 2 + 1 dimensional hypersurface in spacetime formed by those outward-going, future-directed null geodesics that neither escape to infinity nor fall toward the center of the black hole. The event horizon is a gauge-invariant entity, and contains important geometric information about a black hole spacetime. The most general stationary black hole solution to Einstein\u2019s equations is the analytically known Kerr-Newman metric. It is uniquely specified by just three parameters: the mass M, angular momentum J and the charge Q of the black hole . Special cases are the Kerr metric (Q = 0), the Reissner-Nordstrom metric (J = 0) and the Schwarzschild metric (J = 0, Q = 0).","title":"Black Hole"},{"location":"GR/#schwarzschild-black-holes","text":"The Schwarzschild solution for a vacuum spherical spacetime may be written as d s ^ { 2 } = - \\left( 1 - \\frac { 2 M } { r } \\right) d t ^ { 2 } + \\left( 1 - \\frac { 2 M } { r } \\right) ^ { - 1 } d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } d s ^ { 2 } = - \\left( 1 - \\frac { 2 M } { r } \\right) d t ^ { 2 } + \\left( 1 - \\frac { 2 M } { r } \\right) ^ { - 1 } d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } The black hole event horizon is located at r = 2M r = 2M and is sometimes called the Schwarzschild radius. It is also referred to as the \u201cstatic limit\u201d, because static observers cannot exist inside r = 2M r = 2M , and the \u201csurface of infinite redshift\u201d, because photons emitted by a static source just outside r = 2M r = 2M will have infinite wavelength when measured by a static observer at infinity. Circular orbits of test particles exist down to r = 3M r = 3M . The singularity in the metric at r = 2M r = 2M is a coordinate singularity, removable by coordinate transformation , while the singularity at r = 0 r = 0 is a physical spacetime singularity. In fact, the curvature invariant I \\equiv {}^ { ( 4 ) } R _ { a b c d } {}^ { ( 4 ) } R ^ { a b c d } = 48 M ^ { 2 } / r ^ { 6 } I \\equiv {}^ { ( 4 ) } R _ { a b c d } {}^ { ( 4 ) } R ^ { a b c d } = 48 M ^ { 2 } / r ^ { 6 } clearly blows up at the origin, showing that the tidal gravitational field becomes infinite at the center of the black hole. One alternative coordinate choice that removes the coordinate singularity at r = 2M r = 2M is the Kruskal-Szekeres coordinate system. d s ^ { 2 } = \\frac { 32 M ^ { 3 } } { r } e ^ { - r / 2 M } \\left( - d v ^ { 2 } + d u ^ { 2 } \\right) + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } d s ^ { 2 } = \\frac { 32 M ^ { 3 } } { r } e ^ { - r / 2 M } \\left( - d v ^ { 2 } + d u ^ { 2 } \\right) + r ^ { 2 } d \\theta ^ { 2 } + r ^ { 2 } \\sin ^ { 2 } \\theta d \\phi ^ { 2 } The original Schwarzschild coordinate system covers only half of the spacetime manifold, while Kruskal-Szekeres coordinates cover the entire manifold.","title":"Schwarzschild Black Holes"},{"location":"GR/#kerr-black-holes","text":"The solution to Einstein\u2019s equations describing a stationary, rotating, uncharged black hole of mass M and angular momentum J in vacuum may be expressed in Boyer-Lindquist coordinates in the form d s ^ { 2 } = - \\left( 1 - \\frac { 2 M r } { \\Sigma } \\right) d t ^ { 2 } - \\frac { 4 a M r \\sin ^ { 2 } \\theta } { \\Sigma } d t d \\phi + \\frac { \\Sigma } { \\Delta } d r ^ { 2 } + \\Sigma d \\theta ^ { 2 } + \\left( r ^ { 2 } + a ^ { 2 } + \\frac { 2 a ^ { 2 } M r \\sin ^ { 2 } \\theta } { \\Sigma } \\right) \\sin ^ { 2 } \\theta d \\phi ^ { 2 } d s ^ { 2 } = - \\left( 1 - \\frac { 2 M r } { \\Sigma } \\right) d t ^ { 2 } - \\frac { 4 a M r \\sin ^ { 2 } \\theta } { \\Sigma } d t d \\phi + \\frac { \\Sigma } { \\Delta } d r ^ { 2 } + \\Sigma d \\theta ^ { 2 } + \\left( r ^ { 2 } + a ^ { 2 } + \\frac { 2 a ^ { 2 } M r \\sin ^ { 2 } \\theta } { \\Sigma } \\right) \\sin ^ { 2 } \\theta d \\phi ^ { 2 } where a \\equiv J / M , \\quad \\Delta \\equiv r ^ { 2 } - 2 M r + a ^ { 2 } , \\quad \\Sigma \\equiv r ^ { 2 } + a ^ { 2 } \\cos ^ { 2 } \\theta a \\equiv J / M , \\quad \\Delta \\equiv r ^ { 2 } - 2 M r + a ^ { 2 } , \\quad \\Sigma \\equiv r ^ { 2 } + a ^ { 2 } \\cos ^ { 2 } \\theta The horizon of the black hole is located at r_+ r_+ , the largest root of the equation \u2206 = 0 \u2206 = 0 , r _ { + } = M + \\left( M ^ { 2 } - a ^ { 2 } \\right) ^ { 1 / 2 } r _ { + } = M + \\left( M ^ { 2 } - a ^ { 2 } \\right) ^ { 1 / 2 } The static limit is the surface within which no static observers exist; it resides at r_0 r_0 , the largest root of g_{tt} = 0 g_{tt} = 0 : r _ { 0 } = M + \\left( M ^ { 2 } - a ^ { 2 } \\cos ^ { 2 } \\theta \\right) ^ { 1 / 2 } r _ { 0 } = M + \\left( M ^ { 2 } - a ^ { 2 } \\cos ^ { 2 } \\theta \\right) ^ { 1 / 2 } The region between the horizon and static limit is called the ergosphere; in this region all time-like observers are dragged around the hole with angular velocity \u03a9 > 0 \u03a9 > 0 .","title":"Kerr Black Holes"},{"location":"GR/#innermost-stable-circular-orbit","text":"The Innermost stable circular orbit (often called the ISCO ) is the smallest circular orbit in which a test particle can stably orbit a massive object in general relativity. The location of the ISCO, the ISCO-radius ( r_{isco} r_{isco} ), depends on the angular momentum (spin) of the central object. The ISCO plays an important role in black hole accretion disks since it marks the inner edge of the disk . For a non-spinning massive object, the ISCO is located at, r_{isco} = \\frac{6 G M}{c^2} = 3 R_S r_{isco} = \\frac{6 G M}{c^2} = 3 R_S For a rotating black holes","title":"Innermost stable circular orbit"},{"location":"GR/#global-theorems","text":"In an isolated system, the sum of the surface areas of all black holes can never decrease.","title":"Global Theorems"},{"location":"GR/#schwarzschild-black-hole","text":"The fact that the event horizon area cannot decrease motivates the definition of the irreducible mass M_{irr} = (\\frac{\\mathcal{A}}{16 \\pi})^{\\frac{1}{2}} M_{irr} = (\\frac{\\mathcal{A}}{16 \\pi})^{\\frac{1}{2}} The definition then implies that the irreducible mass of the black hole cannot decrease, which motivates its name. The area theorem can be used to place a strict upper limit on the amount of energy that is emitted in gravitational radiation in black hole collisions. Consider two widely separated, non-rotating black holes of masses M_1 M_1 and M_2 M_2 , initially at rest with respect to some distant observer. Use the area theorem to find an upper limit on the energy emitted in gravitational radiation that arises from the head-on collision of the two black holes. Verify that for equal mass black holes at most 29% of the total initial energy can be emitted in gravitational radiation.","title":"Schwarzschild black hole"},{"location":"GR/#kerr-black-holes_1","text":"Given the irreducible mass M_{irr} M_{irr} and the angular momentum J of an isolated, stationary black hole, we can compute the Kerr mass M ( = M_{ADM} = M_{ADM} ) from M^2 = M^2_{irr} + \\frac{1}{4} \\frac{J^2}{M^2_{irr}} M^2 = M^2_{irr} + \\frac{1}{4} \\frac{J^2}{M^2_{irr}} According to the area theorem, only the rotational energy contribution can be tapped as a source of energy by an external system interacting with the hole, since the irreducible mass can never decrease.","title":"Kerr black holes"},{"location":"GR/#weak-equivalence-principle","text":"We imagine that a body is made up of atoms, and that the inertial mass m\\_I m\\_I of an atom consists of the sum of all the mass and energy contributions of its constituents. But we suppose that the different forms of energy may contribute differently to the gravitational mass m\\_G m\\_G than they do to m\\_I m\\_I . One way to express this is to write m\\_G = m\\_I (1 + eta) m\\_G = m\\_I (1 + eta) , where eta eta is a dimensionless parameter that measures the difference. Because different forms of energy arising from the relevant subatomic interactions (such as electromagnetic and nuclear interactions) contribute different amounts to the total, depending on atomic structure, eta eta could depend on the type of atom.","title":"Weak Equivalence Principle"},{"location":"GR/#alternative-theories-of-gravity","text":"The simplest scenario that one could consider in this context is the addition of an extra scalar \ufb01eld, but one might also choose to consider extra vectors, tensors, or even higher rank fields. Of course, the effect of such additional \ufb01eld needs to be suppressed at scales where General Relativity has been well tested, such as in the lab or solar system 1 .","title":"Alternative Theories of Gravity"},{"location":"GR/#scalar-tensor-theories","text":"A general form of the scalar-tensor theory can be derived from the Lagrangian density $$ \\mathcal{L}=\\frac{1}{16 \\pi } \\sqrt{-g} \\left[ f\\left( \\phi \\right) R-g\\left( \\phi \\right) \\nabla {\\mu }\\phi \\nabla ^{\\mu }\\phi -2\\Lambda \\left( \\phi \\right) \\right] +\\mathcal{L} {m}\\left( \\psi ,h\\left( \\phi \\right) g_{\\mu \\nu}\\right) $$ \\mathcal{L}_m \\mathcal{L}_m is the Lagrangian density of the matter fields \\psi \\psi . Clifton, T., Ferreira, P. G., Padilla, A., & Skordis, C. (2011, June 14). Modified Gravity and Cosmology. arXiv.org. http://doi.org/10.1016/j.physrep.2012.01.001 \u21a9","title":"Scalar-Tensor Theories"},{"location":"NR/","text":"Numerical Relativity For all but the simplest systems, analytic solutions for the evolution of such systems do not exist . Hence the task of solving Einstein's equations must be performed numerically on a computer . In classical dynamics, the evolution of a system is uniquely determined by the initial positions and velocities of its constituents. By analogy, the evolution of general relativistic gravitational field is determined by specifying the metric quantities g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} at a given (initial) instant of time t . Now these metric quantities can be integrated forward in time provided we can obtain from the Einstein field equations expressions for \\partial^2_t g_{ab} \\partial^2_t g_{ab} at all points on the hypersurface . That way we can integrate these expressions to compute g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} on a new spacelike hypersurface at some new time t + \\delta t t + \\delta t , and then, by repeating the process, obtain g_{ab} g_{ab} for all other points x^0 x^0 and x^i x^i in the (future) spacetime. Complications The equations that arise in numerical relativity are typically multidimensional, nonlinear, coupled partial differential equations in space and time . They have in common with other areas of computational physics, like magnetohydrodynamics. However, solving Einstein\u2019s equations poses some additional complications that are unique to general relativity. In general relativity, coordinates are merely labels that distinguish points in spacetime; by themselves coordinate intervals have no physical significance. To use coordinate intervals to determine physically measurable proper distances and proper times requires the spacetime metric, but the metric is known only after Einstein\u2019s equations have been solved . Moreover, as the numerical integrations that determine the metric proceed, it often turns out that the original, arbitrary choice of coordinates turns out to be bad, because, for example, singularities appear in the equations. Encountering such singularities , be they physical or coordinate, results in some of the terms in Einstein\u2019s equations becoming infinite, potentially causing overflows in the computer output and premature termination of the numerical integration . Treating black holes is one of the main goals of numerical relativity, but this poses another complication. The reason is that black holes contain physical spacetime singularities \u2013 regions where the gravitational tidal field, the matter density and the spacetime curvature all become infinite. Thus, when dealing with black holes, it is crucial to choose a computational technique that avoids encountering their interior spacetime singularities in the course of the simulation . Another complication arises in the context of one of the most pressing goals of numerical relativity \u2013 the calculation of waveforms from promising astrophysical sources of gravitational radiation. These theoretical templates are essential for the identification and physical interpretation of gravitational wave sources. However, the gravitational wave components of the spacetime metric usually constitute small fractions of the smooth background metric. Moreover, to extract the waves from the background in a simulation requires that one probe the numerical spacetime in the far-field, or radiation, zone, which is typically at large distance from the strong-field central source. Yet it is the strong-field region which usually consumes most the computational resources (e.g. spatial resolution) to guarantee accuracy. Furthermore, waiting for the wave to propagate to the far-field region usually takes nonnegligible integration time. Oppenheimer-Snyder The Oppenheimer-Snyder, or OS, solution illustrates many generic features of gravitational collapse and black hole formation. Since the solution is analytic, it is simple to work with and is often used to test and calibrate numerical codes designed to deal with more complicated cases. 3+1 Decomposition Cauchy problem This is a fundamental problem arising in the mathematical theory of partial differential equations. The Bianchi identities \\nabla_b G^{ab} = 0 \\nabla_b G^{ab} = 0 give \\partial_t G^{a0} = - \\partial_i G^{ai} - G^{bc} \\Gamma^a_{bc} - G^{ab} \\Gamma^c_{bc} \\partial_t G^{a0} = - \\partial_i G^{ai} - G^{bc} \\Gamma^a_{bc} - G^{ab} \\Gamma^c_{bc} Since no term on the right hand side of equation contains third time derivatives or higher, the four quantities G^{a0} G^{a0} cannot contain second time derivatives. Hence the four equations G^{a0} = 8 \\pi T^{a0} G^{a0} = 8 \\pi T^{a0} do not furnish any of the information required for the dynamical evolution of the fields. Rather, they supply four constraints on the initial data, i.e. four relations between g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} on the initial hypersurface at x^0 = t x^0 = t . The only truly dynamical equations must be provided by the six remaining relations G^{ij} = 8 \\pi T^{ij} G^{ij} = 8 \\pi T^{ij} It is not surprising that there is a mismatch between the required number (10) of second time 2 derivatives \\partial_t^2 g_{ab} \\partial_t^2 g_{ab} and the available number (6) of dynamical \ufb01eld equations. After all, there is always a fourfold ambiguity associated with the freedom to choose four different coordinates to label points in spacetime. So, for example, we could always choose Gaussian normal coordinates and set $g_{00} = \u22121 $ and g_{0i} = 0 g_{0i} = 0 . The Cauchy problem in general relativity logically involves a decomposition of four-dimensional spacetime into three dimensional space and one-dimensional time . Cauchy surface Cauchy surface is a plane in space-time which is like an instant of time; its significance is that giving the initial conditions on this plane determines the future (and the past) uniquely. The 3+1 equations are entirely equivalent to the usual \ufb01eld equations but they focus on the evolution of 12 purely spatial quantities closely related to g_{ij} g_{ij} and \\partial_t g_{ij} \\partial_t g_{ij} and the constraints that they must satisfy on spatial hypersurfaces. Once these spatial \ufb01eld quantities are specified on some initial \u201ctime slice\u201d (i.e. spatial hypersurface) consistent with the 3 + 1 constraint equations, the 3 + 1 evolution equations can then be integrated, together with evolution equations for the matter sources, to determine these \ufb01eld quantities at all later times. The 3+1 formalism 4 constraint equations that contain no time derivatives but provide relations between the spatial \ufb01eld quantities and their matter sources that must be satis\ufb01ed on any time slice. A convenient set of 12 coupled, first-order, time-evolution equations for the spatial \ufb01eld variables in terms of \ufb01eld and source quantities residing on the slice. Analogy Maxwell\u2019s equations \\begin{array} { l } { D _ { i } E ^ { i } - 4 \\pi \\rho = 0 } \\\\ D _ { i } B ^ { i } = 0 \\end{array} \\begin{array} { l } { D _ { i } E ^ { i } - 4 \\pi \\rho = 0 } \\\\ D _ { i } B ^ { i } = 0 \\end{array} The above equations involve only spatial derivatives of the electric and magnetic fields and hold at each instant of time independently of the prior or subsequent evolution of the fields. They therefore constrain any possible configurations of the fields, and are correspondingly called the constraint equations. \\begin{aligned} \\partial _ { t } E _ { i } & = \\epsilon _ { i j k } D ^ { j } B ^ { k } - 4 \\pi j _ { i } \\\\ \\partial _ { t } B _ { i } & = - \\epsilon _ { i j k } D ^ { j } E ^ { k } \\end{aligned} \\begin{aligned} \\partial _ { t } E _ { i } & = \\epsilon _ { i j k } D ^ { j } B ^ { k } - 4 \\pi j _ { i } \\\\ \\partial _ { t } B _ { i } & = - \\epsilon _ { i j k } D ^ { j } E ^ { k } \\end{aligned} These equations describe how the fields evolve forward in time, and are therefore called the evolution equations. To completely determine the time evolution of the electromagnetic fields we also have to specify how the sources \u03c1 and j^i j^i evolve according to the net force acting on them. It is possible to bring Maxwell\u2019s equations into a form that is closer to the 3+1 form of Einstein\u2019s equations. To do so, we introduce the vector potential A ^ { a } = \\left( \\Phi , A ^ { i } \\right) A ^ { a } = \\left( \\Phi , A ^ { i } \\right) and write B^i B^i as B _ { i } = \\epsilon _ { i j k } D ^ { j } A ^ { k } B _ { i } = \\epsilon _ { i j k } D ^ { j } A ^ { k } By construction, B_i B_i automatically satisfies the constraint D _ { i } B ^ { i } = 0 D _ { i } B ^ { i } = 0 . The two evolution equations can be rewritten in terms of E_i E_i and A_i A_i \\begin{aligned} \\partial _ { t } A _ { i } & = - E _ { i } - D _ { i } \\Phi \\\\ \\partial _ { t } E _ { i } & = D _ { i } D ^ { j } A _ { j } - D ^ { j } D _ { j } A _ { i } - 4 \\pi j _ { i } \\end{aligned} \\begin{aligned} \\partial _ { t } A _ { i } & = - E _ { i } - D _ { i } \\Phi \\\\ \\partial _ { t } E _ { i } & = D _ { i } D ^ { j } A _ { j } - D ^ { j } D _ { j } A _ { i } - 4 \\pi j _ { i } \\end{aligned} With the vector potential A_i A_i we have introduced a gauge freedom into electrodynamics which is expressed in the freely specifiable gauge variable \u03a6 \u03a6 . The initial value problem in electrodynamics can now be solved in two steps. In the first step, initial data ( A_i A_i , E_i E_i ), together with the sources (\u03c1, j_i j_i ), are specified that satisfy the constraint equations. In the second step, these fields are evolved according to the evolution equations. Before the evolution equations can be solved, a suitable gauge condition has to be chosen . The standard 3 + 1 equations are sometimes referred to as the \u201cADM equations\u201d. Einstein\u2019s equations can be split into a set of constraint and evolution equations To specify gravitational fields (\\gamma_{ij}, K_{ij}) (\\gamma_{ij}, K_{ij}) on some initial spatial slice \u03a3 . These fields can then be used as \u201cstarting values\u201d. the spatial metric \\gamma_{ij} \\gamma_{ij} , the extrinsic curvature K_{ij} K_{ij} and any matter fields have to satisfy the the constraint equations. Contracting Gauss\u2019 equation $$ R + K^2 - K_{ij}K^{ij} = 16 \\pi \\rho $$ Contracting the Codazzi equation $$ D_j (K^{ij} - \\gamma^{ij} K) = 8 \\pi S^i $$ The constraint equations contain no time derivatives and relate \ufb01eld quantities on a given t = constant spacelike hypersurface. The evolution equations contain first-order time derivatives that tell us how the \ufb01eld quantities change from one hypersurface to the next. If the \ufb01eld data (\\gamma_{ij}, K_{ij}) (\\gamma_{ij}, K_{ij}) satisfy the constraints at some time t and are evolved with the evolution equations, then the data will also satisfy the constraint equations at all later times. The goal of achieving numerically stable computer solutions , especially when the absence of spatial symmetries requires us to work in all three spatial dimensions, has led to alternative formulations and to crucial modi\ufb01cations of the standard 3 + 1 equations . Foliations of Spacetime We assume that the spacetime (M, g_{ab}) (M, g_{ab}) can be foliated into a family of non-intersecting spacelike three-surfaces \u03a3, which arise, at least locally, as the level surfaces of a scalar function t that can be interpreted as a global time function. From t we can define the 1-form \\Omega _ { a } = \\nabla _ { a } t \\Omega _ { a } = \\nabla _ { a } t which is closed by construction, \\nabla _ { [ a } \\Omega _ { b ] } = \\nabla _ { [ a } \\nabla _ { b ] } t = 0 \\nabla _ { [ a } \\Omega _ { b ] } = \\nabla _ { [ a } \\nabla _ { b ] } t = 0 The 4-metric g_{ab} g_{ab} allows us to compute the norm of \\tilde{\u03a9} \\tilde{\u03a9} \udbff\udc1e, which we call - \\alpha ^ { - 2 } - \\alpha ^ { - 2 } \\| \\Omega \\| ^ { 2 } = g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t \\equiv - \\frac { 1 } { \\alpha ^ { 2 } } \\| \\Omega \\| ^ { 2 } = g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t \\equiv - \\frac { 1 } { \\alpha ^ { 2 } } \u03b1 \u03b1 measures how much proper time elapses between neighboring time slices along the normal vector \u03a9^a \u03a9^a to the slice, and is therefore called the lapse function. We assume that \u03b1 > 0 \u03b1 > 0 , so that \u03a9^a \u03a9^a is timelike and the hypersurface \u03a3 is spacelike everywhere. We can now define the unit normal to the slices as n ^ { a } \\equiv - g ^ { a b } \\alpha \\Omega _ { b } n ^ { a } \\equiv - g ^ { a b } \\alpha \\Omega _ { b } Here the negative sign has been chosen so that n^a n^a points in the direction of increasing t, and may therefore be thought of as the four-velocity of a \u201cnormal\u201d observer whose worldline is always normal to the spatial slices \u03a3. The spatial metric \\gamma_{ab} \\gamma_{ab} With the normal vector we can construct the spatial metric \\gamma_{ab} \\gamma_{ab} that is induced by g_{ab} g_{ab} on the three-dimensional hypersurfaces \u03a3 \\gamma_{ab} = g_{ab} + n_a n_b \\gamma_{ab} = g_{ab} + n_a n_b Thus \\gamma_{ab} \\gamma_{ab} is a projection tensor that projects out all geometric objects lying along n^a n^a . This metric allows us to compute distances within a slice \u03a3. To see that \u03b3_{ab} \u03b3_{ab} is purely spatial, i.e., resides entirely in \u03a3 with no piece along n^a n^a , we contract it with the normal n^a n^a , n ^ { a } \\gamma _ { a b } = n ^ { a } g _ { a b } + n ^ { a } n _ { a } n _ { b } = n _ { b } - n _ { b } = 0 n ^ { a } \\gamma _ { a b } = n ^ { a } g _ { a b } + n ^ { a } n _ { a } n _ { b } = n _ { b } - n _ { b } = 0 We break up 4-dimensional tensors by decomposing them into a purely spatial part, which lies in the hypersurfaces \\Sigma \\Sigma , and a timelike part, which is normal to the spatial surface. To do so, we need two projection operators. The first one, which projects a 4-dimensional tensor into a spatial slice \\gamma^a_{\\space b} = g^a_{\\space b} + n^a n_b \\gamma^a_{\\space b} = g^a_{\\space b} + n^a n_b Similarly, we may define the normal projection operator as N^a_{\\space b} = - n^a n_b N^a_{\\space b} = - n^a n_b We can now use these two projection operators to decompose any tensor into its spatial and timelike parts. The three-dimensional metric only contains information about the curvature intrinsic to a slice \u03a3 , but it gives no information about what shape this slice takes in the spacetime M in which it is embedded. This information is contained in a tensor called extrinsic curvature . The three-dimensional covariant derivative can be expressed in terms of three-dimensional connection coefficients, which, in a coordinate basis, are given by \\Gamma _ { b c } ^ { a } = \\frac { 1 } { 2 } \\gamma ^ { a d } \\left( \\partial _ { c } \\gamma _ { d b } + \\partial _ { b } \\gamma _ { d c } - \\partial _ { d } \\gamma _ { b c } \\right) \\Gamma _ { b c } ^ { a } = \\frac { 1 } { 2 } \\gamma ^ { a d } \\left( \\partial _ { c } \\gamma _ { d b } + \\partial _ { b } \\gamma _ { d c } - \\partial _ { d } \\gamma _ { b c } \\right) The three-dimensional Riemann tensor can be computed from R _ { a b c } ^ { d } = \\partial _ { b } \\Gamma _ { a c } ^ { d } - \\partial _ { a } \\Gamma _ { b c } ^ { d } + \\Gamma _ { a c } ^ { e } \\Gamma _ { e b } ^ { d } - \\Gamma _ { b c } ^ { e } \\Gamma _ { e a } ^ { d } R _ { a b c } ^ { d } = \\partial _ { b } \\Gamma _ { a c } ^ { d } - \\partial _ { a } \\Gamma _ { b c } ^ { d } + \\Gamma _ { a c } ^ { e } \\Gamma _ { e b } ^ { d } - \\Gamma _ { b c } ^ { e } \\Gamma _ { e a } ^ { d } The three-dimensional curvature R _ { b c d } ^ { a } R _ { b c d } ^ { a } only contains information about the curvature intrinsic to a slice \u03a3, but it gives no information about what shape this slice takes in the spacetime M in which it is embedded. The Extrinsic Curvature K_{ab} K_{ab} The extrinsic curvature K_{ab} K_{ab} can be found by projecting gradients of the normal vector into the slice \u03a3 . The metric and the extrinsic curvature (\\gamma_{ab}, K_{ab}) (\\gamma_{ab}, K_{ab}) can therefore be considered as the equivalent of positions and velocities in classical mechanics \u2013 they measure the \u201cinstantaneous\u201d state of the gravitational \ufb01eld, and form the fundamental variables in our initial value formulation. We now define the extrinsic curvature, K_{ab} K_{ab} , as the negative expansion K_{ab} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_{(c} n_{d)} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d K_{ab} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_{(c} n_{d)} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d By definition, the extrinsic curvature is symmetric and purely spatial. they can only differ in the direction in which they are pointing, and the extrinsic curvature therefore provides information on how much this direction changes from point to point across a spatial hypersurface. As a consequence, the extrinsic curvature measures the rate at which the hypersurface deforms as it is carried forward along a normal. Finally, we can write the extrinsic curvature as K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} where L_n L_n denotes the Lie derivative along n^a n^a . Since n^a n^a is a timelike vector, equation illustrates the intuitive interpretation of the extrinsic curvature as a geometric generalization of the \u201ctime derivative\u201d of the spatial metric \\gamma_{ab} \\gamma_{ab} . Proof: \\gamma_{ab} \\gamma_{ab} changes proportionally to K_{ab} K_{ab} \\begin{align} K_{ab} &= - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d = - (\\delta_a^{\\space c} + n_a n^c) (\\delta_b^{\\space d} + n_b n^d) \\nabla_c n_d \\\\ &= -(\\delta_a^{\\space c} + n_a n^c) \\delta_b^{\\space d} \\nabla_c n_d = - \\nabla_a n_b - n_a a_b \\\\ \\mathcal{L}_n \\gamma_{ab} &= \\mathcal{L}_n (g_{ab} + n_a n_b) = 2 \\nabla_{(a} n_{b)} + n_a \\mathcal{L}_n n_b + n_b \\mathcal{L}_n n_a \\\\ &= 2 (\\nabla_{(a} n_{b)} - n_{(a} a_{b)}) \\\\ \\mathcal{L}_n \\gamma_{ab} &= - 2 K_{ab} \\end{align} \\begin{align} K_{ab} &= - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d = - (\\delta_a^{\\space c} + n_a n^c) (\\delta_b^{\\space d} + n_b n^d) \\nabla_c n_d \\\\ &= -(\\delta_a^{\\space c} + n_a n^c) \\delta_b^{\\space d} \\nabla_c n_d = - \\nabla_a n_b - n_a a_b \\\\ \\mathcal{L}_n \\gamma_{ab} &= \\mathcal{L}_n (g_{ab} + n_a n_b) = 2 \\nabla_{(a} n_{b)} + n_a \\mathcal{L}_n n_b + n_b \\mathcal{L}_n n_a \\\\ &= 2 (\\nabla_{(a} n_{b)} - n_{(a} a_{b)}) \\\\ \\mathcal{L}_n \\gamma_{ab} &= - 2 K_{ab} \\end{align} Riemann Tensor The metric \\gamma_{ab} \\gamma_{ab} and the extrinsic curvature K_{ab} K_{ab} cannot be chosen arbitrarily. Instead, they have to satisfy certain constraints . In order to find these relations, we have to relate the three-dimensional Riemann tensor R^a_{\\space bcd} R^a_{\\space bcd} of the the hypersurfaces \u03a3 to the four-dimensional Riemann tensor ^{(4)} R^a_{\\space bcd} ^{(4)} R^a_{\\space bcd} of M. To do so, we first take a completely spatial projection of ^{(4)} R^a_{\\space bcd} ^{(4)} R^a_{\\space bcd} , then a projection with one index projected in the normal direction, and finally a projection with two indices projected in the normal direction. All other projections vanish identically because of the symmetries of the Riemann tensor. A decomposition of ^{(4)} R^a_{\\space bcd} ^{(4)} R^a_{\\space bcd} into spatial and normal pieces therefore involves these three different types of projections . \\begin{align} ^{(4)} R_{abcd} &= \\gamma_a^{\\space p} \\gamma_b^{\\space q} \\gamma_c^{\\space r} \\gamma_d^{\\space s} {}^{(4)} R_{pqrs} - 2 \\gamma_a^{\\space p} \\gamma_b^{\\space q} \\gamma_{[c}^{\\space r} n_{d]} n^s {}^{(4)} R_{pqrs} \\\\ &- 2 \\gamma_c^{\\space p} \\gamma_d^{\\space q} \\gamma_{[a}^{\\space r} n_{b]} n^s {}^{(4)} R_{pqrs} + 2 \\gamma_a^{\\space p} \\gamma_{[c}^{\\space r} n_{d]} n_b n^q n^s {}^{(4)} R_{pqrs} \\\\ &- 2 \\gamma_b^{\\space p} \\gamma_{[c}^{\\space r} n_{d]} n_a n^q n^s {}^{(4)} R_{pqrs} \\end{align} \\begin{align} ^{(4)} R_{abcd} &= \\gamma_a^{\\space p} \\gamma_b^{\\space q} \\gamma_c^{\\space r} \\gamma_d^{\\space s} {}^{(4)} R_{pqrs} - 2 \\gamma_a^{\\space p} \\gamma_b^{\\space q} \\gamma_{[c}^{\\space r} n_{d]} n^s {}^{(4)} R_{pqrs} \\\\ &- 2 \\gamma_c^{\\space p} \\gamma_d^{\\space q} \\gamma_{[a}^{\\space r} n_{b]} n^s {}^{(4)} R_{pqrs} + 2 \\gamma_a^{\\space p} \\gamma_{[c}^{\\space r} n_{d]} n_b n^q n^s {}^{(4)} R_{pqrs} \\\\ &- 2 \\gamma_b^{\\space p} \\gamma_{[c}^{\\space r} n_{d]} n_a n^q n^s {}^{(4)} R_{pqrs} \\end{align} The above projections give rise to the equations of Gauss, Codazzi and Ricci. Gauss\u2019 equation and Codazzi equations give rise to the \u201cconstraint\u201d equations. Gauss\u2019 equation a completely spatial projection. R_{abcd} + K_{ac} K_{bd} -K_{ad} K_{cb} = \\gamma^P_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} \\gamma^s_{\\space d} {}^{(4)} R_{pqrs} R_{abcd} + K_{ac} K_{bd} -K_{ad} K_{cb} = \\gamma^P_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} \\gamma^s_{\\space d} {}^{(4)} R_{pqrs} Codazzi equation R^a_{\\space bcd} R^a_{\\space bcd} with one index projected in the normal direction. D_b K_{ac} - D_a K_{bc} = \\gamma^P_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} n^s_{\\space d} {}^{(4)} R_{pqrs} D_b K_{ac} - D_a K_{bc} = \\gamma^P_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} n^s_{\\space d} {}^{(4)} R_{pqrs} Constraint equations We can rewrite Einstein\u2019s \ufb01eld equations in a 3+1 form. Basically, we just need to take the equations of Gauss, Codazzi and Ricci and eliminate the four-dimensional Rieman tensor using Einstein\u2019s equations. G_{ab} = {}^{(4)} R_{ab} - \\frac{1}{2} {}^{(4)} R g_{ab} = 8 \\pi T_{ab} G_{ab} = {}^{(4)} R_{ab} - \\frac{1}{2} {}^{(4)} R g_{ab} = 8 \\pi T_{ab} We will first derive the constraint equations from Gauss\u2019 equation and the Codazzi equation. Contracting Gauss\u2019 equation R + K^2 - K_{ab}K^{ab} = 16 \\pi \\rho R + K^2 - K_{ab}K^{ab} = 16 \\pi \\rho We now define the energy density \u03c1 to be the total energy density as measured by a normal observer n^a n^a , \\rho = n_a n_b T^{ab} \\\\ 2 n^p n^r G_{pr} = R + K^2 - K_{ab} K^{ab} \\rho = n_a n_b T^{ab} \\\\ 2 n^p n^r G_{pr} = R + K^2 - K_{ab} K^{ab} Contracting the Codazzi equation $$ D_b K^b_{\\space a} - D_a K = 8 \\pi S_a $$ We now define S_a S_a to be the momentum density as measured by a normal observer n^a n^a , S_a = - \\gamma^b_{\\space a} n^c T_{bc} \\\\ D_b K^b_{\\space a} - D_a K = - \\gamma^q_{\\space a} n^s G_{qs} S_a = - \\gamma^b_{\\space a} n^c T_{bc} \\\\ D_b K^b_{\\space a} - D_a K = - \\gamma^q_{\\space a} n^s G_{qs} They are the conditions that allow a three-dimensional slice \u03a3 with data (\\gamma_{ab}, K_{ab}) (\\gamma_{ab}, K_{ab}) to be embedded in a four-dimensional manifold M with data g_{ab} g_{ab} . We will discuss strategies for solving the constraint equations and finding initial data that represent a snapshot of the gravitational fields at a certain instant of time. The four constraint equations cannot determine all of the gravitational fields (\\gamma_{ij}, K_{ij}) (\\gamma_{ij}, K_{ij}) . Both \\gamma_{ij} \\gamma_{ij} and K_{ij} K_{ij} are symmetric, three-dimensional tensors, they together have twelve independent components . The four constraint equations can only determine four of these Four undetermined functions are related to coordinate choices Two independent sets of values for the conjugate pair (\\gamma_{ij}, K_{ij}) (\\gamma_{ij}, K_{ij}) . Two dynamical degrees of freedom correspond to the two polarization modes of a gravitational wave It is quite intuitive that the state of a dynamical field, like a gravitational wave, cannot be determined from constraint equations . Waves satisfy hyperbolic equations, and their state at any time depends on their past history. It is therefore natural that the constraint equations serve to constrain only the \u201clongitudinal\u201d parts of the fields, while the \u201ctransverse\u201d parts, related to the dynamical degrees of freedom, remain freely specifiable. Ideally one would like to separate unambiguously the longitudinal from the transverse parts of the fields at some initial time, freely specifying the latter and then solving the constraints for the former. Given the nonlinear nature of general relativity such a rigorous separation is not possible; instead, all these fields are entangled in the spatial metric and the extrinsic curvature. Constraint equations constrain the fields in space at one instant of time, independently of their past history. Analogy Electric Field Maxwell\u2019s equations also split into constraint and evolution equations. The constraint equations have to be satis\ufb01ed by any electric and magnetic \ufb01eld at each instant of time, but they are not sufficient to completely determine these fields. Consider the equation for the electric field \\vec{E} \\vec{E} , \\nabla \\cdot \\vec{E} = 4 \\pi \\rho \\nabla \\cdot \\vec{E} = 4 \\pi \\rho Given an electrical charge density \u03c1, we can solve this equation for one of the components of E^i E^i , but not all three of them. For example, we could make certain choices for E^x E^x and E^y E^y , and then solve for E^z E^z , even though we might be troubled by the asymmetry in singling out one particular component in this approach. Alternatively, we may prefer to write E^i E^i as some \u201cbackground\u201d field \\bar { E } ^ { i } \\bar { E } ^ { i } times some overall scaling factor, say \u03c8^4 \u03c8^4 E ^ { i } = \\psi ^ { 4 } \\bar { E } ^ { i } E ^ { i } = \\psi ^ { 4 } \\bar { E } ^ { i } make certain choices for all three components of the background field \\bar { E } ^ { i } \\bar { E } ^ { i } , and then solve for the scaling factor \u03c8^4 \u03c8^4 . Though it might not be so useful for treating Maxwell\u2019s equations, such an approach leads to a very convenient and tractable system for Einstein\u2019s equations. Conformal Transformations Conformal Transformation of the Spatial Metric We begin by writing the spatial metric \\gamma_{ij} \\gamma_{ij} as a product of some power of a positive scaling factor \u03c8 and a background metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} , \\gamma_{ij} = \u03c8^4 \\bar{\\gamma}_{ij} \\gamma_{ij} = \u03c8^4 \\bar{\\gamma}_{ij} This identification is a conformal transformation of the spatial metric. We call \u03c8 the conformal factor , and \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} the conformally related metric . Taking \u03c8 to the fourth power turns out to be convenient, but is otherwise arbitrary. Loosely speaking, the conformal factor absorbs the overall scale of the metric, which leaves five degrees of freedom in the conformally related metric . Superficially, the conformal transformation is just a mathematical trick , namely, rewriting one unknown as a product of two unknowns in order to make solving some equations easier. The inverse of \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} : \\gamma ^ { i j } = \\psi ^ { - 4 } \\bar { \\gamma } ^ { i j } \\gamma ^ { i j } = \\psi ^ { - 4 } \\bar { \\gamma } ^ { i j } In three dimensions, the connection coefficients must transform according to \\Gamma _ { j k } ^ { i } = \\bar { \\Gamma } _ { j k } ^ { i } + 2 \\left( \\delta _ { j } ^ { i } \\bar { D } _ { k } \\ln \\psi + \\delta _ { k } ^ { i } \\bar { D } _ { j } \\ln \\psi - \\bar { \\gamma } _ { j k } \\bar { \\gamma } ^ { i l } \\bar { D } _ { l } \\ln \\psi \\right) \\Gamma _ { j k } ^ { i } = \\bar { \\Gamma } _ { j k } ^ { i } + 2 \\left( \\delta _ { j } ^ { i } \\bar { D } _ { k } \\ln \\psi + \\delta _ { k } ^ { i } \\bar { D } _ { j } \\ln \\psi - \\bar { \\gamma } _ { j k } \\bar { \\gamma } ^ { i l } \\bar { D } _ { l } \\ln \\psi \\right) For the scalar curvature R = \\psi ^ { - 4 } \\bar { R } - 8 \\psi ^ { - 5 } \\bar { D } ^ { 2 } \\psi R = \\psi ^ { - 4 } \\bar { R } - 8 \\psi ^ { - 5 } \\bar { D } ^ { 2 } \\psi Inserting the scalar curvature into the Hamiltonian constraint yields 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { 5 } K _ { i j } K ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { 5 } K _ { i j } K ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho which, for a given choice of the conformally related metric \\bar { \\gamma } ^ { i j } \\bar { \\gamma } ^ { i j } , we may interpret as an equation for the conformal factor \u03c8. The extrinsic curvature K_{ij} K_{ij} has to satisfy the momentum constraint, and it will be useful to rescale K_{ij} K_{ij} conformally as well. Conformal transformation of the extrinsic curvature We have conformally transformed the spatial metric, but before we proceed we also have to decompose the extrinsic curvature. It is convenient to split K_{ij} K_{ij} into its trace K and a traceless part A_{ij} A_{ij} according to K_{ij} = A_{ij} + \\frac{1}{3} \\gamma_{ij} K K_{ij} = A_{ij} + \\frac{1}{3} \\gamma_{ij} K and to conformally transform K and A_{ij} A_{ij} separately. A priori it is not clear how to transform K and A_{ij} A_{ij} , and our only guidance for inventing rules is that the transformation should bring the constraint equations into a simple and solvable form. Consider the transformations \\begin{aligned} A ^ { i j } & = \\psi ^ { \\alpha } \\bar { A } ^ { i j } \\\\ K & = \\psi ^ { \\beta } \\bar { K } \\end{aligned} \\begin{aligned} A ^ { i j } & = \\psi ^ { \\alpha } \\bar { A } ^ { i j } \\\\ K & = \\psi ^ { \\beta } \\bar { K } \\end{aligned} where \u03b1 and \u03b2 are two so far undetermined exponents. Inserting the above expressions into the momentum constraint (the choice \u03b1 = \u221210 \u03b1 = \u221210 ) yields \\psi ^ { - 10 } \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { \\beta - 4 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\bar { K } - \\frac { 2 } { 3 } \\beta \\psi ^ { \\beta - 5 } \\bar { K } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\psi = 8 \\pi S ^ { i } \\psi ^ { - 10 } \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { \\beta - 4 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\bar { K } - \\frac { 2 } { 3 } \\beta \\psi ^ { \\beta - 5 } \\bar { K } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\psi = 8 \\pi S ^ { i } Our desire to simplify equations motivates the choice \u03b2 = 0 \u03b2 = 0 , so that we treat K as a conformal invariant, K = \\bar{K} K = \\bar{K} . With these choices, the Hamiltonian constraint now becomes 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\frac { 2 } { 3 } \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { - 7 } \\bar { A } _ { i j } \\bar { A } ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\frac { 2 } { 3 } \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { - 7 } \\bar { A } _ { i j } \\bar { A } ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho and the momentum constraint is \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { 6 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } K = 8 \\pi \\psi ^ { 10 } S ^ { i } \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { 6 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } K = 8 \\pi \\psi ^ { 10 } S ^ { i } In addition to the spatial metric and extrinsic curvature, it may also be necessary to transform the matter sources \u03c1 and S^i S^i to insure uniqueness of solutions. We start by considering the linear equation \\nabla ^ { 2 } u = f u \\nabla ^ { 2 } u = f u on some domain \u03a9. Here f is some given function, and we will assume u = 0 u = 0 on the boundary \u2202\u03a9 \u2202\u03a9 . If f is non-negative everywhere, we can apply the maximum principle to show that u = 0 everywhere. The point is that if u were non-zero somewhere in \u03a9, say positive, then it must have a maximum somewhere. At the maximum the left hand side of (3.40) must be negative, but the right hand side is non-negative if f \u2265 0 f \u2265 0 , which is a contradiction. Clearly, the argument works the same way if u is negative somewhere, implying that u = 0 u = 0 everywhere if f \u2265 0 f \u2265 0 . Now consider the non-linear equation \\nabla ^ { 2 } u = f u ^ { n } \\nabla ^ { 2 } u = f u ^ { n } and assume there exist two positive solutions u_1 u_1 and u_2 \u2265 u_1 u_2 \u2265 u_1 that are identical, u_1 = u_2 u_1 = u_2 , on the boundary \u2202\u03a9 \u2202\u03a9 . The difference \u2206u = u_2 \u2212 u_1 \u2206u = u_2 \u2212 u_1 must then satisfy an equation \\nabla ^ { 2 } \\Delta u = n f \\tilde { u } ^ { n - 1 } \\Delta u \\nabla ^ { 2 } \\Delta u = n f \\tilde { u } ^ { n - 1 } \\Delta u where \\tilde { u } \\tilde { u } is some positive function satisfying u_1 \u2264 \\tilde{u} \u2264 u_2 u_1 \u2264 \\tilde{u} \u2264 u_2 . Applying the above argument to \u2206u \u2206u , we see that the maximum principle implies \u2206u = 0 \u2206u = 0 and hence uniqueness of solutions if and only if nf \u2265 0 nf \u2265 0 , i.e. if the coefficient and exponent in the source term have the same sign. Inspecting the Hamiltonian constraint we see that the matter term \u221216 \u03c0 \u03c8^5 \u03c1 \u221216 \u03c0 \u03c8^5 \u03c1 features the \u201cwrong signs\u201d: it has a negative coefficient (assuming a positive matter density \u03c1), but a positive exponent for \u03c8. Therefore the maximum principle cannot be applied, and the uniqueness of solutions cannot be established. Uniqueness of solutions can be restored, however, by introducing a conformal rescaling of the density. With \\rho = \\psi ^ { \\delta } \\bar { \\rho } \\rho = \\psi ^ { \\delta } \\bar { \\rho } , where \u03b4 \u2264 \u22125 \u03b4 \u2264 \u22125 and where \\bar{\u03c1} \\bar{\u03c1} is now considered a given function, the matter term carries the \u201cright signs\u201d, and the maximum principle can be applied to establish the uniqueness of solutions. Conformal Transverse-Traceless Decomposition Any symmetric, traceless tensor can be split into a transverse-traceless part that is divergenceless and a longitudinal part that can be written as a symmetric, traceless gradient of a vector. We can therefore decompose \\bar{A}^{ij} \\bar{A}^{ij} as \\bar { A } ^ { i j } = \\bar { A } _ { T T } ^ { i j } + \\bar { A } _ { L } ^ { i j } \\bar { A } ^ { i j } = \\bar { A } _ { T T } ^ { i j } + \\bar { A } _ { L } ^ { i j } where the transverse part is divergenceless \\bar { D } _ { j } \\bar { A } _ { T T } ^ { i j } = 0 \\bar { D } _ { j } \\bar { A } _ { T T } ^ { i j } = 0 and where the longitudinal part satisfies \\bar { A } _ { L } ^ { i j } = \\bar { D } ^ { i } W ^ { j } + \\bar { D } ^ { j } W ^ { i } - \\frac { 2 } { 3 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { k } W ^ { k } \\equiv ( \\bar { L } W ) ^ { i j } \\bar { A } _ { L } ^ { i j } = \\bar { D } ^ { i } W ^ { j } + \\bar { D } ^ { j } W ^ { i } - \\frac { 2 } { 3 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { k } W ^ { k } \\equiv ( \\bar { L } W ) ^ { i j } Here W^i W^i is a vector potential, and it is easy to see that the longitudinal operator or vector gradient \\bar{L} \\bar{L} produces a symmetric, traceless tensor. We can now write the divergence of \\bar{A}^{ij} \\bar{A}^{ij} as \\bar { D } _ { j } A ^ { i j } = \\bar { D } _ { j } A _ { L } ^ { i j } = \\bar { D } _ { j } ( \\bar { L } W ) ^ { i j } = \\bar { D } ^ { 2 } W ^ { i } + \\frac { 1 } { 3 } \\bar { D } ^ { i } \\left( \\bar { D } _ { j } W ^ { j } \\right) + \\bar { R } _ { j } ^ { i } W ^ { j } \\equiv \\left( \\bar { \\Delta } _ { L } W \\right) ^ { i } \\bar { D } _ { j } A ^ { i j } = \\bar { D } _ { j } A _ { L } ^ { i j } = \\bar { D } _ { j } ( \\bar { L } W ) ^ { i j } = \\bar { D } ^ { 2 } W ^ { i } + \\frac { 1 } { 3 } \\bar { D } ^ { i } \\left( \\bar { D } _ { j } W ^ { j } \\right) + \\bar { R } _ { j } ^ { i } W ^ { j } \\equiv \\left( \\bar { \\Delta } _ { L } W \\right) ^ { i } where \\bar{\u2206}_L \\bar{\u2206}_L is the vector Laplacian. Note that \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} and \\bar{A}^{ij}_{L} \\bar{A}^{ij}_{L} are transverse and longitudinal with respect to the conformal metric \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} , which is why this decomposition is called the conformal transverse-traceless decomposition. Alternatively one can also adopt a physical transverse-traceless decomposition, where the corresponding tensors are transverse and longitudinal with respect to the physical metric \u03b3_{ij} \u03b3_{ij} . We started out with six independent variables in both the spatial metric \\gamma_{ij} \\gamma_{ij} and the extrinsic curvature K_{ij} K_{ij} . Splitting o\ufb00 the conformal factor \u03c8 left five degrees of freedom in the conformally related metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} (once we have specified its determinant \\bar{\\gamma} \\bar{\\gamma} ). Of the six independent variables in K_{ij} K_{ij} we moved one into its trace K, two into \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} (which is symmetric, traceless, and divergenceless), and three into \\bar{A}^{ij}_L \\bar{A}^{ij}_L (which is reflected in its representation by a vector). Of the twelve original degrees of freedom, the constraint equations determine only four, namely the conformal factor \u03c8 (Hamiltonian constraint) and the longitudinal part of the traceless extrinsic curvature \\bar{A}^{ij}_L \\bar{A}^{ij}_L (momentum constraint). Four of the remaining eight degrees of freedom are associated with the coordinate freedom - three spatial coordinates hidden in the spatial metric and a time coordinate that is associated with K. This leaves four physical degrees of freedom undetermined - two in the conformally related metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} , and two in the transverse part of traceless extrinsic curvature \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} . These two freely specifiable degrees of freedom carry the dynamical degrees of freedom of the gravitational fields. All others are either fixed by the constraint equations or represent coordinate freedom. We have reduced the Hamiltonian and momentum constraint to equations for the conformal factor \u03c8 and the vector potential W^i W^i , from which the longitudinal part of the extrinsic curvature is constructed. These quantities can be solved for only after choices have been made for the remaining quantities in the equations, namely the conformally related metric \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} , the transverse-traceless part of the extrinsic curvature \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} , the trace of the extrinsic curvature K, and, if present, any matter sources. The choice of these background data has to be made in accordance with the physical or astrophysical situation that one wants to represent. Physically, the choice affects the gravitational wave content present in the initial data, in the sense that a dynamical evolution of data constructed with different background data leads to different amounts of emitted gravitational radiation. It is often not clear how a suitable background can be constructed precisely, and we will return to this issue on several occasions. Given its loose association with the transverse parts of the gravitational fields, one often sets \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} equal to zero in an attempt to minimize the gravitational wave content in the initial data. Conformal Transformations of Black Hole Solutions It is instructive to consider some simple, but physically interesting, solutions to the constraint equation. Consider vacuum solutions for which the matter source terms vanish (\u03c1 = 0 = S^i) (\u03c1 = 0 = S^i) and focus on a \u201cmoment of time symmetry\u201d. At a moment of time symmetry, all time derivatives of \u03b3_{ij} \u03b3_{ij} are zero and the 4\u2212dimensional line interval has to be invariant under time reversal, t \u2192 \u2212t t \u2192 \u2212t . The latter condition implies that the shift must satisfy \u03b2^i = 0 \u03b2^i = 0 and, hence, the extrinsic curvature also has to vanish everywhere on the slice, K_{ij} = 0 = K K_{ij} = 0 = K . On such a time slice the momentum constraints are satisfied trivially. The Hamiltonian constraint reduces to \\bar { D } ^ { 2 } \\psi = \\frac { 1 } { 8 } \\psi \\bar { R } \\bar { D } ^ { 2 } \\psi = \\frac { 1 } { 8 } \\psi \\bar { R } Let us further choose the conformally related metric to be flat, \\bar { \\gamma } _ { i j } = \\eta _ { i j } \\bar { \\gamma } _ { i j } = \\eta _ { i j } Whenever this is the case, we call the physical spatial metric \u03b3_{ij} \u03b3_{ij} conformally flat. \u201cconformal flatness\u201d refers, for our purposes, to the spatial metric and not the spacetime metric. In four or any higher dimensions, we can evaluate the Weyl tensor to examine whether any given metric is conformally flat. This is a consequence of the fact that the Weyl tensor is invariant under conformal transformations of the spacetime metric \u2013 this explains why it is often called the conformal tensor. Any spherically symmetric spatial metric is always conformally flat, meaning that we can always write such a metric as \\gamma _ { i j } = \\psi ^ { 4 } \\eta _ { i j } \\gamma _ { i j } = \\psi ^ { 4 } \\eta _ { i j } . For any spherically symmetric space, we may hence assume conformal flatness without loss of generality. Assuming conformal flatness dramatically simplifies all calculations, since \\bar{D}_i \\bar{D}_i reduces to the flat covariant derivative (and in particular to partial derivatives in cartesian coordinates). Moreover, the Ricci tensor and scalar curvature associated with the conformally related metric must now vanish, \\bar{R}_{ij} = \\bar{R} = 0 \\bar{R}_{ij} = \\bar{R} = 0 . Under this assumption, the Hamiltonian constraint becomes the remarkably simple Laplace equation \\bar { D } ^ { 2 } \\psi = 0 \\bar { D } ^ { 2 } \\psi = 0 Spherically symmetric solutions are \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } in this particular case, the constant M is in fact the black hole mass M. It shouldn\u2019t come as a great surprise that this is just the Schwarzschild solution in isotropic coordinates. d l ^ { 2 } = \\gamma _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\eta _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\left( d r ^ { 2 } + r ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) d l ^ { 2 } = \\gamma _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\eta _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\left( d r ^ { 2 } + r ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) This solution forms the basis of the so-called puncture methods for black holes. The solution is singular at r = 0 r = 0 . However, we can show that this singularity is only a coordinate singularity by considering the coordinate transformation r = \\left( \\frac { \\mathcal { M } } { 2 } \\right) ^ { 2 } \\frac { 1 } { \\hat { r } } r = \\left( \\frac { \\mathcal { M } } { 2 } \\right) ^ { 2 } \\frac { 1 } { \\hat { r } } under which the isotropic Schwarzschild metric becomes d l ^ { 2 } = \\left( 1 + \\frac { \\mathcal { M } } { 2 \\hat { r } } \\right) ^ { 4 } \\left( d \\hat { r } ^ { 2 } + \\hat { r } ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) d l ^ { 2 } = \\left( 1 + \\frac { \\mathcal { M } } { 2 \\hat { r } } \\right) ^ { 4 } \\left( d \\hat { r } ^ { 2 } + \\hat { r } ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) The geometry described by metric evaluated at a radius \\hat{r} = a \\hat{r} = a is identical to that of the above metric evaluated at r = a r = a . The mapping therefore maps the metric into itself, and is hence an isometry. In particular, this demonstrates that the origin r = 0 r = 0 is isomorphic to spatial infinity, which is perfectly regular. This demonstrates that the isotropic radius r covers only the black hole exterior, and that each Schwarzschild R corresponds to two values of the isotropic radius r. The isotropic radius r corresponding to the smallest areal (or circumferential) radius R is r = M/2 r = M/2 , which we refer to as the black hole throat. For a single Schwarzschild black hole, the throat coincides with both the apparent and event horizons. It is almost trivial to generalize our one black hole solution \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } to an arbitrary number of black holes at a moment of time symmetry. Since \\bar { D } ^ { 2 } \\psi = 0 \\bar { D } ^ { 2 } \\psi = 0 is linear, we obtain the solution simply by adding the individual contribution of each black hole according to \\psi = 1 + \\sum_{\\alpha} \\frac { \\mathcal { M } _ { \\alpha } } { 2 r _ { \\alpha } } \\psi = 1 + \\sum_{\\alpha} \\frac { \\mathcal { M } _ { \\alpha } } { 2 r _ { \\alpha } } Here r_\u03b1 = |x^i \u2212 C_\u03b1^i | r_\u03b1 = |x^i \u2212 C_\u03b1^i | is the (coordinate) separation from the center C_\u03b1^i C_\u03b1^i of the \u03b1th black hole. The total mass of the spacetime is the sum of the coefficients M_\u03b1 M_\u03b1 . However, since the total mass will also include contributions from the black hole interactions, M_\u03b1 M_\u03b1 can be identified with the mass of the \u03b1-th black hole only in the limit of large separations. Particularly interesting astrophysically and for the generation of gravitational waves is the case of binary black holes \\psi = 1 + \\frac { \\mathcal { M } _ { 1 } } { 2 r _ { 1 } } + \\frac { \\mathcal { M } _ { 2 } } { 2 r _ { 2 } } \\psi = 1 + \\frac { \\mathcal { M } _ { 1 } } { 2 r _ { 1 } } + \\frac { \\mathcal { M } _ { 2 } } { 2 r _ { 2 } } This simple solution to the constraint equations for two black holes instantaneously at rest at a moment of time symmetry can be used as initial data for head-on collisions of black holes. In general, the existence of other black holes destroys the symmetry that we found for a single black hole. Drawing an embedding diagram for such a geometry yields several different \u201csheets\u201d, where each sheet corresponds to one universe. A geometry containing N black holes may contain up to N + 1 different asymptotically flat universes. For each throat we can add terms inside that throat that correspond to images of the other black holes. Doing so, the solution becomes \u201csymmetrized\u201d so that the reflection through each throat is again an isometry. In other words, each Einstein-Rosen bridge connects to the same asymptotically flat universe, and the geometry consists of only two asymptotically flat universes, which are connected by several Einstein-Rosen bridges. For two equal-mass black holes we may also interpret this solution as a wormhole black hole solution. Cut off the bottom universe at the two throats, which leaves two \u201copen-ended\u201d throats hanging down from the top universe. We can now identify these two open ends with each other, effectively gluing them together. The two throats now form a \u201cwormhole\u201d that connects to a single, asymptotically flat (but multiply connected) universe. Given the original isometry conditions across the throats, and given that they have the same mass, the resulting metric is smooth across the throat and a valid solution to the Hamiltonian constraint. In cylindrical coordinates the metric becomes d l ^ { 2 } = \\psi ^ { 4 } \\left( d \\rho ^ { 2 } + d z ^ { 2 } + \\rho ^ { 2 } d \\phi ^ { 2 } \\right) d l ^ { 2 } = \\psi ^ { 4 } \\left( d \\rho ^ { 2 } + d z ^ { 2 } + \\rho ^ { 2 } d \\phi ^ { 2 } \\right) where the corresponding conformal factor is given by \\psi = 1 + \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } \\left( \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z + z _ { n } \\right) ^ { 2 } } } + \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z - z _ { n } \\right) ^ { 2 } } } \\right) \\psi = 1 + \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } \\left( \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z + z _ { n } \\right) ^ { 2 } } } + \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z - z _ { n } \\right) ^ { 2 } } } \\right) Here z _ { n } = \\operatorname { coth } ( n \\mu ) z _ { n } = \\operatorname { coth } ( n \\mu ) , and \u03bc is a free parameter. the total mass of this system, which we will identify with the \u201cADM mass\u201d is M _ { \\mathrm { ADM } } = 4 \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } M _ { \\mathrm { ADM } } = 4 \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } The proper distance L along the spacelike geodesic connecting the throats, or equivalently the proper length of a geodesic loop through the wormhole, is L = 2 \\left( 1 + 2 \\mu \\sum _ { n = 1 } ^ { \\infty } \\frac { n } { \\sinh ( n \\mu ) } \\right) L = 2 \\left( 1 + 2 \\mu \\sum _ { n = 1 } ^ { \\infty } \\frac { n } { \\sinh ( n \\mu ) } \\right) The parameter \u03bc is seen to parameterize both the mass and separation of the two holes. Since the solution can be rescaled to arbitrary physical mass, \u03bc effectively determines the dimensionless ratio L/M_{ADM} L/M_{ADM} , the parameter that, apart from mass, distinguishes one binary from another in this class of initial data. Mass There are several important global conserved quantities that characterize an isolated system, such as its total mass and angular momentum. The rate of loss of these quantities from an isolated system is equal to the rate at which matter, fields and gravitational waves carry them away . Once we have solved the constraint equations and constructed a complete set of initial data for a system, we can then determine the values of the global conserved parameters associated with the system. During a numerical evolution, monitoring the degree to which these parameters are conserved provides a very useful check on the accuracy of the numerical integration . Suppose the system contains matter. Then we can derive an expression for its conserved rest-mass M_0 M_0 (sometimes called the baryon mass, if the matter is composed of baryons) from the continuity equation, \\nabla _ { a } \\left( \\rho _ { 0 } u ^ { a } \\right) = 0 \\nabla _ { a } \\left( \\rho _ { 0 } u ^ { a } \\right) = 0 where \u03c1_0 \u03c1_0 is the rest-mass density. Integrating this expression over a 4-dimensional region of spacetime \u03a9 yields \\int _ { \\Omega } d ^ { 4 } x \\sqrt { - g } \\nabla _ { a } \\left( \\rho _ { 0 } u ^ { a } \\right) = 0 \\int _ { \\Omega } d ^ { 4 } x \\sqrt { - g } \\nabla _ { a } \\left( \\rho _ { 0 } u ^ { a } \\right) = 0 Using Gauss\u2019s theorem we can relate the divergence of \u03c1_0u^a \u03c1_0u^a inside the region \u03a9 to the value of \u03c1_0u^a \u03c1_0u^a on the region\u2019s 3-dimensional boundary \u2202\u03a9 \u2202\u03a9 \\int _ { \\Omega } d ^ { 4 } x \\sqrt { - g } \\nabla _ { a } \\left( \\rho _ { 0 } u ^ { a } \\right) = \\int _ { \\partial \\Omega } d ^ { 3 } \\Sigma _ { a } \\rho _ { 0 } u ^ { a } \\int _ { \\Omega } d ^ { 4 } x \\sqrt { - g } \\nabla _ { a } \\left( \\rho _ { 0 } u ^ { a } \\right) = \\int _ { \\partial \\Omega } d ^ { 3 } \\Sigma _ { a } \\rho _ { 0 } u ^ { a } where d ^ { 3 } \\Sigma _ { a } = \\epsilon \\mathcal { N } _ { a } \\sqrt { \\gamma } d ^ { 3 } x d ^ { 3 } \\Sigma _ { a } = \\epsilon \\mathcal { N } _ { a } \\sqrt { \\gamma } d ^ { 3 } x and \\mathcal { N } ^ { a } \\mathcal { N } ^ { a } is the outward-pointing unit normal vector on \u2202\u03a9 \u2202\u03a9 . When \u2202\u03a9 \u2202\u03a9 is spacelike, the factor \u03b5 = \u22121 \u03b5 = \u22121 and when \u2202\u03a9 \u2202\u03a9 is timelike, \u03b5 = +1 \u03b5 = +1 . Now imagine a \u201cpill-box\u201d-shaped spacetime region that is bounded by two spatial slices \u03a3_1 \u03a3_1 and \u03a3_2 \u03a3_2 as well as a timelike hypersurface residing entirely outside the source, as illustrated in Figure. In this case only the spatial surfaces contribute to the surface integral. On \u03a3_2 \u03a3_2 the normal vector Na points toward the future, and therefore coincides with the normal vector n^a n^a of the spacetime foliation \\mathcal { N } _ { a } u ^ { a } = n _ { a } u ^ { a } = - \\alpha u ^ { t } \\mathcal { N } _ { a } u ^ { a } = n _ { a } u ^ { a } = - \\alpha u ^ { t } . On \u03a3_1 \u03a3_1 , Na points toward the past, while n^a n^a points toward the future, which introduces a negative sign between them. The conservation law can therefore be written as \\int _ { \\Sigma _ { 1 } } d ^ { 3 } x \\sqrt { \\gamma } \\alpha u ^ { t } \\rho _ { 0 } - \\int _ { \\Sigma _ { 2 } } d ^ { 3 } x \\sqrt { \\gamma } \\alpha u ^ { t } \\rho _ { 0 } = 0 \\int _ { \\Sigma _ { 1 } } d ^ { 3 } x \\sqrt { \\gamma } \\alpha u ^ { t } \\rho _ { 0 } - \\int _ { \\Sigma _ { 2 } } d ^ { 3 } x \\sqrt { \\gamma } \\alpha u ^ { t } \\rho _ { 0 } = 0 implies that the rest mass, defined as M _ { 0 } = \\int _ { \\Sigma } d ^ { 3 } x \\sqrt { \\gamma } \\alpha u ^ { t } \\rho _ { 0 } M _ { 0 } = \\int _ { \\Sigma } d ^ { 3 } x \\sqrt { \\gamma } \\alpha u ^ { t } \\rho _ { 0 } is conserved. The rest-mass is thus determined by a 3\u2212dimensional volume integral over a spatial region spanning the matter source. Defining the total mass-energy of the system is more subtle, since it cannot be defined locally in general relativity . One useful measure of mass-energy is provided by the ADM mass, M_{ADM} M_{ADM} . The ADM mass measures the total mass-energy of an isolated gravitating system at any instant of time measured within a spatial surface enclosing the system at infinity. This definition requires the spacetime to be asymptotically flat and the spacetime metric to approach the Minkowski metric sufficiently quickly with increasing distance from the source, g _ { a b } - \\eta _ { a b } = \\mathcal { O } \\left( r ^ { - 1 } \\right) g _ { a b } - \\eta _ { a b } = \\mathcal { O } \\left( r ^ { - 1 } \\right) The existence of such a surface integral to determine the mass-energy of an isolated system is consistent with the principle that the total mass-energy of such a system can always by determined by a measurement performed by a distant observer . By definition, the spatial surface \u2202\u03a3_\u221e \u2202\u03a3_\u221e must be taken out to infinity, in which case M_{ADM} M_{ADM} is rigorously conserved . In numerical applications, the integral is often evaluated on a large surface at a distant, but finite, radius from the gravitating source , in the asymptotically flat region of spacetime. In this case, M_{ADM} M_{ADM} will change in time whenever there is a flux of matter or gravitational radiation passing across the surface . However, the rate of change of M_{ADM} M_{ADM} will exactly reflect the rate at which mass-energy is carried across the surface by these fluxes. Assume a perfect gas, so that the stress energy tensor is given by T ^ { a b } = \\left( \\rho _ { 0 } + \\epsilon \\rho _ { 0 } + P \\right) u ^ { a } u ^ { b } + P g ^ { a b } T ^ { a b } = \\left( \\rho _ { 0 } + \\epsilon \\rho _ { 0 } + P \\right) u ^ { a } u ^ { b } + P g ^ { a b } where \u03b5 is the specific internal energy density and P the pressure. The difference between the ADM mass M_{ADM} M_{ADM} and the rest mass M_0 M_0 is given by M _ { \\mathrm { ADM } } - M _ { 0 } = T + W + U M _ { \\mathrm { ADM } } - M _ { 0 } = T + W + U in the Newtonian limit, where T is the kinetic energy, T = \\frac { 1 } { 2 } \\int \\rho _ { 0 } v ^ { 2 } d ^ { 3 } x T = \\frac { 1 } { 2 } \\int \\rho _ { 0 } v ^ { 2 } d ^ { 3 } x W the gravitational potential energy, W = \\frac { 1 } { 2 } \\int \\rho _ { 0 } \\phi d ^ { 3 } x W = \\frac { 1 } { 2 } \\int \\rho _ { 0 } \\phi d ^ { 3 } x and U is the internal energy, U = \\int \\rho _ { 0 } \\epsilon d ^ { 3 } x U = \\int \\rho _ { 0 } \\epsilon d ^ { 3 } x On further probing, things can sometimes get a little confusing, as when evaluating the ADM mass for Schwarzschild spacetime in Painleve-Gullstrand coordinates. All the above expressions yield an ADM mass of zero in these coordinates. The reason for this is that the shift in Painleve-Gullstrand coordinates does not fall off sufficiently fast. If nothing else, this result provides a warning to us that we must be careful to check that the metric satisfies the correct asymptotic conditions in the adopted coordinates when applying the above formulae to calculate the mass. It also motivates a search for other mass definitions. Choosing Coordinates The 3+1 evolution equations for \\gamma_{ij} \\gamma_{ij} and for K_{ij} K_{ij} are not quite ready for numerical integration. For one thing, we have yet to impose coordinate conditions by specifying the lapse function \u03b1 \u03b1 and the shift vector \u03b2^i \u03b2^i that appear in these equations. The lapse and shift are freely specifiable gauge variables that need to be chosen in order to advance the field data from one time slice to the next. What constitutes a \u201cgood\u201d coordinate system? Clearly, the adopted coordinates must not allow the appearance of any singularities, which could have dire consequences for a numerical simulation. Such a singularity, which is often associated with a black hole, could be either a coordinate singularity or a physical singularity. To avoid coordinate singularities associated with horizons, like the one at r_s = 2M r_s = 2M , black hole simulations have sometimes been carried out using \u201chorizon penetrating\u201d coordinates in which light cones do not pinch-off at the horizon. The lapse \u03b1 determines how the shape of the slices \u03a3 changes in time, since it relates the advance of proper time to coordinate time along the normal vector na connecting one spatial slice to the next. The shift \u03b2^i \u03b2^i , on the other hand, determines how spatial points at rest with respect to a normal observer n^a n^a are relabeled on neighboring slices. The spatial gauge or spatial coordinates is therefore imposed by a choice for the shift vector. Geodesic Slicing Since the lapse \u03b1 \u03b1 and the shift \u03b2^i \u03b2^i can be chosen freely, let us first consider the simplest possible choice, \\alpha = 1 , \\quad \\beta ^ { i } = 0 \\alpha = 1 , \\quad \\beta ^ { i } = 0 In the context of numerical relativity this gauge choice is often called geodesic slicing; the resulting coordinates are also known as Gaussian-normal coordinates. Recall that coordinate observers move with 4\u2212velocities u ^ { a } = t ^ { a } = e _ { ( 0 ) } ^ { a } u ^ { a } = t ^ { a } = e _ { ( 0 ) } ^ { a } (i.e. spatial velocities u^i = 0 u^i = 0 ). Thus with \u03b2^i = 0 \u03b2^i = 0 , coordinate observers coincide with normal observers ( u^a = n^a u^a = n^a ). With \u03b1 = 1 \u03b1 = 1 , the proper time intervals that they measure agree with coordinate time intervals. Their acceleration is given by equation a _ { b } = D _ { b } \\ln \\alpha = 0 a _ { b } = D _ { b } \\ln \\alpha = 0 Evidently, since their acceleration vanishes, normal observers are freely-falling and therefore follow geodesics, hence the name of this slicing condition. Despite its simplicity, geodesic slicing tends to form coordinate singularities very quickly during an evolution. This result is not surprising, since geodesics tend to focus in the presence of gravitating sources. Coordinate observers therefore approach each other, collide, and thereby form a coordinate singularity . As an example, consider a weak gravitational wave that is initially centered on the origin of an otherwise flat vacuum spacetime. After a brief interaction the wave disperses and leaves behind flat space. Also consider a set of coordinate observers that are at rest with respect to each other initially. The gravitational wave packet carries energy and hence attracts the observers gravitationally, who, initially, start moving toward the origin of the spacetime . Once the gravitational wave has dispersed, the observers are no longer attracted gravitationally to the center, but they continue to coast toward each other until they form a coordinate singularity . As the following exercise demonstrates, we can even estimate the time scale after which this singularity will form. Maximal Slicing A common choice is the maximal slicing condition K = 0 K = 0 If we assume maximal slicing not only on one slice, but at all times, then the time derivative of K must vanish as well, K = 0 = \\partial _ { t } K K = 0 = \\partial _ { t } K D ^ { 2 } \\alpha = \\alpha \\left( K _ { i j } K ^ { i j } + 4 \\pi ( \\rho + S ) \\right) D ^ { 2 } \\alpha = \\alpha \\left( K _ { i j } K ^ { i j } + 4 \\pi ( \\rho + S ) \\right) which we can solve for the lapse \u03b1 \u03b1 independently of the shift \u03b2^i \u03b2^i . By construction, maximal slicing prevents the focussing of normal observers that we have found for geodesic slicing. This means that maximal slices are \u201cvolume preserving\u201d along the normal congruence n^a n^a . Normal observers in maximal slicing move like irrotational and incompressible fluid elements. The incompressible property prevents the focussing of normal observers that occurs in geodesic slicing. Harmonic Coordinates Consider a contraction of the four dimensional connection coefficients ^ { ( 4 ) } \\Gamma ^ { a } \\equiv g ^ { b c ( 4 ) } \\Gamma _ { b c } ^ { a } = - \\frac { 1 } { | g | ^ { 1 / 2 } } \\partial _ { b } \\left( | g | ^ { 1 / 2 } g ^ { a b } \\right) ^ { ( 4 ) } \\Gamma ^ { a } \\equiv g ^ { b c ( 4 ) } \\Gamma _ { b c } ^ { a } = - \\frac { 1 } { | g | ^ { 1 / 2 } } \\partial _ { b } \\left( | g | ^ { 1 / 2 } g ^ { a b } \\right) One way to impose a gauge condition is to set these quantities equal to some pre-determined gauge source functions H^a H^a , ^ { ( 4 ) } \\Gamma ^ { a } = H ^ { a } ^ { ( 4 ) } \\Gamma ^ { a } = H ^ { a } In particular, we may choose these gauge source functions to vanish, which defines harmonic coordinates ^ { ( 4 ) } \\Gamma ^ { a } = 0 ^ { ( 4 ) } \\Gamma ^ { a } = 0 More common in 3+1 calculations is harmonic slicing, in which only the time-component ^ { ( 4 ) } \\Gamma ^ { 0 } ^ { ( 4 ) } \\Gamma ^ { 0 } is set to zero. The singularity avoidance properties of harmonic slicing are weaker than those, for example, of maximal slicing. Quasi-isotropic and Radial Gauge We now turn to gauge conditions for the spatial coordinates, i.e., conditions that specify the shift vector \u03b2^i \u03b2^i . As is the case when picking a lapse, an important goal when choosing a shift is to provide for a stable, long-term dynamical evolution. In addition, it is often desirable to bring the spatial metric into a simple form . Loosely speaking, two different strategies can be employed when constructing a spatial gauge condition. One strategy is to define a geometric condition on the spatial metric from which a gauge condition can be derived. Alternatively, we can impose an algebraic condition on the spatial metric directly. For example, we can set some of its components to zero in order to simplify the Einstein equations. In general the spatial metric \u03b3_{ij} \u03b3_{ij} has six independent components. Using our three degrees of spatial coordinate freedom we can impose three conditions on the metric, and thereby reduce the number of its independent variables to three. In spherical polar coordinates, quasi-isotropic gauge is defined by the three conditions \\gamma _ { r \\theta } = \\gamma _ { r \\phi } = 0 \\\\ \\gamma _ { \\theta \\theta } \\gamma _ { \\phi \\phi } - \\left( \\gamma _ { \\theta \\phi } \\right) ^ { 2 } = \\gamma _ { r r } \\gamma _ { \\phi \\phi } r ^ { 2 } \\gamma _ { r \\theta } = \\gamma _ { r \\phi } = 0 \\\\ \\gamma _ { \\theta \\theta } \\gamma _ { \\phi \\phi } - \\left( \\gamma _ { \\theta \\phi } \\right) ^ { 2 } = \\gamma _ { r r } \\gamma _ { \\phi \\phi } r ^ { 2 } which reduces the metric to the form d l ^ { 2 } = A ^ { 2 } \\left( d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } \\right) + B ^ { 2 } r ^ { 2 } ( \\sin \\theta d \\phi + \\xi d \\theta ) ^ { 2 } d l ^ { 2 } = A ^ { 2 } \\left( d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } \\right) + B ^ { 2 } r ^ { 2 } ( \\sin \\theta d \\phi + \\xi d \\theta ) ^ { 2 } Minimal Distortion The conformally related metric \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} has five independent functions, two of which correspond to true dynamical degrees of freedom and three to coordinate freedom. For a stable and accurate numerical evolution it is desirable to eliminate purely coordinate-related fluctuations in \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} . To accomplish this, one may want to construct a gauge condition that minimizes the time rate of change of the conformally related metric. This gauge condition is called minimal distortion . An \u201capproximate minimal distortion\u201d condition may lead to a coordinate system with similar geometric properties. Matter Sources The stress-energy tensor accounts for all sources of energy-momentum in spacetime, excluding gravity. It thus arises from all forms of matter, electromagnetic fields, neutrinos, scalar fields, etc, in the universe. For brevity, we shall sometimes refer to these sources collectively as the \u201cmatter sources\u201d and the terms that they contribute in the 3 + 1 equations as the \u201cmatter source terms\u201d. \u201cMatter\u201d source terms appear in the Hamiltonian constraint equation, the momentum constraint equation, and the 3 + 1 evolution equation. The evolution equations for the \u201cmatter\u201d sources are given by \\nabla _ { b } T ^ { a b } = 0 \\nabla _ { b } T ^ { a b } = 0 , which express the conservation of the total 4-momentum in spacetime. These conservation equations must be solved simultaneously with the 3 + 1 evolution equations for the gravitational field to determine the entire foliation of spacetime. Some of the quantities appearing in the stress-energy tensor require auxiliary equations. These auxiliary equations include, for example, the continuity equation and an equation of state in the case of hydrodynamic matter, and Maxwell\u2019s equations in the case of an electromagnetic field , and so on. The \u201cmatter\u201d source terms \u03c1, S_i S_i and S_{ij} S_{ij} appearing in the 3+1 equations for the gravitational field are projections of the stress-energy tensor into n^a n^a and \u03a3 and are given by \\rho = n_a n_b T^{ab} \\\\ S_i = - \\gamma_{ia} n_b T^{ab} \\\\ S_{ij} = \\gamma_{ia} \\gamma_{jb} T^{ab} \\rho = n_a n_b T^{ab} \\\\ S_i = - \\gamma_{ia} n_b T^{ab} \\\\ S_{ij} = \\gamma_{ia} \\gamma_{jb} T^{ab} The quantity \\rho \\rho is the total mass-energy density as measured by a normal observer, S_i S_i is the momentum density and S_{ij} S_{ij} is the stress. Finally, S is de\ufb01ned as the trace of S_{ij} S_{ij} , S = \\gamma^{ij} S_{ij} S = \\gamma^{ij} S_{ij} In the following sections, we discuss some of the most important \u201cmatter\u201d sources that arise in astrophysical applications. These sources include hydrodynamic fluids, magnetohydrodynamic plasmas threaded by magnetic fields, radiation gases (e.g., photon and neutrino), collisionless matter, and scalar fields. Vacuum Vacuum spacetimes are characterized by the vacuum stress energy tensor T^{ab} = 0 T^{ab} = 0 Spacetimes containing black holes and (or) gravitational waves, and nothing else, are characterized by such a stress-energy tensor in Einstein\u2019s \ufb01eld equations. Vacuum spacetimes are simpler to deal with numerically since they require no additional energy-momentum conservation equations or auxiliary \ufb01eld equations to solve. Hydrodynamics Relativistic hydrodynamic matter is an important source of stress-energy in many astrophysical applications. Loosely speaking, a hydrodynamic description of matter is appropriate whenever the mean free path of a particle due to collisions with neighboring particles is much shorter than the characteristic size or local scale length of the system. Perfect Gases The stress-energy tensor of a perfect gas is given by T^{ab} = \\rho_0 h u^a u^b + P g^{ab} T^{ab} = \\rho_0 h u^a u^b + P g^{ab} h is the specific enthalpy h = 1 + \\epsilon + P / \\rho _ { 0 } h = 1 + \\epsilon + P / \\rho _ { 0 } where \\epsilon \\epsilon is the specific internal energy density. The total mass-energy density as measured by an observer comoving with the fluid is then given by \\rho ^ { * } = \\rho _ { 0 } ( 1 + \\epsilon ) \\rho ^ { * } = \\rho _ { 0 } ( 1 + \\epsilon ) . The local conservation of energy-momentum \\nabla_b T^{ab} = 0 \\nabla_b T^{ab} = 0 The conservation of rest mass \\nabla_a (\\rho_0 u^a) = 0 \\nabla_a (\\rho_0 u^a) = 0 Imperfect Gases There are many important astrophysical applications that involve imperfect gases characterized by viscosity, conductivity and (or) radiation. For example, viscosity can drive non-axisymmetric instabilities in rotating stars, while radiation can lead to the cooling and contraction of stars. Viscosity The contribution of viscosity to the stress-energy tensor is T _ { \\mathrm { visc } } ^ { a b } = - 2 \\eta \\sigma ^ { a b } - \\zeta \\theta P ^ { a b } T _ { \\mathrm { visc } } ^ { a b } = - 2 \\eta \\sigma ^ { a b } - \\zeta \\theta P ^ { a b } where \u03b7 \u2265 0 \u03b7 \u2265 0 is the coefficient of dynamic, or shear, viscosity, \u03b6 \u2265 0 \u03b6 \u2265 0 is the coefficient of bulk viscosity. Heat and Radiation Diffusion The contribution of heat flux (i.e. conduction) to the stress-energy tensor is T _ { \\text { heat } } ^ { a b } = u ^ { a } q ^ { b } + u ^ { b } q ^ { a } T _ { \\text { heat } } ^ { a b } = u ^ { a } q ^ { b } + u ^ { b } q ^ { a } where the heat-flux 4-vector q^a q^a is given by q ^ { a } = - \\lambda _ { \\mathrm { th } } P ^ { a b } \\left( \\nabla _ { b } T + T a _ { b } \\right) q ^ { a } = - \\lambda _ { \\mathrm { th } } P ^ { a b } \\left( \\nabla _ { b } T + T a _ { b } \\right) T is the temperature, a ^ { a } = u ^ { b } \\nabla _ { b } u ^ { a } a ^ { a } = u ^ { b } \\nabla _ { b } u ^ { a } is the fluid 4-acceleration, and \u03bb_{th} \u03bb_{th} is the coefficient of thermal conduction. A useful application of the thermal conduction formalism is heat transport via thermal radiation. Radiation Hydrodynamics In general, a gas is neither optically thick nor optically thin (i.e. transparent) everywhere, nor is the radiation always in thermal equilibrium with the matter. In such cases we cannot treat radiation transport in the diffusion approximation as discussed above. To handle the more general case, the radiation field can be described by a radiation stress-energy tensor, T _ { \\mathrm { rad } } ^ { a b } = \\iint d \\nu d \\Omega I _ { \\nu } N ^ { a } N ^ { b } T _ { \\mathrm { rad } } ^ { a b } = \\iint d \\nu d \\Omega I _ { \\nu } N ^ { a } N ^ { b } The radiation hydrodynamics problem is very difficult to solve in general, since the intensity is a function of six-dimensional phase space plus time, and the radiation transport equation with complicated radiation-fluid interaction terms (including scattering) has a nontrivial integrodifferential character. Magnetohydrodynamics Magnetic fields play a crucial role in determining the evolution of many relativistic objects. In any highly conducting astrophysical plasma, a frozen-in magnetic field can be amplified appreciably by gas compression or shear. Even when an initial seed field is weak, the field can grow in the course of time to significantly influence the gas dynamical behavior of the system. Electromagnetic Field Equations Along with the electromagnetic field, we shall assume the presence of a perfect fluid, so that the total stress-energy tensor is given by T ^ { a b } = \\rho _ { 0 } h u ^ { a } u ^ { b } + P g ^ { a b } + T _ { \\mathrm { em } } ^ { a b } T ^ { a b } = \\rho _ { 0 } h u ^ { a } u ^ { b } + P g ^ { a b } + T _ { \\mathrm { em } } ^ { a b } The electromagnetic stress-energy tensor 4 \\pi T _ { \\mathrm { em } } ^ { a b } = F ^ { a c } F _ { c } ^ { b } - \\frac { 1 } { 4 } g ^ { a b } F _ { c d } F ^ { c d } 4 \\pi T _ { \\mathrm { em } } ^ { a b } = F ^ { a c } F _ { c } ^ { b } - \\frac { 1 } { 4 } g ^ { a b } F _ { c d } F ^ { c d } Equation of state For many purposes it is useful to employ a simple \u201c\u0393-law\u201d equation of state (EOS) of the form P = (\\Gamma - 1) \\rho_0 \\varepsilon P = (\\Gamma - 1) \\rho_0 \\varepsilon Realistic applications involving relativistic objects are rarely described by EOSs obeying this simple form . However, a \u0393-law EOS provides a computationally practical, albeit crude, approximation that can be adapted to mimick the gross behavior of different states of matter in many applications. For example, to model a stiff nuclear EOS in a neutron star , one can adopt a moderately high value of \u0393 in a \u0393-law EOS, e.g. \u0393 \u2248 2. By contrast, to model a moderately soft, thermal radiation-dominated EOS governing a very massive or supermassive star, one can set \u0393 = 4/3. For isentropic flow, a \u0393-law EOS is equivalent to the equation of state of a polytrope, P = K \\rho _ { 0 } ^ { \\Gamma } , \\quad \\Gamma = 1 + 1 / n P = K \\rho _ { 0 } ^ { \\Gamma } , \\quad \\Gamma = 1 + 1 / n where n is the polytropic index and K is the gas constant. However, for non-isentropic flow, which is always the case when encountering a shock, K is no longer constant throughout the fluid . Collisionless Matter Several important astrophysical systems are made up of particles of collisionless matter. In such systems, the mean-free-path for particle-particle interactions is much longer than the scale of the system. One example of a collisionless system is a star cluster, a large, self-gravitating, N-body system in which the individual particles \u2013 the stars \u2013 interact exclusively via gravitation. Scalar Fields Scalar fields give rise to particles of spin 0, while vector fields (like the electromagnetic field) give rise to particles of spin 1 (like the photon, in the case of electromagnetism), and tensor fields of rank two or higher give rise to higher-spin particles. A complex scalar field has two degrees of freedom instead of just one, and it can be interpreted as a particle and an antiparticle. Real fields are their own antiparticles. A neutral \u03c0 meson is an example of a real scalar field, while the charged \u03c0^+ \u03c0^+ - and \u03c0_\u2212 \u03c0_\u2212 -mesons are described by complex scalar fields. Evolution Equations The evolution equations evolve the data (\u03b3_{ab},K_{ab}) (\u03b3_{ab},K_{ab}) forward in time. However, the Lie derivative along n^a n^a , \\mathcal { L } _ { \\mathbf { n } } \\mathcal { L } _ { \\mathbf { n } } , is not a natural time derivative since n^a n^a is not dual to the surface 1-form \u03a9_a \u03a9_a , i.e. their dot product is not unity n ^ { a } \\Omega _ { a } = - \\alpha g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t = \\alpha ^ { - 1 } n ^ { a } \\Omega _ { a } = - \\alpha g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t = \\alpha ^ { - 1 } Instead, consider the vector t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } which is dual to \u03a9_a \u03a9_a for any spatial shift vector \u03b2^a \u03b2^a , t ^ { a } \\Omega _ { a } = \\alpha n ^ { a } \\Omega _ { a } + \\beta ^ { a } \\Omega _ { a } = 1 t ^ { a } \\Omega _ { a } = \\alpha n ^ { a } \\Omega _ { a } + \\beta ^ { a } \\Omega _ { a } = 1 It will prove useful to choose t^a t^a to be the congruence along which we propagate the spatial coordinate grid from one time slice to the next slice. In other words, t^a t^a will connect points with the same spatial coordinates on neighboring time slices. Then the shift vector \u03b2^a \u03b2^a will measure the amount by which the spatial coordinates are shifted within a slice with respect to the normal vector. The lapse function \u03b1 \u03b1 measures how much proper time elapses between neighboring time slices along the normal vector. The lapse and the shift therefore determine how the coordinates evolve in time. The choice of \u03b1 \u03b1 and \u03b2^a \u03b2^a is quite arbitrary. The freedom to choose these four gauge functions \u03b1 \u03b1 and \u03b2^a \u03b2^a completely arbitrarily embodies the four-fold coordinate degrees of freedom inherent in general relativity . The lapse and the shift determine how the coordinates evolve from one time slice \u03a3 to the next, whereas the constraint equations represent integrability conditions which have to be satisfied within each slice. Therefore, the constraints have to be independent of how the coordinates evolve, and the lapse and the shift can enter only the evolution equations . Observers who are \u201cat rest\u201d relative to the slices follow the normal congruence n^a n^a and are called either normal or Eulerian observers. while observers following the congruence t^a t^a are called coordinate observers. If matter is present it moves entirely independently of the coordinates with four-velocity u^a u^a . Ricci\u2019s equation: The evolution equation for the extrinsic curvature: \\begin{align} \\mathcal{L}_{t} K_{ab} = &- D_{a} D_{b} \\alpha + \\alpha (R_{ab} - 2 K_{ac} K^{c}_{\\space b} + K K_{ab}) \\\\ &- 8 \\pi \\alpha \\left( S_{ab} - \\frac{1}{2} \\gamma_{ab} \\left( S-\\rho \\right) \\right) + \\mathcal{L}_{\\beta}K_{ab} \\end{align} \\begin{align} \\mathcal{L}_{t} K_{ab} = &- D_{a} D_{b} \\alpha + \\alpha (R_{ab} - 2 K_{ac} K^{c}_{\\space b} + K K_{ab}) \\\\ &- 8 \\pi \\alpha \\left( S_{ab} - \\frac{1}{2} \\gamma_{ab} \\left( S-\\rho \\right) \\right) + \\mathcal{L}_{\\beta}K_{ab} \\end{align} a projection with two indices projected in the normal direction. \\mathcal{L}_n K_{ab} = n^d n^c \\gamma^q_{\\space a} \\gamma^r_{\\space b} {}^{(4)} R_{drcq} - \\frac{1}{\\alpha} D_a D_b \\alpha - K^c_{\\space b} K_{ac} \\\\ S_{ab} = \\gamma^c_{\\space a} \\gamma^d_{\\space b} T_{cd} \\\\ S = S^a_{\\space a} \\mathcal{L}_n K_{ab} = n^d n^c \\gamma^q_{\\space a} \\gamma^r_{\\space b} {}^{(4)} R_{drcq} - \\frac{1}{\\alpha} D_a D_b \\alpha - K^c_{\\space b} K_{ac} \\\\ S_{ab} = \\gamma^c_{\\space a} \\gamma^d_{\\space b} T_{cd} \\\\ S = S^a_{\\space a} The evolution equation for the spatial metric \\gamma_{ab} \\gamma_{ab} : \\mathcal{L}_t \\gamma_{ab} = - 2 \\alpha K_{ab} + \\mathcal{L}_{\\beta} \\gamma_{ab} \\mathcal{L}_t \\gamma_{ab} = - 2 \\alpha K_{ab} + \\mathcal{L}_{\\beta} \\gamma_{ab} K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} It is quite intuitive, though, that things will simplify if we adopt a coordinate system that reflects our 3 + 1 split of spacetime in a natural way. We will see that the Lie derivative in the evolution equations then reduces to a partial derivative with respect to coordinate time and, as an additional bene\ufb01t, we will be able to ignore all timelike components of spatial tensors. The coupled evolution equations the extrinsic curvature and the spatial metric determine the evolution of the gravitational \ufb01eld data (\\gamma_{ab}, K_{ab}) (\\gamma_{ab}, K_{ab}) . Together with the constraint equations they are completely equivalent to Einstein\u2019s equations. Note we have succeeded in recasting Einstein\u2019s equations, which are second order in time in their original form, as a coupled set of partial differential equations that are now first order in time . So far, we have expressed our equations in a covariant, coordinate independent manner, i.e. the basis vectors e_a e_a have been completely arbitrary and have no particular relationship to the 1-form \u03a9_a \u03a9_a or to the congruence defined by t^a t^a . ADM Equations It is quite intuitive, though, that things will simplify if we adopt a coordinate system that effects our 3 + 1 split of spacetime in a natural way. To do so, we first introduce a basis of three spatial vectors e^a_{(i)} e^a_{(i)} , reside in a particular time slice \u03a3: \\Omega_a e^a_{(i)} = 0 \\Omega_a e^a_{(i)} = 0 We extend our spatial vectors to other slices \u03a3 by Lie dragging along t^a t^a \\mathcal{L}_t e^a_{(i)} = 0 \\mathcal{L}_t e^a_{(i)} = 0 As the fourth basis vector we pick e^a_0 = t^a e^a_0 = t^a . The duality condition then implies that e^a_{(0)} e^a_{(0)} has the components t ^ { a } = e _ { ( 0 ) } ^ { a } = ( 1,0,0,0 ) t ^ { a } = e _ { ( 0 ) } ^ { a } = ( 1,0,0,0 ) This means that the Lie derivative along t^a t^a reduces to a partial derivative with respect to t: \\mathcal{L}_t = \\partial_t \\mathcal{L}_t = \\partial_t . Since spatial tensors vanish when contracted with the normal vector, this also means that all components of spatial tensors with a contravariant index equal to zero must vanish. For the shift vector, \\beta ^ { a } = \\left( 0 , \\beta ^ { i } \\right) \\beta ^ { a } = \\left( 0 , \\beta ^ { i } \\right) Solving equation t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } for n^a n^a then yields the contravariant components n ^ { a } = \\left( \\alpha ^ { - 1 } , - \\alpha ^ { - 1 } \\beta ^ { i } \\right) n ^ { a } = \\left( \\alpha ^ { - 1 } , - \\alpha ^ { - 1 } \\beta ^ { i } \\right) and from the normalization condition n_a n^a = \u22121 n_a n^a = \u22121 we find n _ { a } = ( - \\alpha , 0,0,0 ) n _ { a } = ( - \\alpha , 0,0,0 ) From the definition of the spatial metric we have \\gamma_{ij} = g_{ij} \\gamma_{ij} = g_{ij} meaning that the metric on \u03a3 is just the spatial part of the four-metric. Since zeroth components of spatial contravariant tensors have to vanish, we also have \\gamma^{a0} = 0 \\gamma^{a0} = 0 . The inverse metric can therefore be expressed as: g^{ab} = \\gamma^{ab} - n^{a} n^{b} = \\begin{pmatrix} \\alpha^{-2} & \\alpha^{-2} \\beta^{i} \\\\ \\alpha^{-2} \\beta^{j} & \\gamma^{ij} - \\alpha^{2} \\beta^{i} \\beta^{j} \\end{pmatrix} g^{ab} = \\gamma^{ab} - n^{a} n^{b} = \\begin{pmatrix} \\alpha^{-2} & \\alpha^{-2} \\beta^{i} \\\\ \\alpha^{-2} \\beta^{j} & \\gamma^{ij} - \\alpha^{2} \\beta^{i} \\beta^{j} \\end{pmatrix} We can now invert it and find the components of the four-dimensional metric g_{ab} = \\begin{pmatrix} \\alpha^{-2} + \\beta_l \\beta^l & \\beta_{i} \\\\ \\beta_{j} & \\gamma_{ij} \\end{pmatrix} g_{ab} = \\begin{pmatrix} \\alpha^{-2} + \\beta_l \\beta^l & \\beta_{i} \\\\ \\beta_{j} & \\gamma_{ij} \\end{pmatrix} Equivalently, the line element may be decomposed as: ds^{2} = - \\alpha^{2} dt^{2} + \\gamma_{ij} \\left( dx^{i} + \\beta^{i} dt \\right) \\left( dx^{j} + \\beta^{j}dt \\right) ds^{2} = - \\alpha^{2} dt^{2} + \\gamma_{ij} \\left( dx^{i} + \\beta^{i} dt \\right) \\left( dx^{j} + \\beta^{j}dt \\right) which is often refered to as the metric in 3 + 1 form. We may interpret this line element as the Pythagorean Theorem for a 4-dimensional spacetime, ds^2 = - (proper time between neighboring spatial hypersurfaces)^2 + (proper distance within the spatial hypersurface)^2 ds^2 = - (proper time between neighboring spatial hypersurfaces)^2 + (proper distance within the spatial hypersurface)^2 . This equation thus determines the invariant interval between neighboring points A and B. Therefore, the entire content of the decomposed Einstein equations is contained in their spatial components alone, and we can rewrite: the Hamiltonian constraint R + K^2 - K_{ij} K^{ij} = 16 \\pi \\rho R + K^2 - K_{ij} K^{ij} = 16 \\pi \\rho the momentum constraint D_{j} (K^{ij} - \\gamma^{ij} K) = 8 \\pi S^i D_{j} (K^{ij} - \\gamma^{ij} K) = 8 \\pi S^i the evolution equation for the extrinsic curvature \\begin{align} \\partial_{t} K_{ij} = &- D_{i} D_{j} \\alpha + \\alpha \\left( R_{ij} - 2 K_{ik} K^{k}_{\\space j} + K K_{ij}\\right) - 8 \\pi \\alpha \\left( S_{ij} - \\frac{1}{2} \\gamma_{ij} \\left( S - \\rho \\right) \\right) \\\\ &+ \\beta^{k} D_{k} K_{ij} + K_{ik} D_{j} \\beta^{k} + K_{kj} D_{i} \\beta^{k} \\end{align} \\begin{align} \\partial_{t} K_{ij} = &- D_{i} D_{j} \\alpha + \\alpha \\left( R_{ij} - 2 K_{ik} K^{k}_{\\space j} + K K_{ij}\\right) - 8 \\pi \\alpha \\left( S_{ij} - \\frac{1}{2} \\gamma_{ij} \\left( S - \\rho \\right) \\right) \\\\ &+ \\beta^{k} D_{k} K_{ij} + K_{ik} D_{j} \\beta^{k} + K_{kj} D_{i} \\beta^{k} \\end{align} the evolution equation for the spatial metric \\partial_t \\gamma_{ij} = - 2 \\alpha K_{ij} + D_i \\beta_j + D_j \\beta_i \\partial_t \\gamma_{ij} = - 2 \\alpha K_{ij} + D_i \\beta_j + D_j \\beta_i Equations comprise the \u201cstandard\u201d 3 + 1 equations. Sometimes they are referred to as the \u201cADM\u201d equations. The decomposed Einstein equations do not provide any equations for \u03b1 \u03b1 and \u03b2_i \u03b2_i . Again, this is not surprising, since these functions represent the coordinate freedom of general relativity. The lapse and shift are therefore arbitrary, and must be determined by imposing gauge conditions . Clearly, different gauge conditions will lead to different functions for the spatial metric \u03b3_{ij} \u03b3_{ij} and the extrinsic curvature K_{ij} K_{ij} when they are used in the evolution equations. Even for a stationary spacetime, like Schwarzschild, most choices for the lapse and shift will lead to a time-dependent spatial metric function . Only for special choices of the lapse and the shift will the spatial metric of a stationary spacetime remain time-independent. This will be the case if our time-vector t^a t^a is aligned with a Killing-vector of the spacetime, Killing lapse and Killing shift. \u03be^a = t^a = \u03b1 n^a + \u03b2^a. \u03be^a = t^a = \u03b1 n^a + \u03b2^a. The lapses and shifts that we listed in Table are examples of such Killing lapses and Killing shifts. Numerical Methods As we have seen, Einstein\u2019s field equations in 3 + 1 form consist of a set of nonlinear, multidimensional, coupled partial differential equations in space and time. The equations of motion of the matter fields that may be present are typically of a similar nature. Except for very idealized problems with special symmetries, such equations must be solved by numerical means, often on supercomputers. Classification of Partial Differential Equations Consider the general equation of second-order partial differential equation A \\partial _ { \\xi } ^ { 2 } \\phi + 2 B \\partial _ { \\xi } \\partial _ { \\eta } \\phi + C \\partial _ { \\eta } ^ { 2 } \\phi = \\tilde { \\rho } A \\partial _ { \\xi } ^ { 2 } \\phi + 2 B \\partial _ { \\xi } \\partial _ { \\eta } \\phi + C \\partial _ { \\eta } ^ { 2 } \\phi = \\tilde { \\rho } where the coefficients A, B and C are real, differentiable, and do not vanish simultaneously. Also, the source term \\tilde { \\rho } \\tilde { \\rho } may depend on \u03c6, but only up to first order derivatives. Most of the resulting equations are second-order partial differential equations and can be classified into three categories: elliptic, parabolic or hyperbolic. If AC \u2212 B^2 > 0 AC \u2212 B^2 > 0 , then we can find a coordinate transformation from (\u03be, \u03b7) to some (x, y) that brings equation into the elliptic. The prototypical example of an elliptic equation is Poisson\u2019s equation , \\partial _ { x } ^ { 2 } \\phi + \\partial _ { y } ^ { 2 } \\phi = \\rho \\partial _ { x } ^ { 2 } \\phi + \\partial _ { y } ^ { 2 } \\phi = \\rho where \\rho \\rho is a source term that may depend on position, or even on \\phi \\phi up to first-order derivatives. For vanishing sources this equation is Laplace\u2019s equation. If AC \u2212 B^2 = 0 AC \u2212 B^2 = 0 , then we can find a coordinate transformation that brings equation into the parabolic. An example of a parabolic equation is the diffusion equation, \\partial _ { t } \\phi - \\partial _ { x } \\left( \\kappa \\partial _ { x } \\phi \\right) = \\rho \\partial _ { t } \\phi - \\partial _ { x } \\left( \\kappa \\partial _ { x } \\phi \\right) = \\rho where \\kappa \\kappa is the diffusion coefficient. Finally, if AC \u2212 B^2 < 0 AC \u2212 B^2 < 0 , then we can find a coordinate transformation that brings equation into the hyperbolic. The prototypical example of a hyperbolic equation is the wave equation, \\partial _ { t } ^ { 2 } \\phi - c ^ { 2 } \\partial _ { x } ^ { 2 } \\phi = \\rho \\partial _ { t } ^ { 2 } \\phi - c ^ { 2 } \\partial _ { x } ^ { 2 } \\phi = \\rho where c is the constant wave speed. The different types of partial differential equations require different kinds of boundary and/or initial conditions. The differential equations then tell us how these initial fields evolve with time. We may also have to impose spatial boundary conditions on the outer boundaries of our computational domain. Elliptic equations, on the other hand, determine a solution on a given spatial hypersurface. No initial data are required, but we must supply boundary values at the outer edge(s) of our computational domain. Boundary conditions can take various forms. For example, Dirichlet conditions specify the values of the solution functions on the boundary, while Neumann conditions specify their gradients on the boundary. We introduce the first time derivative of \\phi \\phi as a new independent variable, say \u2212k \u2212k , in which case we can rewrite the wave equation as the pair of equations \\begin{aligned} \\partial _ { t } \\phi & = - k \\\\ \\partial _ { t } k & = - c ^ { 2 } \\partial _ { x } ^ { 2 } \\phi - \\rho \\end{aligned} \\begin{aligned} \\partial _ { t } \\phi & = - k \\\\ \\partial _ { t } k & = - c ^ { 2 } \\partial _ { x } ^ { 2 } \\phi - \\rho \\end{aligned} The form is not a particularly elegant representation of a wave equation, since it contains first order time derivatives but second order space derivatives. We can fix that quite easily by also introducing the space derivative of \\phi \\phi as a new independent variable. With l \\equiv \\partial _ { x } \\phi l \\equiv \\partial _ { x } \\phi we now find the system \\begin{array} { l l } { \\partial _ { t } \\phi } & { = - k } \\\\ { \\partial _ { t } k + c ^ { 2 } \\partial _ { x } l } & { = - \\rho } \\\\ { \\partial _ { t } l } & { + \\partial _ { x } k } & { = 0 } \\end{array} \\begin{array} { l l } { \\partial _ { t } \\phi } & { = - k } \\\\ { \\partial _ { t } k + c ^ { 2 } \\partial _ { x } l } & { = - \\rho } \\\\ { \\partial _ { t } l } & { + \\partial _ { x } k } & { = 0 } \\end{array} where the last equation holds because the partial derivatives must commute. In a more compact notation we can write this as \\partial _ { t } \\mathbf { u } + \\mathbf { A } \\cdot \\partial _ { x } \\mathbf { u } = \\mathbf { S } \\partial _ { t } \\mathbf { u } + \\mathbf { A } \\cdot \\partial _ { x } \\mathbf { u } = \\mathbf { S } where u = (\u03c6, k, l) u = (\u03c6, k, l) is the solution vector, S = (\u2212k, \u2212\u03c1, 0) S = (\u2212k, \u2212\u03c1, 0) is the source vector, and where \\mathbf { A } = \\left( \\begin{array} { c c c } { 0 } & { 0 } & { 0 } \\\\ { 0 } & { 0 } & { c ^ { 2 } } \\\\ { 0 } & { 1 } & { 0 } \\end{array} \\right) \\mathbf { A } = \\left( \\begin{array} { c c c } { 0 } & { 0 } & { 0 } \\\\ { 0 } & { 0 } & { c ^ { 2 } } \\\\ { 0 } & { 1 } & { 0 } \\end{array} \\right) is the velocity matrix. Verify that any function \\phi = g ( x + c t ) + h ( x - c t ) \\phi = g ( x + c t ) + h ( x - c t ) satisfies the wave equation for \u03c1 = 0. Part of the solution \u03c6, namely g, travels along lines x + ct = const x + ct = const , while the other part h travels along x \u2212 ct = const x \u2212 ct = const . These lines are called the characteristic curves; they are those curves along which partial information about the solution propagates. Even if we cannot derive the general solution analytically, we can find the corresponding characteristic speeds dx/dt dx/dt from the eigenvalues of the velocity matrix A. In our example, these eigenvalues are \u00b1c \u00b1c and zero, as we would expect. Since no information can travel faster than the fastest characteristics, the solution at a certain event can only be affected by those events that lie inside the causal past, or past cone defined by the fastest ingoing and outgoing characteristics. In the context of relativity we are quite used to this concept, since causality demands that an event can only be affected by events in its past light cone. Consider the event Q, whose past characteristics are marked by solid lines. To completely determine \u03c6(t,r) \u03c6(t,r) at Q, we would have to provide initial data \u03c6(0,r) \u03c6(0,r) and \u2202_t\u03c6(0,r) \u2202_t\u03c6(0,r) inside the past cone defined by the two backward characteristics, namely on the interval \u03b3_Q \u03b3_Q . This is the domain of dependence of the point Q. In reverse, for any interval \u03b3 \u03b3 on the r-axis, there is a region of the spacetime in which all events depend only on initial data provided on \u03b3. This region is called the domain of determinacy. Suppose we want to obtain a solution to the wave equation. We will have to provide initial data on an interval \u03b3 \u03b3 that extends from a certain radius r_{min} r_{min} to a radius r_{max} r_{max} at, say, t = 0 t = 0 . If we want to construct the solution only in the domain of determinacy of \u03b3, then the solution is completely determined by the initial data on \u03b3, and no boundary conditions are needed. This situation, however, is rarely the case. It is more typical that we would like to construct the solution in the entire domain between r_{min} r_{min} and r_{max} r_{max} for all t > 0 t > 0 . For concreteness, imagine we want to find \u03c6 in the domain between r_{min}/M = 1 r_{min}/M = 1 and r_{max}/M = 9 r_{max}/M = 9 , marked by the dashed-dotted lines in Fig. 6.1. The event Q would still be completely determined by the initial data, but the event S, for example, would not. One of its backward characteristics intersects the outer boundary at r_{max}/M = 9 r_{max}/M = 9 . The event S is therefore outside the domain of determinacy of \u03b3, and the solution at S depends on more information than is provided by the initial data. This missing information now has to be provided by the boundary conditions. The situation is different at the inner boundary r_{min} r_{min} . Consider, for example, the event P, which lies on the boundary r_{min} r_{min} . Since we have chosen r_{min} r_{min} to be inside the event horizon, both characteristics originate from a larger r, and neither one intersects the boundary r_{min} r_{min} . The event P is therefore completely determined by the initial data (and, had we chosen P at a later time, by the outer boundary condition at r_{max} r_{max} ). There is no need to impose a boundary condition at r_{min} r_{min} , and in fact it would be inconsistent with the equations. This property will be important when we discuss black hole. Black Hole Horizons Several different notions of horizons exist in general relativity. The defining property of a black hole is the presence of an event horizon, but apparent horizons also play an extremely important role in the context of numerical relativity. In addition, the concepts of isolated and dynamical horizons serve as useful diagnostics in numerical spacetimes containing black holes. A black hole is defined as a region of spacetime from which no null geodesic can escape to infinity. The surface of a black hole, the event horizon, acts as a one-way membrane through which light and matter can enter the black hole, but once inside, can never escape. It is the boundary in spacetime separating those events that can emit light rays that can propagate to infinity and those which cannot. More precisely, the event horizon is defined as the boundary of the causal past of future null infinity. The event horizon is a gauge-invariant entity, and contains important geometric information about a black hole spacetime. The area theorem2 of classical general relativity states that this surface area can never decrease in time, \\delta \\mathcal { A } \\geq 0 \\delta \\mathcal { A } \\geq 0 Two-dimensional surface, whose proper surface area we denote as \\mathcal { A } \\mathcal { A } . In the collision and coalescence of two or more black holes, the surface area of the remnant black hole must be greater than the sum of the progenitor black holes. The fact that the event horizon area cannot decrease motivates the definition of the irreducible mass. M _ { \\mathrm { irr } } \\equiv \\left( \\frac { \\mathcal { A } } { 16 \\pi } \\right) ^ { 1 / 2 } M _ { \\mathrm { irr } } \\equiv \\left( \\frac { \\mathcal { A } } { 16 \\pi } \\right) ^ { 1 / 2 } It is possible to extract energy and angular momentum from a rotating Kerr black hole. While such an interaction can reduce the black hole\u2019s mass, it cannot reduce its area, according to the area theorem. The irreducible mass of the black hole cannot decrease, which motivates its name. The area theorem can be used to place a strict upper limit on the amount of energy that is emitted in gravitational radiation in black hole collisions. Consider two widely separated, non-rotating black holes of masses M_1 M_1 and M_2 M_2 , initially at rest with respect to some distant observer. Use the area theorem to find an upper limit on the energy emitted in gravitational radiation that arises from the head-on collision of the two black holes. Verify that for equal mass black holes at most 29% 29% of the total initial energy can be emitted in gravitational radiation. Given the irreducible mass M_{irr} M_{irr} and the angular momentum J J of an isolated, stationary black hole, we can compute the Kerr mass M (= M_{ADM}) M (= M_{ADM}) from M ^ { 2 } = M _ { \\mathrm { irr } } ^ { 2 } + \\frac { 1 } { 4 } \\frac { J ^ { 2 } } { M _ { \\mathrm { irr } } ^ { 2 } } M ^ { 2 } = M _ { \\mathrm { irr } } ^ { 2 } + \\frac { 1 } { 4 } \\frac { J ^ { 2 } } { M _ { \\mathrm { irr } } ^ { 2 } } While the event horizon has some very interesting geometric properties, its global nature makes it very difficult to locate in a numerical simulation. The reason is that knowledge of the entire future spacetime is required to decide whether or not any particular null geodesic will ultimately escape to infinity . In numerical simulations an event horizon can be found only \u201cafter the fact\u201d, i.e., after the evolution has proceeded long enough to have settled down to a stationary state. The spacetime singularities inside the black holes must be excluded from the numerical grid, since they would otherwise spoil the numerical calculation. Several different strategies for avoiding black hole singularities numerically. One approach is based on the realization that, by definition, the interior of a black hole is causally disconnected from, and hence can never influence, the exterior. This fact suggests that we may \u201cexcise\u201d, i.e. remove from the computational domain, the spacetime region inside the event horizon. Black hole \u201cexcision\u201d requires at least approximate knowledge of the location of the horizon at all times during the evolution. The singularity theorems of general relativity tell us that if an apparent horizon exists on a given time slice, it must be inside a black hole event horizon. This theorem makes it safe to excise the interior of an apparent horizon from a numerical domain. Note the absence of an apparent horizon does not necessarily imply that a black hole is absent. Finite Difference Methods In a finite difference approximation a function f(t,x) f(t,x) is represented by values at a discrete set of points. At the core of finite difference approximation is therefore a discretization of the spacetime, or a numerical grid. Instead of evaluating f at all values of x, for example, we only consider discrete values x_i x_i . The distance between the gridpoints x_i x_i is called the gridspacing \u2206x \u2206x . For uniform grids, for which \u2206x \u2206x is constant, we have x _ { i } = x _ { 0 } + i \\Delta x x _ { i } = x _ { 0 } + i \\Delta x If the solution depends on time we also discretize the time coordinate, for example as t ^ { n } = t ^ { 0 } + n \\Delta t t ^ { n } = t ^ { 0 } + n \\Delta t The finite difference representation of the function f(t,x) f(t,x) , for example, is f _ { i } ^ { n } = f \\left( t ^ { n } , x _ { i } \\right) + \\text { truncation error. } f _ { i } ^ { n } = f \\left( t ^ { n } , x _ { i } \\right) + \\text { truncation error. } Differential equations involve derivatives, so we must next discuss how to represent derivatives in a finite difference representation. Assuming that f(x) f(x) can be differentiated to sufficiently high order and that it can be represented as a Taylor series, we have f _ { i + 1 } = f \\left( x _ { i } + \\Delta x \\right) = f \\left( x _ { i } \\right) + \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) f _ { i + 1 } = f \\left( x _ { i } + \\Delta x \\right) = f \\left( x _ { i } \\right) + \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) Solving for \\left( \\partial _ { x } f \\right) _ { x _ { i } } = \\left( \\partial _ { x } f \\right) _ { i } \\left( \\partial _ { x } f \\right) _ { x _ { i } } = \\left( \\partial _ { x } f \\right) _ { i } we find \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i } } { \\Delta x } + \\mathcal { O } ( \\Delta x ) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i } } { \\Delta x } + \\mathcal { O } ( \\Delta x ) The truncation error of this expression is linear in \u2206x \u2206x , and it turns out that we can do better. We call equation a one-sided derivative , since it uses only neighbors on one side of x_i x_i . Consider the Taylor expansion to the point x_{ i \u2212 1 } x_{ i \u2212 1 } , f _ { i - 1 } = f \\left( x _ { i } - \\Delta x \\right) = f \\left( x _ { i } \\right) - \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) f _ { i - 1 } = f \\left( x _ { i } - \\Delta x \\right) = f \\left( x _ { i } \\right) - \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) we now find \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i - 1 } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i - 1 } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) which is second order in \u2206x \u2206x . In general, centered derivatives lead to higher order schemes than one-sided derivatives for the same number of gridpoints. The key point is that we are able to combine the two Taylor expansions in such a way that the leading order error term cancels out, leaving us with a higher order representation of the derivative . This cancellation only works out for uniform grids , when \u2206x \u2206x is independent of x. This is one of the reasons why many current numerical relativity applications of finite difference schemes work with uniform grids. Higher order derivatives can be constructed in a similar fashion. Adding the two Taylor expansions all terms odd in \u2206x \u2206x drop out and we find for the second derivative \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } } { ( \\Delta x ) ^ { 2 } } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } } { ( \\Delta x ) ^ { 2 } } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { 1 } { 12 \\Delta x } \\left( f _ { i - 2 } - 8 f _ { i - 1 } + 8 f _ { i + 1 } - f _ { i + 2 } \\right) \\\\ \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { 1 } { 12 ( \\Delta x ) ^ { 2 } } \\left( - f _ { i - 2 } + 16 f _ { i - 1 } - 30 f _ { i } + 16 f _ { i + 1 } - f _ { i + 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { 1 } { 12 \\Delta x } \\left( f _ { i - 2 } - 8 f _ { i - 1 } + 8 f _ { i + 1 } - f _ { i + 2 } \\right) \\\\ \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { 1 } { 12 ( \\Delta x ) ^ { 2 } } \\left( - f _ { i - 2 } + 16 f _ { i - 1 } - 30 f _ { i } + 16 f _ { i + 1 } - f _ { i + 2 } \\right) where we have omitted the truncation error, \\mathcal { O } \\left( \\Delta x ^ { 4 } \\right) \\mathcal { O } \\left( \\Delta x ^ { 4 } \\right) Elliptic Equations As an example of a simple, one-dimensional elliptic equation consider \\partial _ { x } ^ { 2 } f = s \\partial _ { x } ^ { 2 } f = s For concreteness, let us assume that the solution f is a symmetric function about x = 0 x = 0 , in which case we can restrict the analysis to positive x and impose a Neuman condition at the origin, \\partial _ { x } f = 0 \\quad \\text { at } x = 0 \\partial _ { x } f = 0 \\quad \\text { at } x = 0 Let us also assume that f falls off with 1/x 1/x for large x, which results in the Robin boundary condition \\partial _ { x } ( x f ) = 0 \\quad \\text { as } x \\rightarrow \\infty \\partial _ { x } ( x f ) = 0 \\quad \\text { as } x \\rightarrow \\infty We will further assume that the source term s is some known function of x. To do so, we first have to construct a numerical grid that covers an interval between x_{min} = 0 x_{min} = 0 and x_{max} x_{max} . We then divide the interval [x_{min},x_{max}] [x_{min},x_{max}] into N gridcells, leading to a gridspacing of \\Delta x = \\frac { x _ { \\max } - x _ { \\min } } { N } \\Delta x = \\frac { x _ { \\max } - x _ { \\min } } { N } We can choose our grid points to be located either at the center of these cells, which would be referred to as a cell-centered grid, or on the vertices, which would be refered to as a vertex-centered grid. For a cell-centered grid we have N grid points located at x _ { i } = x _ { \\min } + ( i - 1 / 2 ) \\Delta x , \\quad i = 1 , \\ldots , N x _ { i } = x _ { \\min } + ( i - 1 / 2 ) \\Delta x , \\quad i = 1 , \\ldots , N We define two arrays, f_i f_i and s_i s_i , which represent the functions f and s at the gridpoints x_i x_i for i = 1, ..., N i = 1, ..., N . In the interior of our domain we can represent the differential equation as f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } = ( \\Delta x ) ^ { 2 } s _ { i } \\quad i = 2 , \\ldots , N - 1 f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } = ( \\Delta x ) ^ { 2 } s _ { i } \\quad i = 2 , \\ldots , N - 1 The boundary condition \\left( \\partial _ { x } f \\right) _ { 1 / 2 } = \\frac { f _ { 1 } - f _ { 0 } } { \\Delta x } = 0 \\\\ f _ { N + 1 } = \\frac { x _ { N } } { x _ { N + 1 } } f _ { N } = \\frac { x _ { N } } { x _ { N } + \\Delta x } f _ { N } \\left( \\partial _ { x } f \\right) _ { 1 / 2 } = \\frac { f _ { 1 } - f _ { 0 } } { \\Delta x } = 0 \\\\ f _ { N + 1 } = \\frac { x _ { N } } { x _ { N + 1 } } f _ { N } = \\frac { x _ { N } } { x _ { N } + \\Delta x } f _ { N } a coupled set of N linear equations for the N elements f_i f_i that we can write as \\left( \\begin{array} { c c c c c c c } { - 1 } & { 1 } & { 0 } & { 0 } & { 0 } & { 0 } & { 0 } \\\\ { 1 } & { - 2 } & { 1 } & { 0 } & { 0 } & { 0 } & { 0 } \\\\ { 0 } & { \\ddots } & { \\ddots } & { \\ddots } & { 0 } & { 0 } & { 0 } \\\\ { 0 } & { 0 } & { 1 } & { - 2 } & { 1 } & { 0 } & { 0 } \\\\ { 0 } & { 0 } & { 0 } & { \\ddots } & { \\ddots } & { \\ddots } & { 0 } \\\\ { 0 } & { 0 } & { 0 } & { 0 } & { 1 } & { - 2 } & { 1 } \\\\ { 0 } & { 0 } & { 0 } & { 0 } & { 0 } & { 1 } & { x _ { N } / \\left( x _ { N } + \\Delta x \\right) - 2 } \\end{array} \\right) \\left( \\begin{array} { c } { f _ { 1 } } \\\\ { f _ { 2 } } \\\\ { \\vdots } \\\\ { f _ { i } } \\\\ { \\vdots } \\\\ { f _ { N - 1 } } \\\\ { f _ { N } } \\end{array} \\right) = ( \\Delta x ) ^ { 2 } \\left( \\begin{array} { c } { s _ { 1 } } \\\\ { s _ { 2 } } \\\\ { \\vdots } \\\\ { s _ { i } } \\\\ { \\vdots } \\\\ { s _ { N - 1 } } \\\\ { s _ { N } } \\end{array} \\right) \\left( \\begin{array} { c c c c c c c } { - 1 } & { 1 } & { 0 } & { 0 } & { 0 } & { 0 } & { 0 } \\\\ { 1 } & { - 2 } & { 1 } & { 0 } & { 0 } & { 0 } & { 0 } \\\\ { 0 } & { \\ddots } & { \\ddots } & { \\ddots } & { 0 } & { 0 } & { 0 } \\\\ { 0 } & { 0 } & { 1 } & { - 2 } & { 1 } & { 0 } & { 0 } \\\\ { 0 } & { 0 } & { 0 } & { \\ddots } & { \\ddots } & { \\ddots } & { 0 } \\\\ { 0 } & { 0 } & { 0 } & { 0 } & { 1 } & { - 2 } & { 1 } \\\\ { 0 } & { 0 } & { 0 } & { 0 } & { 0 } & { 1 } & { x _ { N } / \\left( x _ { N } + \\Delta x \\right) - 2 } \\end{array} \\right) \\left( \\begin{array} { c } { f _ { 1 } } \\\\ { f _ { 2 } } \\\\ { \\vdots } \\\\ { f _ { i } } \\\\ { \\vdots } \\\\ { f _ { N - 1 } } \\\\ { f _ { N } } \\end{array} \\right) = ( \\Delta x ) ^ { 2 } \\left( \\begin{array} { c } { s _ { 1 } } \\\\ { s _ { 2 } } \\\\ { \\vdots } \\\\ { s _ { i } } \\\\ { \\vdots } \\\\ { s _ { N - 1 } } \\\\ { s _ { N } } \\end{array} \\right) or, in a more compact form, \\mathbf { A } \\cdot \\mathbf { f } = ( \\Delta x ) ^ { 2 } \\mathbf { S } \\mathbf { A } \\cdot \\mathbf { f } = ( \\Delta x ) ^ { 2 } \\mathbf { S } The solution is given by \\mathbf { f } = ( \\Delta x ) ^ { 2 } \\mathbf { A } ^ { - 1 } \\cdot \\mathbf { S } \\mathbf { f } = ( \\Delta x ) ^ { 2 } \\mathbf { A } ^ { - 1 } \\cdot \\mathbf { S } Sticking with our example in **two dimension**s, another multigrid methods becomes apparent. The numerical solution is computed on a hierarchy of computational grids. The coarse grid is sufficiently small so that we can compute a solution with a direct solver (i.e. direct matrix inversion). This provides the \u201cglobal\u201d features of the solution , albeit on a coarse grid and hence with a large local truncation error. We then interpolate this approximate solution to the next finer grid . This interpolation from a coarser grid to a finer grid is called a \u201cprolongation\u201d , and we point out that the details of this interpolation depend on whether the grid is cell-centered or vertex-centered. On the finer grid we can then apply a relaxation method. The interpolation from a finer grid to a coarser grid is called a \u201crestriction\u201d . The coarser grids now \u201clearn\u201d from the finer grids by comparing their last solution with the one that comes back from a finer grid. This comparison provides an estimate for the local truncation error. These sweeps through the grid hierarchy can be repeated until the solution has converged to a pre-determined accuracy . f _ { i , j } = \\frac { 1 } { 4 } \\left( f _ { i + 1 , j } + f _ { i - 1 , j } + f _ { i , j + i } + f _ { i , j - 1 } \\right) - \\frac { \\Delta ^ { 2 } } { 4 } s _ { i , j } f _ { i , j } = \\frac { 1 } { 4 } \\left( f _ { i + 1 , j } + f _ { i - 1 , j } + f _ { i , j + i } + f _ { i , j - 1 } \\right) - \\frac { \\Delta ^ { 2 } } { 4 } s _ { i , j } Evidently, finite differencing the flat-space Laplace operator results in each grid function at every grid point being directly related to the average value of its nearest neighbors. nonlinear elliptic equations Consider an equation of the form \\nabla ^ { 2 } f = f ^ { n } g \\nabla ^ { 2 } f = f ^ { n } g where g is a given function and n is some number. Linear equations that are straighforward to solve by the same matrix techniques. But what about the situation for other values of n, resulting in a nonlinear equation for f? We linearize the equation first and then iterate to get the nonlinear solution. Hyperbolic Equations As a model of hyperbolic equations, consider a \u201cscalar\u201d version of equation. For simplicity it does not contain any source terms, and the the wave speed v is constant. \\partial _ { t } u + v \\partial _ { x } u = 0 \\partial _ { t } u + v \\partial _ { x } u = 0 The equation is satisfied exactly by any function of the form u ( t , x ) = u ( x - v t ) u ( t , x ) = u ( x - v t ) . In contrast to the elliptic equations the equation has a time derivative in addition to the space derivative, and thus requires initial data . Inserting both finite-difference representations \\left( \\partial _ { x } u \\right) _ { j } ^ { n } = \\frac { u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\\\ \\left( \\partial _ { t } u \\right) _ { j } ^ { n } = \\frac { u _ { j } ^ { n + 1 } - u _ { j } ^ { n } } { \\Delta t } + \\mathcal { O } ( \\Delta t ) \\left( \\partial _ { x } u \\right) _ { j } ^ { n } = \\frac { u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\\\ \\left( \\partial _ { t } u \\right) _ { j } ^ { n } = \\frac { u _ { j } ^ { n + 1 } - u _ { j } ^ { n } } { \\Delta t } + \\mathcal { O } ( \\Delta t ) we can solve for u^{n+1}_j u^{n+1}_j and find u _ { j } ^ { n + 1 } = u _ { j } ^ { n } - \\frac { v } { 2 } \\frac { \\Delta t } { \\Delta x } \\left( u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } \\right) u _ { j } ^ { n + 1 } = u _ { j } ^ { n } - \\frac { v } { 2 } \\frac { \\Delta t } { \\Delta x } \\left( u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } \\right) or reasons that are quite obivous this differencing scheme is called forward-time centered-space, or FTCS. The Courant-Friedrichs-Lewy condition \\frac { | v | \\Delta t } { \\Delta x } \\leq 1 \\frac { | v | \\Delta t } { \\Delta x } \\leq 1 The Courant condition states that the the grid point u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } at the new time level n+1 has to reside inside the domain of determinacy of the interval spanned by the finite difference stencil at the time level n. This makes intuitive sense: if u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } were outside this domain, its physical specification would require more information about the past than we are providing numerically, which may trigger an instability. Recalling that v represents the speed of a characteristic, we may interpret the Courant condition in terms of the domain of determinacy. Mesh Refinement Many current numerical relativity codes use a uniform grid spacing to cover the entire spatial domain. On the one hand we have to resolve these sources well, so as to minimize truncation error in the strong-field region. On the other hand, the grid must extend into the weak-field region at large distances from the sources, so as to minimize error from the outer boundaries and to enable us to extract the emitted gravitational radiation accurately. A very promising alternative is mesh refinement, which has been widely developed and used in the computational fluid dynamics community and is becoming increasingly popular in numerical relativity. The basic idea underlying mesh refinement techniques is to perform the simulation not on one numerical grid, but on several , as in the multigrid methods. A coarse grid covers the entire space, and extends to large physical separations. Wherever finer resolution is needed to resolve small-scale structures. Typically, the gridspacing on the finer grid is half that on the next coarser grid, but clearly other refinement factors can be chosen. The hierarchy can be extended, and typical mesh refinement applications employ multiple refinement levels . Two versions of mesh refinement can be implemented. In the simpler version, called fixed mesh refinement or FMR , it is assumed that the refined grids will be needed only at known locations in space that remain fixed throughout the simulation. The situation is more complicated for objects that are moving, as is the case for a coalescing binary star system. Moreover, these regions will be changing as the system evolves and the stars move. Clearly, we would like to move the refined grids with the stars. Such an approach, whereby the grid is relocated during the simulation to give optimal resolution at each time step, is called adaptive mesh refinement or AMR . Example Spherically Symmetric Spacetimes Non-rotating stars and black holes are themselves spherical, so many important aspects of gravitational collapse, including black hole formation and growth, can be studied in spherical symmetry. For example, the numerical study of spherically symmetric collapse to black holes led to the discovery of critical phenomena in black hole formation. The field equations reduce to 1+1 dimensions \u2013 variables may be written as functions of only two parameters, a time coordinate t and a suitable radial coordinate r. The high degree of symmetry permits us to write the 3-metric of a spherical spacetime in the general form d l ^ { 2 } = A d r ^ { 2 } + B r ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) d l ^ { 2 } = A d r ^ { 2 } + B r ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) where A and B are functions only of t and r. Rotation cannot be treated in spherical symmetry. Spinning stars, star clusters and black holes, rotational instabilities in stars and star clusters, relativistic effects induced by the dragging of inertial frames \u2013 none of these features are present in spherical symmetry. Moreover, gravitational radiation cannot be generated in spherical spacetimes: Birkhoff\u2019s theorem forbids it. We thus will have to postpone studying rotation and gravitational wave generation until we relax the restriction to spherical symmetry and advance to axisymmetry. In axisymmetry, spacetime has 2+1 dimensions \u2013 two spatial coordinates, e.g., r and a polar angle \u03b8, plus t are necessary to specify the value of any function.","title":"Numerical Relativity"},{"location":"NR/#numerical-relativity","text":"For all but the simplest systems, analytic solutions for the evolution of such systems do not exist . Hence the task of solving Einstein's equations must be performed numerically on a computer . In classical dynamics, the evolution of a system is uniquely determined by the initial positions and velocities of its constituents. By analogy, the evolution of general relativistic gravitational field is determined by specifying the metric quantities g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} at a given (initial) instant of time t . Now these metric quantities can be integrated forward in time provided we can obtain from the Einstein field equations expressions for \\partial^2_t g_{ab} \\partial^2_t g_{ab} at all points on the hypersurface . That way we can integrate these expressions to compute g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} on a new spacelike hypersurface at some new time t + \\delta t t + \\delta t , and then, by repeating the process, obtain g_{ab} g_{ab} for all other points x^0 x^0 and x^i x^i in the (future) spacetime.","title":"Numerical Relativity"},{"location":"NR/#complications","text":"The equations that arise in numerical relativity are typically multidimensional, nonlinear, coupled partial differential equations in space and time . They have in common with other areas of computational physics, like magnetohydrodynamics. However, solving Einstein\u2019s equations poses some additional complications that are unique to general relativity. In general relativity, coordinates are merely labels that distinguish points in spacetime; by themselves coordinate intervals have no physical significance. To use coordinate intervals to determine physically measurable proper distances and proper times requires the spacetime metric, but the metric is known only after Einstein\u2019s equations have been solved . Moreover, as the numerical integrations that determine the metric proceed, it often turns out that the original, arbitrary choice of coordinates turns out to be bad, because, for example, singularities appear in the equations. Encountering such singularities , be they physical or coordinate, results in some of the terms in Einstein\u2019s equations becoming infinite, potentially causing overflows in the computer output and premature termination of the numerical integration . Treating black holes is one of the main goals of numerical relativity, but this poses another complication. The reason is that black holes contain physical spacetime singularities \u2013 regions where the gravitational tidal field, the matter density and the spacetime curvature all become infinite. Thus, when dealing with black holes, it is crucial to choose a computational technique that avoids encountering their interior spacetime singularities in the course of the simulation . Another complication arises in the context of one of the most pressing goals of numerical relativity \u2013 the calculation of waveforms from promising astrophysical sources of gravitational radiation. These theoretical templates are essential for the identification and physical interpretation of gravitational wave sources. However, the gravitational wave components of the spacetime metric usually constitute small fractions of the smooth background metric. Moreover, to extract the waves from the background in a simulation requires that one probe the numerical spacetime in the far-field, or radiation, zone, which is typically at large distance from the strong-field central source. Yet it is the strong-field region which usually consumes most the computational resources (e.g. spatial resolution) to guarantee accuracy. Furthermore, waiting for the wave to propagate to the far-field region usually takes nonnegligible integration time. Oppenheimer-Snyder The Oppenheimer-Snyder, or OS, solution illustrates many generic features of gravitational collapse and black hole formation. Since the solution is analytic, it is simple to work with and is often used to test and calibrate numerical codes designed to deal with more complicated cases.","title":"Complications"},{"location":"NR/#31-decomposition","text":"Cauchy problem This is a fundamental problem arising in the mathematical theory of partial differential equations. The Bianchi identities \\nabla_b G^{ab} = 0 \\nabla_b G^{ab} = 0 give \\partial_t G^{a0} = - \\partial_i G^{ai} - G^{bc} \\Gamma^a_{bc} - G^{ab} \\Gamma^c_{bc} \\partial_t G^{a0} = - \\partial_i G^{ai} - G^{bc} \\Gamma^a_{bc} - G^{ab} \\Gamma^c_{bc} Since no term on the right hand side of equation contains third time derivatives or higher, the four quantities G^{a0} G^{a0} cannot contain second time derivatives. Hence the four equations G^{a0} = 8 \\pi T^{a0} G^{a0} = 8 \\pi T^{a0} do not furnish any of the information required for the dynamical evolution of the fields. Rather, they supply four constraints on the initial data, i.e. four relations between g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} on the initial hypersurface at x^0 = t x^0 = t . The only truly dynamical equations must be provided by the six remaining relations G^{ij} = 8 \\pi T^{ij} G^{ij} = 8 \\pi T^{ij} It is not surprising that there is a mismatch between the required number (10) of second time 2 derivatives \\partial_t^2 g_{ab} \\partial_t^2 g_{ab} and the available number (6) of dynamical \ufb01eld equations. After all, there is always a fourfold ambiguity associated with the freedom to choose four different coordinates to label points in spacetime. So, for example, we could always choose Gaussian normal coordinates and set $g_{00} = \u22121 $ and g_{0i} = 0 g_{0i} = 0 . The Cauchy problem in general relativity logically involves a decomposition of four-dimensional spacetime into three dimensional space and one-dimensional time . Cauchy surface Cauchy surface is a plane in space-time which is like an instant of time; its significance is that giving the initial conditions on this plane determines the future (and the past) uniquely. The 3+1 equations are entirely equivalent to the usual \ufb01eld equations but they focus on the evolution of 12 purely spatial quantities closely related to g_{ij} g_{ij} and \\partial_t g_{ij} \\partial_t g_{ij} and the constraints that they must satisfy on spatial hypersurfaces. Once these spatial \ufb01eld quantities are specified on some initial \u201ctime slice\u201d (i.e. spatial hypersurface) consistent with the 3 + 1 constraint equations, the 3 + 1 evolution equations can then be integrated, together with evolution equations for the matter sources, to determine these \ufb01eld quantities at all later times. The 3+1 formalism 4 constraint equations that contain no time derivatives but provide relations between the spatial \ufb01eld quantities and their matter sources that must be satis\ufb01ed on any time slice. A convenient set of 12 coupled, first-order, time-evolution equations for the spatial \ufb01eld variables in terms of \ufb01eld and source quantities residing on the slice. Analogy Maxwell\u2019s equations \\begin{array} { l } { D _ { i } E ^ { i } - 4 \\pi \\rho = 0 } \\\\ D _ { i } B ^ { i } = 0 \\end{array} \\begin{array} { l } { D _ { i } E ^ { i } - 4 \\pi \\rho = 0 } \\\\ D _ { i } B ^ { i } = 0 \\end{array} The above equations involve only spatial derivatives of the electric and magnetic fields and hold at each instant of time independently of the prior or subsequent evolution of the fields. They therefore constrain any possible configurations of the fields, and are correspondingly called the constraint equations. \\begin{aligned} \\partial _ { t } E _ { i } & = \\epsilon _ { i j k } D ^ { j } B ^ { k } - 4 \\pi j _ { i } \\\\ \\partial _ { t } B _ { i } & = - \\epsilon _ { i j k } D ^ { j } E ^ { k } \\end{aligned} \\begin{aligned} \\partial _ { t } E _ { i } & = \\epsilon _ { i j k } D ^ { j } B ^ { k } - 4 \\pi j _ { i } \\\\ \\partial _ { t } B _ { i } & = - \\epsilon _ { i j k } D ^ { j } E ^ { k } \\end{aligned} These equations describe how the fields evolve forward in time, and are therefore called the evolution equations. To completely determine the time evolution of the electromagnetic fields we also have to specify how the sources \u03c1 and j^i j^i evolve according to the net force acting on them. It is possible to bring Maxwell\u2019s equations into a form that is closer to the 3+1 form of Einstein\u2019s equations. To do so, we introduce the vector potential A ^ { a } = \\left( \\Phi , A ^ { i } \\right) A ^ { a } = \\left( \\Phi , A ^ { i } \\right) and write B^i B^i as B _ { i } = \\epsilon _ { i j k } D ^ { j } A ^ { k } B _ { i } = \\epsilon _ { i j k } D ^ { j } A ^ { k } By construction, B_i B_i automatically satisfies the constraint D _ { i } B ^ { i } = 0 D _ { i } B ^ { i } = 0 . The two evolution equations can be rewritten in terms of E_i E_i and A_i A_i \\begin{aligned} \\partial _ { t } A _ { i } & = - E _ { i } - D _ { i } \\Phi \\\\ \\partial _ { t } E _ { i } & = D _ { i } D ^ { j } A _ { j } - D ^ { j } D _ { j } A _ { i } - 4 \\pi j _ { i } \\end{aligned} \\begin{aligned} \\partial _ { t } A _ { i } & = - E _ { i } - D _ { i } \\Phi \\\\ \\partial _ { t } E _ { i } & = D _ { i } D ^ { j } A _ { j } - D ^ { j } D _ { j } A _ { i } - 4 \\pi j _ { i } \\end{aligned} With the vector potential A_i A_i we have introduced a gauge freedom into electrodynamics which is expressed in the freely specifiable gauge variable \u03a6 \u03a6 . The initial value problem in electrodynamics can now be solved in two steps. In the first step, initial data ( A_i A_i , E_i E_i ), together with the sources (\u03c1, j_i j_i ), are specified that satisfy the constraint equations. In the second step, these fields are evolved according to the evolution equations. Before the evolution equations can be solved, a suitable gauge condition has to be chosen . The standard 3 + 1 equations are sometimes referred to as the \u201cADM equations\u201d. Einstein\u2019s equations can be split into a set of constraint and evolution equations To specify gravitational fields (\\gamma_{ij}, K_{ij}) (\\gamma_{ij}, K_{ij}) on some initial spatial slice \u03a3 . These fields can then be used as \u201cstarting values\u201d. the spatial metric \\gamma_{ij} \\gamma_{ij} , the extrinsic curvature K_{ij} K_{ij} and any matter fields have to satisfy the the constraint equations. Contracting Gauss\u2019 equation $$ R + K^2 - K_{ij}K^{ij} = 16 \\pi \\rho $$ Contracting the Codazzi equation $$ D_j (K^{ij} - \\gamma^{ij} K) = 8 \\pi S^i $$ The constraint equations contain no time derivatives and relate \ufb01eld quantities on a given t = constant spacelike hypersurface. The evolution equations contain first-order time derivatives that tell us how the \ufb01eld quantities change from one hypersurface to the next. If the \ufb01eld data (\\gamma_{ij}, K_{ij}) (\\gamma_{ij}, K_{ij}) satisfy the constraints at some time t and are evolved with the evolution equations, then the data will also satisfy the constraint equations at all later times. The goal of achieving numerically stable computer solutions , especially when the absence of spatial symmetries requires us to work in all three spatial dimensions, has led to alternative formulations and to crucial modi\ufb01cations of the standard 3 + 1 equations .","title":"3+1 Decomposition"},{"location":"NR/#foliations-of-spacetime","text":"We assume that the spacetime (M, g_{ab}) (M, g_{ab}) can be foliated into a family of non-intersecting spacelike three-surfaces \u03a3, which arise, at least locally, as the level surfaces of a scalar function t that can be interpreted as a global time function. From t we can define the 1-form \\Omega _ { a } = \\nabla _ { a } t \\Omega _ { a } = \\nabla _ { a } t which is closed by construction, \\nabla _ { [ a } \\Omega _ { b ] } = \\nabla _ { [ a } \\nabla _ { b ] } t = 0 \\nabla _ { [ a } \\Omega _ { b ] } = \\nabla _ { [ a } \\nabla _ { b ] } t = 0 The 4-metric g_{ab} g_{ab} allows us to compute the norm of \\tilde{\u03a9} \\tilde{\u03a9} \udbff\udc1e, which we call - \\alpha ^ { - 2 } - \\alpha ^ { - 2 } \\| \\Omega \\| ^ { 2 } = g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t \\equiv - \\frac { 1 } { \\alpha ^ { 2 } } \\| \\Omega \\| ^ { 2 } = g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t \\equiv - \\frac { 1 } { \\alpha ^ { 2 } } \u03b1 \u03b1 measures how much proper time elapses between neighboring time slices along the normal vector \u03a9^a \u03a9^a to the slice, and is therefore called the lapse function. We assume that \u03b1 > 0 \u03b1 > 0 , so that \u03a9^a \u03a9^a is timelike and the hypersurface \u03a3 is spacelike everywhere. We can now define the unit normal to the slices as n ^ { a } \\equiv - g ^ { a b } \\alpha \\Omega _ { b } n ^ { a } \\equiv - g ^ { a b } \\alpha \\Omega _ { b } Here the negative sign has been chosen so that n^a n^a points in the direction of increasing t, and may therefore be thought of as the four-velocity of a \u201cnormal\u201d observer whose worldline is always normal to the spatial slices \u03a3.","title":"Foliations of Spacetime"},{"location":"NR/#the-spatial-metric-gamma_abgamma_ab","text":"With the normal vector we can construct the spatial metric \\gamma_{ab} \\gamma_{ab} that is induced by g_{ab} g_{ab} on the three-dimensional hypersurfaces \u03a3 \\gamma_{ab} = g_{ab} + n_a n_b \\gamma_{ab} = g_{ab} + n_a n_b Thus \\gamma_{ab} \\gamma_{ab} is a projection tensor that projects out all geometric objects lying along n^a n^a . This metric allows us to compute distances within a slice \u03a3. To see that \u03b3_{ab} \u03b3_{ab} is purely spatial, i.e., resides entirely in \u03a3 with no piece along n^a n^a , we contract it with the normal n^a n^a , n ^ { a } \\gamma _ { a b } = n ^ { a } g _ { a b } + n ^ { a } n _ { a } n _ { b } = n _ { b } - n _ { b } = 0 n ^ { a } \\gamma _ { a b } = n ^ { a } g _ { a b } + n ^ { a } n _ { a } n _ { b } = n _ { b } - n _ { b } = 0 We break up 4-dimensional tensors by decomposing them into a purely spatial part, which lies in the hypersurfaces \\Sigma \\Sigma , and a timelike part, which is normal to the spatial surface. To do so, we need two projection operators. The first one, which projects a 4-dimensional tensor into a spatial slice \\gamma^a_{\\space b} = g^a_{\\space b} + n^a n_b \\gamma^a_{\\space b} = g^a_{\\space b} + n^a n_b Similarly, we may define the normal projection operator as N^a_{\\space b} = - n^a n_b N^a_{\\space b} = - n^a n_b We can now use these two projection operators to decompose any tensor into its spatial and timelike parts. The three-dimensional metric only contains information about the curvature intrinsic to a slice \u03a3 , but it gives no information about what shape this slice takes in the spacetime M in which it is embedded. This information is contained in a tensor called extrinsic curvature . The three-dimensional covariant derivative can be expressed in terms of three-dimensional connection coefficients, which, in a coordinate basis, are given by \\Gamma _ { b c } ^ { a } = \\frac { 1 } { 2 } \\gamma ^ { a d } \\left( \\partial _ { c } \\gamma _ { d b } + \\partial _ { b } \\gamma _ { d c } - \\partial _ { d } \\gamma _ { b c } \\right) \\Gamma _ { b c } ^ { a } = \\frac { 1 } { 2 } \\gamma ^ { a d } \\left( \\partial _ { c } \\gamma _ { d b } + \\partial _ { b } \\gamma _ { d c } - \\partial _ { d } \\gamma _ { b c } \\right) The three-dimensional Riemann tensor can be computed from R _ { a b c } ^ { d } = \\partial _ { b } \\Gamma _ { a c } ^ { d } - \\partial _ { a } \\Gamma _ { b c } ^ { d } + \\Gamma _ { a c } ^ { e } \\Gamma _ { e b } ^ { d } - \\Gamma _ { b c } ^ { e } \\Gamma _ { e a } ^ { d } R _ { a b c } ^ { d } = \\partial _ { b } \\Gamma _ { a c } ^ { d } - \\partial _ { a } \\Gamma _ { b c } ^ { d } + \\Gamma _ { a c } ^ { e } \\Gamma _ { e b } ^ { d } - \\Gamma _ { b c } ^ { e } \\Gamma _ { e a } ^ { d } The three-dimensional curvature R _ { b c d } ^ { a } R _ { b c d } ^ { a } only contains information about the curvature intrinsic to a slice \u03a3, but it gives no information about what shape this slice takes in the spacetime M in which it is embedded.","title":"The spatial metric \\gamma_{ab}\\gamma_{ab}"},{"location":"NR/#the-extrinsic-curvature-k_abk_ab","text":"The extrinsic curvature K_{ab} K_{ab} can be found by projecting gradients of the normal vector into the slice \u03a3 . The metric and the extrinsic curvature (\\gamma_{ab}, K_{ab}) (\\gamma_{ab}, K_{ab}) can therefore be considered as the equivalent of positions and velocities in classical mechanics \u2013 they measure the \u201cinstantaneous\u201d state of the gravitational \ufb01eld, and form the fundamental variables in our initial value formulation. We now define the extrinsic curvature, K_{ab} K_{ab} , as the negative expansion K_{ab} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_{(c} n_{d)} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d K_{ab} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_{(c} n_{d)} = - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d By definition, the extrinsic curvature is symmetric and purely spatial. they can only differ in the direction in which they are pointing, and the extrinsic curvature therefore provides information on how much this direction changes from point to point across a spatial hypersurface. As a consequence, the extrinsic curvature measures the rate at which the hypersurface deforms as it is carried forward along a normal. Finally, we can write the extrinsic curvature as K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} where L_n L_n denotes the Lie derivative along n^a n^a . Since n^a n^a is a timelike vector, equation illustrates the intuitive interpretation of the extrinsic curvature as a geometric generalization of the \u201ctime derivative\u201d of the spatial metric \\gamma_{ab} \\gamma_{ab} . Proof: \\gamma_{ab} \\gamma_{ab} changes proportionally to K_{ab} K_{ab} \\begin{align} K_{ab} &= - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d = - (\\delta_a^{\\space c} + n_a n^c) (\\delta_b^{\\space d} + n_b n^d) \\nabla_c n_d \\\\ &= -(\\delta_a^{\\space c} + n_a n^c) \\delta_b^{\\space d} \\nabla_c n_d = - \\nabla_a n_b - n_a a_b \\\\ \\mathcal{L}_n \\gamma_{ab} &= \\mathcal{L}_n (g_{ab} + n_a n_b) = 2 \\nabla_{(a} n_{b)} + n_a \\mathcal{L}_n n_b + n_b \\mathcal{L}_n n_a \\\\ &= 2 (\\nabla_{(a} n_{b)} - n_{(a} a_{b)}) \\\\ \\mathcal{L}_n \\gamma_{ab} &= - 2 K_{ab} \\end{align} \\begin{align} K_{ab} &= - \\gamma_a^{\\space c} \\gamma_b^{\\space d} \\nabla_c n_d = - (\\delta_a^{\\space c} + n_a n^c) (\\delta_b^{\\space d} + n_b n^d) \\nabla_c n_d \\\\ &= -(\\delta_a^{\\space c} + n_a n^c) \\delta_b^{\\space d} \\nabla_c n_d = - \\nabla_a n_b - n_a a_b \\\\ \\mathcal{L}_n \\gamma_{ab} &= \\mathcal{L}_n (g_{ab} + n_a n_b) = 2 \\nabla_{(a} n_{b)} + n_a \\mathcal{L}_n n_b + n_b \\mathcal{L}_n n_a \\\\ &= 2 (\\nabla_{(a} n_{b)} - n_{(a} a_{b)}) \\\\ \\mathcal{L}_n \\gamma_{ab} &= - 2 K_{ab} \\end{align}","title":"The Extrinsic Curvature K_{ab}K_{ab}"},{"location":"NR/#riemann-tensor","text":"The metric \\gamma_{ab} \\gamma_{ab} and the extrinsic curvature K_{ab} K_{ab} cannot be chosen arbitrarily. Instead, they have to satisfy certain constraints . In order to find these relations, we have to relate the three-dimensional Riemann tensor R^a_{\\space bcd} R^a_{\\space bcd} of the the hypersurfaces \u03a3 to the four-dimensional Riemann tensor ^{(4)} R^a_{\\space bcd} ^{(4)} R^a_{\\space bcd} of M. To do so, we first take a completely spatial projection of ^{(4)} R^a_{\\space bcd} ^{(4)} R^a_{\\space bcd} , then a projection with one index projected in the normal direction, and finally a projection with two indices projected in the normal direction. All other projections vanish identically because of the symmetries of the Riemann tensor. A decomposition of ^{(4)} R^a_{\\space bcd} ^{(4)} R^a_{\\space bcd} into spatial and normal pieces therefore involves these three different types of projections . \\begin{align} ^{(4)} R_{abcd} &= \\gamma_a^{\\space p} \\gamma_b^{\\space q} \\gamma_c^{\\space r} \\gamma_d^{\\space s} {}^{(4)} R_{pqrs} - 2 \\gamma_a^{\\space p} \\gamma_b^{\\space q} \\gamma_{[c}^{\\space r} n_{d]} n^s {}^{(4)} R_{pqrs} \\\\ &- 2 \\gamma_c^{\\space p} \\gamma_d^{\\space q} \\gamma_{[a}^{\\space r} n_{b]} n^s {}^{(4)} R_{pqrs} + 2 \\gamma_a^{\\space p} \\gamma_{[c}^{\\space r} n_{d]} n_b n^q n^s {}^{(4)} R_{pqrs} \\\\ &- 2 \\gamma_b^{\\space p} \\gamma_{[c}^{\\space r} n_{d]} n_a n^q n^s {}^{(4)} R_{pqrs} \\end{align} \\begin{align} ^{(4)} R_{abcd} &= \\gamma_a^{\\space p} \\gamma_b^{\\space q} \\gamma_c^{\\space r} \\gamma_d^{\\space s} {}^{(4)} R_{pqrs} - 2 \\gamma_a^{\\space p} \\gamma_b^{\\space q} \\gamma_{[c}^{\\space r} n_{d]} n^s {}^{(4)} R_{pqrs} \\\\ &- 2 \\gamma_c^{\\space p} \\gamma_d^{\\space q} \\gamma_{[a}^{\\space r} n_{b]} n^s {}^{(4)} R_{pqrs} + 2 \\gamma_a^{\\space p} \\gamma_{[c}^{\\space r} n_{d]} n_b n^q n^s {}^{(4)} R_{pqrs} \\\\ &- 2 \\gamma_b^{\\space p} \\gamma_{[c}^{\\space r} n_{d]} n_a n^q n^s {}^{(4)} R_{pqrs} \\end{align} The above projections give rise to the equations of Gauss, Codazzi and Ricci. Gauss\u2019 equation and Codazzi equations give rise to the \u201cconstraint\u201d equations.","title":"Riemann Tensor"},{"location":"NR/#gauss-equation","text":"a completely spatial projection. R_{abcd} + K_{ac} K_{bd} -K_{ad} K_{cb} = \\gamma^P_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} \\gamma^s_{\\space d} {}^{(4)} R_{pqrs} R_{abcd} + K_{ac} K_{bd} -K_{ad} K_{cb} = \\gamma^P_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} \\gamma^s_{\\space d} {}^{(4)} R_{pqrs}","title":"Gauss\u2019 equation"},{"location":"NR/#codazzi-equation","text":"R^a_{\\space bcd} R^a_{\\space bcd} with one index projected in the normal direction. D_b K_{ac} - D_a K_{bc} = \\gamma^P_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} n^s_{\\space d} {}^{(4)} R_{pqrs} D_b K_{ac} - D_a K_{bc} = \\gamma^P_{\\space a} \\gamma^q_{\\space b} \\gamma^r_{\\space c} n^s_{\\space d} {}^{(4)} R_{pqrs}","title":"Codazzi equation"},{"location":"NR/#constraint-equations","text":"We can rewrite Einstein\u2019s \ufb01eld equations in a 3+1 form. Basically, we just need to take the equations of Gauss, Codazzi and Ricci and eliminate the four-dimensional Rieman tensor using Einstein\u2019s equations. G_{ab} = {}^{(4)} R_{ab} - \\frac{1}{2} {}^{(4)} R g_{ab} = 8 \\pi T_{ab} G_{ab} = {}^{(4)} R_{ab} - \\frac{1}{2} {}^{(4)} R g_{ab} = 8 \\pi T_{ab} We will first derive the constraint equations from Gauss\u2019 equation and the Codazzi equation. Contracting Gauss\u2019 equation R + K^2 - K_{ab}K^{ab} = 16 \\pi \\rho R + K^2 - K_{ab}K^{ab} = 16 \\pi \\rho We now define the energy density \u03c1 to be the total energy density as measured by a normal observer n^a n^a , \\rho = n_a n_b T^{ab} \\\\ 2 n^p n^r G_{pr} = R + K^2 - K_{ab} K^{ab} \\rho = n_a n_b T^{ab} \\\\ 2 n^p n^r G_{pr} = R + K^2 - K_{ab} K^{ab} Contracting the Codazzi equation $$ D_b K^b_{\\space a} - D_a K = 8 \\pi S_a $$ We now define S_a S_a to be the momentum density as measured by a normal observer n^a n^a , S_a = - \\gamma^b_{\\space a} n^c T_{bc} \\\\ D_b K^b_{\\space a} - D_a K = - \\gamma^q_{\\space a} n^s G_{qs} S_a = - \\gamma^b_{\\space a} n^c T_{bc} \\\\ D_b K^b_{\\space a} - D_a K = - \\gamma^q_{\\space a} n^s G_{qs} They are the conditions that allow a three-dimensional slice \u03a3 with data (\\gamma_{ab}, K_{ab}) (\\gamma_{ab}, K_{ab}) to be embedded in a four-dimensional manifold M with data g_{ab} g_{ab} . We will discuss strategies for solving the constraint equations and finding initial data that represent a snapshot of the gravitational fields at a certain instant of time. The four constraint equations cannot determine all of the gravitational fields (\\gamma_{ij}, K_{ij}) (\\gamma_{ij}, K_{ij}) . Both \\gamma_{ij} \\gamma_{ij} and K_{ij} K_{ij} are symmetric, three-dimensional tensors, they together have twelve independent components . The four constraint equations can only determine four of these Four undetermined functions are related to coordinate choices Two independent sets of values for the conjugate pair (\\gamma_{ij}, K_{ij}) (\\gamma_{ij}, K_{ij}) . Two dynamical degrees of freedom correspond to the two polarization modes of a gravitational wave It is quite intuitive that the state of a dynamical field, like a gravitational wave, cannot be determined from constraint equations . Waves satisfy hyperbolic equations, and their state at any time depends on their past history. It is therefore natural that the constraint equations serve to constrain only the \u201clongitudinal\u201d parts of the fields, while the \u201ctransverse\u201d parts, related to the dynamical degrees of freedom, remain freely specifiable. Ideally one would like to separate unambiguously the longitudinal from the transverse parts of the fields at some initial time, freely specifying the latter and then solving the constraints for the former. Given the nonlinear nature of general relativity such a rigorous separation is not possible; instead, all these fields are entangled in the spatial metric and the extrinsic curvature. Constraint equations constrain the fields in space at one instant of time, independently of their past history. Analogy Electric Field Maxwell\u2019s equations also split into constraint and evolution equations. The constraint equations have to be satis\ufb01ed by any electric and magnetic \ufb01eld at each instant of time, but they are not sufficient to completely determine these fields. Consider the equation for the electric field \\vec{E} \\vec{E} , \\nabla \\cdot \\vec{E} = 4 \\pi \\rho \\nabla \\cdot \\vec{E} = 4 \\pi \\rho Given an electrical charge density \u03c1, we can solve this equation for one of the components of E^i E^i , but not all three of them. For example, we could make certain choices for E^x E^x and E^y E^y , and then solve for E^z E^z , even though we might be troubled by the asymmetry in singling out one particular component in this approach. Alternatively, we may prefer to write E^i E^i as some \u201cbackground\u201d field \\bar { E } ^ { i } \\bar { E } ^ { i } times some overall scaling factor, say \u03c8^4 \u03c8^4 E ^ { i } = \\psi ^ { 4 } \\bar { E } ^ { i } E ^ { i } = \\psi ^ { 4 } \\bar { E } ^ { i } make certain choices for all three components of the background field \\bar { E } ^ { i } \\bar { E } ^ { i } , and then solve for the scaling factor \u03c8^4 \u03c8^4 . Though it might not be so useful for treating Maxwell\u2019s equations, such an approach leads to a very convenient and tractable system for Einstein\u2019s equations.","title":"Constraint equations"},{"location":"NR/#conformal-transformations","text":"","title":"Conformal Transformations"},{"location":"NR/#conformal-transformation-of-the-spatial-metric","text":"We begin by writing the spatial metric \\gamma_{ij} \\gamma_{ij} as a product of some power of a positive scaling factor \u03c8 and a background metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} , \\gamma_{ij} = \u03c8^4 \\bar{\\gamma}_{ij} \\gamma_{ij} = \u03c8^4 \\bar{\\gamma}_{ij} This identification is a conformal transformation of the spatial metric. We call \u03c8 the conformal factor , and \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} the conformally related metric . Taking \u03c8 to the fourth power turns out to be convenient, but is otherwise arbitrary. Loosely speaking, the conformal factor absorbs the overall scale of the metric, which leaves five degrees of freedom in the conformally related metric . Superficially, the conformal transformation is just a mathematical trick , namely, rewriting one unknown as a product of two unknowns in order to make solving some equations easier. The inverse of \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} : \\gamma ^ { i j } = \\psi ^ { - 4 } \\bar { \\gamma } ^ { i j } \\gamma ^ { i j } = \\psi ^ { - 4 } \\bar { \\gamma } ^ { i j } In three dimensions, the connection coefficients must transform according to \\Gamma _ { j k } ^ { i } = \\bar { \\Gamma } _ { j k } ^ { i } + 2 \\left( \\delta _ { j } ^ { i } \\bar { D } _ { k } \\ln \\psi + \\delta _ { k } ^ { i } \\bar { D } _ { j } \\ln \\psi - \\bar { \\gamma } _ { j k } \\bar { \\gamma } ^ { i l } \\bar { D } _ { l } \\ln \\psi \\right) \\Gamma _ { j k } ^ { i } = \\bar { \\Gamma } _ { j k } ^ { i } + 2 \\left( \\delta _ { j } ^ { i } \\bar { D } _ { k } \\ln \\psi + \\delta _ { k } ^ { i } \\bar { D } _ { j } \\ln \\psi - \\bar { \\gamma } _ { j k } \\bar { \\gamma } ^ { i l } \\bar { D } _ { l } \\ln \\psi \\right) For the scalar curvature R = \\psi ^ { - 4 } \\bar { R } - 8 \\psi ^ { - 5 } \\bar { D } ^ { 2 } \\psi R = \\psi ^ { - 4 } \\bar { R } - 8 \\psi ^ { - 5 } \\bar { D } ^ { 2 } \\psi Inserting the scalar curvature into the Hamiltonian constraint yields 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { 5 } K _ { i j } K ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { 5 } K _ { i j } K ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho which, for a given choice of the conformally related metric \\bar { \\gamma } ^ { i j } \\bar { \\gamma } ^ { i j } , we may interpret as an equation for the conformal factor \u03c8. The extrinsic curvature K_{ij} K_{ij} has to satisfy the momentum constraint, and it will be useful to rescale K_{ij} K_{ij} conformally as well.","title":"Conformal Transformation of the Spatial Metric"},{"location":"NR/#conformal-transformation-of-the-extrinsic-curvature","text":"We have conformally transformed the spatial metric, but before we proceed we also have to decompose the extrinsic curvature. It is convenient to split K_{ij} K_{ij} into its trace K and a traceless part A_{ij} A_{ij} according to K_{ij} = A_{ij} + \\frac{1}{3} \\gamma_{ij} K K_{ij} = A_{ij} + \\frac{1}{3} \\gamma_{ij} K and to conformally transform K and A_{ij} A_{ij} separately. A priori it is not clear how to transform K and A_{ij} A_{ij} , and our only guidance for inventing rules is that the transformation should bring the constraint equations into a simple and solvable form. Consider the transformations \\begin{aligned} A ^ { i j } & = \\psi ^ { \\alpha } \\bar { A } ^ { i j } \\\\ K & = \\psi ^ { \\beta } \\bar { K } \\end{aligned} \\begin{aligned} A ^ { i j } & = \\psi ^ { \\alpha } \\bar { A } ^ { i j } \\\\ K & = \\psi ^ { \\beta } \\bar { K } \\end{aligned} where \u03b1 and \u03b2 are two so far undetermined exponents. Inserting the above expressions into the momentum constraint (the choice \u03b1 = \u221210 \u03b1 = \u221210 ) yields \\psi ^ { - 10 } \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { \\beta - 4 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\bar { K } - \\frac { 2 } { 3 } \\beta \\psi ^ { \\beta - 5 } \\bar { K } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\psi = 8 \\pi S ^ { i } \\psi ^ { - 10 } \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { \\beta - 4 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\bar { K } - \\frac { 2 } { 3 } \\beta \\psi ^ { \\beta - 5 } \\bar { K } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } \\psi = 8 \\pi S ^ { i } Our desire to simplify equations motivates the choice \u03b2 = 0 \u03b2 = 0 , so that we treat K as a conformal invariant, K = \\bar{K} K = \\bar{K} . With these choices, the Hamiltonian constraint now becomes 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\frac { 2 } { 3 } \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { - 7 } \\bar { A } _ { i j } \\bar { A } ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho 8 \\bar { D } ^ { 2 } \\psi - \\psi \\bar { R } - \\frac { 2 } { 3 } \\psi ^ { 5 } K ^ { 2 } + \\psi ^ { - 7 } \\bar { A } _ { i j } \\bar { A } ^ { i j } = - 16 \\pi \\psi ^ { 5 } \\rho and the momentum constraint is \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { 6 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } K = 8 \\pi \\psi ^ { 10 } S ^ { i } \\bar { D } _ { j } \\bar { A } ^ { i j } - \\frac { 2 } { 3 } \\psi ^ { 6 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { j } K = 8 \\pi \\psi ^ { 10 } S ^ { i } In addition to the spatial metric and extrinsic curvature, it may also be necessary to transform the matter sources \u03c1 and S^i S^i to insure uniqueness of solutions. We start by considering the linear equation \\nabla ^ { 2 } u = f u \\nabla ^ { 2 } u = f u on some domain \u03a9. Here f is some given function, and we will assume u = 0 u = 0 on the boundary \u2202\u03a9 \u2202\u03a9 . If f is non-negative everywhere, we can apply the maximum principle to show that u = 0 everywhere. The point is that if u were non-zero somewhere in \u03a9, say positive, then it must have a maximum somewhere. At the maximum the left hand side of (3.40) must be negative, but the right hand side is non-negative if f \u2265 0 f \u2265 0 , which is a contradiction. Clearly, the argument works the same way if u is negative somewhere, implying that u = 0 u = 0 everywhere if f \u2265 0 f \u2265 0 . Now consider the non-linear equation \\nabla ^ { 2 } u = f u ^ { n } \\nabla ^ { 2 } u = f u ^ { n } and assume there exist two positive solutions u_1 u_1 and u_2 \u2265 u_1 u_2 \u2265 u_1 that are identical, u_1 = u_2 u_1 = u_2 , on the boundary \u2202\u03a9 \u2202\u03a9 . The difference \u2206u = u_2 \u2212 u_1 \u2206u = u_2 \u2212 u_1 must then satisfy an equation \\nabla ^ { 2 } \\Delta u = n f \\tilde { u } ^ { n - 1 } \\Delta u \\nabla ^ { 2 } \\Delta u = n f \\tilde { u } ^ { n - 1 } \\Delta u where \\tilde { u } \\tilde { u } is some positive function satisfying u_1 \u2264 \\tilde{u} \u2264 u_2 u_1 \u2264 \\tilde{u} \u2264 u_2 . Applying the above argument to \u2206u \u2206u , we see that the maximum principle implies \u2206u = 0 \u2206u = 0 and hence uniqueness of solutions if and only if nf \u2265 0 nf \u2265 0 , i.e. if the coefficient and exponent in the source term have the same sign. Inspecting the Hamiltonian constraint we see that the matter term \u221216 \u03c0 \u03c8^5 \u03c1 \u221216 \u03c0 \u03c8^5 \u03c1 features the \u201cwrong signs\u201d: it has a negative coefficient (assuming a positive matter density \u03c1), but a positive exponent for \u03c8. Therefore the maximum principle cannot be applied, and the uniqueness of solutions cannot be established. Uniqueness of solutions can be restored, however, by introducing a conformal rescaling of the density. With \\rho = \\psi ^ { \\delta } \\bar { \\rho } \\rho = \\psi ^ { \\delta } \\bar { \\rho } , where \u03b4 \u2264 \u22125 \u03b4 \u2264 \u22125 and where \\bar{\u03c1} \\bar{\u03c1} is now considered a given function, the matter term carries the \u201cright signs\u201d, and the maximum principle can be applied to establish the uniqueness of solutions.","title":"Conformal transformation of the extrinsic curvature"},{"location":"NR/#conformal-transverse-traceless-decomposition","text":"Any symmetric, traceless tensor can be split into a transverse-traceless part that is divergenceless and a longitudinal part that can be written as a symmetric, traceless gradient of a vector. We can therefore decompose \\bar{A}^{ij} \\bar{A}^{ij} as \\bar { A } ^ { i j } = \\bar { A } _ { T T } ^ { i j } + \\bar { A } _ { L } ^ { i j } \\bar { A } ^ { i j } = \\bar { A } _ { T T } ^ { i j } + \\bar { A } _ { L } ^ { i j } where the transverse part is divergenceless \\bar { D } _ { j } \\bar { A } _ { T T } ^ { i j } = 0 \\bar { D } _ { j } \\bar { A } _ { T T } ^ { i j } = 0 and where the longitudinal part satisfies \\bar { A } _ { L } ^ { i j } = \\bar { D } ^ { i } W ^ { j } + \\bar { D } ^ { j } W ^ { i } - \\frac { 2 } { 3 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { k } W ^ { k } \\equiv ( \\bar { L } W ) ^ { i j } \\bar { A } _ { L } ^ { i j } = \\bar { D } ^ { i } W ^ { j } + \\bar { D } ^ { j } W ^ { i } - \\frac { 2 } { 3 } \\bar { \\gamma } ^ { i j } \\bar { D } _ { k } W ^ { k } \\equiv ( \\bar { L } W ) ^ { i j } Here W^i W^i is a vector potential, and it is easy to see that the longitudinal operator or vector gradient \\bar{L} \\bar{L} produces a symmetric, traceless tensor. We can now write the divergence of \\bar{A}^{ij} \\bar{A}^{ij} as \\bar { D } _ { j } A ^ { i j } = \\bar { D } _ { j } A _ { L } ^ { i j } = \\bar { D } _ { j } ( \\bar { L } W ) ^ { i j } = \\bar { D } ^ { 2 } W ^ { i } + \\frac { 1 } { 3 } \\bar { D } ^ { i } \\left( \\bar { D } _ { j } W ^ { j } \\right) + \\bar { R } _ { j } ^ { i } W ^ { j } \\equiv \\left( \\bar { \\Delta } _ { L } W \\right) ^ { i } \\bar { D } _ { j } A ^ { i j } = \\bar { D } _ { j } A _ { L } ^ { i j } = \\bar { D } _ { j } ( \\bar { L } W ) ^ { i j } = \\bar { D } ^ { 2 } W ^ { i } + \\frac { 1 } { 3 } \\bar { D } ^ { i } \\left( \\bar { D } _ { j } W ^ { j } \\right) + \\bar { R } _ { j } ^ { i } W ^ { j } \\equiv \\left( \\bar { \\Delta } _ { L } W \\right) ^ { i } where \\bar{\u2206}_L \\bar{\u2206}_L is the vector Laplacian. Note that \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} and \\bar{A}^{ij}_{L} \\bar{A}^{ij}_{L} are transverse and longitudinal with respect to the conformal metric \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} , which is why this decomposition is called the conformal transverse-traceless decomposition. Alternatively one can also adopt a physical transverse-traceless decomposition, where the corresponding tensors are transverse and longitudinal with respect to the physical metric \u03b3_{ij} \u03b3_{ij} . We started out with six independent variables in both the spatial metric \\gamma_{ij} \\gamma_{ij} and the extrinsic curvature K_{ij} K_{ij} . Splitting o\ufb00 the conformal factor \u03c8 left five degrees of freedom in the conformally related metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} (once we have specified its determinant \\bar{\\gamma} \\bar{\\gamma} ). Of the six independent variables in K_{ij} K_{ij} we moved one into its trace K, two into \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} (which is symmetric, traceless, and divergenceless), and three into \\bar{A}^{ij}_L \\bar{A}^{ij}_L (which is reflected in its representation by a vector). Of the twelve original degrees of freedom, the constraint equations determine only four, namely the conformal factor \u03c8 (Hamiltonian constraint) and the longitudinal part of the traceless extrinsic curvature \\bar{A}^{ij}_L \\bar{A}^{ij}_L (momentum constraint). Four of the remaining eight degrees of freedom are associated with the coordinate freedom - three spatial coordinates hidden in the spatial metric and a time coordinate that is associated with K. This leaves four physical degrees of freedom undetermined - two in the conformally related metric \\bar{\\gamma}_{ij} \\bar{\\gamma}_{ij} , and two in the transverse part of traceless extrinsic curvature \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} . These two freely specifiable degrees of freedom carry the dynamical degrees of freedom of the gravitational fields. All others are either fixed by the constraint equations or represent coordinate freedom. We have reduced the Hamiltonian and momentum constraint to equations for the conformal factor \u03c8 and the vector potential W^i W^i , from which the longitudinal part of the extrinsic curvature is constructed. These quantities can be solved for only after choices have been made for the remaining quantities in the equations, namely the conformally related metric \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} , the transverse-traceless part of the extrinsic curvature \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} , the trace of the extrinsic curvature K, and, if present, any matter sources. The choice of these background data has to be made in accordance with the physical or astrophysical situation that one wants to represent. Physically, the choice affects the gravitational wave content present in the initial data, in the sense that a dynamical evolution of data constructed with different background data leads to different amounts of emitted gravitational radiation. It is often not clear how a suitable background can be constructed precisely, and we will return to this issue on several occasions. Given its loose association with the transverse parts of the gravitational fields, one often sets \\bar{A}^{ij}_{TT} \\bar{A}^{ij}_{TT} equal to zero in an attempt to minimize the gravitational wave content in the initial data.","title":"Conformal Transverse-Traceless Decomposition"},{"location":"NR/#conformal-transformations-of-black-hole-solutions","text":"It is instructive to consider some simple, but physically interesting, solutions to the constraint equation. Consider vacuum solutions for which the matter source terms vanish (\u03c1 = 0 = S^i) (\u03c1 = 0 = S^i) and focus on a \u201cmoment of time symmetry\u201d. At a moment of time symmetry, all time derivatives of \u03b3_{ij} \u03b3_{ij} are zero and the 4\u2212dimensional line interval has to be invariant under time reversal, t \u2192 \u2212t t \u2192 \u2212t . The latter condition implies that the shift must satisfy \u03b2^i = 0 \u03b2^i = 0 and, hence, the extrinsic curvature also has to vanish everywhere on the slice, K_{ij} = 0 = K K_{ij} = 0 = K . On such a time slice the momentum constraints are satisfied trivially. The Hamiltonian constraint reduces to \\bar { D } ^ { 2 } \\psi = \\frac { 1 } { 8 } \\psi \\bar { R } \\bar { D } ^ { 2 } \\psi = \\frac { 1 } { 8 } \\psi \\bar { R } Let us further choose the conformally related metric to be flat, \\bar { \\gamma } _ { i j } = \\eta _ { i j } \\bar { \\gamma } _ { i j } = \\eta _ { i j } Whenever this is the case, we call the physical spatial metric \u03b3_{ij} \u03b3_{ij} conformally flat. \u201cconformal flatness\u201d refers, for our purposes, to the spatial metric and not the spacetime metric. In four or any higher dimensions, we can evaluate the Weyl tensor to examine whether any given metric is conformally flat. This is a consequence of the fact that the Weyl tensor is invariant under conformal transformations of the spacetime metric \u2013 this explains why it is often called the conformal tensor. Any spherically symmetric spatial metric is always conformally flat, meaning that we can always write such a metric as \\gamma _ { i j } = \\psi ^ { 4 } \\eta _ { i j } \\gamma _ { i j } = \\psi ^ { 4 } \\eta _ { i j } . For any spherically symmetric space, we may hence assume conformal flatness without loss of generality. Assuming conformal flatness dramatically simplifies all calculations, since \\bar{D}_i \\bar{D}_i reduces to the flat covariant derivative (and in particular to partial derivatives in cartesian coordinates). Moreover, the Ricci tensor and scalar curvature associated with the conformally related metric must now vanish, \\bar{R}_{ij} = \\bar{R} = 0 \\bar{R}_{ij} = \\bar{R} = 0 . Under this assumption, the Hamiltonian constraint becomes the remarkably simple Laplace equation \\bar { D } ^ { 2 } \\psi = 0 \\bar { D } ^ { 2 } \\psi = 0 Spherically symmetric solutions are \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } in this particular case, the constant M is in fact the black hole mass M. It shouldn\u2019t come as a great surprise that this is just the Schwarzschild solution in isotropic coordinates. d l ^ { 2 } = \\gamma _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\eta _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\left( d r ^ { 2 } + r ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) d l ^ { 2 } = \\gamma _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\eta _ { i j } d x ^ { i } d x ^ { j } = \\left( 1 + \\frac { M } { 2 r } \\right) ^ { 4 } \\left( d r ^ { 2 } + r ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) This solution forms the basis of the so-called puncture methods for black holes. The solution is singular at r = 0 r = 0 . However, we can show that this singularity is only a coordinate singularity by considering the coordinate transformation r = \\left( \\frac { \\mathcal { M } } { 2 } \\right) ^ { 2 } \\frac { 1 } { \\hat { r } } r = \\left( \\frac { \\mathcal { M } } { 2 } \\right) ^ { 2 } \\frac { 1 } { \\hat { r } } under which the isotropic Schwarzschild metric becomes d l ^ { 2 } = \\left( 1 + \\frac { \\mathcal { M } } { 2 \\hat { r } } \\right) ^ { 4 } \\left( d \\hat { r } ^ { 2 } + \\hat { r } ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) d l ^ { 2 } = \\left( 1 + \\frac { \\mathcal { M } } { 2 \\hat { r } } \\right) ^ { 4 } \\left( d \\hat { r } ^ { 2 } + \\hat { r } ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) \\right) The geometry described by metric evaluated at a radius \\hat{r} = a \\hat{r} = a is identical to that of the above metric evaluated at r = a r = a . The mapping therefore maps the metric into itself, and is hence an isometry. In particular, this demonstrates that the origin r = 0 r = 0 is isomorphic to spatial infinity, which is perfectly regular. This demonstrates that the isotropic radius r covers only the black hole exterior, and that each Schwarzschild R corresponds to two values of the isotropic radius r. The isotropic radius r corresponding to the smallest areal (or circumferential) radius R is r = M/2 r = M/2 , which we refer to as the black hole throat. For a single Schwarzschild black hole, the throat coincides with both the apparent and event horizons. It is almost trivial to generalize our one black hole solution \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } \\psi = 1 + \\frac { \\mathcal { M } } { 2 r } to an arbitrary number of black holes at a moment of time symmetry. Since \\bar { D } ^ { 2 } \\psi = 0 \\bar { D } ^ { 2 } \\psi = 0 is linear, we obtain the solution simply by adding the individual contribution of each black hole according to \\psi = 1 + \\sum_{\\alpha} \\frac { \\mathcal { M } _ { \\alpha } } { 2 r _ { \\alpha } } \\psi = 1 + \\sum_{\\alpha} \\frac { \\mathcal { M } _ { \\alpha } } { 2 r _ { \\alpha } } Here r_\u03b1 = |x^i \u2212 C_\u03b1^i | r_\u03b1 = |x^i \u2212 C_\u03b1^i | is the (coordinate) separation from the center C_\u03b1^i C_\u03b1^i of the \u03b1th black hole. The total mass of the spacetime is the sum of the coefficients M_\u03b1 M_\u03b1 . However, since the total mass will also include contributions from the black hole interactions, M_\u03b1 M_\u03b1 can be identified with the mass of the \u03b1-th black hole only in the limit of large separations. Particularly interesting astrophysically and for the generation of gravitational waves is the case of binary black holes \\psi = 1 + \\frac { \\mathcal { M } _ { 1 } } { 2 r _ { 1 } } + \\frac { \\mathcal { M } _ { 2 } } { 2 r _ { 2 } } \\psi = 1 + \\frac { \\mathcal { M } _ { 1 } } { 2 r _ { 1 } } + \\frac { \\mathcal { M } _ { 2 } } { 2 r _ { 2 } } This simple solution to the constraint equations for two black holes instantaneously at rest at a moment of time symmetry can be used as initial data for head-on collisions of black holes. In general, the existence of other black holes destroys the symmetry that we found for a single black hole. Drawing an embedding diagram for such a geometry yields several different \u201csheets\u201d, where each sheet corresponds to one universe. A geometry containing N black holes may contain up to N + 1 different asymptotically flat universes. For each throat we can add terms inside that throat that correspond to images of the other black holes. Doing so, the solution becomes \u201csymmetrized\u201d so that the reflection through each throat is again an isometry. In other words, each Einstein-Rosen bridge connects to the same asymptotically flat universe, and the geometry consists of only two asymptotically flat universes, which are connected by several Einstein-Rosen bridges. For two equal-mass black holes we may also interpret this solution as a wormhole black hole solution. Cut off the bottom universe at the two throats, which leaves two \u201copen-ended\u201d throats hanging down from the top universe. We can now identify these two open ends with each other, effectively gluing them together. The two throats now form a \u201cwormhole\u201d that connects to a single, asymptotically flat (but multiply connected) universe. Given the original isometry conditions across the throats, and given that they have the same mass, the resulting metric is smooth across the throat and a valid solution to the Hamiltonian constraint. In cylindrical coordinates the metric becomes d l ^ { 2 } = \\psi ^ { 4 } \\left( d \\rho ^ { 2 } + d z ^ { 2 } + \\rho ^ { 2 } d \\phi ^ { 2 } \\right) d l ^ { 2 } = \\psi ^ { 4 } \\left( d \\rho ^ { 2 } + d z ^ { 2 } + \\rho ^ { 2 } d \\phi ^ { 2 } \\right) where the corresponding conformal factor is given by \\psi = 1 + \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } \\left( \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z + z _ { n } \\right) ^ { 2 } } } + \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z - z _ { n } \\right) ^ { 2 } } } \\right) \\psi = 1 + \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } \\left( \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z + z _ { n } \\right) ^ { 2 } } } + \\frac { 1 } { \\sqrt { \\rho ^ { 2 } + \\left( z - z _ { n } \\right) ^ { 2 } } } \\right) Here z _ { n } = \\operatorname { coth } ( n \\mu ) z _ { n } = \\operatorname { coth } ( n \\mu ) , and \u03bc is a free parameter. the total mass of this system, which we will identify with the \u201cADM mass\u201d is M _ { \\mathrm { ADM } } = 4 \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } M _ { \\mathrm { ADM } } = 4 \\sum _ { n = 1 } ^ { \\infty } \\frac { 1 } { \\sinh ( n \\mu ) } The proper distance L along the spacelike geodesic connecting the throats, or equivalently the proper length of a geodesic loop through the wormhole, is L = 2 \\left( 1 + 2 \\mu \\sum _ { n = 1 } ^ { \\infty } \\frac { n } { \\sinh ( n \\mu ) } \\right) L = 2 \\left( 1 + 2 \\mu \\sum _ { n = 1 } ^ { \\infty } \\frac { n } { \\sinh ( n \\mu ) } \\right) The parameter \u03bc is seen to parameterize both the mass and separation of the two holes. Since the solution can be rescaled to arbitrary physical mass, \u03bc effectively determines the dimensionless ratio L/M_{ADM} L/M_{ADM} , the parameter that, apart from mass, distinguishes one binary from another in this class of initial data.","title":"Conformal Transformations of Black Hole Solutions"},{"location":"NR/#mass","text":"There are several important global conserved quantities that characterize an isolated system, such as its total mass and angular momentum. The rate of loss of these quantities from an isolated system is equal to the rate at which matter, fields and gravitational waves carry them away . Once we have solved the constraint equations and constructed a complete set of initial data for a system, we can then determine the values of the global conserved parameters associated with the system. During a numerical evolution, monitoring the degree to which these parameters are conserved provides a very useful check on the accuracy of the numerical integration . Suppose the system contains matter. Then we can derive an expression for its conserved rest-mass M_0 M_0 (sometimes called the baryon mass, if the matter is composed of baryons) from the continuity equation, \\nabla _ { a } \\left( \\rho _ { 0 } u ^ { a } \\right) = 0 \\nabla _ { a } \\left( \\rho _ { 0 } u ^ { a } \\right) = 0 where \u03c1_0 \u03c1_0 is the rest-mass density. Integrating this expression over a 4-dimensional region of spacetime \u03a9 yields \\int _ { \\Omega } d ^ { 4 } x \\sqrt { - g } \\nabla _ { a } \\left( \\rho _ { 0 } u ^ { a } \\right) = 0 \\int _ { \\Omega } d ^ { 4 } x \\sqrt { - g } \\nabla _ { a } \\left( \\rho _ { 0 } u ^ { a } \\right) = 0 Using Gauss\u2019s theorem we can relate the divergence of \u03c1_0u^a \u03c1_0u^a inside the region \u03a9 to the value of \u03c1_0u^a \u03c1_0u^a on the region\u2019s 3-dimensional boundary \u2202\u03a9 \u2202\u03a9 \\int _ { \\Omega } d ^ { 4 } x \\sqrt { - g } \\nabla _ { a } \\left( \\rho _ { 0 } u ^ { a } \\right) = \\int _ { \\partial \\Omega } d ^ { 3 } \\Sigma _ { a } \\rho _ { 0 } u ^ { a } \\int _ { \\Omega } d ^ { 4 } x \\sqrt { - g } \\nabla _ { a } \\left( \\rho _ { 0 } u ^ { a } \\right) = \\int _ { \\partial \\Omega } d ^ { 3 } \\Sigma _ { a } \\rho _ { 0 } u ^ { a } where d ^ { 3 } \\Sigma _ { a } = \\epsilon \\mathcal { N } _ { a } \\sqrt { \\gamma } d ^ { 3 } x d ^ { 3 } \\Sigma _ { a } = \\epsilon \\mathcal { N } _ { a } \\sqrt { \\gamma } d ^ { 3 } x and \\mathcal { N } ^ { a } \\mathcal { N } ^ { a } is the outward-pointing unit normal vector on \u2202\u03a9 \u2202\u03a9 . When \u2202\u03a9 \u2202\u03a9 is spacelike, the factor \u03b5 = \u22121 \u03b5 = \u22121 and when \u2202\u03a9 \u2202\u03a9 is timelike, \u03b5 = +1 \u03b5 = +1 . Now imagine a \u201cpill-box\u201d-shaped spacetime region that is bounded by two spatial slices \u03a3_1 \u03a3_1 and \u03a3_2 \u03a3_2 as well as a timelike hypersurface residing entirely outside the source, as illustrated in Figure. In this case only the spatial surfaces contribute to the surface integral. On \u03a3_2 \u03a3_2 the normal vector Na points toward the future, and therefore coincides with the normal vector n^a n^a of the spacetime foliation \\mathcal { N } _ { a } u ^ { a } = n _ { a } u ^ { a } = - \\alpha u ^ { t } \\mathcal { N } _ { a } u ^ { a } = n _ { a } u ^ { a } = - \\alpha u ^ { t } . On \u03a3_1 \u03a3_1 , Na points toward the past, while n^a n^a points toward the future, which introduces a negative sign between them. The conservation law can therefore be written as \\int _ { \\Sigma _ { 1 } } d ^ { 3 } x \\sqrt { \\gamma } \\alpha u ^ { t } \\rho _ { 0 } - \\int _ { \\Sigma _ { 2 } } d ^ { 3 } x \\sqrt { \\gamma } \\alpha u ^ { t } \\rho _ { 0 } = 0 \\int _ { \\Sigma _ { 1 } } d ^ { 3 } x \\sqrt { \\gamma } \\alpha u ^ { t } \\rho _ { 0 } - \\int _ { \\Sigma _ { 2 } } d ^ { 3 } x \\sqrt { \\gamma } \\alpha u ^ { t } \\rho _ { 0 } = 0 implies that the rest mass, defined as M _ { 0 } = \\int _ { \\Sigma } d ^ { 3 } x \\sqrt { \\gamma } \\alpha u ^ { t } \\rho _ { 0 } M _ { 0 } = \\int _ { \\Sigma } d ^ { 3 } x \\sqrt { \\gamma } \\alpha u ^ { t } \\rho _ { 0 } is conserved. The rest-mass is thus determined by a 3\u2212dimensional volume integral over a spatial region spanning the matter source. Defining the total mass-energy of the system is more subtle, since it cannot be defined locally in general relativity . One useful measure of mass-energy is provided by the ADM mass, M_{ADM} M_{ADM} . The ADM mass measures the total mass-energy of an isolated gravitating system at any instant of time measured within a spatial surface enclosing the system at infinity. This definition requires the spacetime to be asymptotically flat and the spacetime metric to approach the Minkowski metric sufficiently quickly with increasing distance from the source, g _ { a b } - \\eta _ { a b } = \\mathcal { O } \\left( r ^ { - 1 } \\right) g _ { a b } - \\eta _ { a b } = \\mathcal { O } \\left( r ^ { - 1 } \\right) The existence of such a surface integral to determine the mass-energy of an isolated system is consistent with the principle that the total mass-energy of such a system can always by determined by a measurement performed by a distant observer . By definition, the spatial surface \u2202\u03a3_\u221e \u2202\u03a3_\u221e must be taken out to infinity, in which case M_{ADM} M_{ADM} is rigorously conserved . In numerical applications, the integral is often evaluated on a large surface at a distant, but finite, radius from the gravitating source , in the asymptotically flat region of spacetime. In this case, M_{ADM} M_{ADM} will change in time whenever there is a flux of matter or gravitational radiation passing across the surface . However, the rate of change of M_{ADM} M_{ADM} will exactly reflect the rate at which mass-energy is carried across the surface by these fluxes. Assume a perfect gas, so that the stress energy tensor is given by T ^ { a b } = \\left( \\rho _ { 0 } + \\epsilon \\rho _ { 0 } + P \\right) u ^ { a } u ^ { b } + P g ^ { a b } T ^ { a b } = \\left( \\rho _ { 0 } + \\epsilon \\rho _ { 0 } + P \\right) u ^ { a } u ^ { b } + P g ^ { a b } where \u03b5 is the specific internal energy density and P the pressure. The difference between the ADM mass M_{ADM} M_{ADM} and the rest mass M_0 M_0 is given by M _ { \\mathrm { ADM } } - M _ { 0 } = T + W + U M _ { \\mathrm { ADM } } - M _ { 0 } = T + W + U in the Newtonian limit, where T is the kinetic energy, T = \\frac { 1 } { 2 } \\int \\rho _ { 0 } v ^ { 2 } d ^ { 3 } x T = \\frac { 1 } { 2 } \\int \\rho _ { 0 } v ^ { 2 } d ^ { 3 } x W the gravitational potential energy, W = \\frac { 1 } { 2 } \\int \\rho _ { 0 } \\phi d ^ { 3 } x W = \\frac { 1 } { 2 } \\int \\rho _ { 0 } \\phi d ^ { 3 } x and U is the internal energy, U = \\int \\rho _ { 0 } \\epsilon d ^ { 3 } x U = \\int \\rho _ { 0 } \\epsilon d ^ { 3 } x On further probing, things can sometimes get a little confusing, as when evaluating the ADM mass for Schwarzschild spacetime in Painleve-Gullstrand coordinates. All the above expressions yield an ADM mass of zero in these coordinates. The reason for this is that the shift in Painleve-Gullstrand coordinates does not fall off sufficiently fast. If nothing else, this result provides a warning to us that we must be careful to check that the metric satisfies the correct asymptotic conditions in the adopted coordinates when applying the above formulae to calculate the mass. It also motivates a search for other mass definitions.","title":"Mass"},{"location":"NR/#choosing-coordinates","text":"The 3+1 evolution equations for \\gamma_{ij} \\gamma_{ij} and for K_{ij} K_{ij} are not quite ready for numerical integration. For one thing, we have yet to impose coordinate conditions by specifying the lapse function \u03b1 \u03b1 and the shift vector \u03b2^i \u03b2^i that appear in these equations. The lapse and shift are freely specifiable gauge variables that need to be chosen in order to advance the field data from one time slice to the next. What constitutes a \u201cgood\u201d coordinate system? Clearly, the adopted coordinates must not allow the appearance of any singularities, which could have dire consequences for a numerical simulation. Such a singularity, which is often associated with a black hole, could be either a coordinate singularity or a physical singularity. To avoid coordinate singularities associated with horizons, like the one at r_s = 2M r_s = 2M , black hole simulations have sometimes been carried out using \u201chorizon penetrating\u201d coordinates in which light cones do not pinch-off at the horizon. The lapse \u03b1 determines how the shape of the slices \u03a3 changes in time, since it relates the advance of proper time to coordinate time along the normal vector na connecting one spatial slice to the next. The shift \u03b2^i \u03b2^i , on the other hand, determines how spatial points at rest with respect to a normal observer n^a n^a are relabeled on neighboring slices. The spatial gauge or spatial coordinates is therefore imposed by a choice for the shift vector.","title":"Choosing Coordinates"},{"location":"NR/#geodesic-slicing","text":"Since the lapse \u03b1 \u03b1 and the shift \u03b2^i \u03b2^i can be chosen freely, let us first consider the simplest possible choice, \\alpha = 1 , \\quad \\beta ^ { i } = 0 \\alpha = 1 , \\quad \\beta ^ { i } = 0 In the context of numerical relativity this gauge choice is often called geodesic slicing; the resulting coordinates are also known as Gaussian-normal coordinates. Recall that coordinate observers move with 4\u2212velocities u ^ { a } = t ^ { a } = e _ { ( 0 ) } ^ { a } u ^ { a } = t ^ { a } = e _ { ( 0 ) } ^ { a } (i.e. spatial velocities u^i = 0 u^i = 0 ). Thus with \u03b2^i = 0 \u03b2^i = 0 , coordinate observers coincide with normal observers ( u^a = n^a u^a = n^a ). With \u03b1 = 1 \u03b1 = 1 , the proper time intervals that they measure agree with coordinate time intervals. Their acceleration is given by equation a _ { b } = D _ { b } \\ln \\alpha = 0 a _ { b } = D _ { b } \\ln \\alpha = 0 Evidently, since their acceleration vanishes, normal observers are freely-falling and therefore follow geodesics, hence the name of this slicing condition. Despite its simplicity, geodesic slicing tends to form coordinate singularities very quickly during an evolution. This result is not surprising, since geodesics tend to focus in the presence of gravitating sources. Coordinate observers therefore approach each other, collide, and thereby form a coordinate singularity . As an example, consider a weak gravitational wave that is initially centered on the origin of an otherwise flat vacuum spacetime. After a brief interaction the wave disperses and leaves behind flat space. Also consider a set of coordinate observers that are at rest with respect to each other initially. The gravitational wave packet carries energy and hence attracts the observers gravitationally, who, initially, start moving toward the origin of the spacetime . Once the gravitational wave has dispersed, the observers are no longer attracted gravitationally to the center, but they continue to coast toward each other until they form a coordinate singularity . As the following exercise demonstrates, we can even estimate the time scale after which this singularity will form.","title":"Geodesic Slicing"},{"location":"NR/#maximal-slicing","text":"A common choice is the maximal slicing condition K = 0 K = 0 If we assume maximal slicing not only on one slice, but at all times, then the time derivative of K must vanish as well, K = 0 = \\partial _ { t } K K = 0 = \\partial _ { t } K D ^ { 2 } \\alpha = \\alpha \\left( K _ { i j } K ^ { i j } + 4 \\pi ( \\rho + S ) \\right) D ^ { 2 } \\alpha = \\alpha \\left( K _ { i j } K ^ { i j } + 4 \\pi ( \\rho + S ) \\right) which we can solve for the lapse \u03b1 \u03b1 independently of the shift \u03b2^i \u03b2^i . By construction, maximal slicing prevents the focussing of normal observers that we have found for geodesic slicing. This means that maximal slices are \u201cvolume preserving\u201d along the normal congruence n^a n^a . Normal observers in maximal slicing move like irrotational and incompressible fluid elements. The incompressible property prevents the focussing of normal observers that occurs in geodesic slicing.","title":"Maximal Slicing"},{"location":"NR/#harmonic-coordinates","text":"Consider a contraction of the four dimensional connection coefficients ^ { ( 4 ) } \\Gamma ^ { a } \\equiv g ^ { b c ( 4 ) } \\Gamma _ { b c } ^ { a } = - \\frac { 1 } { | g | ^ { 1 / 2 } } \\partial _ { b } \\left( | g | ^ { 1 / 2 } g ^ { a b } \\right) ^ { ( 4 ) } \\Gamma ^ { a } \\equiv g ^ { b c ( 4 ) } \\Gamma _ { b c } ^ { a } = - \\frac { 1 } { | g | ^ { 1 / 2 } } \\partial _ { b } \\left( | g | ^ { 1 / 2 } g ^ { a b } \\right) One way to impose a gauge condition is to set these quantities equal to some pre-determined gauge source functions H^a H^a , ^ { ( 4 ) } \\Gamma ^ { a } = H ^ { a } ^ { ( 4 ) } \\Gamma ^ { a } = H ^ { a } In particular, we may choose these gauge source functions to vanish, which defines harmonic coordinates ^ { ( 4 ) } \\Gamma ^ { a } = 0 ^ { ( 4 ) } \\Gamma ^ { a } = 0 More common in 3+1 calculations is harmonic slicing, in which only the time-component ^ { ( 4 ) } \\Gamma ^ { 0 } ^ { ( 4 ) } \\Gamma ^ { 0 } is set to zero. The singularity avoidance properties of harmonic slicing are weaker than those, for example, of maximal slicing.","title":"Harmonic Coordinates"},{"location":"NR/#quasi-isotropic-and-radial-gauge","text":"We now turn to gauge conditions for the spatial coordinates, i.e., conditions that specify the shift vector \u03b2^i \u03b2^i . As is the case when picking a lapse, an important goal when choosing a shift is to provide for a stable, long-term dynamical evolution. In addition, it is often desirable to bring the spatial metric into a simple form . Loosely speaking, two different strategies can be employed when constructing a spatial gauge condition. One strategy is to define a geometric condition on the spatial metric from which a gauge condition can be derived. Alternatively, we can impose an algebraic condition on the spatial metric directly. For example, we can set some of its components to zero in order to simplify the Einstein equations. In general the spatial metric \u03b3_{ij} \u03b3_{ij} has six independent components. Using our three degrees of spatial coordinate freedom we can impose three conditions on the metric, and thereby reduce the number of its independent variables to three. In spherical polar coordinates, quasi-isotropic gauge is defined by the three conditions \\gamma _ { r \\theta } = \\gamma _ { r \\phi } = 0 \\\\ \\gamma _ { \\theta \\theta } \\gamma _ { \\phi \\phi } - \\left( \\gamma _ { \\theta \\phi } \\right) ^ { 2 } = \\gamma _ { r r } \\gamma _ { \\phi \\phi } r ^ { 2 } \\gamma _ { r \\theta } = \\gamma _ { r \\phi } = 0 \\\\ \\gamma _ { \\theta \\theta } \\gamma _ { \\phi \\phi } - \\left( \\gamma _ { \\theta \\phi } \\right) ^ { 2 } = \\gamma _ { r r } \\gamma _ { \\phi \\phi } r ^ { 2 } which reduces the metric to the form d l ^ { 2 } = A ^ { 2 } \\left( d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } \\right) + B ^ { 2 } r ^ { 2 } ( \\sin \\theta d \\phi + \\xi d \\theta ) ^ { 2 } d l ^ { 2 } = A ^ { 2 } \\left( d r ^ { 2 } + r ^ { 2 } d \\theta ^ { 2 } \\right) + B ^ { 2 } r ^ { 2 } ( \\sin \\theta d \\phi + \\xi d \\theta ) ^ { 2 }","title":"Quasi-isotropic and Radial Gauge"},{"location":"NR/#minimal-distortion","text":"The conformally related metric \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} has five independent functions, two of which correspond to true dynamical degrees of freedom and three to coordinate freedom. For a stable and accurate numerical evolution it is desirable to eliminate purely coordinate-related fluctuations in \\bar{\u03b3}_{ij} \\bar{\u03b3}_{ij} . To accomplish this, one may want to construct a gauge condition that minimizes the time rate of change of the conformally related metric. This gauge condition is called minimal distortion . An \u201capproximate minimal distortion\u201d condition may lead to a coordinate system with similar geometric properties.","title":"Minimal Distortion"},{"location":"NR/#matter-sources","text":"The stress-energy tensor accounts for all sources of energy-momentum in spacetime, excluding gravity. It thus arises from all forms of matter, electromagnetic fields, neutrinos, scalar fields, etc, in the universe. For brevity, we shall sometimes refer to these sources collectively as the \u201cmatter sources\u201d and the terms that they contribute in the 3 + 1 equations as the \u201cmatter source terms\u201d. \u201cMatter\u201d source terms appear in the Hamiltonian constraint equation, the momentum constraint equation, and the 3 + 1 evolution equation. The evolution equations for the \u201cmatter\u201d sources are given by \\nabla _ { b } T ^ { a b } = 0 \\nabla _ { b } T ^ { a b } = 0 , which express the conservation of the total 4-momentum in spacetime. These conservation equations must be solved simultaneously with the 3 + 1 evolution equations for the gravitational field to determine the entire foliation of spacetime. Some of the quantities appearing in the stress-energy tensor require auxiliary equations. These auxiliary equations include, for example, the continuity equation and an equation of state in the case of hydrodynamic matter, and Maxwell\u2019s equations in the case of an electromagnetic field , and so on. The \u201cmatter\u201d source terms \u03c1, S_i S_i and S_{ij} S_{ij} appearing in the 3+1 equations for the gravitational field are projections of the stress-energy tensor into n^a n^a and \u03a3 and are given by \\rho = n_a n_b T^{ab} \\\\ S_i = - \\gamma_{ia} n_b T^{ab} \\\\ S_{ij} = \\gamma_{ia} \\gamma_{jb} T^{ab} \\rho = n_a n_b T^{ab} \\\\ S_i = - \\gamma_{ia} n_b T^{ab} \\\\ S_{ij} = \\gamma_{ia} \\gamma_{jb} T^{ab} The quantity \\rho \\rho is the total mass-energy density as measured by a normal observer, S_i S_i is the momentum density and S_{ij} S_{ij} is the stress. Finally, S is de\ufb01ned as the trace of S_{ij} S_{ij} , S = \\gamma^{ij} S_{ij} S = \\gamma^{ij} S_{ij} In the following sections, we discuss some of the most important \u201cmatter\u201d sources that arise in astrophysical applications. These sources include hydrodynamic fluids, magnetohydrodynamic plasmas threaded by magnetic fields, radiation gases (e.g., photon and neutrino), collisionless matter, and scalar fields.","title":"Matter Sources"},{"location":"NR/#vacuum","text":"Vacuum spacetimes are characterized by the vacuum stress energy tensor T^{ab} = 0 T^{ab} = 0 Spacetimes containing black holes and (or) gravitational waves, and nothing else, are characterized by such a stress-energy tensor in Einstein\u2019s \ufb01eld equations. Vacuum spacetimes are simpler to deal with numerically since they require no additional energy-momentum conservation equations or auxiliary \ufb01eld equations to solve.","title":"Vacuum"},{"location":"NR/#hydrodynamics","text":"Relativistic hydrodynamic matter is an important source of stress-energy in many astrophysical applications. Loosely speaking, a hydrodynamic description of matter is appropriate whenever the mean free path of a particle due to collisions with neighboring particles is much shorter than the characteristic size or local scale length of the system.","title":"Hydrodynamics"},{"location":"NR/#perfect-gases","text":"The stress-energy tensor of a perfect gas is given by T^{ab} = \\rho_0 h u^a u^b + P g^{ab} T^{ab} = \\rho_0 h u^a u^b + P g^{ab} h is the specific enthalpy h = 1 + \\epsilon + P / \\rho _ { 0 } h = 1 + \\epsilon + P / \\rho _ { 0 } where \\epsilon \\epsilon is the specific internal energy density. The total mass-energy density as measured by an observer comoving with the fluid is then given by \\rho ^ { * } = \\rho _ { 0 } ( 1 + \\epsilon ) \\rho ^ { * } = \\rho _ { 0 } ( 1 + \\epsilon ) . The local conservation of energy-momentum \\nabla_b T^{ab} = 0 \\nabla_b T^{ab} = 0 The conservation of rest mass \\nabla_a (\\rho_0 u^a) = 0 \\nabla_a (\\rho_0 u^a) = 0","title":"Perfect Gases"},{"location":"NR/#imperfect-gases","text":"There are many important astrophysical applications that involve imperfect gases characterized by viscosity, conductivity and (or) radiation. For example, viscosity can drive non-axisymmetric instabilities in rotating stars, while radiation can lead to the cooling and contraction of stars. Viscosity The contribution of viscosity to the stress-energy tensor is T _ { \\mathrm { visc } } ^ { a b } = - 2 \\eta \\sigma ^ { a b } - \\zeta \\theta P ^ { a b } T _ { \\mathrm { visc } } ^ { a b } = - 2 \\eta \\sigma ^ { a b } - \\zeta \\theta P ^ { a b } where \u03b7 \u2265 0 \u03b7 \u2265 0 is the coefficient of dynamic, or shear, viscosity, \u03b6 \u2265 0 \u03b6 \u2265 0 is the coefficient of bulk viscosity. Heat and Radiation Diffusion The contribution of heat flux (i.e. conduction) to the stress-energy tensor is T _ { \\text { heat } } ^ { a b } = u ^ { a } q ^ { b } + u ^ { b } q ^ { a } T _ { \\text { heat } } ^ { a b } = u ^ { a } q ^ { b } + u ^ { b } q ^ { a } where the heat-flux 4-vector q^a q^a is given by q ^ { a } = - \\lambda _ { \\mathrm { th } } P ^ { a b } \\left( \\nabla _ { b } T + T a _ { b } \\right) q ^ { a } = - \\lambda _ { \\mathrm { th } } P ^ { a b } \\left( \\nabla _ { b } T + T a _ { b } \\right) T is the temperature, a ^ { a } = u ^ { b } \\nabla _ { b } u ^ { a } a ^ { a } = u ^ { b } \\nabla _ { b } u ^ { a } is the fluid 4-acceleration, and \u03bb_{th} \u03bb_{th} is the coefficient of thermal conduction. A useful application of the thermal conduction formalism is heat transport via thermal radiation. Radiation Hydrodynamics In general, a gas is neither optically thick nor optically thin (i.e. transparent) everywhere, nor is the radiation always in thermal equilibrium with the matter. In such cases we cannot treat radiation transport in the diffusion approximation as discussed above. To handle the more general case, the radiation field can be described by a radiation stress-energy tensor, T _ { \\mathrm { rad } } ^ { a b } = \\iint d \\nu d \\Omega I _ { \\nu } N ^ { a } N ^ { b } T _ { \\mathrm { rad } } ^ { a b } = \\iint d \\nu d \\Omega I _ { \\nu } N ^ { a } N ^ { b } The radiation hydrodynamics problem is very difficult to solve in general, since the intensity is a function of six-dimensional phase space plus time, and the radiation transport equation with complicated radiation-fluid interaction terms (including scattering) has a nontrivial integrodifferential character.","title":"Imperfect Gases"},{"location":"NR/#magnetohydrodynamics","text":"Magnetic fields play a crucial role in determining the evolution of many relativistic objects. In any highly conducting astrophysical plasma, a frozen-in magnetic field can be amplified appreciably by gas compression or shear. Even when an initial seed field is weak, the field can grow in the course of time to significantly influence the gas dynamical behavior of the system.","title":"Magnetohydrodynamics"},{"location":"NR/#electromagnetic-field-equations","text":"Along with the electromagnetic field, we shall assume the presence of a perfect fluid, so that the total stress-energy tensor is given by T ^ { a b } = \\rho _ { 0 } h u ^ { a } u ^ { b } + P g ^ { a b } + T _ { \\mathrm { em } } ^ { a b } T ^ { a b } = \\rho _ { 0 } h u ^ { a } u ^ { b } + P g ^ { a b } + T _ { \\mathrm { em } } ^ { a b } The electromagnetic stress-energy tensor 4 \\pi T _ { \\mathrm { em } } ^ { a b } = F ^ { a c } F _ { c } ^ { b } - \\frac { 1 } { 4 } g ^ { a b } F _ { c d } F ^ { c d } 4 \\pi T _ { \\mathrm { em } } ^ { a b } = F ^ { a c } F _ { c } ^ { b } - \\frac { 1 } { 4 } g ^ { a b } F _ { c d } F ^ { c d }","title":"Electromagnetic Field Equations"},{"location":"NR/#equation-of-state","text":"For many purposes it is useful to employ a simple \u201c\u0393-law\u201d equation of state (EOS) of the form P = (\\Gamma - 1) \\rho_0 \\varepsilon P = (\\Gamma - 1) \\rho_0 \\varepsilon Realistic applications involving relativistic objects are rarely described by EOSs obeying this simple form . However, a \u0393-law EOS provides a computationally practical, albeit crude, approximation that can be adapted to mimick the gross behavior of different states of matter in many applications. For example, to model a stiff nuclear EOS in a neutron star , one can adopt a moderately high value of \u0393 in a \u0393-law EOS, e.g. \u0393 \u2248 2. By contrast, to model a moderately soft, thermal radiation-dominated EOS governing a very massive or supermassive star, one can set \u0393 = 4/3. For isentropic flow, a \u0393-law EOS is equivalent to the equation of state of a polytrope, P = K \\rho _ { 0 } ^ { \\Gamma } , \\quad \\Gamma = 1 + 1 / n P = K \\rho _ { 0 } ^ { \\Gamma } , \\quad \\Gamma = 1 + 1 / n where n is the polytropic index and K is the gas constant. However, for non-isentropic flow, which is always the case when encountering a shock, K is no longer constant throughout the fluid .","title":"Equation of state"},{"location":"NR/#collisionless-matter","text":"Several important astrophysical systems are made up of particles of collisionless matter. In such systems, the mean-free-path for particle-particle interactions is much longer than the scale of the system. One example of a collisionless system is a star cluster, a large, self-gravitating, N-body system in which the individual particles \u2013 the stars \u2013 interact exclusively via gravitation.","title":"Collisionless Matter"},{"location":"NR/#scalar-fields","text":"Scalar fields give rise to particles of spin 0, while vector fields (like the electromagnetic field) give rise to particles of spin 1 (like the photon, in the case of electromagnetism), and tensor fields of rank two or higher give rise to higher-spin particles. A complex scalar field has two degrees of freedom instead of just one, and it can be interpreted as a particle and an antiparticle. Real fields are their own antiparticles. A neutral \u03c0 meson is an example of a real scalar field, while the charged \u03c0^+ \u03c0^+ - and \u03c0_\u2212 \u03c0_\u2212 -mesons are described by complex scalar fields.","title":"Scalar Fields"},{"location":"NR/#evolution-equations","text":"The evolution equations evolve the data (\u03b3_{ab},K_{ab}) (\u03b3_{ab},K_{ab}) forward in time. However, the Lie derivative along n^a n^a , \\mathcal { L } _ { \\mathbf { n } } \\mathcal { L } _ { \\mathbf { n } } , is not a natural time derivative since n^a n^a is not dual to the surface 1-form \u03a9_a \u03a9_a , i.e. their dot product is not unity n ^ { a } \\Omega _ { a } = - \\alpha g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t = \\alpha ^ { - 1 } n ^ { a } \\Omega _ { a } = - \\alpha g ^ { a b } \\nabla _ { a } t \\nabla _ { b } t = \\alpha ^ { - 1 } Instead, consider the vector t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } which is dual to \u03a9_a \u03a9_a for any spatial shift vector \u03b2^a \u03b2^a , t ^ { a } \\Omega _ { a } = \\alpha n ^ { a } \\Omega _ { a } + \\beta ^ { a } \\Omega _ { a } = 1 t ^ { a } \\Omega _ { a } = \\alpha n ^ { a } \\Omega _ { a } + \\beta ^ { a } \\Omega _ { a } = 1 It will prove useful to choose t^a t^a to be the congruence along which we propagate the spatial coordinate grid from one time slice to the next slice. In other words, t^a t^a will connect points with the same spatial coordinates on neighboring time slices. Then the shift vector \u03b2^a \u03b2^a will measure the amount by which the spatial coordinates are shifted within a slice with respect to the normal vector. The lapse function \u03b1 \u03b1 measures how much proper time elapses between neighboring time slices along the normal vector. The lapse and the shift therefore determine how the coordinates evolve in time. The choice of \u03b1 \u03b1 and \u03b2^a \u03b2^a is quite arbitrary. The freedom to choose these four gauge functions \u03b1 \u03b1 and \u03b2^a \u03b2^a completely arbitrarily embodies the four-fold coordinate degrees of freedom inherent in general relativity . The lapse and the shift determine how the coordinates evolve from one time slice \u03a3 to the next, whereas the constraint equations represent integrability conditions which have to be satisfied within each slice. Therefore, the constraints have to be independent of how the coordinates evolve, and the lapse and the shift can enter only the evolution equations . Observers who are \u201cat rest\u201d relative to the slices follow the normal congruence n^a n^a and are called either normal or Eulerian observers. while observers following the congruence t^a t^a are called coordinate observers. If matter is present it moves entirely independently of the coordinates with four-velocity u^a u^a . Ricci\u2019s equation: The evolution equation for the extrinsic curvature: \\begin{align} \\mathcal{L}_{t} K_{ab} = &- D_{a} D_{b} \\alpha + \\alpha (R_{ab} - 2 K_{ac} K^{c}_{\\space b} + K K_{ab}) \\\\ &- 8 \\pi \\alpha \\left( S_{ab} - \\frac{1}{2} \\gamma_{ab} \\left( S-\\rho \\right) \\right) + \\mathcal{L}_{\\beta}K_{ab} \\end{align} \\begin{align} \\mathcal{L}_{t} K_{ab} = &- D_{a} D_{b} \\alpha + \\alpha (R_{ab} - 2 K_{ac} K^{c}_{\\space b} + K K_{ab}) \\\\ &- 8 \\pi \\alpha \\left( S_{ab} - \\frac{1}{2} \\gamma_{ab} \\left( S-\\rho \\right) \\right) + \\mathcal{L}_{\\beta}K_{ab} \\end{align} a projection with two indices projected in the normal direction. \\mathcal{L}_n K_{ab} = n^d n^c \\gamma^q_{\\space a} \\gamma^r_{\\space b} {}^{(4)} R_{drcq} - \\frac{1}{\\alpha} D_a D_b \\alpha - K^c_{\\space b} K_{ac} \\\\ S_{ab} = \\gamma^c_{\\space a} \\gamma^d_{\\space b} T_{cd} \\\\ S = S^a_{\\space a} \\mathcal{L}_n K_{ab} = n^d n^c \\gamma^q_{\\space a} \\gamma^r_{\\space b} {}^{(4)} R_{drcq} - \\frac{1}{\\alpha} D_a D_b \\alpha - K^c_{\\space b} K_{ac} \\\\ S_{ab} = \\gamma^c_{\\space a} \\gamma^d_{\\space b} T_{cd} \\\\ S = S^a_{\\space a} The evolution equation for the spatial metric \\gamma_{ab} \\gamma_{ab} : \\mathcal{L}_t \\gamma_{ab} = - 2 \\alpha K_{ab} + \\mathcal{L}_{\\beta} \\gamma_{ab} \\mathcal{L}_t \\gamma_{ab} = - 2 \\alpha K_{ab} + \\mathcal{L}_{\\beta} \\gamma_{ab} K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} K_{ab} = - \\frac{1}{2} \\mathcal{L}_n \\gamma_{ab} It is quite intuitive, though, that things will simplify if we adopt a coordinate system that reflects our 3 + 1 split of spacetime in a natural way. We will see that the Lie derivative in the evolution equations then reduces to a partial derivative with respect to coordinate time and, as an additional bene\ufb01t, we will be able to ignore all timelike components of spatial tensors. The coupled evolution equations the extrinsic curvature and the spatial metric determine the evolution of the gravitational \ufb01eld data (\\gamma_{ab}, K_{ab}) (\\gamma_{ab}, K_{ab}) . Together with the constraint equations they are completely equivalent to Einstein\u2019s equations. Note we have succeeded in recasting Einstein\u2019s equations, which are second order in time in their original form, as a coupled set of partial differential equations that are now first order in time . So far, we have expressed our equations in a covariant, coordinate independent manner, i.e. the basis vectors e_a e_a have been completely arbitrary and have no particular relationship to the 1-form \u03a9_a \u03a9_a or to the congruence defined by t^a t^a .","title":"Evolution Equations"},{"location":"NR/#adm-equations","text":"It is quite intuitive, though, that things will simplify if we adopt a coordinate system that effects our 3 + 1 split of spacetime in a natural way. To do so, we first introduce a basis of three spatial vectors e^a_{(i)} e^a_{(i)} , reside in a particular time slice \u03a3: \\Omega_a e^a_{(i)} = 0 \\Omega_a e^a_{(i)} = 0 We extend our spatial vectors to other slices \u03a3 by Lie dragging along t^a t^a \\mathcal{L}_t e^a_{(i)} = 0 \\mathcal{L}_t e^a_{(i)} = 0 As the fourth basis vector we pick e^a_0 = t^a e^a_0 = t^a . The duality condition then implies that e^a_{(0)} e^a_{(0)} has the components t ^ { a } = e _ { ( 0 ) } ^ { a } = ( 1,0,0,0 ) t ^ { a } = e _ { ( 0 ) } ^ { a } = ( 1,0,0,0 ) This means that the Lie derivative along t^a t^a reduces to a partial derivative with respect to t: \\mathcal{L}_t = \\partial_t \\mathcal{L}_t = \\partial_t . Since spatial tensors vanish when contracted with the normal vector, this also means that all components of spatial tensors with a contravariant index equal to zero must vanish. For the shift vector, \\beta ^ { a } = \\left( 0 , \\beta ^ { i } \\right) \\beta ^ { a } = \\left( 0 , \\beta ^ { i } \\right) Solving equation t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } t ^ { a } = \\alpha n ^ { a } + \\beta ^ { a } for n^a n^a then yields the contravariant components n ^ { a } = \\left( \\alpha ^ { - 1 } , - \\alpha ^ { - 1 } \\beta ^ { i } \\right) n ^ { a } = \\left( \\alpha ^ { - 1 } , - \\alpha ^ { - 1 } \\beta ^ { i } \\right) and from the normalization condition n_a n^a = \u22121 n_a n^a = \u22121 we find n _ { a } = ( - \\alpha , 0,0,0 ) n _ { a } = ( - \\alpha , 0,0,0 ) From the definition of the spatial metric we have \\gamma_{ij} = g_{ij} \\gamma_{ij} = g_{ij} meaning that the metric on \u03a3 is just the spatial part of the four-metric. Since zeroth components of spatial contravariant tensors have to vanish, we also have \\gamma^{a0} = 0 \\gamma^{a0} = 0 . The inverse metric can therefore be expressed as: g^{ab} = \\gamma^{ab} - n^{a} n^{b} = \\begin{pmatrix} \\alpha^{-2} & \\alpha^{-2} \\beta^{i} \\\\ \\alpha^{-2} \\beta^{j} & \\gamma^{ij} - \\alpha^{2} \\beta^{i} \\beta^{j} \\end{pmatrix} g^{ab} = \\gamma^{ab} - n^{a} n^{b} = \\begin{pmatrix} \\alpha^{-2} & \\alpha^{-2} \\beta^{i} \\\\ \\alpha^{-2} \\beta^{j} & \\gamma^{ij} - \\alpha^{2} \\beta^{i} \\beta^{j} \\end{pmatrix} We can now invert it and find the components of the four-dimensional metric g_{ab} = \\begin{pmatrix} \\alpha^{-2} + \\beta_l \\beta^l & \\beta_{i} \\\\ \\beta_{j} & \\gamma_{ij} \\end{pmatrix} g_{ab} = \\begin{pmatrix} \\alpha^{-2} + \\beta_l \\beta^l & \\beta_{i} \\\\ \\beta_{j} & \\gamma_{ij} \\end{pmatrix} Equivalently, the line element may be decomposed as: ds^{2} = - \\alpha^{2} dt^{2} + \\gamma_{ij} \\left( dx^{i} + \\beta^{i} dt \\right) \\left( dx^{j} + \\beta^{j}dt \\right) ds^{2} = - \\alpha^{2} dt^{2} + \\gamma_{ij} \\left( dx^{i} + \\beta^{i} dt \\right) \\left( dx^{j} + \\beta^{j}dt \\right) which is often refered to as the metric in 3 + 1 form. We may interpret this line element as the Pythagorean Theorem for a 4-dimensional spacetime, ds^2 = - (proper time between neighboring spatial hypersurfaces)^2 + (proper distance within the spatial hypersurface)^2 ds^2 = - (proper time between neighboring spatial hypersurfaces)^2 + (proper distance within the spatial hypersurface)^2 . This equation thus determines the invariant interval between neighboring points A and B. Therefore, the entire content of the decomposed Einstein equations is contained in their spatial components alone, and we can rewrite: the Hamiltonian constraint R + K^2 - K_{ij} K^{ij} = 16 \\pi \\rho R + K^2 - K_{ij} K^{ij} = 16 \\pi \\rho the momentum constraint D_{j} (K^{ij} - \\gamma^{ij} K) = 8 \\pi S^i D_{j} (K^{ij} - \\gamma^{ij} K) = 8 \\pi S^i the evolution equation for the extrinsic curvature \\begin{align} \\partial_{t} K_{ij} = &- D_{i} D_{j} \\alpha + \\alpha \\left( R_{ij} - 2 K_{ik} K^{k}_{\\space j} + K K_{ij}\\right) - 8 \\pi \\alpha \\left( S_{ij} - \\frac{1}{2} \\gamma_{ij} \\left( S - \\rho \\right) \\right) \\\\ &+ \\beta^{k} D_{k} K_{ij} + K_{ik} D_{j} \\beta^{k} + K_{kj} D_{i} \\beta^{k} \\end{align} \\begin{align} \\partial_{t} K_{ij} = &- D_{i} D_{j} \\alpha + \\alpha \\left( R_{ij} - 2 K_{ik} K^{k}_{\\space j} + K K_{ij}\\right) - 8 \\pi \\alpha \\left( S_{ij} - \\frac{1}{2} \\gamma_{ij} \\left( S - \\rho \\right) \\right) \\\\ &+ \\beta^{k} D_{k} K_{ij} + K_{ik} D_{j} \\beta^{k} + K_{kj} D_{i} \\beta^{k} \\end{align} the evolution equation for the spatial metric \\partial_t \\gamma_{ij} = - 2 \\alpha K_{ij} + D_i \\beta_j + D_j \\beta_i \\partial_t \\gamma_{ij} = - 2 \\alpha K_{ij} + D_i \\beta_j + D_j \\beta_i Equations comprise the \u201cstandard\u201d 3 + 1 equations. Sometimes they are referred to as the \u201cADM\u201d equations. The decomposed Einstein equations do not provide any equations for \u03b1 \u03b1 and \u03b2_i \u03b2_i . Again, this is not surprising, since these functions represent the coordinate freedom of general relativity. The lapse and shift are therefore arbitrary, and must be determined by imposing gauge conditions . Clearly, different gauge conditions will lead to different functions for the spatial metric \u03b3_{ij} \u03b3_{ij} and the extrinsic curvature K_{ij} K_{ij} when they are used in the evolution equations. Even for a stationary spacetime, like Schwarzschild, most choices for the lapse and shift will lead to a time-dependent spatial metric function . Only for special choices of the lapse and the shift will the spatial metric of a stationary spacetime remain time-independent. This will be the case if our time-vector t^a t^a is aligned with a Killing-vector of the spacetime, Killing lapse and Killing shift. \u03be^a = t^a = \u03b1 n^a + \u03b2^a. \u03be^a = t^a = \u03b1 n^a + \u03b2^a. The lapses and shifts that we listed in Table are examples of such Killing lapses and Killing shifts.","title":"ADM Equations"},{"location":"NR/#numerical-methods","text":"As we have seen, Einstein\u2019s field equations in 3 + 1 form consist of a set of nonlinear, multidimensional, coupled partial differential equations in space and time. The equations of motion of the matter fields that may be present are typically of a similar nature. Except for very idealized problems with special symmetries, such equations must be solved by numerical means, often on supercomputers.","title":"Numerical Methods"},{"location":"NR/#classification-of-partial-differential-equations","text":"Consider the general equation of second-order partial differential equation A \\partial _ { \\xi } ^ { 2 } \\phi + 2 B \\partial _ { \\xi } \\partial _ { \\eta } \\phi + C \\partial _ { \\eta } ^ { 2 } \\phi = \\tilde { \\rho } A \\partial _ { \\xi } ^ { 2 } \\phi + 2 B \\partial _ { \\xi } \\partial _ { \\eta } \\phi + C \\partial _ { \\eta } ^ { 2 } \\phi = \\tilde { \\rho } where the coefficients A, B and C are real, differentiable, and do not vanish simultaneously. Also, the source term \\tilde { \\rho } \\tilde { \\rho } may depend on \u03c6, but only up to first order derivatives. Most of the resulting equations are second-order partial differential equations and can be classified into three categories: elliptic, parabolic or hyperbolic. If AC \u2212 B^2 > 0 AC \u2212 B^2 > 0 , then we can find a coordinate transformation from (\u03be, \u03b7) to some (x, y) that brings equation into the elliptic. The prototypical example of an elliptic equation is Poisson\u2019s equation , \\partial _ { x } ^ { 2 } \\phi + \\partial _ { y } ^ { 2 } \\phi = \\rho \\partial _ { x } ^ { 2 } \\phi + \\partial _ { y } ^ { 2 } \\phi = \\rho where \\rho \\rho is a source term that may depend on position, or even on \\phi \\phi up to first-order derivatives. For vanishing sources this equation is Laplace\u2019s equation. If AC \u2212 B^2 = 0 AC \u2212 B^2 = 0 , then we can find a coordinate transformation that brings equation into the parabolic. An example of a parabolic equation is the diffusion equation, \\partial _ { t } \\phi - \\partial _ { x } \\left( \\kappa \\partial _ { x } \\phi \\right) = \\rho \\partial _ { t } \\phi - \\partial _ { x } \\left( \\kappa \\partial _ { x } \\phi \\right) = \\rho where \\kappa \\kappa is the diffusion coefficient. Finally, if AC \u2212 B^2 < 0 AC \u2212 B^2 < 0 , then we can find a coordinate transformation that brings equation into the hyperbolic. The prototypical example of a hyperbolic equation is the wave equation, \\partial _ { t } ^ { 2 } \\phi - c ^ { 2 } \\partial _ { x } ^ { 2 } \\phi = \\rho \\partial _ { t } ^ { 2 } \\phi - c ^ { 2 } \\partial _ { x } ^ { 2 } \\phi = \\rho where c is the constant wave speed. The different types of partial differential equations require different kinds of boundary and/or initial conditions. The differential equations then tell us how these initial fields evolve with time. We may also have to impose spatial boundary conditions on the outer boundaries of our computational domain. Elliptic equations, on the other hand, determine a solution on a given spatial hypersurface. No initial data are required, but we must supply boundary values at the outer edge(s) of our computational domain. Boundary conditions can take various forms. For example, Dirichlet conditions specify the values of the solution functions on the boundary, while Neumann conditions specify their gradients on the boundary. We introduce the first time derivative of \\phi \\phi as a new independent variable, say \u2212k \u2212k , in which case we can rewrite the wave equation as the pair of equations \\begin{aligned} \\partial _ { t } \\phi & = - k \\\\ \\partial _ { t } k & = - c ^ { 2 } \\partial _ { x } ^ { 2 } \\phi - \\rho \\end{aligned} \\begin{aligned} \\partial _ { t } \\phi & = - k \\\\ \\partial _ { t } k & = - c ^ { 2 } \\partial _ { x } ^ { 2 } \\phi - \\rho \\end{aligned} The form is not a particularly elegant representation of a wave equation, since it contains first order time derivatives but second order space derivatives. We can fix that quite easily by also introducing the space derivative of \\phi \\phi as a new independent variable. With l \\equiv \\partial _ { x } \\phi l \\equiv \\partial _ { x } \\phi we now find the system \\begin{array} { l l } { \\partial _ { t } \\phi } & { = - k } \\\\ { \\partial _ { t } k + c ^ { 2 } \\partial _ { x } l } & { = - \\rho } \\\\ { \\partial _ { t } l } & { + \\partial _ { x } k } & { = 0 } \\end{array} \\begin{array} { l l } { \\partial _ { t } \\phi } & { = - k } \\\\ { \\partial _ { t } k + c ^ { 2 } \\partial _ { x } l } & { = - \\rho } \\\\ { \\partial _ { t } l } & { + \\partial _ { x } k } & { = 0 } \\end{array} where the last equation holds because the partial derivatives must commute. In a more compact notation we can write this as \\partial _ { t } \\mathbf { u } + \\mathbf { A } \\cdot \\partial _ { x } \\mathbf { u } = \\mathbf { S } \\partial _ { t } \\mathbf { u } + \\mathbf { A } \\cdot \\partial _ { x } \\mathbf { u } = \\mathbf { S } where u = (\u03c6, k, l) u = (\u03c6, k, l) is the solution vector, S = (\u2212k, \u2212\u03c1, 0) S = (\u2212k, \u2212\u03c1, 0) is the source vector, and where \\mathbf { A } = \\left( \\begin{array} { c c c } { 0 } & { 0 } & { 0 } \\\\ { 0 } & { 0 } & { c ^ { 2 } } \\\\ { 0 } & { 1 } & { 0 } \\end{array} \\right) \\mathbf { A } = \\left( \\begin{array} { c c c } { 0 } & { 0 } & { 0 } \\\\ { 0 } & { 0 } & { c ^ { 2 } } \\\\ { 0 } & { 1 } & { 0 } \\end{array} \\right) is the velocity matrix. Verify that any function \\phi = g ( x + c t ) + h ( x - c t ) \\phi = g ( x + c t ) + h ( x - c t ) satisfies the wave equation for \u03c1 = 0. Part of the solution \u03c6, namely g, travels along lines x + ct = const x + ct = const , while the other part h travels along x \u2212 ct = const x \u2212 ct = const . These lines are called the characteristic curves; they are those curves along which partial information about the solution propagates. Even if we cannot derive the general solution analytically, we can find the corresponding characteristic speeds dx/dt dx/dt from the eigenvalues of the velocity matrix A. In our example, these eigenvalues are \u00b1c \u00b1c and zero, as we would expect. Since no information can travel faster than the fastest characteristics, the solution at a certain event can only be affected by those events that lie inside the causal past, or past cone defined by the fastest ingoing and outgoing characteristics. In the context of relativity we are quite used to this concept, since causality demands that an event can only be affected by events in its past light cone. Consider the event Q, whose past characteristics are marked by solid lines. To completely determine \u03c6(t,r) \u03c6(t,r) at Q, we would have to provide initial data \u03c6(0,r) \u03c6(0,r) and \u2202_t\u03c6(0,r) \u2202_t\u03c6(0,r) inside the past cone defined by the two backward characteristics, namely on the interval \u03b3_Q \u03b3_Q . This is the domain of dependence of the point Q. In reverse, for any interval \u03b3 \u03b3 on the r-axis, there is a region of the spacetime in which all events depend only on initial data provided on \u03b3. This region is called the domain of determinacy. Suppose we want to obtain a solution to the wave equation. We will have to provide initial data on an interval \u03b3 \u03b3 that extends from a certain radius r_{min} r_{min} to a radius r_{max} r_{max} at, say, t = 0 t = 0 . If we want to construct the solution only in the domain of determinacy of \u03b3, then the solution is completely determined by the initial data on \u03b3, and no boundary conditions are needed. This situation, however, is rarely the case. It is more typical that we would like to construct the solution in the entire domain between r_{min} r_{min} and r_{max} r_{max} for all t > 0 t > 0 . For concreteness, imagine we want to find \u03c6 in the domain between r_{min}/M = 1 r_{min}/M = 1 and r_{max}/M = 9 r_{max}/M = 9 , marked by the dashed-dotted lines in Fig. 6.1. The event Q would still be completely determined by the initial data, but the event S, for example, would not. One of its backward characteristics intersects the outer boundary at r_{max}/M = 9 r_{max}/M = 9 . The event S is therefore outside the domain of determinacy of \u03b3, and the solution at S depends on more information than is provided by the initial data. This missing information now has to be provided by the boundary conditions. The situation is different at the inner boundary r_{min} r_{min} . Consider, for example, the event P, which lies on the boundary r_{min} r_{min} . Since we have chosen r_{min} r_{min} to be inside the event horizon, both characteristics originate from a larger r, and neither one intersects the boundary r_{min} r_{min} . The event P is therefore completely determined by the initial data (and, had we chosen P at a later time, by the outer boundary condition at r_{max} r_{max} ). There is no need to impose a boundary condition at r_{min} r_{min} , and in fact it would be inconsistent with the equations. This property will be important when we discuss black hole.","title":"Classification of Partial Differential Equations"},{"location":"NR/#black-hole-horizons","text":"Several different notions of horizons exist in general relativity. The defining property of a black hole is the presence of an event horizon, but apparent horizons also play an extremely important role in the context of numerical relativity. In addition, the concepts of isolated and dynamical horizons serve as useful diagnostics in numerical spacetimes containing black holes. A black hole is defined as a region of spacetime from which no null geodesic can escape to infinity. The surface of a black hole, the event horizon, acts as a one-way membrane through which light and matter can enter the black hole, but once inside, can never escape. It is the boundary in spacetime separating those events that can emit light rays that can propagate to infinity and those which cannot. More precisely, the event horizon is defined as the boundary of the causal past of future null infinity. The event horizon is a gauge-invariant entity, and contains important geometric information about a black hole spacetime. The area theorem2 of classical general relativity states that this surface area can never decrease in time, \\delta \\mathcal { A } \\geq 0 \\delta \\mathcal { A } \\geq 0 Two-dimensional surface, whose proper surface area we denote as \\mathcal { A } \\mathcal { A } . In the collision and coalescence of two or more black holes, the surface area of the remnant black hole must be greater than the sum of the progenitor black holes. The fact that the event horizon area cannot decrease motivates the definition of the irreducible mass. M _ { \\mathrm { irr } } \\equiv \\left( \\frac { \\mathcal { A } } { 16 \\pi } \\right) ^ { 1 / 2 } M _ { \\mathrm { irr } } \\equiv \\left( \\frac { \\mathcal { A } } { 16 \\pi } \\right) ^ { 1 / 2 } It is possible to extract energy and angular momentum from a rotating Kerr black hole. While such an interaction can reduce the black hole\u2019s mass, it cannot reduce its area, according to the area theorem. The irreducible mass of the black hole cannot decrease, which motivates its name. The area theorem can be used to place a strict upper limit on the amount of energy that is emitted in gravitational radiation in black hole collisions. Consider two widely separated, non-rotating black holes of masses M_1 M_1 and M_2 M_2 , initially at rest with respect to some distant observer. Use the area theorem to find an upper limit on the energy emitted in gravitational radiation that arises from the head-on collision of the two black holes. Verify that for equal mass black holes at most 29% 29% of the total initial energy can be emitted in gravitational radiation. Given the irreducible mass M_{irr} M_{irr} and the angular momentum J J of an isolated, stationary black hole, we can compute the Kerr mass M (= M_{ADM}) M (= M_{ADM}) from M ^ { 2 } = M _ { \\mathrm { irr } } ^ { 2 } + \\frac { 1 } { 4 } \\frac { J ^ { 2 } } { M _ { \\mathrm { irr } } ^ { 2 } } M ^ { 2 } = M _ { \\mathrm { irr } } ^ { 2 } + \\frac { 1 } { 4 } \\frac { J ^ { 2 } } { M _ { \\mathrm { irr } } ^ { 2 } } While the event horizon has some very interesting geometric properties, its global nature makes it very difficult to locate in a numerical simulation. The reason is that knowledge of the entire future spacetime is required to decide whether or not any particular null geodesic will ultimately escape to infinity . In numerical simulations an event horizon can be found only \u201cafter the fact\u201d, i.e., after the evolution has proceeded long enough to have settled down to a stationary state. The spacetime singularities inside the black holes must be excluded from the numerical grid, since they would otherwise spoil the numerical calculation. Several different strategies for avoiding black hole singularities numerically. One approach is based on the realization that, by definition, the interior of a black hole is causally disconnected from, and hence can never influence, the exterior. This fact suggests that we may \u201cexcise\u201d, i.e. remove from the computational domain, the spacetime region inside the event horizon. Black hole \u201cexcision\u201d requires at least approximate knowledge of the location of the horizon at all times during the evolution. The singularity theorems of general relativity tell us that if an apparent horizon exists on a given time slice, it must be inside a black hole event horizon. This theorem makes it safe to excise the interior of an apparent horizon from a numerical domain. Note the absence of an apparent horizon does not necessarily imply that a black hole is absent.","title":"Black Hole Horizons"},{"location":"NR/#finite-difference-methods","text":"In a finite difference approximation a function f(t,x) f(t,x) is represented by values at a discrete set of points. At the core of finite difference approximation is therefore a discretization of the spacetime, or a numerical grid. Instead of evaluating f at all values of x, for example, we only consider discrete values x_i x_i . The distance between the gridpoints x_i x_i is called the gridspacing \u2206x \u2206x . For uniform grids, for which \u2206x \u2206x is constant, we have x _ { i } = x _ { 0 } + i \\Delta x x _ { i } = x _ { 0 } + i \\Delta x If the solution depends on time we also discretize the time coordinate, for example as t ^ { n } = t ^ { 0 } + n \\Delta t t ^ { n } = t ^ { 0 } + n \\Delta t The finite difference representation of the function f(t,x) f(t,x) , for example, is f _ { i } ^ { n } = f \\left( t ^ { n } , x _ { i } \\right) + \\text { truncation error. } f _ { i } ^ { n } = f \\left( t ^ { n } , x _ { i } \\right) + \\text { truncation error. } Differential equations involve derivatives, so we must next discuss how to represent derivatives in a finite difference representation. Assuming that f(x) f(x) can be differentiated to sufficiently high order and that it can be represented as a Taylor series, we have f _ { i + 1 } = f \\left( x _ { i } + \\Delta x \\right) = f \\left( x _ { i } \\right) + \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) f _ { i + 1 } = f \\left( x _ { i } + \\Delta x \\right) = f \\left( x _ { i } \\right) + \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) Solving for \\left( \\partial _ { x } f \\right) _ { x _ { i } } = \\left( \\partial _ { x } f \\right) _ { i } \\left( \\partial _ { x } f \\right) _ { x _ { i } } = \\left( \\partial _ { x } f \\right) _ { i } we find \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i } } { \\Delta x } + \\mathcal { O } ( \\Delta x ) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i } } { \\Delta x } + \\mathcal { O } ( \\Delta x ) The truncation error of this expression is linear in \u2206x \u2206x , and it turns out that we can do better. We call equation a one-sided derivative , since it uses only neighbors on one side of x_i x_i . Consider the Taylor expansion to the point x_{ i \u2212 1 } x_{ i \u2212 1 } , f _ { i - 1 } = f \\left( x _ { i } - \\Delta x \\right) = f \\left( x _ { i } \\right) - \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) f _ { i - 1 } = f \\left( x _ { i } - \\Delta x \\right) = f \\left( x _ { i } \\right) - \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) we now find \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i - 1 } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i - 1 } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) which is second order in \u2206x \u2206x . In general, centered derivatives lead to higher order schemes than one-sided derivatives for the same number of gridpoints. The key point is that we are able to combine the two Taylor expansions in such a way that the leading order error term cancels out, leaving us with a higher order representation of the derivative . This cancellation only works out for uniform grids , when \u2206x \u2206x is independent of x. This is one of the reasons why many current numerical relativity applications of finite difference schemes work with uniform grids. Higher order derivatives can be constructed in a similar fashion. Adding the two Taylor expansions all terms odd in \u2206x \u2206x drop out and we find for the second derivative \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } } { ( \\Delta x ) ^ { 2 } } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } } { ( \\Delta x ) ^ { 2 } } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { 1 } { 12 \\Delta x } \\left( f _ { i - 2 } - 8 f _ { i - 1 } + 8 f _ { i + 1 } - f _ { i + 2 } \\right) \\\\ \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { 1 } { 12 ( \\Delta x ) ^ { 2 } } \\left( - f _ { i - 2 } + 16 f _ { i - 1 } - 30 f _ { i } + 16 f _ { i + 1 } - f _ { i + 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { 1 } { 12 \\Delta x } \\left( f _ { i - 2 } - 8 f _ { i - 1 } + 8 f _ { i + 1 } - f _ { i + 2 } \\right) \\\\ \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { 1 } { 12 ( \\Delta x ) ^ { 2 } } \\left( - f _ { i - 2 } + 16 f _ { i - 1 } - 30 f _ { i } + 16 f _ { i + 1 } - f _ { i + 2 } \\right) where we have omitted the truncation error, \\mathcal { O } \\left( \\Delta x ^ { 4 } \\right) \\mathcal { O } \\left( \\Delta x ^ { 4 } \\right)","title":"Finite Difference Methods"},{"location":"NR/#elliptic-equations","text":"As an example of a simple, one-dimensional elliptic equation consider \\partial _ { x } ^ { 2 } f = s \\partial _ { x } ^ { 2 } f = s For concreteness, let us assume that the solution f is a symmetric function about x = 0 x = 0 , in which case we can restrict the analysis to positive x and impose a Neuman condition at the origin, \\partial _ { x } f = 0 \\quad \\text { at } x = 0 \\partial _ { x } f = 0 \\quad \\text { at } x = 0 Let us also assume that f falls off with 1/x 1/x for large x, which results in the Robin boundary condition \\partial _ { x } ( x f ) = 0 \\quad \\text { as } x \\rightarrow \\infty \\partial _ { x } ( x f ) = 0 \\quad \\text { as } x \\rightarrow \\infty We will further assume that the source term s is some known function of x. To do so, we first have to construct a numerical grid that covers an interval between x_{min} = 0 x_{min} = 0 and x_{max} x_{max} . We then divide the interval [x_{min},x_{max}] [x_{min},x_{max}] into N gridcells, leading to a gridspacing of \\Delta x = \\frac { x _ { \\max } - x _ { \\min } } { N } \\Delta x = \\frac { x _ { \\max } - x _ { \\min } } { N } We can choose our grid points to be located either at the center of these cells, which would be referred to as a cell-centered grid, or on the vertices, which would be refered to as a vertex-centered grid. For a cell-centered grid we have N grid points located at x _ { i } = x _ { \\min } + ( i - 1 / 2 ) \\Delta x , \\quad i = 1 , \\ldots , N x _ { i } = x _ { \\min } + ( i - 1 / 2 ) \\Delta x , \\quad i = 1 , \\ldots , N We define two arrays, f_i f_i and s_i s_i , which represent the functions f and s at the gridpoints x_i x_i for i = 1, ..., N i = 1, ..., N . In the interior of our domain we can represent the differential equation as f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } = ( \\Delta x ) ^ { 2 } s _ { i } \\quad i = 2 , \\ldots , N - 1 f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } = ( \\Delta x ) ^ { 2 } s _ { i } \\quad i = 2 , \\ldots , N - 1 The boundary condition \\left( \\partial _ { x } f \\right) _ { 1 / 2 } = \\frac { f _ { 1 } - f _ { 0 } } { \\Delta x } = 0 \\\\ f _ { N + 1 } = \\frac { x _ { N } } { x _ { N + 1 } } f _ { N } = \\frac { x _ { N } } { x _ { N } + \\Delta x } f _ { N } \\left( \\partial _ { x } f \\right) _ { 1 / 2 } = \\frac { f _ { 1 } - f _ { 0 } } { \\Delta x } = 0 \\\\ f _ { N + 1 } = \\frac { x _ { N } } { x _ { N + 1 } } f _ { N } = \\frac { x _ { N } } { x _ { N } + \\Delta x } f _ { N } a coupled set of N linear equations for the N elements f_i f_i that we can write as \\left( \\begin{array} { c c c c c c c } { - 1 } & { 1 } & { 0 } & { 0 } & { 0 } & { 0 } & { 0 } \\\\ { 1 } & { - 2 } & { 1 } & { 0 } & { 0 } & { 0 } & { 0 } \\\\ { 0 } & { \\ddots } & { \\ddots } & { \\ddots } & { 0 } & { 0 } & { 0 } \\\\ { 0 } & { 0 } & { 1 } & { - 2 } & { 1 } & { 0 } & { 0 } \\\\ { 0 } & { 0 } & { 0 } & { \\ddots } & { \\ddots } & { \\ddots } & { 0 } \\\\ { 0 } & { 0 } & { 0 } & { 0 } & { 1 } & { - 2 } & { 1 } \\\\ { 0 } & { 0 } & { 0 } & { 0 } & { 0 } & { 1 } & { x _ { N } / \\left( x _ { N } + \\Delta x \\right) - 2 } \\end{array} \\right) \\left( \\begin{array} { c } { f _ { 1 } } \\\\ { f _ { 2 } } \\\\ { \\vdots } \\\\ { f _ { i } } \\\\ { \\vdots } \\\\ { f _ { N - 1 } } \\\\ { f _ { N } } \\end{array} \\right) = ( \\Delta x ) ^ { 2 } \\left( \\begin{array} { c } { s _ { 1 } } \\\\ { s _ { 2 } } \\\\ { \\vdots } \\\\ { s _ { i } } \\\\ { \\vdots } \\\\ { s _ { N - 1 } } \\\\ { s _ { N } } \\end{array} \\right) \\left( \\begin{array} { c c c c c c c } { - 1 } & { 1 } & { 0 } & { 0 } & { 0 } & { 0 } & { 0 } \\\\ { 1 } & { - 2 } & { 1 } & { 0 } & { 0 } & { 0 } & { 0 } \\\\ { 0 } & { \\ddots } & { \\ddots } & { \\ddots } & { 0 } & { 0 } & { 0 } \\\\ { 0 } & { 0 } & { 1 } & { - 2 } & { 1 } & { 0 } & { 0 } \\\\ { 0 } & { 0 } & { 0 } & { \\ddots } & { \\ddots } & { \\ddots } & { 0 } \\\\ { 0 } & { 0 } & { 0 } & { 0 } & { 1 } & { - 2 } & { 1 } \\\\ { 0 } & { 0 } & { 0 } & { 0 } & { 0 } & { 1 } & { x _ { N } / \\left( x _ { N } + \\Delta x \\right) - 2 } \\end{array} \\right) \\left( \\begin{array} { c } { f _ { 1 } } \\\\ { f _ { 2 } } \\\\ { \\vdots } \\\\ { f _ { i } } \\\\ { \\vdots } \\\\ { f _ { N - 1 } } \\\\ { f _ { N } } \\end{array} \\right) = ( \\Delta x ) ^ { 2 } \\left( \\begin{array} { c } { s _ { 1 } } \\\\ { s _ { 2 } } \\\\ { \\vdots } \\\\ { s _ { i } } \\\\ { \\vdots } \\\\ { s _ { N - 1 } } \\\\ { s _ { N } } \\end{array} \\right) or, in a more compact form, \\mathbf { A } \\cdot \\mathbf { f } = ( \\Delta x ) ^ { 2 } \\mathbf { S } \\mathbf { A } \\cdot \\mathbf { f } = ( \\Delta x ) ^ { 2 } \\mathbf { S } The solution is given by \\mathbf { f } = ( \\Delta x ) ^ { 2 } \\mathbf { A } ^ { - 1 } \\cdot \\mathbf { S } \\mathbf { f } = ( \\Delta x ) ^ { 2 } \\mathbf { A } ^ { - 1 } \\cdot \\mathbf { S } Sticking with our example in **two dimension**s, another multigrid methods becomes apparent. The numerical solution is computed on a hierarchy of computational grids. The coarse grid is sufficiently small so that we can compute a solution with a direct solver (i.e. direct matrix inversion). This provides the \u201cglobal\u201d features of the solution , albeit on a coarse grid and hence with a large local truncation error. We then interpolate this approximate solution to the next finer grid . This interpolation from a coarser grid to a finer grid is called a \u201cprolongation\u201d , and we point out that the details of this interpolation depend on whether the grid is cell-centered or vertex-centered. On the finer grid we can then apply a relaxation method. The interpolation from a finer grid to a coarser grid is called a \u201crestriction\u201d . The coarser grids now \u201clearn\u201d from the finer grids by comparing their last solution with the one that comes back from a finer grid. This comparison provides an estimate for the local truncation error. These sweeps through the grid hierarchy can be repeated until the solution has converged to a pre-determined accuracy . f _ { i , j } = \\frac { 1 } { 4 } \\left( f _ { i + 1 , j } + f _ { i - 1 , j } + f _ { i , j + i } + f _ { i , j - 1 } \\right) - \\frac { \\Delta ^ { 2 } } { 4 } s _ { i , j } f _ { i , j } = \\frac { 1 } { 4 } \\left( f _ { i + 1 , j } + f _ { i - 1 , j } + f _ { i , j + i } + f _ { i , j - 1 } \\right) - \\frac { \\Delta ^ { 2 } } { 4 } s _ { i , j } Evidently, finite differencing the flat-space Laplace operator results in each grid function at every grid point being directly related to the average value of its nearest neighbors. nonlinear elliptic equations Consider an equation of the form \\nabla ^ { 2 } f = f ^ { n } g \\nabla ^ { 2 } f = f ^ { n } g where g is a given function and n is some number. Linear equations that are straighforward to solve by the same matrix techniques. But what about the situation for other values of n, resulting in a nonlinear equation for f? We linearize the equation first and then iterate to get the nonlinear solution.","title":"Elliptic Equations"},{"location":"NR/#hyperbolic-equations","text":"As a model of hyperbolic equations, consider a \u201cscalar\u201d version of equation. For simplicity it does not contain any source terms, and the the wave speed v is constant. \\partial _ { t } u + v \\partial _ { x } u = 0 \\partial _ { t } u + v \\partial _ { x } u = 0 The equation is satisfied exactly by any function of the form u ( t , x ) = u ( x - v t ) u ( t , x ) = u ( x - v t ) . In contrast to the elliptic equations the equation has a time derivative in addition to the space derivative, and thus requires initial data . Inserting both finite-difference representations \\left( \\partial _ { x } u \\right) _ { j } ^ { n } = \\frac { u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\\\ \\left( \\partial _ { t } u \\right) _ { j } ^ { n } = \\frac { u _ { j } ^ { n + 1 } - u _ { j } ^ { n } } { \\Delta t } + \\mathcal { O } ( \\Delta t ) \\left( \\partial _ { x } u \\right) _ { j } ^ { n } = \\frac { u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\\\ \\left( \\partial _ { t } u \\right) _ { j } ^ { n } = \\frac { u _ { j } ^ { n + 1 } - u _ { j } ^ { n } } { \\Delta t } + \\mathcal { O } ( \\Delta t ) we can solve for u^{n+1}_j u^{n+1}_j and find u _ { j } ^ { n + 1 } = u _ { j } ^ { n } - \\frac { v } { 2 } \\frac { \\Delta t } { \\Delta x } \\left( u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } \\right) u _ { j } ^ { n + 1 } = u _ { j } ^ { n } - \\frac { v } { 2 } \\frac { \\Delta t } { \\Delta x } \\left( u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } \\right) or reasons that are quite obivous this differencing scheme is called forward-time centered-space, or FTCS. The Courant-Friedrichs-Lewy condition \\frac { | v | \\Delta t } { \\Delta x } \\leq 1 \\frac { | v | \\Delta t } { \\Delta x } \\leq 1 The Courant condition states that the the grid point u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } at the new time level n+1 has to reside inside the domain of determinacy of the interval spanned by the finite difference stencil at the time level n. This makes intuitive sense: if u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } were outside this domain, its physical specification would require more information about the past than we are providing numerically, which may trigger an instability. Recalling that v represents the speed of a characteristic, we may interpret the Courant condition in terms of the domain of determinacy.","title":"Hyperbolic Equations"},{"location":"NR/#mesh-refinement","text":"Many current numerical relativity codes use a uniform grid spacing to cover the entire spatial domain. On the one hand we have to resolve these sources well, so as to minimize truncation error in the strong-field region. On the other hand, the grid must extend into the weak-field region at large distances from the sources, so as to minimize error from the outer boundaries and to enable us to extract the emitted gravitational radiation accurately. A very promising alternative is mesh refinement, which has been widely developed and used in the computational fluid dynamics community and is becoming increasingly popular in numerical relativity. The basic idea underlying mesh refinement techniques is to perform the simulation not on one numerical grid, but on several , as in the multigrid methods. A coarse grid covers the entire space, and extends to large physical separations. Wherever finer resolution is needed to resolve small-scale structures. Typically, the gridspacing on the finer grid is half that on the next coarser grid, but clearly other refinement factors can be chosen. The hierarchy can be extended, and typical mesh refinement applications employ multiple refinement levels . Two versions of mesh refinement can be implemented. In the simpler version, called fixed mesh refinement or FMR , it is assumed that the refined grids will be needed only at known locations in space that remain fixed throughout the simulation. The situation is more complicated for objects that are moving, as is the case for a coalescing binary star system. Moreover, these regions will be changing as the system evolves and the stars move. Clearly, we would like to move the refined grids with the stars. Such an approach, whereby the grid is relocated during the simulation to give optimal resolution at each time step, is called adaptive mesh refinement or AMR .","title":"Mesh Refinement"},{"location":"NR/#example","text":"","title":"Example"},{"location":"NR/#spherically-symmetric-spacetimes","text":"Non-rotating stars and black holes are themselves spherical, so many important aspects of gravitational collapse, including black hole formation and growth, can be studied in spherical symmetry. For example, the numerical study of spherically symmetric collapse to black holes led to the discovery of critical phenomena in black hole formation. The field equations reduce to 1+1 dimensions \u2013 variables may be written as functions of only two parameters, a time coordinate t and a suitable radial coordinate r. The high degree of symmetry permits us to write the 3-metric of a spherical spacetime in the general form d l ^ { 2 } = A d r ^ { 2 } + B r ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) d l ^ { 2 } = A d r ^ { 2 } + B r ^ { 2 } \\left( d \\theta ^ { 2 } + \\sin ^ { 2 } \\theta d \\phi ^ { 2 } \\right) where A and B are functions only of t and r. Rotation cannot be treated in spherical symmetry. Spinning stars, star clusters and black holes, rotational instabilities in stars and star clusters, relativistic effects induced by the dragging of inertial frames \u2013 none of these features are present in spherical symmetry. Moreover, gravitational radiation cannot be generated in spherical spacetimes: Birkhoff\u2019s theorem forbids it. We thus will have to postpone studying rotation and gravitational wave generation until we relax the restriction to spherical symmetry and advance to axisymmetry. In axisymmetry, spacetime has 2+1 dimensions \u2013 two spatial coordinates, e.g., r and a polar angle \u03b8, plus t are necessary to specify the value of any function.","title":"Spherically Symmetric Spacetimes"},{"location":"ET/Cactus/","text":"Cactus executables always run from a parameter file, which specifies which thorns to use and sets the values of each thorn\u2019s parameters (the parameters that are not set will take on default values). There is no restriction on the name of the parameter file, although it is conventional to use the file extension .par . A parameter file is a text file whose lines are either comments or parameter statements. Comments are blank lines or lines that begin with \u2018#\u2019. A parameter statement consists of one or more parameter names, followed by an \u2018=\u2019, followed by the value(s) for this (these) parameter(s). The first parameter statement in any parameter file should set ActiveThorns, which is a special parameter that tells the program which thorns are to be activated. Only parameters from active thorns can be set (and only those routines scheduled by active thorns are run). By default all thorns are inactive. For example, 1 ActiveThorns = \"CartGrid3D\" Parameter specifications following ActiveThorns usually are carried out by listing the name of the thorn which defined the parameter, two colons, and the name of the parameter 1 wavetoyF77::amplitude Screen output As your Cactus executable runs, standard output and standard error are usually written to the screen. Standard output provides you with information about the run, and standard error reports warnings and errors from the flesh and thorns. As the program runs, the normal output provides the following information: Active thorns: This report shows whether the thorn activation was successful, and if successful gives the thorn\u2019s implementation. Failed parameters: If any of the parameters in the parameter file does not belong to any of the active thorns, or if the parameter value is not in the allowed range, an error is registered. For example, 1 2 3 4 5 Activating thorn idscalarwave...Success -> active implementation idscalarwave # if the parameter is not recognised Unknown parameter time::ddtfac # if the parameter value is not in the allowed range Unable to set keyword CartGrid3D::type - ByMouth not in any active range Checkpointing Checkpointing is defined as saving the current state of a run to a file. At a later time, this run can then be restarted from that state by recovering all the data from the checkpoint file. Cactus checkpointing and recovery methods are provided by thorns. In general, these thorns decide how often to generate a checkpoint. Parameter File Syntax A parameter file (or par file) is used to control the behaviour of a Cactus executable. A parameter statement is an expression of the form Left-Hand-Side = Right-Hand-Side . The Left-Hand-Side may be a fully qualified parameter name. The Right-Hand-Side is a value. Values can be any of the following Booleans : Booleans are either true (i.e. 1, true, on, \"true\", or \"on\") or false (i.e. 0, false, off, \"false\", or \"off\"). Integers : Integers can be positive or negative. Real numbers : Real numbers can be positive or negative and may be written with exponents (e.g. 1.0e-3, or -2.94d+10). Strings : Sequences of characters delimited by quotes. Variables : Parameter values can also contain variables of the form ${ VARIABLE } or $ENV{VARIABLE} . Expressions : Parameters statements of numeric or boolean type can use arithmetic expressions in place of explicit values. Array assignments : Arrays of parameters can be set by including an integer expression inside the square brackets following the name, e.g. thorn::parameters[0] . Optionally, an array of parameters may be set by means of a comma delimited list of values inside square brackets, e.g. thorn::parameters = [4.8, 3.2] . Please see the file par.peg in the directory Cactus/src/piraha/pegs for the full grammar describing the par file. The parameter file is read sequentially from top to bottom, this means that if you set the value of a parameter twice in the parameter file, the second value will be used. Note You can obtain lists of the parameters associated with each thorn using the command-line options. -O : Prints a full list of all parameters from all thorns which were compiled, along with descriptions and allowed values. -o : Prints the description and allowed values for a given parameter\u2014takes one argument.","title":"Cactus"},{"location":"ET/Cactus/#parameter-file-syntax","text":"A parameter file (or par file) is used to control the behaviour of a Cactus executable. A parameter statement is an expression of the form Left-Hand-Side = Right-Hand-Side . The Left-Hand-Side may be a fully qualified parameter name. The Right-Hand-Side is a value. Values can be any of the following Booleans : Booleans are either true (i.e. 1, true, on, \"true\", or \"on\") or false (i.e. 0, false, off, \"false\", or \"off\"). Integers : Integers can be positive or negative. Real numbers : Real numbers can be positive or negative and may be written with exponents (e.g. 1.0e-3, or -2.94d+10). Strings : Sequences of characters delimited by quotes. Variables : Parameter values can also contain variables of the form ${ VARIABLE } or $ENV{VARIABLE} . Expressions : Parameters statements of numeric or boolean type can use arithmetic expressions in place of explicit values. Array assignments : Arrays of parameters can be set by including an integer expression inside the square brackets following the name, e.g. thorn::parameters[0] . Optionally, an array of parameters may be set by means of a comma delimited list of values inside square brackets, e.g. thorn::parameters = [4.8, 3.2] . Please see the file par.peg in the directory Cactus/src/piraha/pegs for the full grammar describing the par file. The parameter file is read sequentially from top to bottom, this means that if you set the value of a parameter twice in the parameter file, the second value will be used. Note You can obtain lists of the parameters associated with each thorn using the command-line options. -O : Prints a full list of all parameters from all thorns which were compiled, along with descriptions and allowed values. -o : Prints the description and allowed values for a given parameter\u2014takes one argument.","title":"Parameter File Syntax"},{"location":"ET/Install/","text":"Required Software 1 2 3 4 5 6 7 8 # On Debian/Ubuntu use this command: sudo apt-get install -y subversion gcc git numactl libgsl-dev libpapi-dev python libhwloc-dev make libopenmpi-dev libhdf5-openmpi-dev libfftw3-dev libssl-dev liblapack-dev g++ curl gfortran patch pkg-config libhdf5-dev libjpeg-turbo?-dev # On Fedora use this command: sudo dnf install -y libjpeg-turbo-devel gcc git lapack-devel make subversion gcc-c++ which papi-devel python hwloc-devel openmpi-devel hdf5-openmpi-devel openssl-devel libtool-ltdl-devel numactl-devel gcc-gfortran findutils hdf5-devel fftw-devel patch gsl-devel pkgconfig module load mpi/openmpi-x86_64 # On Centos use this command: sudo yum install -y epel-release sudo yum install -y libjpeg-turbo-devel gcc git lapack-devel make subversion gcc-c++ which papi-devel hwloc-devel openmpi-devel hdf5-openmpi-devel openssl-devel libtool-ltdl-devel numactl-devel gcc-gfortran hdf5-devel fftw-devel patch gsl-devel Download A script called GetComponents is used to fetch the components of the Einstein Toolkit. 1 2 3 4 5 cd ~/ curl -kLO https://raw.githubusercontent.com/gridaphobe/CRL/ET_2018_09/GetComponents chmod a+x GetComponents ./GetComponents --parallel https://bitbucket.org/einsteintoolkit/manifest/raw/ET_2018_09/einsteintoolkit.th cd ~/Cactus Configuring SimFactory for your machine 1 ./simfactory/bin/sim setup-silent Building the Einstein Toolkit 1 ./simfactory/bin/sim build --mdbkey make 'make -j2' --thornlist ../einsteintoolkit.th | cat A step by step guide to downloading, configuring, and running the Einstein Toolkit.","title":"Install"},{"location":"ET/Introduction/","text":"The Einstein Toolkit is a community-driven software platform of core computational tools to advance and support research in relativistic astrophysics and gravitational physics.","title":"Introduction"},{"location":"ET/Thorn/","text":"A thorn is the basic working module within Cactus. All user supplied code goes into thorns, which are, by and large, independent of each other. Relationships among thorns are all based upon relationships among the implementations they provide. Thorns are grouped into arrangements. This is a logical grouping of thorns which is purely for organisational purposes. The arrangements live in the arrangements directory of the main Cactus directory. A thorn consists of a subdirectory of an arrangement containing four administrative files: Name Describe interface.ccl This defines the implementation the thorn provides, and the variables the thorn needs, along with their visibility to other implementations. param.ccl This defines the parameters that are used to control the thorn, along with their visibility to other implementations. schedule.ccl This defines which functions are called from the thorn and when they are called. It also handles memory and communication assignment for grid variables. configuration.ccl This file is optional for a thorn. If it exists, it contains extra configuration options of this thorn. Thorns can also contain a subdirectory called src, which should hold source files and compilation instructions for the thorn a subdirectory src/include for include files a README containing a brief description of the thorn a doc directory for documentation a par directory for example parameter files a test subdirectory may also be added, to hold the thorn\u2019s test suite. General Syntax of CCL Files Cactus Configuration Language (CCL) files are text files used to define configuration information for a thorn. A Grammar File for each type of CCL file is provided in the src/piraha/pegs directory of the Cactus source tree. CCL files are (mostly) case independent, and may contain comments introduced by the hash \u2018#\u2019 character, which indicates that the rest of the line is a comment. If the last non-blank character of a line in a CCL file is a backslash \u2018\\\u2019, the following line is treated as a continuation of the current line. see https://github.com/stevenrbrandt/piraha-peg for a description of formal syntax. The interface.ccl File The interface.ccl file is used to declare the implementation provided by the thorn the variables provided by the thorn the include files provided by the thorn the functions provided by the thorn Header Block The implementation is declared by a single line at the top of the file implements: <name> There are three different access levels available for variables Name Describe Public Can be \u2018inherited\u2019 by other implementations. Protected Can be shared with other implementations which declare themselves to be friends of this one. Private Can only be seen by this thorn. For example 1 2 3 4 # This gets all Public variables from implementation <name>, and all variables that <name> has in turn inherited. Inherits: <name> # This gets all Protected variables from implementation <name>. Friend: <name> Include Files The include file section has the form: 1 2 USES INCLUDE [SOURCE|HEADER]: <file_name> INCLUDE[S] [SOURCE|HEADER]: <file_to_include> in <file_name> The former is used when a thorn wishes to use an include file from another thorn. The latter indicates that this thorn adds the code in to the include file . If the include file is described as SOURCE, the included code is only executed if the providing thorn is active. Both default to HEADER. Function Aliasing If any aliased function is to be used or provided by the thorn, then the prototype must be declared with the form: 1 <return_type> FUNCTION <alias>(<arg1_type> <intent1> [ARRAY] <arg1>, ...) The must be either void, CCTK_INT, CCTK_REAL, CCTK_COMPLEX, CCTK_POINTER, or CCTK_POINTER_TO_CONST. The keyword SUBROUTINE is equivalent to void FUNCTION. The name of the aliased function must contain at least one uppercase and one lowercase letter and follow the C standard for function names. The type of each argument, , must be either CCTK_INT, CCTK_REAL, CCTK_COMPLEX, CCTK_POINTER, CCTK_POINTER_TO_CONST, or STRING. All string arguments must be the last arguments in the list. The intent of each argument, , must be either IN, OUT, or INOUT. An argument may only be modified if it is declared to have intent OUT or INOUT. If the argument is an array then the prefix ARRAY must also be given. If an aliased function is to be required, then the block is required. 1 REQUIRES FUNCTION <alias> If an aliased function is to be (optionally) used, then the block is required. 1 USES FUNCTION <alias> Variable Blocks The thorn\u2019s variables are collected into groups. The thorn\u2019s variables are defined by: 1 2 3 4 5 6 7 [<access>:] <data_type> <group_name> [<number>] [TYPE = <group_type>] [DIM=<dim>] [TIMELEVELS=<num>] [SIZE=<size in each direction>] [DISTRIB=<distribution_type>] [GHOSTSIZE=<ghostsize>] [TAGS=<string>] [\"<group_description>\"] { <variable_name> <variable_name> } [\"<group_description>\"] The options TYPE, DIM, etc., following must all appear on one line. Name Describe access defines which thorns can use the following groups of variables. access can be either public, protected or private. data_type defines the data type of the variables in the group. Supported data types are CHAR, BYTE, INT, REAL, and COMPLEX. group_name must be an alphanumeric name (which may also contain underscores) which is unique across group and variable names within the scope of the thorn. A group name is compulsory. [number] if present, indicates that this is a vector group. TYPE designates the kind of variables held by the group. The choices are GF, ARRAY or SCALAR. This field is optional, with the default variable type being SCALAR. DIM defines the spatial dimension of the ARRAY or GF. The default value is DIM=3. TIMELEVELS defines the number of timelevels a group has if the group is of type ARRAY or GF, and can take any positive value. The default is one timelevel. SIZE defines the number grid-points an ARRAY has in each direction. This should be a comma- separated list of valid arithmetical expressions consisting of integers or integer-valued parameters. DISTRIB defines the processor decomposition of an ARRAY. DISTRIB=DEFAULT distributes SIZE grid- points across all processors. DISTRIB=CONSTANT implies that SIZE grid-points should be allocated on each processor. The default value is DISTRIB=DEFAULT. GHOSTSIZE defines number of ghost zones in each dimension of an ARRAY. It defaults to zero. TAGS defines an optional string which is used to create a set of key-value pairs associated with the group. An optional description of the group can be given on the last line. If the variable block is omitted, this description can be given at the end of the declaration line. The param.ccl File The param.ccl file is used to specify the parameters used to control an individual thorn, and to specify the values these parameters are allowed to take. If a parameter is not assigned in a parameter file, it is given its default value. Parameter Data Scoping Items : The keyword access designates that all parameter object specification items, up to the next parameter data scoping item, are in the same protection or scoping class. access can take the values: Name Describe Global These parameters are seen by all thorns. Restricted These parameters may be used by other implementations if they so desire. Private These are only seen by this thorn. shares in this case, an implementation name must follow the colon. It declares that all the parameters in the following scoping block are restricted variables from the specified implementation. Parameter Object Specification Items 1 2 3 4 5 [EXTENDS|USES] <parameter type> <parameter name> [<len>] \"<parameter description>\" [AS <alias>] [STEERABLE=<NEVER|ALWAYS|RECOVER>] [ACCUMULATOR=<expression>] [ACCUMULATOR-BASE=<parameter name>] { <parameter values> } <default value> where the options AS, STEERABLE, etc., following , must all appear in one line. Note that the beginning brace ({) must sit on a line by itself; the ending brace (}) must be at the beginning of a line followed by on that same line. A thorn can declare that it EXTENDS a parameter of another thorn. This allows it to declare additional acceptable values. By default, it is acceptable for two thorns to declare the same value as acceptable. If the thorn wants to simply use a parameter from another thorn, without declaring additional values, use USES instead. The parameter name must be unique within the scope of the thorn. The default value must match one of the ranges given in the parameter type [len] is an integer, if present, indicates that this is an array parameter of len values of the specified type. alias allows a parameter to appear under a different name in this thorn, other than its original name in another thorn. The name, as seen in the parameter file, is unchanged. STEERABLE specifies when a parameter value may be changed. By default, parameters may not be changed after the parameter file has been read, or on restarting from checkpoint. This option relaxes this restriction, specifying that the parameter may be changed at recovery time from a parameter file or at any time using the flesh routine CCTK_ParameterSet . The value RECOVERY is used in checkpoint/recovery situations, and indicates that the parameter may be altered until the value is read in from a recovery par file, but not after. ACCUMULATOR specifies that this is an accumulator parameter. Such parameters cannot be set directly, but are set by other parameters who specify this one as an ACCUMULATOR-BASE . The expression is a two-parameter arithmetical expression of x and y. Setting the parameter consists of evaluating this expression successively, with x being the current value of the parameter (at the first iteration this is the default value), and y the value of the setting parameter. This procedure is repeated, starting from the default value of the parameter, each time one of the setting parameters changes. ACCUMULATOR-BASE specifies the name of an ACCUMULATOR parameter which this parameter sets. The depend on the , which may be one of the following: INT 1 <range description> [::\"<comment describing this range>\"] Here, a <range description> specifies a set of integers, and has one of the following forms: * : means any integer <integer> : means only <integer> <lower bound>:<upper bound> : means all integers in the range from to <lower bound>:<upper bound>:<positive step> : means all integers in the range from to in steps of where has one of the forms <empty field> : means no lower limit * : means no lower limit <integer> : means a closed interval starting at [<integer> : also means a closed interval starting at (<integer> : means an open interval starting at Name Describe REAL The range specification is the same as with integers, except that here, no step implies a continuum of values. Note that numeric constants should be expressed as in C (e.g. 1e-10). Note also that one cannot use the Cactus types such as CCTK_REAL4 to specify the precision of the parameter; parameters always have the default precision. KEYWORD Each entry in the list of acceptable values for a keyword has the form <keyword value> :: \"<description>\" Keyword values should be enclosed in double quotes. The double quotes are mandatory if the keyword contains spaces. STRING Allowed values for strings should be specified using regular expressions. To allow any string, the regular expression \"\" should be used. (An empty regular expression matches anything.) Regular expressions and string values should be enclosed in double quotes. The double quotes are mandatory if the regular expression or the string value is empty or contains spaces. BOOLEAN No should be specified for a boolean parameter. The schedule.ccl File Cactus contains a rule-based scheduling system, which determines which routines, from which thorns are run in which order. A usual simple specification for a schedule declaration is 1 2 3 4 5 schedule <function name> AT <schedule bin> { LANG: <language> [STORAGE: <group>[timelevels] } \"Description of function\" Each schedule item is scheduled either AT a particular scheduling bin, or IN a schedule group. Assignment Statements These lines have the form: 1 STORAGE: <group>[timelevels] The storage line includes the number of timelevels to activate storage for, this number can be from 1 up to the maximum number or timelevels for the group, as specified in the defining interface.ccl file. If the maximum number of timelevels is 1 (the default), this number may be omitted. Alternatively timelevels can be the name of a parameter accessible to the thorn. The parameter name is the same as used in C routines of the thorn, fully qualified parameter names of the form thorn::parameter are not allowed. In this case 0 (zero) timelevels can be requested, which is equivalent to the STORAGE statement being absent. Schedule Blocks 1 2 3 4 5 6 7 8 9 10 11 12 schedule [GROUP] <function name|group name> AT|IN <time> [AS <alias>] [WHILE <variable>] [IF <variable>] [BEFORE|AFTER <function name>|(<function name>)] { [LANG: <language>] [OPTIONS: <option>,<option >...] [TAGS: <keyword=value>,<keyword=value >...] [STORAGE: <group>[timelevels],<group>[timelevels]...] [READS: <group>,<group>...] [WRITES: <group>,<group>...] [TRIGGER: <group>,<group>...] [SYNCHRONISE: <group>,<group>...] [OPTIONS: <option>,<option>...] } \"Description of function\" Name Describe GROUP Schedule a schedule group with the same options as a schedule function. The schedule group will be created if it doesn\u2019t exist. <function name group name> Initial data The initial data are computed using the Compact Object CALculator (COCAL) 1 Diagnostics The BH apparent horizon is located and monitored through the AHFinderDirect thorn. We estimate the BH mass M_{\\mathrm{BH}} M_{\\mathrm{BH}} and the BH dimensionless spin parameter a / M_{\\mathrm{BH}} a / M_{\\mathrm{BH}} using the isolated horizon formalism. Extract Gravitational Wave To measure the flux of energy and angular momentum carried away by GWs, we use a modi\ufb01ed version of the Psikadelia thorn. https://arxiv.org/pdf/1502.05674.pdf https://arxiv.org/pdf/1809.08237.pdf https://arxiv.org/pdf/gr-qc/0306056.pdf https://arxiv.org/pdf/gr-qc/0206008.pdf Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9","title":"Thorn"},{"location":"ET/Thorn/#general-syntax-of-ccl-files","text":"Cactus Configuration Language (CCL) files are text files used to define configuration information for a thorn. A Grammar File for each type of CCL file is provided in the src/piraha/pegs directory of the Cactus source tree. CCL files are (mostly) case independent, and may contain comments introduced by the hash \u2018#\u2019 character, which indicates that the rest of the line is a comment. If the last non-blank character of a line in a CCL file is a backslash \u2018\\\u2019, the following line is treated as a continuation of the current line. see https://github.com/stevenrbrandt/piraha-peg for a description of formal syntax.","title":"General Syntax of CCL Files"},{"location":"ET/Thorn/#the-interfaceccl-file","text":"The interface.ccl file is used to declare the implementation provided by the thorn the variables provided by the thorn the include files provided by the thorn the functions provided by the thorn","title":"The interface.ccl File"},{"location":"ET/Thorn/#header-block","text":"The implementation is declared by a single line at the top of the file implements: <name> There are three different access levels available for variables Name Describe Public Can be \u2018inherited\u2019 by other implementations. Protected Can be shared with other implementations which declare themselves to be friends of this one. Private Can only be seen by this thorn. For example 1 2 3 4 # This gets all Public variables from implementation <name>, and all variables that <name> has in turn inherited. Inherits: <name> # This gets all Protected variables from implementation <name>. Friend: <name>","title":"Header Block"},{"location":"ET/Thorn/#include-files","text":"The include file section has the form: 1 2 USES INCLUDE [SOURCE|HEADER]: <file_name> INCLUDE[S] [SOURCE|HEADER]: <file_to_include> in <file_name> The former is used when a thorn wishes to use an include file from another thorn. The latter indicates that this thorn adds the code in to the include file . If the include file is described as SOURCE, the included code is only executed if the providing thorn is active. Both default to HEADER.","title":"Include Files"},{"location":"ET/Thorn/#function-aliasing","text":"If any aliased function is to be used or provided by the thorn, then the prototype must be declared with the form: 1 <return_type> FUNCTION <alias>(<arg1_type> <intent1> [ARRAY] <arg1>, ...) The must be either void, CCTK_INT, CCTK_REAL, CCTK_COMPLEX, CCTK_POINTER, or CCTK_POINTER_TO_CONST. The keyword SUBROUTINE is equivalent to void FUNCTION. The name of the aliased function must contain at least one uppercase and one lowercase letter and follow the C standard for function names. The type of each argument, , must be either CCTK_INT, CCTK_REAL, CCTK_COMPLEX, CCTK_POINTER, CCTK_POINTER_TO_CONST, or STRING. All string arguments must be the last arguments in the list. The intent of each argument, , must be either IN, OUT, or INOUT. An argument may only be modified if it is declared to have intent OUT or INOUT. If the argument is an array then the prefix ARRAY must also be given. If an aliased function is to be required, then the block is required. 1 REQUIRES FUNCTION <alias> If an aliased function is to be (optionally) used, then the block is required. 1 USES FUNCTION <alias>","title":"Function Aliasing"},{"location":"ET/Thorn/#variable-blocks","text":"The thorn\u2019s variables are collected into groups. The thorn\u2019s variables are defined by: 1 2 3 4 5 6 7 [<access>:] <data_type> <group_name> [<number>] [TYPE = <group_type>] [DIM=<dim>] [TIMELEVELS=<num>] [SIZE=<size in each direction>] [DISTRIB=<distribution_type>] [GHOSTSIZE=<ghostsize>] [TAGS=<string>] [\"<group_description>\"] { <variable_name> <variable_name> } [\"<group_description>\"] The options TYPE, DIM, etc., following must all appear on one line. Name Describe access defines which thorns can use the following groups of variables. access can be either public, protected or private. data_type defines the data type of the variables in the group. Supported data types are CHAR, BYTE, INT, REAL, and COMPLEX. group_name must be an alphanumeric name (which may also contain underscores) which is unique across group and variable names within the scope of the thorn. A group name is compulsory. [number] if present, indicates that this is a vector group. TYPE designates the kind of variables held by the group. The choices are GF, ARRAY or SCALAR. This field is optional, with the default variable type being SCALAR. DIM defines the spatial dimension of the ARRAY or GF. The default value is DIM=3. TIMELEVELS defines the number of timelevels a group has if the group is of type ARRAY or GF, and can take any positive value. The default is one timelevel. SIZE defines the number grid-points an ARRAY has in each direction. This should be a comma- separated list of valid arithmetical expressions consisting of integers or integer-valued parameters. DISTRIB defines the processor decomposition of an ARRAY. DISTRIB=DEFAULT distributes SIZE grid- points across all processors. DISTRIB=CONSTANT implies that SIZE grid-points should be allocated on each processor. The default value is DISTRIB=DEFAULT. GHOSTSIZE defines number of ghost zones in each dimension of an ARRAY. It defaults to zero. TAGS defines an optional string which is used to create a set of key-value pairs associated with the group. An optional description of the group can be given on the last line. If the variable block is omitted, this description can be given at the end of the declaration line.","title":"Variable Blocks"},{"location":"ET/Thorn/#the-paramccl-file","text":"The param.ccl file is used to specify the parameters used to control an individual thorn, and to specify the values these parameters are allowed to take. If a parameter is not assigned in a parameter file, it is given its default value.","title":"The param.ccl File"},{"location":"ET/Thorn/#parameter-data-scoping-items","text":": The keyword access designates that all parameter object specification items, up to the next parameter data scoping item, are in the same protection or scoping class. access can take the values: Name Describe Global These parameters are seen by all thorns. Restricted These parameters may be used by other implementations if they so desire. Private These are only seen by this thorn. shares in this case, an implementation name must follow the colon. It declares that all the parameters in the following scoping block are restricted variables from the specified implementation.","title":"Parameter Data Scoping Items"},{"location":"ET/Thorn/#parameter-object-specification-items","text":"1 2 3 4 5 [EXTENDS|USES] <parameter type> <parameter name> [<len>] \"<parameter description>\" [AS <alias>] [STEERABLE=<NEVER|ALWAYS|RECOVER>] [ACCUMULATOR=<expression>] [ACCUMULATOR-BASE=<parameter name>] { <parameter values> } <default value> where the options AS, STEERABLE, etc., following , must all appear in one line. Note that the beginning brace ({) must sit on a line by itself; the ending brace (}) must be at the beginning of a line followed by on that same line. A thorn can declare that it EXTENDS a parameter of another thorn. This allows it to declare additional acceptable values. By default, it is acceptable for two thorns to declare the same value as acceptable. If the thorn wants to simply use a parameter from another thorn, without declaring additional values, use USES instead. The parameter name must be unique within the scope of the thorn. The default value must match one of the ranges given in the parameter type [len] is an integer, if present, indicates that this is an array parameter of len values of the specified type. alias allows a parameter to appear under a different name in this thorn, other than its original name in another thorn. The name, as seen in the parameter file, is unchanged. STEERABLE specifies when a parameter value may be changed. By default, parameters may not be changed after the parameter file has been read, or on restarting from checkpoint. This option relaxes this restriction, specifying that the parameter may be changed at recovery time from a parameter file or at any time using the flesh routine CCTK_ParameterSet . The value RECOVERY is used in checkpoint/recovery situations, and indicates that the parameter may be altered until the value is read in from a recovery par file, but not after. ACCUMULATOR specifies that this is an accumulator parameter. Such parameters cannot be set directly, but are set by other parameters who specify this one as an ACCUMULATOR-BASE . The expression is a two-parameter arithmetical expression of x and y. Setting the parameter consists of evaluating this expression successively, with x being the current value of the parameter (at the first iteration this is the default value), and y the value of the setting parameter. This procedure is repeated, starting from the default value of the parameter, each time one of the setting parameters changes. ACCUMULATOR-BASE specifies the name of an ACCUMULATOR parameter which this parameter sets. The depend on the , which may be one of the following: INT 1 <range description> [::\"<comment describing this range>\"] Here, a <range description> specifies a set of integers, and has one of the following forms: * : means any integer <integer> : means only <integer> <lower bound>:<upper bound> : means all integers in the range from to <lower bound>:<upper bound>:<positive step> : means all integers in the range from to in steps of where has one of the forms <empty field> : means no lower limit * : means no lower limit <integer> : means a closed interval starting at [<integer> : also means a closed interval starting at (<integer> : means an open interval starting at Name Describe REAL The range specification is the same as with integers, except that here, no step implies a continuum of values. Note that numeric constants should be expressed as in C (e.g. 1e-10). Note also that one cannot use the Cactus types such as CCTK_REAL4 to specify the precision of the parameter; parameters always have the default precision. KEYWORD Each entry in the list of acceptable values for a keyword has the form <keyword value> :: \"<description>\" Keyword values should be enclosed in double quotes. The double quotes are mandatory if the keyword contains spaces. STRING Allowed values for strings should be specified using regular expressions. To allow any string, the regular expression \"\" should be used. (An empty regular expression matches anything.) Regular expressions and string values should be enclosed in double quotes. The double quotes are mandatory if the regular expression or the string value is empty or contains spaces. BOOLEAN No should be specified for a boolean parameter.","title":"Parameter Object Specification Items"},{"location":"ET/Thorn/#the-scheduleccl-file","text":"Cactus contains a rule-based scheduling system, which determines which routines, from which thorns are run in which order. A usual simple specification for a schedule declaration is 1 2 3 4 5 schedule <function name> AT <schedule bin> { LANG: <language> [STORAGE: <group>[timelevels] } \"Description of function\" Each schedule item is scheduled either AT a particular scheduling bin, or IN a schedule group.","title":"The schedule.ccl File"},{"location":"ET/Thorn/#assignment-statements","text":"These lines have the form: 1 STORAGE: <group>[timelevels] The storage line includes the number of timelevels to activate storage for, this number can be from 1 up to the maximum number or timelevels for the group, as specified in the defining interface.ccl file. If the maximum number of timelevels is 1 (the default), this number may be omitted. Alternatively timelevels can be the name of a parameter accessible to the thorn. The parameter name is the same as used in C routines of the thorn, fully qualified parameter names of the form thorn::parameter are not allowed. In this case 0 (zero) timelevels can be requested, which is equivalent to the STORAGE statement being absent.","title":"Assignment Statements"},{"location":"ET/Thorn/#schedule-blocks","text":"1 2 3 4 5 6 7 8 9 10 11 12 schedule [GROUP] <function name|group name> AT|IN <time> [AS <alias>] [WHILE <variable>] [IF <variable>] [BEFORE|AFTER <function name>|(<function name>)] { [LANG: <language>] [OPTIONS: <option>,<option >...] [TAGS: <keyword=value>,<keyword=value >...] [STORAGE: <group>[timelevels],<group>[timelevels]...] [READS: <group>,<group>...] [WRITES: <group>,<group>...] [TRIGGER: <group>,<group>...] [SYNCHRONISE: <group>,<group>...] [OPTIONS: <option>,<option>...] } \"Description of function\" Name Describe GROUP Schedule a schedule group with the same options as a schedule function. The schedule group will be created if it doesn\u2019t exist. <function name group name>","title":"Schedule Blocks"},{"location":"ET/Thorn/#initial-data","text":"The initial data are computed using the Compact Object CALculator (COCAL) 1","title":"Initial data"},{"location":"ET/Thorn/#diagnostics","text":"The BH apparent horizon is located and monitored through the AHFinderDirect thorn. We estimate the BH mass M_{\\mathrm{BH}} M_{\\mathrm{BH}} and the BH dimensionless spin parameter a / M_{\\mathrm{BH}} a / M_{\\mathrm{BH}} using the isolated horizon formalism.","title":"Diagnostics"},{"location":"ET/Thorn/#extract-gravitational-wave","text":"To measure the flux of energy and angular momentum carried away by GWs, we use a modi\ufb01ed version of the Psikadelia thorn. https://arxiv.org/pdf/1502.05674.pdf https://arxiv.org/pdf/1809.08237.pdf https://arxiv.org/pdf/gr-qc/0306056.pdf https://arxiv.org/pdf/gr-qc/0206008.pdf Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9","title":"Extract Gravitational Wave"},{"location":"GR/Solutions/","text":"The gravitational equilibrium of masses of neutrons 1 We study the gravitational equilibrium of masses of neutrons, using the equation of state for a cold Fermi gas, and general relativity . Whether there is an upper limit to the possible size of such a neutron core? Landau showed that for a model consisting of a cold degenerate Fermi gas there exist no stable equilibrium configurations for masses greater than a certain critical mass, all larger masses tending to collapse. Relativistic Treatment Of Equilibrium The most general static line element exhibiting spherical symmetry may be expressed in the form ds^2 = - e^{\\lambda} dr^2 - r^2 d \\theta^2 - r^2 sin^2 \\theta d \\phi^2 + e^{\\nu} dt^2 \\\\ \\lambda = \\lambda (r), \\nu = \\nu (r). ds^2 = - e^{\\lambda} dr^2 - r^2 d \\theta^2 - r^2 sin^2 \\theta d \\phi^2 + e^{\\nu} dt^2 \\\\ \\lambda = \\lambda (r), \\nu = \\nu (r). If the matter supports no transverse stresses and has no mass motion, then its energy momentum tensor is given by T^{\\space 1}_{1} = T^{\\space 2}_{2} = T^{\\space 3}_{3} = - P, \\space T^{\\space 4}_{4} = \\rho T^{\\space 1}_{1} = T^{\\space 2}_{2} = T^{\\space 3}_{3} = - P, \\space T^{\\space 4}_{4} = \\rho where p and \\rho \\rho are respectively the pressure and the macroscopic energy density measured in proper coordinates. The cosmological constant \\Lambda \\Lambda taken equal to zero, Einstein's field equations reduce to: 8 \\pi P = e^{-\\lambda} (\\frac{\\nu'}{r} + \\frac{1}{r^2}) - \\frac{1}{r^2} \\\\ 8 \\pi \\rho = e^{-\\lambda} (\\frac{\\lambda'}{r} - \\frac{1}{r^2}) + \\frac{1}{r^2} \\\\ \\frac{dP}{dr} = - \\frac{(P + \\rho)}{2} \\nu' 8 \\pi P = e^{-\\lambda} (\\frac{\\nu'}{r} + \\frac{1}{r^2}) - \\frac{1}{r^2} \\\\ 8 \\pi \\rho = e^{-\\lambda} (\\frac{\\lambda'}{r} - \\frac{1}{r^2}) + \\frac{1}{r^2} \\\\ \\frac{dP}{dr} = - \\frac{(P + \\rho)}{2} \\nu' where primes denote differentiation with respect to r. These three equations together with the equation of state of the material \\rho = \\rho (P) \\rho = \\rho (P) determine the mechanical equilibrium of the matter distribution. The boundary of the matter distribution is the value of r = r_b r = r_b for which P = 0 P = 0 , and such that for value r < r_b r < r_b where P > O P > O . In empty space surrounding the spherically symmetric distribution of matter P = \\rho = 0 P = \\rho = 0 , and Schwarzschild's exterior solution is obtained: e^{-\\lambda} = 1 + \\frac{A}{r} \\\\ e^{\\nu} = B (1 + \\frac{A}{r}) e^{-\\lambda} = 1 + \\frac{A}{r} \\\\ e^{\\nu} = B (1 + \\frac{A}{r}) The constants A and 8 are fixed by the requirement that at great distances away from the matter distribution the g_{\\mu \\nu} g_{\\mu \\nu} must go over into their weak-field form, i.e., B = 1 B = 1 , A = - 2m A = - 2m where m is the total Newtonian mass of the matter as calculated by a distant observer. Further introduce a new variable u(r) = \\frac{1}{2} r (1 - e^{-\\lambda}) u(r) = \\frac{1}{2} r (1 - e^{-\\lambda}) Then above equations becomes: e^{\\nu(r)} = (1 - \\frac{2m}{r_b}) e^{- \\int_0^{P(r)} \\frac{2dP}{P + \\rho(P)}} \\\\ \\frac{du}{dr} = 4 \\pi \\rho(P) r^2 \\\\ \\frac{dP}{dr} = - \\frac{P + \\rho(P)}{r(r - 2 u)}(4 \\pi P r^3 + u) e^{\\nu(r)} = (1 - \\frac{2m}{r_b}) e^{- \\int_0^{P(r)} \\frac{2dP}{P + \\rho(P)}} \\\\ \\frac{du}{dr} = 4 \\pi \\rho(P) r^2 \\\\ \\frac{dP}{dr} = - \\frac{P + \\rho(P)}{r(r - 2 u)}(4 \\pi P r^3 + u) From this equation we can see that u is very similar to m. Starting with some initial values u = u_0 u = u_0 , P = P_0 P = P_0 at r = 0 r = 0 , the two equations are integrated simultaneously to the value r = r_b r = r_b where P = O P = O , until the boundary of the matter distribution is reached. The value of u = u_b u = u_b at r = r_b r = r_b determines the value of e^{\\lambda(r_b)} e^{\\lambda(r_b)} at the boundary, and this is joined continuously across the boundary to the exterior solution, making u_b = m u_b = m Thus the mass of this spherical distribution of matter as measured by a distant observer is given by the value u_b u_b of u at r = r_b r = r_b . The following restrictions must be made on the choice of P_0 P_0 and u_0 u_0 , the initial values of P and u at r = 0 r = 0 . Particular Equations Of State The above arguments show that \\frac{du}{dr} \\frac{du}{dr} and \\frac{dP}{dr} \\frac{dP}{dr} together with a given equation of state completely determine the distribution of matter. If the matter is taken to consist of particles of rest mass \\mu_0 \\mu_0 obeying Fermi statistics, and their thermal energy and all forces between them are neglected, then it may be shown that a parametric form for the equation of state is: \\rho = K (sinht - t) \\\\ P = \\frac{1}{3} K (sinht - 8 sinh(\\frac{1}{2}t) + 3 t) \\rho = K (sinht - t) \\\\ P = \\frac{1}{3} K (sinht - 8 sinh(\\frac{1}{2}t) + 3 t) where K = \\frac{\\pi \\mu_0^4 c^5}{4 h^3} \\\\ t = 4 log(\\frac{\\widehat{P}}{\\mu_0 c} + [1 + (\\frac{\\widehat{P}}{\\mu_0 c})^2]^{\\frac{1}{2}}) K = \\frac{\\pi \\mu_0^4 c^5}{4 h^3} \\\\ t = 4 log(\\frac{\\widehat{P}}{\\mu_0 c} + [1 + (\\frac{\\widehat{P}}{\\mu_0 c})^2]^{\\frac{1}{2}}) where \\widehat{P} \\widehat{P} is the maximum momentum in the Fermi distribution and is related to the proper particle density \\frac{N}{V} \\frac{N}{V} by \\frac{N}{V} = \\frac{8 \\pi}{3 h^3} \\widehat{P}^3 \\frac{N}{V} = \\frac{8 \\pi}{3 h^3} \\widehat{P}^3 the uncertainty of a particle in space is \\frac{V}{N} \\frac{V}{N} , and the uncertainty in momentum space is 2\\frac{4 \\pi}{3} \\widehat{P}^3 2\\frac{4 \\pi}{3} \\widehat{P}^3 . so \\frac{V}{N} \\times 2\\frac{4 \\pi}{3} \\widehat{P}^3 = h^3 \\frac{V}{N} \\times 2\\frac{4 \\pi}{3} \\widehat{P}^3 = h^3 . The above equations become: \\frac{du}{dr} = 4 \\pi r^2 K (sinht - t) \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} \\frac{sinht - 2 sinh(\\frac{1}{2}t)}{cosht - 4 cosh(\\frac{1}{2}t) + 3}[\\frac{4}{3} \\pi K r^3 (sinht - 8 sinh(\\frac{1}{2}t) + 3t) + u] \\frac{du}{dr} = 4 \\pi r^2 K (sinht - t) \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} \\frac{sinht - 2 sinh(\\frac{1}{2}t)}{cosht - 4 cosh(\\frac{1}{2}t) + 3}[\\frac{4}{3} \\pi K r^3 (sinht - 8 sinh(\\frac{1}{2}t) + 3t) + u] These equations are to be integrated from the values u = 0 u = 0 , t = t_0 t = t_0 at r = 0 r = 0 to r = r_b r = r_b where t_b = 0 t_b = 0 (which makes P = 0 P = 0 ), and u = u_0 u = u_0 . No way was found to carry out the integration analytically, so equations were integrated numerically for several finite values of t_0 t_0 . For all these cases u_0 u_0 was taken to be equal to zero, since the equation of state near the origin for finite t_0 t_0 behaves like \\rho(P) = K P^s \\rho(P) = K P^s , s < 1 s < 1 . For very small values of t the equation of state reduces to P = K \\rho^{\\frac{5}{3}} P = K \\rho^{\\frac{5}{3}} and \\widehat{P} \\propto t \\widehat{P} \\propto t . Using this equation of state and Newtonian gravitational theory (which is expected to give a good result for small masses and densities), one finds that m \\propto t^{\\frac{3}{2}} m \\propto t^{\\frac{3}{2}} . Foe t_0 \\to \\infty t_0 \\to \\infty , Equation may be replaced by their expressions: \\frac{du}{dr} = \\frac{1}{2} r^2 e^t \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} (\\frac{r^3}{6}e^t + u) \\frac{du}{dr} = \\frac{1}{2} r^2 e^t \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} (\\frac{r^3}{6}e^t + u) An exact solution of these equations is: e^t = \\frac{3}{7r^2} \\\\ u = \\frac{3r}{14} e^t = \\frac{3}{7r^2} \\\\ u = \\frac{3r}{14} Then the mass carried out to r = r_b r = r_b where t = 0 t = 0 . The striking feature of the curve is that the mass increases with increasing t_0 t_0 until a maximum is reached at about t_0 =3 t_0 =3 , after which the curve drops until a value roughly \\frac{1}{3} \\odot \\frac{1}{3} \\odot is reached for t_0 = \\infty t_0 = \\infty . In other words no static solutions at all exist for m > \\frac{3}{4} \\odot m > \\frac{3}{4} \\odot , two solutions exist for all m in \\frac{3}{4} \\odot > m > \\frac{1}{3} \\odot \\frac{3}{4} \\odot > m > \\frac{1}{3} \\odot , and one solution exists for all m < \\frac{1}{3} \\odot m < \\frac{1}{3} \\odot . Free Energy In the non-relativistic polytrope solutions of Emden the equation of state was assumed to be P = K \\rho^{\\gamma} P = K \\rho^{\\gamma} . But Landau pointed out that although these solutions in \\gamma > \\frac{6}{5} \\gamma > \\frac{6}{5} give an equilibrium configuration, they do not in every case give stable equilibrium. Thus, unless \\gamma >frac{4}{3} \\gamma >frac{4}{3} the equilibrium configuration is unstable. The part of the free energy caused by compression is F = - a \\rho^{\\frac{1}{3}} + b \\rho^{\\gamma - 1} F = - a \\rho^{\\frac{1}{3}} + b \\rho^{\\gamma - 1} Polytrope solutions exist for \\gamma = \\frac{5}{3} (> \\frac{4}{3}) \\gamma = \\frac{5}{3} (> \\frac{4}{3}) corresponds to stable equilibrium, for \\gamma = \\frac{5}{4} (< \\frac{4}{3}) \\gamma = \\frac{5}{4} (< \\frac{4}{3}) to unstable equilibrium. Since the free energy must be a continuous function of t_0 t_0 , and since we know from non-relativistic calculations that for small masses (and low densities) we have a position of stable equilibrium (a minimum in the free energy curve) we can conclude that the second equilibrium position corresponds either to a maximum or to an inflection point in the free energy curve (and certainly not to a minimum). Fig. 3 gives a schematic plot of free energy against t_0 t_0 for different values of M_0 M_0 which would explain the existence of one equilibrium position for small masses, two for intermediate masses, and none for large masses. The masses marked on the curves are the actual gravitational masses corresponding to the equilibrium points of the critical free energy curves. Application To Stellar Matter Since neutron cores can hardly be stable (with respect to formation of electrons and nuclei) for masses less than \\sim 0.1 M_{\\odot} \\sim 0.1 M_{\\odot} . Since, even after thermonuclear sources of energy are exhausted, they will** not tend to form by collapse of ordinary matter for masses under 1.5 M_{\\odot} 1.5 M_{\\odot} (Landau's limit) . It seems **unlikely that static neutron cores can play any great part in stellar evolution , and the question of what happens, after energy sources are exhausted, to stars of mass greater than 1.5 M_{\\odot} 1.5 M_{\\odot} still remains unanswered . There would then seem to be only two answers possible to the question of the \"final\" behavior of very massive stars: The equation of state we have used so far fails to describe the behavior of highly condensed matter that the conclusions reached above are qualitatively misleading The star will continue to contract indefinitely, never reaching equilibrium. Non-static Solutions From this discussion it appears probable that for an understanding of the long time behavior of actual heavy stars a consideration of non-static solutions must be essential. Among all (spherical) non-static solutions one would hope to find some for which the rate of contraction, and in general the time variation, become slower and slower, so that these solutions might be regarded, not as equilibrium solutions, but as quasi-static. Some reason for this we may see in the following argument: for large enough mass the core will collapse; near the center the density and pressure will grow, and g_{tt} = e^{\\nu} g_{tt} = e^{\\nu} will be small; and as e^{\\nu} e^{\\nu} grows smaller, all processes will, as seen by an outside observer, slow down in the central region. For masses under \\frac{1}{3} M_{\\odot} \\frac{1}{3} M_{\\odot} only one equilibrium solution exists, which is approximately described by the non-relativistic Fermi equation of state and Newtonian gravitational theory. For masses \\frac{1}{3} M_{\\odot} < m < \\frac{3}{4} M_{\\odot} \\frac{1}{3} M_{\\odot} < m < \\frac{3}{4} M_{\\odot} two solutions exist, one stable and quasi-Newtonian, one more condensed, and unstable. For masses greater than \\frac{3}{4} M_{\\odot} \\frac{3}{4} M_{\\odot} there are no static equilibrium solutions. Oppenheimer(1939) On Massive Neutron Cores \u21a9","title":"Solutions"},{"location":"GR/Solutions/#the-gravitational-equilibrium-of-masses-of-neutrons1","text":"We study the gravitational equilibrium of masses of neutrons, using the equation of state for a cold Fermi gas, and general relativity . Whether there is an upper limit to the possible size of such a neutron core? Landau showed that for a model consisting of a cold degenerate Fermi gas there exist no stable equilibrium configurations for masses greater than a certain critical mass, all larger masses tending to collapse.","title":"The gravitational equilibrium of masses of neutrons1"},{"location":"GR/Solutions/#relativistic-treatment-of-equilibrium","text":"The most general static line element exhibiting spherical symmetry may be expressed in the form ds^2 = - e^{\\lambda} dr^2 - r^2 d \\theta^2 - r^2 sin^2 \\theta d \\phi^2 + e^{\\nu} dt^2 \\\\ \\lambda = \\lambda (r), \\nu = \\nu (r). ds^2 = - e^{\\lambda} dr^2 - r^2 d \\theta^2 - r^2 sin^2 \\theta d \\phi^2 + e^{\\nu} dt^2 \\\\ \\lambda = \\lambda (r), \\nu = \\nu (r). If the matter supports no transverse stresses and has no mass motion, then its energy momentum tensor is given by T^{\\space 1}_{1} = T^{\\space 2}_{2} = T^{\\space 3}_{3} = - P, \\space T^{\\space 4}_{4} = \\rho T^{\\space 1}_{1} = T^{\\space 2}_{2} = T^{\\space 3}_{3} = - P, \\space T^{\\space 4}_{4} = \\rho where p and \\rho \\rho are respectively the pressure and the macroscopic energy density measured in proper coordinates. The cosmological constant \\Lambda \\Lambda taken equal to zero, Einstein's field equations reduce to: 8 \\pi P = e^{-\\lambda} (\\frac{\\nu'}{r} + \\frac{1}{r^2}) - \\frac{1}{r^2} \\\\ 8 \\pi \\rho = e^{-\\lambda} (\\frac{\\lambda'}{r} - \\frac{1}{r^2}) + \\frac{1}{r^2} \\\\ \\frac{dP}{dr} = - \\frac{(P + \\rho)}{2} \\nu' 8 \\pi P = e^{-\\lambda} (\\frac{\\nu'}{r} + \\frac{1}{r^2}) - \\frac{1}{r^2} \\\\ 8 \\pi \\rho = e^{-\\lambda} (\\frac{\\lambda'}{r} - \\frac{1}{r^2}) + \\frac{1}{r^2} \\\\ \\frac{dP}{dr} = - \\frac{(P + \\rho)}{2} \\nu' where primes denote differentiation with respect to r. These three equations together with the equation of state of the material \\rho = \\rho (P) \\rho = \\rho (P) determine the mechanical equilibrium of the matter distribution. The boundary of the matter distribution is the value of r = r_b r = r_b for which P = 0 P = 0 , and such that for value r < r_b r < r_b where P > O P > O . In empty space surrounding the spherically symmetric distribution of matter P = \\rho = 0 P = \\rho = 0 , and Schwarzschild's exterior solution is obtained: e^{-\\lambda} = 1 + \\frac{A}{r} \\\\ e^{\\nu} = B (1 + \\frac{A}{r}) e^{-\\lambda} = 1 + \\frac{A}{r} \\\\ e^{\\nu} = B (1 + \\frac{A}{r}) The constants A and 8 are fixed by the requirement that at great distances away from the matter distribution the g_{\\mu \\nu} g_{\\mu \\nu} must go over into their weak-field form, i.e., B = 1 B = 1 , A = - 2m A = - 2m where m is the total Newtonian mass of the matter as calculated by a distant observer. Further introduce a new variable u(r) = \\frac{1}{2} r (1 - e^{-\\lambda}) u(r) = \\frac{1}{2} r (1 - e^{-\\lambda}) Then above equations becomes: e^{\\nu(r)} = (1 - \\frac{2m}{r_b}) e^{- \\int_0^{P(r)} \\frac{2dP}{P + \\rho(P)}} \\\\ \\frac{du}{dr} = 4 \\pi \\rho(P) r^2 \\\\ \\frac{dP}{dr} = - \\frac{P + \\rho(P)}{r(r - 2 u)}(4 \\pi P r^3 + u) e^{\\nu(r)} = (1 - \\frac{2m}{r_b}) e^{- \\int_0^{P(r)} \\frac{2dP}{P + \\rho(P)}} \\\\ \\frac{du}{dr} = 4 \\pi \\rho(P) r^2 \\\\ \\frac{dP}{dr} = - \\frac{P + \\rho(P)}{r(r - 2 u)}(4 \\pi P r^3 + u) From this equation we can see that u is very similar to m. Starting with some initial values u = u_0 u = u_0 , P = P_0 P = P_0 at r = 0 r = 0 , the two equations are integrated simultaneously to the value r = r_b r = r_b where P = O P = O , until the boundary of the matter distribution is reached. The value of u = u_b u = u_b at r = r_b r = r_b determines the value of e^{\\lambda(r_b)} e^{\\lambda(r_b)} at the boundary, and this is joined continuously across the boundary to the exterior solution, making u_b = m u_b = m Thus the mass of this spherical distribution of matter as measured by a distant observer is given by the value u_b u_b of u at r = r_b r = r_b . The following restrictions must be made on the choice of P_0 P_0 and u_0 u_0 , the initial values of P and u at r = 0 r = 0 .","title":"Relativistic Treatment Of Equilibrium"},{"location":"GR/Solutions/#particular-equations-of-state","text":"The above arguments show that \\frac{du}{dr} \\frac{du}{dr} and \\frac{dP}{dr} \\frac{dP}{dr} together with a given equation of state completely determine the distribution of matter. If the matter is taken to consist of particles of rest mass \\mu_0 \\mu_0 obeying Fermi statistics, and their thermal energy and all forces between them are neglected, then it may be shown that a parametric form for the equation of state is: \\rho = K (sinht - t) \\\\ P = \\frac{1}{3} K (sinht - 8 sinh(\\frac{1}{2}t) + 3 t) \\rho = K (sinht - t) \\\\ P = \\frac{1}{3} K (sinht - 8 sinh(\\frac{1}{2}t) + 3 t) where K = \\frac{\\pi \\mu_0^4 c^5}{4 h^3} \\\\ t = 4 log(\\frac{\\widehat{P}}{\\mu_0 c} + [1 + (\\frac{\\widehat{P}}{\\mu_0 c})^2]^{\\frac{1}{2}}) K = \\frac{\\pi \\mu_0^4 c^5}{4 h^3} \\\\ t = 4 log(\\frac{\\widehat{P}}{\\mu_0 c} + [1 + (\\frac{\\widehat{P}}{\\mu_0 c})^2]^{\\frac{1}{2}}) where \\widehat{P} \\widehat{P} is the maximum momentum in the Fermi distribution and is related to the proper particle density \\frac{N}{V} \\frac{N}{V} by \\frac{N}{V} = \\frac{8 \\pi}{3 h^3} \\widehat{P}^3 \\frac{N}{V} = \\frac{8 \\pi}{3 h^3} \\widehat{P}^3 the uncertainty of a particle in space is \\frac{V}{N} \\frac{V}{N} , and the uncertainty in momentum space is 2\\frac{4 \\pi}{3} \\widehat{P}^3 2\\frac{4 \\pi}{3} \\widehat{P}^3 . so \\frac{V}{N} \\times 2\\frac{4 \\pi}{3} \\widehat{P}^3 = h^3 \\frac{V}{N} \\times 2\\frac{4 \\pi}{3} \\widehat{P}^3 = h^3 . The above equations become: \\frac{du}{dr} = 4 \\pi r^2 K (sinht - t) \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} \\frac{sinht - 2 sinh(\\frac{1}{2}t)}{cosht - 4 cosh(\\frac{1}{2}t) + 3}[\\frac{4}{3} \\pi K r^3 (sinht - 8 sinh(\\frac{1}{2}t) + 3t) + u] \\frac{du}{dr} = 4 \\pi r^2 K (sinht - t) \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} \\frac{sinht - 2 sinh(\\frac{1}{2}t)}{cosht - 4 cosh(\\frac{1}{2}t) + 3}[\\frac{4}{3} \\pi K r^3 (sinht - 8 sinh(\\frac{1}{2}t) + 3t) + u] These equations are to be integrated from the values u = 0 u = 0 , t = t_0 t = t_0 at r = 0 r = 0 to r = r_b r = r_b where t_b = 0 t_b = 0 (which makes P = 0 P = 0 ), and u = u_0 u = u_0 . No way was found to carry out the integration analytically, so equations were integrated numerically for several finite values of t_0 t_0 . For all these cases u_0 u_0 was taken to be equal to zero, since the equation of state near the origin for finite t_0 t_0 behaves like \\rho(P) = K P^s \\rho(P) = K P^s , s < 1 s < 1 . For very small values of t the equation of state reduces to P = K \\rho^{\\frac{5}{3}} P = K \\rho^{\\frac{5}{3}} and \\widehat{P} \\propto t \\widehat{P} \\propto t . Using this equation of state and Newtonian gravitational theory (which is expected to give a good result for small masses and densities), one finds that m \\propto t^{\\frac{3}{2}} m \\propto t^{\\frac{3}{2}} . Foe t_0 \\to \\infty t_0 \\to \\infty , Equation may be replaced by their expressions: \\frac{du}{dr} = \\frac{1}{2} r^2 e^t \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} (\\frac{r^3}{6}e^t + u) \\frac{du}{dr} = \\frac{1}{2} r^2 e^t \\\\ \\frac{dt}{dr} = - \\frac{4}{r(r - 2u)} (\\frac{r^3}{6}e^t + u) An exact solution of these equations is: e^t = \\frac{3}{7r^2} \\\\ u = \\frac{3r}{14} e^t = \\frac{3}{7r^2} \\\\ u = \\frac{3r}{14} Then the mass carried out to r = r_b r = r_b where t = 0 t = 0 . The striking feature of the curve is that the mass increases with increasing t_0 t_0 until a maximum is reached at about t_0 =3 t_0 =3 , after which the curve drops until a value roughly \\frac{1}{3} \\odot \\frac{1}{3} \\odot is reached for t_0 = \\infty t_0 = \\infty . In other words no static solutions at all exist for m > \\frac{3}{4} \\odot m > \\frac{3}{4} \\odot , two solutions exist for all m in \\frac{3}{4} \\odot > m > \\frac{1}{3} \\odot \\frac{3}{4} \\odot > m > \\frac{1}{3} \\odot , and one solution exists for all m < \\frac{1}{3} \\odot m < \\frac{1}{3} \\odot .","title":"Particular Equations Of State"},{"location":"GR/Solutions/#free-energy","text":"In the non-relativistic polytrope solutions of Emden the equation of state was assumed to be P = K \\rho^{\\gamma} P = K \\rho^{\\gamma} . But Landau pointed out that although these solutions in \\gamma > \\frac{6}{5} \\gamma > \\frac{6}{5} give an equilibrium configuration, they do not in every case give stable equilibrium. Thus, unless \\gamma >frac{4}{3} \\gamma >frac{4}{3} the equilibrium configuration is unstable. The part of the free energy caused by compression is F = - a \\rho^{\\frac{1}{3}} + b \\rho^{\\gamma - 1} F = - a \\rho^{\\frac{1}{3}} + b \\rho^{\\gamma - 1} Polytrope solutions exist for \\gamma = \\frac{5}{3} (> \\frac{4}{3}) \\gamma = \\frac{5}{3} (> \\frac{4}{3}) corresponds to stable equilibrium, for \\gamma = \\frac{5}{4} (< \\frac{4}{3}) \\gamma = \\frac{5}{4} (< \\frac{4}{3}) to unstable equilibrium. Since the free energy must be a continuous function of t_0 t_0 , and since we know from non-relativistic calculations that for small masses (and low densities) we have a position of stable equilibrium (a minimum in the free energy curve) we can conclude that the second equilibrium position corresponds either to a maximum or to an inflection point in the free energy curve (and certainly not to a minimum). Fig. 3 gives a schematic plot of free energy against t_0 t_0 for different values of M_0 M_0 which would explain the existence of one equilibrium position for small masses, two for intermediate masses, and none for large masses. The masses marked on the curves are the actual gravitational masses corresponding to the equilibrium points of the critical free energy curves.","title":"Free Energy"},{"location":"GR/Solutions/#application-to-stellar-matter","text":"Since neutron cores can hardly be stable (with respect to formation of electrons and nuclei) for masses less than \\sim 0.1 M_{\\odot} \\sim 0.1 M_{\\odot} . Since, even after thermonuclear sources of energy are exhausted, they will** not tend to form by collapse of ordinary matter for masses under 1.5 M_{\\odot} 1.5 M_{\\odot} (Landau's limit) . It seems **unlikely that static neutron cores can play any great part in stellar evolution , and the question of what happens, after energy sources are exhausted, to stars of mass greater than 1.5 M_{\\odot} 1.5 M_{\\odot} still remains unanswered . There would then seem to be only two answers possible to the question of the \"final\" behavior of very massive stars: The equation of state we have used so far fails to describe the behavior of highly condensed matter that the conclusions reached above are qualitatively misleading The star will continue to contract indefinitely, never reaching equilibrium.","title":"Application To Stellar Matter"},{"location":"GR/Solutions/#non-static-solutions","text":"From this discussion it appears probable that for an understanding of the long time behavior of actual heavy stars a consideration of non-static solutions must be essential. Among all (spherical) non-static solutions one would hope to find some for which the rate of contraction, and in general the time variation, become slower and slower, so that these solutions might be regarded, not as equilibrium solutions, but as quasi-static. Some reason for this we may see in the following argument: for large enough mass the core will collapse; near the center the density and pressure will grow, and g_{tt} = e^{\\nu} g_{tt} = e^{\\nu} will be small; and as e^{\\nu} e^{\\nu} grows smaller, all processes will, as seen by an outside observer, slow down in the central region. For masses under \\frac{1}{3} M_{\\odot} \\frac{1}{3} M_{\\odot} only one equilibrium solution exists, which is approximately described by the non-relativistic Fermi equation of state and Newtonian gravitational theory. For masses \\frac{1}{3} M_{\\odot} < m < \\frac{3}{4} M_{\\odot} \\frac{1}{3} M_{\\odot} < m < \\frac{3}{4} M_{\\odot} two solutions exist, one stable and quasi-Newtonian, one more condensed, and unstable. For masses greater than \\frac{3}{4} M_{\\odot} \\frac{3}{4} M_{\\odot} there are no static equilibrium solutions. Oppenheimer(1939) On Massive Neutron Cores \u21a9","title":"Non-static Solutions"},{"location":"GW/Extracting Gravitational Waveforms/","text":"Numerical relativity simulations focus on the strong-field regime of the sources, and compute a 3 + 1 spacetime metric decomposed in terms of a lapse function, shift vector and spatial three-metric. The functional form of this spacetime metric is strongly dependent on the chosen coordinate system. The Gauge-Invariant Moncrief Formalism","title":"Extracting Gravitational Waveforms"},{"location":"GW/Introduction/","text":"One of the major motivations for performing numerical relativity simulations is the accurate calculation of gravitational waveforms from promising sources in order that these theoretically computed signals can be compared with observational data from gravitational wave detectors. Gravitational wave detection In many ways, gravitational wave detection is more like hearing than seeing. In most other astronomical observations we detect photons, which behave very differently from their gravitational analogs. Photons typically have wavelengths that are much shorter than the emitting object, so that we can create images. Gravitational waves, on the other hand, have wavelengths that are larger than or at least comparable to the size of the emitting object. That means that we cannot use gravitational waves to create an image of the emitting object. In analogy to hearing we cannot even locate a gravitational wave source in the sky with just one detector. This makes it so important to operate a number of different gravitational wave detectors, spread far apart over the Earth or in space. Gravitational wave detectors measure gravitational amplitudes directly, as a function of time, and this measurement can be compared with theoretical models. In addition, \u201cmatched-filtering\u201d techniques \u2013 in which the noisy output of the detector is compared with a catalog of theoretical gravitational waveform templates \u2013 dramatically increase the likelihood of identifying a particular signal. Using this technique, the distance out to which an object can be observed increases approximately with the square root of the number of wave cycles . Ground-based gravitational wave interferometers The high frequency band includes frequencies in the approximate range 1 \\mathrm { Hz } \\lesssim f \\lesssim 10 ^ { 4 } \\mathrm { Hz } 1 \\mathrm { Hz } \\lesssim f \\lesssim 10 ^ { 4 } \\mathrm { Hz } . This frequency band is observable with the new generation of ground-based gravitational wave interferometers. A passing gravitational wave will distort the relative length of the two arms, and will therefore modify the interference pattern of the two returning light beams. gravitational wave strain The effect of a passing gravitational wave on two nearby, freely-falling test particles at a spatial separation \\xi ^ { i } \\xi ^ { i } is to change their separation according to \\ddot { \\xi } _ { i } = \\frac { 1 } { 2 } \\ddot { h } _ { i j } ^ { T T } \\xi ^ { j } \\ddot { \\xi } _ { i } = \\frac { 1 } { 2 } \\ddot { h } _ { i j } ^ { T T } \\xi ^ { j } The relative strain \\frac{\\delta \\xi}{\\xi} \\frac{\\delta \\xi}{\\xi} between these two particles is therefore proportional to the gravitational wave amplitude, which explains why h _ { i j } ^ { T T } h _ { i j } ^ { T T } is sometimes called the gravitational wave strain. Space-based detectors The low frequency band between 10 ^ { - 5 } \\mathrm { Hz } \\lesssim f \\lesssim 1 \\mathrm { Hz } 10 ^ { - 5 } \\mathrm { Hz } \\lesssim f \\lesssim 1 \\mathrm { Hz } cannot be observed with ground-based detectors. This leaves space-based observatories as the best means of detecting such radiation.","title":"Introduction"},{"location":"GW/Introduction/#gravitational-wave-detection","text":"In many ways, gravitational wave detection is more like hearing than seeing. In most other astronomical observations we detect photons, which behave very differently from their gravitational analogs. Photons typically have wavelengths that are much shorter than the emitting object, so that we can create images. Gravitational waves, on the other hand, have wavelengths that are larger than or at least comparable to the size of the emitting object. That means that we cannot use gravitational waves to create an image of the emitting object. In analogy to hearing we cannot even locate a gravitational wave source in the sky with just one detector. This makes it so important to operate a number of different gravitational wave detectors, spread far apart over the Earth or in space. Gravitational wave detectors measure gravitational amplitudes directly, as a function of time, and this measurement can be compared with theoretical models. In addition, \u201cmatched-filtering\u201d techniques \u2013 in which the noisy output of the detector is compared with a catalog of theoretical gravitational waveform templates \u2013 dramatically increase the likelihood of identifying a particular signal. Using this technique, the distance out to which an object can be observed increases approximately with the square root of the number of wave cycles . Ground-based gravitational wave interferometers The high frequency band includes frequencies in the approximate range 1 \\mathrm { Hz } \\lesssim f \\lesssim 10 ^ { 4 } \\mathrm { Hz } 1 \\mathrm { Hz } \\lesssim f \\lesssim 10 ^ { 4 } \\mathrm { Hz } . This frequency band is observable with the new generation of ground-based gravitational wave interferometers. A passing gravitational wave will distort the relative length of the two arms, and will therefore modify the interference pattern of the two returning light beams. gravitational wave strain The effect of a passing gravitational wave on two nearby, freely-falling test particles at a spatial separation \\xi ^ { i } \\xi ^ { i } is to change their separation according to \\ddot { \\xi } _ { i } = \\frac { 1 } { 2 } \\ddot { h } _ { i j } ^ { T T } \\xi ^ { j } \\ddot { \\xi } _ { i } = \\frac { 1 } { 2 } \\ddot { h } _ { i j } ^ { T T } \\xi ^ { j } The relative strain \\frac{\\delta \\xi}{\\xi} \\frac{\\delta \\xi}{\\xi} between these two particles is therefore proportional to the gravitational wave amplitude, which explains why h _ { i j } ^ { T T } h _ { i j } ^ { T T } is sometimes called the gravitational wave strain. Space-based detectors The low frequency band between 10 ^ { - 5 } \\mathrm { Hz } \\lesssim f \\lesssim 1 \\mathrm { Hz } 10 ^ { - 5 } \\mathrm { Hz } \\lesssim f \\lesssim 1 \\mathrm { Hz } cannot be observed with ground-based detectors. This leaves space-based observatories as the best means of detecting such radiation.","title":"Gravitational wave detection"},{"location":"GW/Linearized Waves/","text":"In the near-field region about sources, the gravitational fields consist of a combination of longitudinal and transverse components that cannot be disentangled unambigiously. As the transverse fields propagate away from their sources, however, they will reach an asymptotic region in which they can be modeled as a linear perturbation of a nearly Minkowski spacetime. These linearized gravitational waves carry information about the nature of the nonlinear sources that generated them. It is these linearized waves that are measured by gravitational wave detectors. Perturbation Theory Consider a small perturbation h _ { a b } h _ { a b } of a known \u201cbackground\u201d solution to Einstein\u2019s equations. In principle the background could be any solution, but here we are interested in waves propagating in a nearly Minkowski spacetime, for which the metric becomes g _ { a b } = \\eta _ { a b } + h _ { a b } , \\quad \\left| h _ { a b } \\right| \\ll 1 g _ { a b } = \\eta _ { a b } + h _ { a b } , \\quad \\left| h _ { a b } \\right| \\ll 1 It is convenient to introduce the \u201ctrace-reversed\u201d perturbation \\bar { h } _ { a b } \\equiv h _ { a b } - \\frac { 1 } { 2 } \\eta _ { a b } h _ { c } ^ { c } \\bar { h } _ { a b } \\equiv h _ { a b } - \\frac { 1 } { 2 } \\eta _ { a b } h _ { c } ^ { c } We can now exploit our coordinate-freedom to impose the \u201cLorentz gauge\u201d condition, \\nabla _ { a } \\bar { h } ^ { a b } = 0 \\nabla _ { a } \\bar { h } ^ { a b } = 0 Vacuum Solutions Einstein\u2019s equations in vacuum reduce to the wave equation \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = 0 \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = 0 the Lorentz-gauge condition does not determine \\bar { h } _ { a b } \\bar { h } _ { a b } uniquely, since we can introduce further infinitesimal gauge transformations that leave this condition unchanged. Particularly useful is the transverse-traceless or \u201cTT\u201d gauge, in which \\bar { h } _ { a 0 } ^ { T T } = 0 , \\quad \\bar { h } ^ { T T a } _ { a } = 0 \\bar { h } _ { a 0 } ^ { T T } = 0 , \\quad \\bar { h } ^ { T T a } _ { a } = 0 The first condition implies that the only nonzero components of \\bar { h } _ { a b } ^ { T T } \\bar { h } _ { a b } ^ { T T } are purely spatial. The second condition implies that h _ { c } ^ { c } = 0 h _ { c } ^ { c } = 0 , so that, the trace-reversed metric perturbations \\bar { h } _ { a b } \\bar { h } _ { a b } are identical to the original perturbations h _ { a b } h _ { a b } , and we are entitled to drop the bars whenever we write down results in the TT gauge. Together, the \u201cLorentz gauge\u201d condition and \u201cTT\u201d gauge provide eight constraints on the originally ten independent components of h _ { a b } h _ { a b } . The remaining two degrees of freedom correspond to the two possible polarization states of gravitational radiation. A general gravitational wave is then specified by two dimensionless amplitudes h _ { + } h _ { + } and h _ { \\times } h _ { \\times } as h _ { j k } ^ { T T } = h _ { + } e _ { i j } ^ { + } + h _ { \\times } e _ { i j } ^ { \\times } h _ { j k } ^ { T T } = h _ { + } e _ { i j } ^ { + } + h _ { \\times } e _ { i j } ^ { \\times } a linear plane wave For a linear plane wave propagating in vacuum in the z-direction, we have e _ { x x } ^ { + } = - e _ { y y } ^ { + } = 1 , e _ { x y } ^ { \\times } = e _ { y x } ^ { \\times } = 1 e _ { x x } ^ { + } = - e _ { y y } ^ { + } = 1 , e _ { x y } ^ { \\times } = e _ { y x } ^ { \\times } = 1 , all other components zero. Just as in electrodynamics, this type of equation admits simple plane wave solutions of the form \\bar { h } _ { a b } = \\Re \\left( A _ { a b } e ^ { i k _ { c } x ^ { c } } \\right) \\bar { h } _ { a b } = \\Re \\left( A _ { a b } e ^ { i k _ { c } x ^ { c } } \\right) Einstein\u2019s equations then demand that k ^ { a } k ^ { a } be a null vector, k _ { a } k ^ { a } = 0 k _ { a } k ^ { a } = 0 The Lorentz condition requires k ^ { a } A _ { a b } = 0 k ^ { a } A _ { a b } = 0 implying that gravitational waves are transverse. From a numerical point of view the plane wave solutions found above are not the most useful. Most numerical simulations treat spacetimes with finite, bounded sources, for which the waves propagate radially outward at large distance. Moreover such spacetimes approach asymptotic flatness at least as fast as r ^ { - 1 } r ^ { - 1 } . Clearly spacetimes containing with plane waves do not share these properties. More useful for simulation purposes are in terms of tensor spherical harmonics. Gravitational radiation carries energy, momentum, and angular momentum. We can express the radiated energy in terms of the wave amplitudes h _ { + } h _ { + } and h _ { \\times } h _ { \\times } L _ { \\mathrm { GW } } = - \\frac { d E } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega L _ { \\mathrm { GW } } = - \\frac { d E } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega Similarly, we can find the loss of angular momentum due to radiation, \\frac { d J _ { z } } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\partial _ { t } h _ { + } \\partial _ { \\phi } h _ { + } + \\partial _ { t } h _ { \\times } \\partial _ { \\phi } h _ { \\times } \\right\\rangle d \\Omega \\frac { d J _ { z } } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\partial _ { t } h _ { + } \\partial _ { \\phi } h _ { + } + \\partial _ { t } h _ { \\times } \\partial _ { \\phi } h _ { \\times } \\right\\rangle d \\Omega Finally, the loss of linear momentum due to radiation is \\frac { d P ^ { i } } { d t } = \\lim _ { r \\rightarrow \\infty } - \\frac { r ^ { 2 } } { 16 \\pi } \\int \\frac { x ^ { i } } { r } \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega \\frac { d P ^ { i } } { d t } = \\lim _ { r \\rightarrow \\infty } - \\frac { r ^ { 2 } } { 16 \\pi } \\int \\frac { x ^ { i } } { r } \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega In all the above expressions the quantities E, J and P^i P^i refer to the source, and their changes are equal and opposite to the corresponding quantities carried off by the waves. Sources Consider now the generation of gravitational radiation from a weak-field, slow-velocity source. For such a source, Einstein\u2019s equations reduce to \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = - 16 \\pi T _ { a b } \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = - 16 \\pi T _ { a b } Imposing an outgoing-wave boundary condition, we can solve equation with the help of a Green\u2019s function to obtain the integral equation, \\bar { h } _ { a b } \\left( t , x ^ { i } \\right) = 4 \\int d ^ { 3 } x ^ { \\prime } \\frac { T _ { a b } \\left( t - \\left| x ^ { i } - x ^ { i } \\right| , x ^ { i } \\right) } { \\left| x ^ { i } - x ^ { \\prime } \\right| } \\bar { h } _ { a b } \\left( t , x ^ { i } \\right) = 4 \\int d ^ { 3 } x ^ { \\prime } \\frac { T _ { a b } \\left( t - \\left| x ^ { i } - x ^ { i } \\right| , x ^ { i } \\right) } { \\left| x ^ { i } - x ^ { \\prime } \\right| } For a binary, we can estimate the typical gravitational wave strain h. For equal-mass binaries we have \\mu = M / 4 \\mu = M / 4 , so h \\simeq \\frac { 4 } { r } \\frac { \\mu M } { R } \\simeq 5 \\times 10 ^ { - 20 } \\left( \\frac { 1 \\mathrm { Mpc } } { r } \\right) \\left( \\frac { M } { M _ { \\odot } } \\right) \\left( \\frac { M } { R } \\right) h \\simeq \\frac { 4 } { r } \\frac { \\mu M } { R } \\simeq 5 \\times 10 ^ { - 20 } \\left( \\frac { 1 \\mathrm { Mpc } } { r } \\right) \\left( \\frac { M } { M _ { \\odot } } \\right) \\left( \\frac { M } { R } \\right) The characteristic gravitational wave frequency from a stellar object of mass M, radius R and compaction M/R M/R by f \\simeq \\frac { 1 } { M } \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } \\simeq 2 \\times 10 ^ { 5 } \\mathrm { Hz } \\left( \\frac { M _ { \\odot } } { M } \\right) \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } f \\simeq \\frac { 1 } { M } \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } \\simeq 2 \\times 10 ^ { 5 } \\mathrm { Hz } \\left( \\frac { M _ { \\odot } } { M } \\right) \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } The highest frequency sources are compact objects with large compactions (black holes or neutron stars) and small masses; stellar-mass compact objects fall into this category. These sources fall into the high frequency band.","title":"Linearized Waves"},{"location":"GW/Linearized Waves/#perturbation-theory","text":"Consider a small perturbation h _ { a b } h _ { a b } of a known \u201cbackground\u201d solution to Einstein\u2019s equations. In principle the background could be any solution, but here we are interested in waves propagating in a nearly Minkowski spacetime, for which the metric becomes g _ { a b } = \\eta _ { a b } + h _ { a b } , \\quad \\left| h _ { a b } \\right| \\ll 1 g _ { a b } = \\eta _ { a b } + h _ { a b } , \\quad \\left| h _ { a b } \\right| \\ll 1 It is convenient to introduce the \u201ctrace-reversed\u201d perturbation \\bar { h } _ { a b } \\equiv h _ { a b } - \\frac { 1 } { 2 } \\eta _ { a b } h _ { c } ^ { c } \\bar { h } _ { a b } \\equiv h _ { a b } - \\frac { 1 } { 2 } \\eta _ { a b } h _ { c } ^ { c } We can now exploit our coordinate-freedom to impose the \u201cLorentz gauge\u201d condition, \\nabla _ { a } \\bar { h } ^ { a b } = 0 \\nabla _ { a } \\bar { h } ^ { a b } = 0 Vacuum Solutions Einstein\u2019s equations in vacuum reduce to the wave equation \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = 0 \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = 0 the Lorentz-gauge condition does not determine \\bar { h } _ { a b } \\bar { h } _ { a b } uniquely, since we can introduce further infinitesimal gauge transformations that leave this condition unchanged. Particularly useful is the transverse-traceless or \u201cTT\u201d gauge, in which \\bar { h } _ { a 0 } ^ { T T } = 0 , \\quad \\bar { h } ^ { T T a } _ { a } = 0 \\bar { h } _ { a 0 } ^ { T T } = 0 , \\quad \\bar { h } ^ { T T a } _ { a } = 0 The first condition implies that the only nonzero components of \\bar { h } _ { a b } ^ { T T } \\bar { h } _ { a b } ^ { T T } are purely spatial. The second condition implies that h _ { c } ^ { c } = 0 h _ { c } ^ { c } = 0 , so that, the trace-reversed metric perturbations \\bar { h } _ { a b } \\bar { h } _ { a b } are identical to the original perturbations h _ { a b } h _ { a b } , and we are entitled to drop the bars whenever we write down results in the TT gauge. Together, the \u201cLorentz gauge\u201d condition and \u201cTT\u201d gauge provide eight constraints on the originally ten independent components of h _ { a b } h _ { a b } . The remaining two degrees of freedom correspond to the two possible polarization states of gravitational radiation. A general gravitational wave is then specified by two dimensionless amplitudes h _ { + } h _ { + } and h _ { \\times } h _ { \\times } as h _ { j k } ^ { T T } = h _ { + } e _ { i j } ^ { + } + h _ { \\times } e _ { i j } ^ { \\times } h _ { j k } ^ { T T } = h _ { + } e _ { i j } ^ { + } + h _ { \\times } e _ { i j } ^ { \\times } a linear plane wave For a linear plane wave propagating in vacuum in the z-direction, we have e _ { x x } ^ { + } = - e _ { y y } ^ { + } = 1 , e _ { x y } ^ { \\times } = e _ { y x } ^ { \\times } = 1 e _ { x x } ^ { + } = - e _ { y y } ^ { + } = 1 , e _ { x y } ^ { \\times } = e _ { y x } ^ { \\times } = 1 , all other components zero. Just as in electrodynamics, this type of equation admits simple plane wave solutions of the form \\bar { h } _ { a b } = \\Re \\left( A _ { a b } e ^ { i k _ { c } x ^ { c } } \\right) \\bar { h } _ { a b } = \\Re \\left( A _ { a b } e ^ { i k _ { c } x ^ { c } } \\right) Einstein\u2019s equations then demand that k ^ { a } k ^ { a } be a null vector, k _ { a } k ^ { a } = 0 k _ { a } k ^ { a } = 0 The Lorentz condition requires k ^ { a } A _ { a b } = 0 k ^ { a } A _ { a b } = 0 implying that gravitational waves are transverse. From a numerical point of view the plane wave solutions found above are not the most useful. Most numerical simulations treat spacetimes with finite, bounded sources, for which the waves propagate radially outward at large distance. Moreover such spacetimes approach asymptotic flatness at least as fast as r ^ { - 1 } r ^ { - 1 } . Clearly spacetimes containing with plane waves do not share these properties. More useful for simulation purposes are in terms of tensor spherical harmonics. Gravitational radiation carries energy, momentum, and angular momentum. We can express the radiated energy in terms of the wave amplitudes h _ { + } h _ { + } and h _ { \\times } h _ { \\times } L _ { \\mathrm { GW } } = - \\frac { d E } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega L _ { \\mathrm { GW } } = - \\frac { d E } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega Similarly, we can find the loss of angular momentum due to radiation, \\frac { d J _ { z } } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\partial _ { t } h _ { + } \\partial _ { \\phi } h _ { + } + \\partial _ { t } h _ { \\times } \\partial _ { \\phi } h _ { \\times } \\right\\rangle d \\Omega \\frac { d J _ { z } } { d t } = \\lim _ { r \\rightarrow \\infty } \\frac { r ^ { 2 } } { 16 \\pi } \\int \\left\\langle \\partial _ { t } h _ { + } \\partial _ { \\phi } h _ { + } + \\partial _ { t } h _ { \\times } \\partial _ { \\phi } h _ { \\times } \\right\\rangle d \\Omega Finally, the loss of linear momentum due to radiation is \\frac { d P ^ { i } } { d t } = \\lim _ { r \\rightarrow \\infty } - \\frac { r ^ { 2 } } { 16 \\pi } \\int \\frac { x ^ { i } } { r } \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega \\frac { d P ^ { i } } { d t } = \\lim _ { r \\rightarrow \\infty } - \\frac { r ^ { 2 } } { 16 \\pi } \\int \\frac { x ^ { i } } { r } \\left\\langle \\dot { h } _ { + } ^ { 2 } + \\dot { h } _ { \\times } ^ { 2 } \\right\\rangle d \\Omega In all the above expressions the quantities E, J and P^i P^i refer to the source, and their changes are equal and opposite to the corresponding quantities carried off by the waves. Sources Consider now the generation of gravitational radiation from a weak-field, slow-velocity source. For such a source, Einstein\u2019s equations reduce to \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = - 16 \\pi T _ { a b } \\square \\bar { h } _ { a b } = \\nabla ^ { c } \\nabla _ { c } \\bar { h } _ { a b } = - 16 \\pi T _ { a b } Imposing an outgoing-wave boundary condition, we can solve equation with the help of a Green\u2019s function to obtain the integral equation, \\bar { h } _ { a b } \\left( t , x ^ { i } \\right) = 4 \\int d ^ { 3 } x ^ { \\prime } \\frac { T _ { a b } \\left( t - \\left| x ^ { i } - x ^ { i } \\right| , x ^ { i } \\right) } { \\left| x ^ { i } - x ^ { \\prime } \\right| } \\bar { h } _ { a b } \\left( t , x ^ { i } \\right) = 4 \\int d ^ { 3 } x ^ { \\prime } \\frac { T _ { a b } \\left( t - \\left| x ^ { i } - x ^ { i } \\right| , x ^ { i } \\right) } { \\left| x ^ { i } - x ^ { \\prime } \\right| } For a binary, we can estimate the typical gravitational wave strain h. For equal-mass binaries we have \\mu = M / 4 \\mu = M / 4 , so h \\simeq \\frac { 4 } { r } \\frac { \\mu M } { R } \\simeq 5 \\times 10 ^ { - 20 } \\left( \\frac { 1 \\mathrm { Mpc } } { r } \\right) \\left( \\frac { M } { M _ { \\odot } } \\right) \\left( \\frac { M } { R } \\right) h \\simeq \\frac { 4 } { r } \\frac { \\mu M } { R } \\simeq 5 \\times 10 ^ { - 20 } \\left( \\frac { 1 \\mathrm { Mpc } } { r } \\right) \\left( \\frac { M } { M _ { \\odot } } \\right) \\left( \\frac { M } { R } \\right) The characteristic gravitational wave frequency from a stellar object of mass M, radius R and compaction M/R M/R by f \\simeq \\frac { 1 } { M } \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } \\simeq 2 \\times 10 ^ { 5 } \\mathrm { Hz } \\left( \\frac { M _ { \\odot } } { M } \\right) \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } f \\simeq \\frac { 1 } { M } \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } \\simeq 2 \\times 10 ^ { 5 } \\mathrm { Hz } \\left( \\frac { M _ { \\odot } } { M } \\right) \\left( \\frac { M } { R } \\right) ^ { 3 / 2 } The highest frequency sources are compact objects with large compactions (black holes or neutron stars) and small masses; stellar-mass compact objects fall into this category. These sources fall into the high frequency band.","title":"Perturbation Theory"},{"location":"NR/3+1 Decomposition/","text":"The 3+1 equations are entirely equivalent to the usual \ufb01eld equations but they focus on the evolution of 12 purely spatial quantities closely related to g_{ij} g_{ij} and \\partial_t g_{ij} \\partial_t g_{ij} and the constraints that they must satisfy on spatial hypersurfaces. Once these spatial \ufb01eld quantities are specified on some initial \u201ctime slice\u201d (i.e. spatial hypersurface) consistent with the 3 + 1 constraint equations, the 3 + 1 evolution equations can then be integrated, together with evolution equations for the matter sources, to determine these \ufb01eld quantities at all later times.","title":"3+1 Decomposition"},{"location":"NR/ADM/","text":"","title":"ADM"},{"location":"NR/Introduction/","text":"For all but the simplest systems, analytic solutions for the evolution of such systems do not exist . Hence the task of solving Einstein's equations must be performed numerically on a computer . In classical dynamics, the evolution of a system is uniquely determined by the initial positions and velocities of its constituents. By analogy, the evolution of general relativistic gravitational field is determined by specifying the metric quantities g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} at a given (initial) instant of time t . Now these metric quantities can be integrated forward in time provided we can obtain from the Einstein field equations expressions for \\partial^2_t g_{ab} \\partial^2_t g_{ab} at all points on the hypersurface . That way we can integrate these expressions to compute g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} on a new spacelike hypersurface at some new time t + \\delta t t + \\delta t , and then, by repeating the process, obtain g_{ab} g_{ab} for all other points x^0 x^0 and x^i x^i in the (future) spacetime. Cauchy problem This is a fundamental problem arising in the mathematical theory of partial differential equations. The Bianchi identities \\nabla_b G^{ab} = 0 \\nabla_b G^{ab} = 0 give \\partial_t G^{a0} = - \\partial_i G^{ai} - G^{bc} \\Gamma^a_{bc} - G^{ab} \\Gamma^c_{bc} \\partial_t G^{a0} = - \\partial_i G^{ai} - G^{bc} \\Gamma^a_{bc} - G^{ab} \\Gamma^c_{bc} Since no term on the right hand side of equation contains third time derivatives or higher, the four quantities G^{a0} G^{a0} cannot contain second time derivatives. Hence the four equations G^{a0} = 8 \\pi T^{a0} G^{a0} = 8 \\pi T^{a0} do not furnish any of the information required for the dynamical evolution of the fields. Rather, they supply four constraints on the initial data, i.e. four relations between g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} on the initial hypersurface at x^0 = t x^0 = t . The only truly dynamical equations must be provided by the six remaining relations G^{ij} = 8 \\pi T^{ij} G^{ij} = 8 \\pi T^{ij} It is not surprising that there is a mismatch between the required number (10) of second time 2 derivatives \\partial_t^2 g_{ab} \\partial_t^2 g_{ab} and the available number (6) of dynamical \ufb01eld equations. After all, there is always a fourfold ambiguity associated with the freedom to choose four different coordinates to label points in spacetime. So, for example, we could always choose Gaussian normal coordinates and set $g_{00} = \u22121 $ and g_{0i} = 0 g_{0i} = 0 . The Cauchy problem in general relativity logically involves a decomposition of four-dimensional spacetime into three dimensional space and one-dimensional time . Cauchy surface Cauchy surface is a plane in space-time which is like an instant of time; its significance is that giving the initial conditions on this plane determines the future (and the past) uniquely. Analogy Maxwell\u2019s equations \\begin{array} { l } { D _ { i } E ^ { i } - 4 \\pi \\rho = 0 } \\\\ D _ { i } B ^ { i } = 0 \\end{array} \\begin{array} { l } { D _ { i } E ^ { i } - 4 \\pi \\rho = 0 } \\\\ D _ { i } B ^ { i } = 0 \\end{array} The above equations involve only spatial derivatives of the electric and magnetic fields and hold at each instant of time independently of the prior or subsequent evolution of the fields. They therefore constrain any possible configurations of the fields, and are correspondingly called the constraint equations . \\begin{aligned} \\partial _ { t } E _ { i } & = \\epsilon _ { i j k } D ^ { j } B ^ { k } - 4 \\pi j _ { i } \\\\ \\partial _ { t } B _ { i } & = - \\epsilon _ { i j k } D ^ { j } E ^ { k } \\end{aligned} \\begin{aligned} \\partial _ { t } E _ { i } & = \\epsilon _ { i j k } D ^ { j } B ^ { k } - 4 \\pi j _ { i } \\\\ \\partial _ { t } B _ { i } & = - \\epsilon _ { i j k } D ^ { j } E ^ { k } \\end{aligned} These equations describe how the fields evolve forward in time, and are therefore called the evolution equations . To completely determine the time evolution of the electromagnetic fields we also have to specify how the sources \u03c1 and j^i j^i evolve according to the net force acting on them. It is possible to bring Maxwell\u2019s equations into a form that is closer to the 3+1 form of Einstein\u2019s equations. To do so, we introduce the vector potential A ^ { a } = \\left( \\Phi , A ^ { i } \\right) A ^ { a } = \\left( \\Phi , A ^ { i } \\right) and write B^i B^i as B _ { i } = \\epsilon _ { i j k } D ^ { j } A ^ { k } B _ { i } = \\epsilon _ { i j k } D ^ { j } A ^ { k } By construction, B_i B_i automatically satisfies the constraint D _ { i } B ^ { i } = 0 D _ { i } B ^ { i } = 0 . The two evolution equations can be rewritten in terms of E_i E_i and A_i A_i \\begin{aligned} \\partial _ { t } A _ { i } & = - E _ { i } - D _ { i } \\Phi \\\\ \\partial _ { t } E _ { i } & = D _ { i } D ^ { j } A _ { j } - D ^ { j } D _ { j } A _ { i } - 4 \\pi j _ { i } \\end{aligned} \\begin{aligned} \\partial _ { t } A _ { i } & = - E _ { i } - D _ { i } \\Phi \\\\ \\partial _ { t } E _ { i } & = D _ { i } D ^ { j } A _ { j } - D ^ { j } D _ { j } A _ { i } - 4 \\pi j _ { i } \\end{aligned} With the vector potential A_i A_i we have introduced a gauge freedom into electrodynamics which is expressed in the freely specifiable gauge variable \u03a6 \u03a6 . The initial value problem in electrodynamics can now be solved in two steps. In the first step, initial data ( A_i A_i , E_i E_i ), together with the sources (\u03c1, j_i j_i ), are specified that satisfy the constraint equations. In the second step, these fields are evolved according to the evolution equations. Before the evolution equations can be solved, a suitable gauge condition has to be chosen . Complications The equations that arise in numerical relativity are typically multidimensional, nonlinear, coupled partial differential equations in space and time . They have in common with other areas of computational physics, like magnetohydrodynamics. However, solving Einstein\u2019s equations poses some additional complications that are unique to general relativity. In general relativity, coordinates are merely labels that distinguish points in spacetime; by themselves coordinate intervals have no physical significance. To use coordinate intervals to determine physically measurable proper distances and proper times requires the spacetime metric, but the metric is known only after Einstein\u2019s equations have been solved . Moreover, as the numerical integrations that determine the metric proceed, it often turns out that the original, arbitrary choice of coordinates turns out to be bad, because, for example, singularities appear in the equations. Encountering such singularities , be they physical or coordinate, results in some of the terms in Einstein\u2019s equations becoming infinite, potentially causing overflows in the computer output and premature termination of the numerical integration . Treating black holes is one of the main goals of numerical relativity, but this poses another complication. The reason is that black holes contain physical spacetime singularities \u2013 regions where the gravitational tidal field, the matter density and the spacetime curvature all become infinite. Thus, when dealing with black holes, it is crucial to choose a computational technique that avoids encountering their interior spacetime singularities in the course of the simulation . Another complication arises in the context of one of the most pressing goals of numerical relativity \u2013 the calculation of waveforms from promising astrophysical sources of gravitational radiation. These theoretical templates are essential for the identification and physical interpretation of gravitational wave sources. However, the gravitational wave components of the spacetime metric usually constitute small fractions of the smooth background metric. Moreover, to extract the waves from the background in a simulation requires that one probe the numerical spacetime in the far-field, or radiation, zone, which is typically at large distance from the strong-field central source. Yet it is the strong-field region which usually consumes most the computational resources (e.g. spatial resolution) to guarantee accuracy. Furthermore, waiting for the wave to propagate to the far-field region usually takes nonnegligible integration time.","title":"Introduction"},{"location":"NR/Introduction/#cauchy-problem","text":"This is a fundamental problem arising in the mathematical theory of partial differential equations. The Bianchi identities \\nabla_b G^{ab} = 0 \\nabla_b G^{ab} = 0 give \\partial_t G^{a0} = - \\partial_i G^{ai} - G^{bc} \\Gamma^a_{bc} - G^{ab} \\Gamma^c_{bc} \\partial_t G^{a0} = - \\partial_i G^{ai} - G^{bc} \\Gamma^a_{bc} - G^{ab} \\Gamma^c_{bc} Since no term on the right hand side of equation contains third time derivatives or higher, the four quantities G^{a0} G^{a0} cannot contain second time derivatives. Hence the four equations G^{a0} = 8 \\pi T^{a0} G^{a0} = 8 \\pi T^{a0} do not furnish any of the information required for the dynamical evolution of the fields. Rather, they supply four constraints on the initial data, i.e. four relations between g_{ab} g_{ab} and \\partial_t g_{ab} \\partial_t g_{ab} on the initial hypersurface at x^0 = t x^0 = t . The only truly dynamical equations must be provided by the six remaining relations G^{ij} = 8 \\pi T^{ij} G^{ij} = 8 \\pi T^{ij} It is not surprising that there is a mismatch between the required number (10) of second time 2 derivatives \\partial_t^2 g_{ab} \\partial_t^2 g_{ab} and the available number (6) of dynamical \ufb01eld equations. After all, there is always a fourfold ambiguity associated with the freedom to choose four different coordinates to label points in spacetime. So, for example, we could always choose Gaussian normal coordinates and set $g_{00} = \u22121 $ and g_{0i} = 0 g_{0i} = 0 . The Cauchy problem in general relativity logically involves a decomposition of four-dimensional spacetime into three dimensional space and one-dimensional time . Cauchy surface Cauchy surface is a plane in space-time which is like an instant of time; its significance is that giving the initial conditions on this plane determines the future (and the past) uniquely. Analogy Maxwell\u2019s equations \\begin{array} { l } { D _ { i } E ^ { i } - 4 \\pi \\rho = 0 } \\\\ D _ { i } B ^ { i } = 0 \\end{array} \\begin{array} { l } { D _ { i } E ^ { i } - 4 \\pi \\rho = 0 } \\\\ D _ { i } B ^ { i } = 0 \\end{array} The above equations involve only spatial derivatives of the electric and magnetic fields and hold at each instant of time independently of the prior or subsequent evolution of the fields. They therefore constrain any possible configurations of the fields, and are correspondingly called the constraint equations . \\begin{aligned} \\partial _ { t } E _ { i } & = \\epsilon _ { i j k } D ^ { j } B ^ { k } - 4 \\pi j _ { i } \\\\ \\partial _ { t } B _ { i } & = - \\epsilon _ { i j k } D ^ { j } E ^ { k } \\end{aligned} \\begin{aligned} \\partial _ { t } E _ { i } & = \\epsilon _ { i j k } D ^ { j } B ^ { k } - 4 \\pi j _ { i } \\\\ \\partial _ { t } B _ { i } & = - \\epsilon _ { i j k } D ^ { j } E ^ { k } \\end{aligned} These equations describe how the fields evolve forward in time, and are therefore called the evolution equations . To completely determine the time evolution of the electromagnetic fields we also have to specify how the sources \u03c1 and j^i j^i evolve according to the net force acting on them. It is possible to bring Maxwell\u2019s equations into a form that is closer to the 3+1 form of Einstein\u2019s equations. To do so, we introduce the vector potential A ^ { a } = \\left( \\Phi , A ^ { i } \\right) A ^ { a } = \\left( \\Phi , A ^ { i } \\right) and write B^i B^i as B _ { i } = \\epsilon _ { i j k } D ^ { j } A ^ { k } B _ { i } = \\epsilon _ { i j k } D ^ { j } A ^ { k } By construction, B_i B_i automatically satisfies the constraint D _ { i } B ^ { i } = 0 D _ { i } B ^ { i } = 0 . The two evolution equations can be rewritten in terms of E_i E_i and A_i A_i \\begin{aligned} \\partial _ { t } A _ { i } & = - E _ { i } - D _ { i } \\Phi \\\\ \\partial _ { t } E _ { i } & = D _ { i } D ^ { j } A _ { j } - D ^ { j } D _ { j } A _ { i } - 4 \\pi j _ { i } \\end{aligned} \\begin{aligned} \\partial _ { t } A _ { i } & = - E _ { i } - D _ { i } \\Phi \\\\ \\partial _ { t } E _ { i } & = D _ { i } D ^ { j } A _ { j } - D ^ { j } D _ { j } A _ { i } - 4 \\pi j _ { i } \\end{aligned} With the vector potential A_i A_i we have introduced a gauge freedom into electrodynamics which is expressed in the freely specifiable gauge variable \u03a6 \u03a6 . The initial value problem in electrodynamics can now be solved in two steps. In the first step, initial data ( A_i A_i , E_i E_i ), together with the sources (\u03c1, j_i j_i ), are specified that satisfy the constraint equations. In the second step, these fields are evolved according to the evolution equations. Before the evolution equations can be solved, a suitable gauge condition has to be chosen .","title":"Cauchy problem"},{"location":"NR/Introduction/#complications","text":"The equations that arise in numerical relativity are typically multidimensional, nonlinear, coupled partial differential equations in space and time . They have in common with other areas of computational physics, like magnetohydrodynamics. However, solving Einstein\u2019s equations poses some additional complications that are unique to general relativity. In general relativity, coordinates are merely labels that distinguish points in spacetime; by themselves coordinate intervals have no physical significance. To use coordinate intervals to determine physically measurable proper distances and proper times requires the spacetime metric, but the metric is known only after Einstein\u2019s equations have been solved . Moreover, as the numerical integrations that determine the metric proceed, it often turns out that the original, arbitrary choice of coordinates turns out to be bad, because, for example, singularities appear in the equations. Encountering such singularities , be they physical or coordinate, results in some of the terms in Einstein\u2019s equations becoming infinite, potentially causing overflows in the computer output and premature termination of the numerical integration . Treating black holes is one of the main goals of numerical relativity, but this poses another complication. The reason is that black holes contain physical spacetime singularities \u2013 regions where the gravitational tidal field, the matter density and the spacetime curvature all become infinite. Thus, when dealing with black holes, it is crucial to choose a computational technique that avoids encountering their interior spacetime singularities in the course of the simulation . Another complication arises in the context of one of the most pressing goals of numerical relativity \u2013 the calculation of waveforms from promising astrophysical sources of gravitational radiation. These theoretical templates are essential for the identification and physical interpretation of gravitational wave sources. However, the gravitational wave components of the spacetime metric usually constitute small fractions of the smooth background metric. Moreover, to extract the waves from the background in a simulation requires that one probe the numerical spacetime in the far-field, or radiation, zone, which is typically at large distance from the strong-field central source. Yet it is the strong-field region which usually consumes most the computational resources (e.g. spatial resolution) to guarantee accuracy. Furthermore, waiting for the wave to propagate to the far-field region usually takes nonnegligible integration time.","title":"Complications"},{"location":"NR/Numerical Methods/","text":"Finite Difference Methods In a finite difference approximation a function f(t,x) f(t,x) is represented by values at a discrete set of points. At the core of finite difference approximation is therefore a discretization of the spacetime, or a numerical grid. Instead of evaluating f at all values of x, for example, we only consider discrete values x_i x_i . The distance between the gridpoints x_i x_i is called the gridspacing \u2206x \u2206x . For uniform grids, for which \u2206x \u2206x is constant, we have x _ { i } = x _ { 0 } + i \\Delta x x _ { i } = x _ { 0 } + i \\Delta x If the solution depends on time we also discretize the time coordinate, for example as t ^ { n } = t ^ { 0 } + n \\Delta t t ^ { n } = t ^ { 0 } + n \\Delta t The finite difference representation of the function f(t,x) f(t,x) , for example, is f _ { i } ^ { n } = f \\left( t ^ { n } , x _ { i } \\right) + \\text { truncation error. } f _ { i } ^ { n } = f \\left( t ^ { n } , x _ { i } \\right) + \\text { truncation error. } Differential equations involve derivatives, so we must next discuss how to represent derivatives in a finite difference representation. Assuming that f(x) f(x) can be differentiated to sufficiently high order and that it can be represented as a Taylor series, we have f _ { i + 1 } = f \\left( x _ { i } + \\Delta x \\right) = f \\left( x _ { i } \\right) + \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) f _ { i + 1 } = f \\left( x _ { i } + \\Delta x \\right) = f \\left( x _ { i } \\right) + \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) Solving for \\left( \\partial _ { x } f \\right) _ { x _ { i } } = \\left( \\partial _ { x } f \\right) _ { i } \\left( \\partial _ { x } f \\right) _ { x _ { i } } = \\left( \\partial _ { x } f \\right) _ { i } we find \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i } } { \\Delta x } + \\mathcal { O } ( \\Delta x ) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i } } { \\Delta x } + \\mathcal { O } ( \\Delta x ) The truncation error of this expression is linear in \u2206x \u2206x , and it turns out that we can do better. We call equation a one-sided derivative , since it uses only neighbors on one side of x_i x_i . Consider the Taylor expansion to the point x_{ i \u2212 1 } x_{ i \u2212 1 } , f _ { i - 1 } = f \\left( x _ { i } - \\Delta x \\right) = f \\left( x _ { i } \\right) - \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) f _ { i - 1 } = f \\left( x _ { i } - \\Delta x \\right) = f \\left( x _ { i } \\right) - \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) we now find \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i - 1 } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i - 1 } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) which is second order in \u2206x \u2206x . In general, centered derivatives lead to higher order schemes than one-sided derivatives for the same number of gridpoints. The key point is that we are able to combine the two Taylor expansions in such a way that the leading order error term cancels out, leaving us with a higher order representation of the derivative . This cancellation only works out for uniform grids , when \u2206x \u2206x is independent of x. This is one of the reasons why many current numerical relativity applications of finite difference schemes work with uniform grids. Higher order derivatives can be constructed in a similar fashion. Adding the two Taylor expansions all terms odd in \u2206x \u2206x drop out and we find for the second derivative \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } } { ( \\Delta x ) ^ { 2 } } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } } { ( \\Delta x ) ^ { 2 } } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { 1 } { 12 \\Delta x } \\left( f _ { i - 2 } - 8 f _ { i - 1 } + 8 f _ { i + 1 } - f _ { i + 2 } \\right) \\\\ \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { 1 } { 12 ( \\Delta x ) ^ { 2 } } \\left( - f _ { i - 2 } + 16 f _ { i - 1 } - 30 f _ { i } + 16 f _ { i + 1 } - f _ { i + 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { 1 } { 12 \\Delta x } \\left( f _ { i - 2 } - 8 f _ { i - 1 } + 8 f _ { i + 1 } - f _ { i + 2 } \\right) \\\\ \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { 1 } { 12 ( \\Delta x ) ^ { 2 } } \\left( - f _ { i - 2 } + 16 f _ { i - 1 } - 30 f _ { i } + 16 f _ { i + 1 } - f _ { i + 2 } \\right) where we have omitted the truncation error, \\mathcal { O } \\left( \\Delta x ^ { 4 } \\right) \\mathcal { O } \\left( \\Delta x ^ { 4 } \\right) Hyperbolic Equations For simplicity it does not contain any source terms, and the the wave speed v is constant. \\partial _ { t } u + v \\partial _ { x } u = 0 \\partial _ { t } u + v \\partial _ { x } u = 0 The equation is satisfied exactly by any function of the form u ( t , x ) = u ( x - v t ) u ( t , x ) = u ( x - v t ) . The equation has a time derivative in addition to the space derivative, and thus requires initial data . Inserting both finite-difference representations \\left( \\partial _ { x } u \\right) _ { j } ^ { n } = \\frac { u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\\\ \\left( \\partial _ { t } u \\right) _ { j } ^ { n } = \\frac { u _ { j } ^ { n + 1 } - u _ { j } ^ { n } } { \\Delta t } + \\mathcal { O } ( \\Delta t ) \\left( \\partial _ { x } u \\right) _ { j } ^ { n } = \\frac { u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\\\ \\left( \\partial _ { t } u \\right) _ { j } ^ { n } = \\frac { u _ { j } ^ { n + 1 } - u _ { j } ^ { n } } { \\Delta t } + \\mathcal { O } ( \\Delta t ) we can solve for u^{n+1}_j u^{n+1}_j and find u _ { j } ^ { n + 1 } = u _ { j } ^ { n } - \\frac { v } { 2 } \\frac { \\Delta t } { \\Delta x } \\left( u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } \\right) u _ { j } ^ { n + 1 } = u _ { j } ^ { n } - \\frac { v } { 2 } \\frac { \\Delta t } { \\Delta x } \\left( u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } \\right) or reasons that are quite obivous this differencing scheme is called forward-time centered-space, or FTCS. It is an example of an explicit scheme, meaning that we can solve for the grid function u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } at the new time level n + 1 directly in terms of function values on the old time level n. Courant-Friedrichs-Lewy condition Unfortunately, however, FTCS is fairly useless. The equation is satisfied exactly by any function of the form u ( t , x ) = u ( x - v t ) u ( t , x ) = u ( x - v t ) . we can write the solution u ( t , x ) u ( t , x ) to our continuum hyperbolic differential equation as a superposition of eigenmodes e^{i(\\omega t+k x)} e^{i(\\omega t+k x)} . Here k is a spatial wave number. A real \\omega \\omega , for which e^{i \\omega t} e^{i \\omega t} has a magnitude of unity, yields sinusoidally oscillating modes, while the existence of a complex piece in \\omega \\omega leads to exponentially growing or damping modes. In the case of exponential growth, the magnitude of e^{i \\omega t} e^{i \\omega t} will exceed unity. We can perform a similar spectral analysis of the finite difference equation. Write the eigenmode for u_{j}^{n} u_{j}^{n} as u_{j}^{n}=\\xi^{n} e^{i k(j \\Delta x)} u_{j}^{n}=\\xi^{n} e^{i k(j \\Delta x)} Here the quantity \\xi \\xi plays the role of e^{i \\omega \\Delta t} e^{i \\omega \\Delta t} and is called the amplification factor: u_{j}^{n}=\\xi u_{j}^{n-1} = \\xi^{2} u_{j}^{n-2} \\ldots=\\xi^{n} u_{j}^{0} u_{j}^{n}=\\xi u_{j}^{n-1} = \\xi^{2} u_{j}^{n-2} \\ldots=\\xi^{n} u_{j}^{0} For the scheme to be stable, the magnitude \\xi \\xi must be smaller or equal to unity for all k, |\\xi(k)| \\leq 1 |\\xi(k)| \\leq 1 To perform a von Neumann stability anaylsis of the FTCS scheme \\xi(k)=1-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x \\xi(k)=1-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x the magnitude of \\xi \\xi is greater than unity for all k, indicating that this scheme is unstable. In fact, we have |\\xi|>1 |\\xi|>1 independently of our choice for \\Delta x \\Delta x and \\Delta t \\Delta t , which makes this scheme unconditionally unstable. That is bad. The good news is that there are several ways of fixing this problem. For example We could replace the term u_{j}^{n} u_{j}^{n} by the spatial average \\left(u_{j+1}^{n}+u_{j-1}^{n}\\right) / 2 \\left(u_{j+1}^{n}+u_{j-1}^{n}\\right) / 2 . u_{j}^{n+1}=\\frac{1}{2}\\left(u_{j+1}^{n}+u_{j-1}^{n}\\right)-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n}-u_{j-1}^{n}\\right) u_{j}^{n+1}=\\frac{1}{2}\\left(u_{j+1}^{n}+u_{j-1}^{n}\\right)-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n}-u_{j-1}^{n}\\right) a von Neumann analysis results in the amplification factor \\xi=\\cos k \\Delta x-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x \\xi=\\cos k \\Delta x-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x The von Neumann stability criterion then implies that we must have \\frac { | v | \\Delta t } { \\Delta x } \\leq 1 \\frac { | v | \\Delta t } { \\Delta x } \\leq 1 The Courant condition states that the the grid point u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } at the new time level n+1 has to reside inside the domain of determinacy of the interval spanned by the finite difference stencil at the time level n. This makes intuitive sense: if u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } were outside this domain, its physical specification would require more information about the past than we are providing numerically, which may trigger an instability. Recalling that v represents the speed of a characteristic, we may interpret the Courant condition in terms of the domain of determinacy.","title":"Numerical Methods"},{"location":"NR/Numerical Methods/#finite-difference-methods","text":"In a finite difference approximation a function f(t,x) f(t,x) is represented by values at a discrete set of points. At the core of finite difference approximation is therefore a discretization of the spacetime, or a numerical grid. Instead of evaluating f at all values of x, for example, we only consider discrete values x_i x_i . The distance between the gridpoints x_i x_i is called the gridspacing \u2206x \u2206x . For uniform grids, for which \u2206x \u2206x is constant, we have x _ { i } = x _ { 0 } + i \\Delta x x _ { i } = x _ { 0 } + i \\Delta x If the solution depends on time we also discretize the time coordinate, for example as t ^ { n } = t ^ { 0 } + n \\Delta t t ^ { n } = t ^ { 0 } + n \\Delta t The finite difference representation of the function f(t,x) f(t,x) , for example, is f _ { i } ^ { n } = f \\left( t ^ { n } , x _ { i } \\right) + \\text { truncation error. } f _ { i } ^ { n } = f \\left( t ^ { n } , x _ { i } \\right) + \\text { truncation error. } Differential equations involve derivatives, so we must next discuss how to represent derivatives in a finite difference representation. Assuming that f(x) f(x) can be differentiated to sufficiently high order and that it can be represented as a Taylor series, we have f _ { i + 1 } = f \\left( x _ { i } + \\Delta x \\right) = f \\left( x _ { i } \\right) + \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) f _ { i + 1 } = f \\left( x _ { i } + \\Delta x \\right) = f \\left( x _ { i } \\right) + \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) Solving for \\left( \\partial _ { x } f \\right) _ { x _ { i } } = \\left( \\partial _ { x } f \\right) _ { i } \\left( \\partial _ { x } f \\right) _ { x _ { i } } = \\left( \\partial _ { x } f \\right) _ { i } we find \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i } } { \\Delta x } + \\mathcal { O } ( \\Delta x ) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i } } { \\Delta x } + \\mathcal { O } ( \\Delta x ) The truncation error of this expression is linear in \u2206x \u2206x , and it turns out that we can do better. We call equation a one-sided derivative , since it uses only neighbors on one side of x_i x_i . Consider the Taylor expansion to the point x_{ i \u2212 1 } x_{ i \u2212 1 } , f _ { i - 1 } = f \\left( x _ { i } - \\Delta x \\right) = f \\left( x _ { i } \\right) - \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) f _ { i - 1 } = f \\left( x _ { i } - \\Delta x \\right) = f \\left( x _ { i } \\right) - \\Delta x \\left( \\partial _ { x } f \\right) _ { x _ { i } } + \\frac { ( \\Delta x ) ^ { 2 } } { 2 } \\left( \\partial _ { x } ^ { 2 } f \\right) _ { x _ { i } } + \\mathcal { O } \\left( \\Delta x ^ { 3 } \\right) we now find \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i - 1 } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { f _ { i + 1 } - f _ { i - 1 } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) which is second order in \u2206x \u2206x . In general, centered derivatives lead to higher order schemes than one-sided derivatives for the same number of gridpoints. The key point is that we are able to combine the two Taylor expansions in such a way that the leading order error term cancels out, leaving us with a higher order representation of the derivative . This cancellation only works out for uniform grids , when \u2206x \u2206x is independent of x. This is one of the reasons why many current numerical relativity applications of finite difference schemes work with uniform grids. Higher order derivatives can be constructed in a similar fashion. Adding the two Taylor expansions all terms odd in \u2206x \u2206x drop out and we find for the second derivative \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } } { ( \\Delta x ) ^ { 2 } } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { f _ { i + 1 } - 2 f _ { i } + f _ { i - 1 } } { ( \\Delta x ) ^ { 2 } } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { 1 } { 12 \\Delta x } \\left( f _ { i - 2 } - 8 f _ { i - 1 } + 8 f _ { i + 1 } - f _ { i + 2 } \\right) \\\\ \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { 1 } { 12 ( \\Delta x ) ^ { 2 } } \\left( - f _ { i - 2 } + 16 f _ { i - 1 } - 30 f _ { i } + 16 f _ { i + 1 } - f _ { i + 2 } \\right) \\left( \\partial _ { x } f \\right) _ { i } = \\frac { 1 } { 12 \\Delta x } \\left( f _ { i - 2 } - 8 f _ { i - 1 } + 8 f _ { i + 1 } - f _ { i + 2 } \\right) \\\\ \\left( \\partial _ { x } ^ { 2 } f \\right) _ { i } = \\frac { 1 } { 12 ( \\Delta x ) ^ { 2 } } \\left( - f _ { i - 2 } + 16 f _ { i - 1 } - 30 f _ { i } + 16 f _ { i + 1 } - f _ { i + 2 } \\right) where we have omitted the truncation error, \\mathcal { O } \\left( \\Delta x ^ { 4 } \\right) \\mathcal { O } \\left( \\Delta x ^ { 4 } \\right)","title":"Finite Difference Methods"},{"location":"NR/Numerical Methods/#hyperbolic-equations","text":"For simplicity it does not contain any source terms, and the the wave speed v is constant. \\partial _ { t } u + v \\partial _ { x } u = 0 \\partial _ { t } u + v \\partial _ { x } u = 0 The equation is satisfied exactly by any function of the form u ( t , x ) = u ( x - v t ) u ( t , x ) = u ( x - v t ) . The equation has a time derivative in addition to the space derivative, and thus requires initial data . Inserting both finite-difference representations \\left( \\partial _ { x } u \\right) _ { j } ^ { n } = \\frac { u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\\\ \\left( \\partial _ { t } u \\right) _ { j } ^ { n } = \\frac { u _ { j } ^ { n + 1 } - u _ { j } ^ { n } } { \\Delta t } + \\mathcal { O } ( \\Delta t ) \\left( \\partial _ { x } u \\right) _ { j } ^ { n } = \\frac { u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } } { 2 \\Delta x } + \\mathcal { O } \\left( \\Delta x ^ { 2 } \\right) \\\\ \\left( \\partial _ { t } u \\right) _ { j } ^ { n } = \\frac { u _ { j } ^ { n + 1 } - u _ { j } ^ { n } } { \\Delta t } + \\mathcal { O } ( \\Delta t ) we can solve for u^{n+1}_j u^{n+1}_j and find u _ { j } ^ { n + 1 } = u _ { j } ^ { n } - \\frac { v } { 2 } \\frac { \\Delta t } { \\Delta x } \\left( u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } \\right) u _ { j } ^ { n + 1 } = u _ { j } ^ { n } - \\frac { v } { 2 } \\frac { \\Delta t } { \\Delta x } \\left( u _ { j + 1 } ^ { n } - u _ { j - 1 } ^ { n } \\right) or reasons that are quite obivous this differencing scheme is called forward-time centered-space, or FTCS. It is an example of an explicit scheme, meaning that we can solve for the grid function u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } at the new time level n + 1 directly in terms of function values on the old time level n.","title":"Hyperbolic Equations"},{"location":"NR/Numerical Methods/#courant-friedrichs-lewy-condition","text":"Unfortunately, however, FTCS is fairly useless. The equation is satisfied exactly by any function of the form u ( t , x ) = u ( x - v t ) u ( t , x ) = u ( x - v t ) . we can write the solution u ( t , x ) u ( t , x ) to our continuum hyperbolic differential equation as a superposition of eigenmodes e^{i(\\omega t+k x)} e^{i(\\omega t+k x)} . Here k is a spatial wave number. A real \\omega \\omega , for which e^{i \\omega t} e^{i \\omega t} has a magnitude of unity, yields sinusoidally oscillating modes, while the existence of a complex piece in \\omega \\omega leads to exponentially growing or damping modes. In the case of exponential growth, the magnitude of e^{i \\omega t} e^{i \\omega t} will exceed unity. We can perform a similar spectral analysis of the finite difference equation. Write the eigenmode for u_{j}^{n} u_{j}^{n} as u_{j}^{n}=\\xi^{n} e^{i k(j \\Delta x)} u_{j}^{n}=\\xi^{n} e^{i k(j \\Delta x)} Here the quantity \\xi \\xi plays the role of e^{i \\omega \\Delta t} e^{i \\omega \\Delta t} and is called the amplification factor: u_{j}^{n}=\\xi u_{j}^{n-1} = \\xi^{2} u_{j}^{n-2} \\ldots=\\xi^{n} u_{j}^{0} u_{j}^{n}=\\xi u_{j}^{n-1} = \\xi^{2} u_{j}^{n-2} \\ldots=\\xi^{n} u_{j}^{0} For the scheme to be stable, the magnitude \\xi \\xi must be smaller or equal to unity for all k, |\\xi(k)| \\leq 1 |\\xi(k)| \\leq 1 To perform a von Neumann stability anaylsis of the FTCS scheme \\xi(k)=1-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x \\xi(k)=1-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x the magnitude of \\xi \\xi is greater than unity for all k, indicating that this scheme is unstable. In fact, we have |\\xi|>1 |\\xi|>1 independently of our choice for \\Delta x \\Delta x and \\Delta t \\Delta t , which makes this scheme unconditionally unstable. That is bad. The good news is that there are several ways of fixing this problem. For example We could replace the term u_{j}^{n} u_{j}^{n} by the spatial average \\left(u_{j+1}^{n}+u_{j-1}^{n}\\right) / 2 \\left(u_{j+1}^{n}+u_{j-1}^{n}\\right) / 2 . u_{j}^{n+1}=\\frac{1}{2}\\left(u_{j+1}^{n}+u_{j-1}^{n}\\right)-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n}-u_{j-1}^{n}\\right) u_{j}^{n+1}=\\frac{1}{2}\\left(u_{j+1}^{n}+u_{j-1}^{n}\\right)-\\frac{v}{2} \\frac{\\Delta t}{\\Delta x}\\left(u_{j+1}^{n}-u_{j-1}^{n}\\right) a von Neumann analysis results in the amplification factor \\xi=\\cos k \\Delta x-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x \\xi=\\cos k \\Delta x-i \\frac{v \\Delta t}{\\Delta x} \\sin k \\Delta x The von Neumann stability criterion then implies that we must have \\frac { | v | \\Delta t } { \\Delta x } \\leq 1 \\frac { | v | \\Delta t } { \\Delta x } \\leq 1 The Courant condition states that the the grid point u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } at the new time level n+1 has to reside inside the domain of determinacy of the interval spanned by the finite difference stencil at the time level n. This makes intuitive sense: if u _ { j } ^ { n + 1 } u _ { j } ^ { n + 1 } were outside this domain, its physical specification would require more information about the past than we are providing numerically, which may trigger an instability. Recalling that v represents the speed of a characteristic, we may interpret the Courant condition in terms of the domain of determinacy.","title":"Courant-Friedrichs-Lewy condition"},{"location":"SP/Introduction/","text":"These detections required technically sophisticated analysis pipelines to reduce the strain data. This is because typical events are buried under the detector noise, and cannot be simply \u201cseen\u201d in raw data at current sensitivities. Hence, any search for signals in the data needs to properly and precisely model the detector noise.","title":"Introduction"},{"location":"SP/matched filter/","text":"Let h be the gravitational-wave signal we are looking for and let \ud835\udc5b be the detector\u2019s noise. For convenience we assume that the signal h is a continuous function of time \ud835\udc61 and that the noise \ud835\udc5b is a continuous random process. Assuming that the noise is additive the data x x can be written as x(t)=n(t)+h(t) x(t)=n(t)+h(t)","title":"Matched Filtering"}]}